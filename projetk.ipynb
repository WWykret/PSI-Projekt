{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"mymoviedb.csv\", lineterminator=\"\\n\")\n",
    "movies.drop(movies[movies[\"Vote_Count\"] == 0].index,\n",
    "            inplace=True)  # usun filmy z przyszlosci\n",
    "movies.drop([\"Overview\", \"Popularity\", \"Vote_Count\",\n",
    "            \"Poster_Url\"], axis=1, inplace=True)\n",
    "\n",
    "X = movies.drop(\"Vote_Average\", axis=1)\n",
    "y = movies[\"Vote_Average\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42)\n",
    "kFold = KFold(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "simple_cat_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector([\"Original_Language\"])),\n",
    "    (\"imputer\", MostFrequentImputer()),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "simple_cat_pipeline.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class DateEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        cols = []\n",
    "        for col_name in X.columns:\n",
    "            cols.append(X[col_name].map(\n",
    "                lambda x: datetime.strptime(x, \"%Y-%m-%d\").year))\n",
    "            cols.append(X[col_name].map(\n",
    "                lambda x: datetime.strptime(x, \"%Y-%m-%d\").month))\n",
    "        return np.c_[cols].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2015,    1],\n",
       "       [2005,    9],\n",
       "       [1992,    4],\n",
       "       ...,\n",
       "       [1983,    7],\n",
       "       [2015,    7],\n",
       "       [2007,    3]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_pipeline = Pipeline([\n",
    "    (\"select_date\", DataFrameSelector([\"Release_Date\"])),\n",
    "    (\"imputer\", MostFrequentImputer()),\n",
    "    (\"date_encoder\", DateEncoder()),\n",
    "])\n",
    "\n",
    "date_pipeline.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None, delimeter=\",\"):\n",
    "        self.genres = {}\n",
    "        for col in X.columns:\n",
    "            self.genres[col] = set()\n",
    "            for index, row in X.iterrows():\n",
    "                self.genres[col] |= set(\n",
    "                    map(lambda x: x.strip(), row[col].split(delimeter)))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        encoded = []\n",
    "        for col, curr_genres in self.genres.items():\n",
    "            for genre in curr_genres:\n",
    "                encoded.append(X[col].str.contains(genre).astype(int))\n",
    "        return np.c_[encoded].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 1],\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_pipeline = Pipeline([\n",
    "    (\"select_genre\", DataFrameSelector([\"Genre\"])),\n",
    "    (\"imputer\", MostFrequentImputer()),\n",
    "    (\"genre_encoder\", GenreEncoder()),\n",
    "])\n",
    "\n",
    "genre_pipeline.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class TitleEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.genres = {}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        encoded = []\n",
    "        for col in X.columns:\n",
    "            encoded.append(X[\"Title\"].map(lambda x: bool(\n",
    "                re.search(r'\\d', x))).astype(int))  # cyfry w tytule\n",
    "            # ilosc slow w tytule\n",
    "            encoded.append(X[\"Title\"].map(lambda x: len(x.split())))\n",
    "            encoded.append(X[\"Title\"].str.contains(\n",
    "                \":\").astype(int))  # dwukropek w tytule\n",
    "            encoded.append(X[\"Title\"].str.contains(\n",
    "                \"-\").astype(int))  # pauza w tytule\n",
    "\n",
    "        return np.c_[encoded].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0, 0],\n",
       "       [0, 4, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, 0],\n",
       "       [0, 5, 1, 0],\n",
       "       [0, 5, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_pipeline = Pipeline([\n",
    "    (\"select_title\", DataFrameSelector([\"Title\"])),\n",
    "    (\"imputer\", MostFrequentImputer()),\n",
    "    (\"title_encoder\", TitleEncoder()),\n",
    "])\n",
    "\n",
    "title_pipeline.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"simple_cat_pipeline\", simple_cat_pipeline),\n",
    "    (\"date_pipeline\", date_pipeline),\n",
    "    (\"genre_pipeline\", genre_pipeline),\n",
    "    (\"title_pipeline\", title_pipeline),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8754, 66)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pipeline.transform(X_train).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.065e+01, tolerance: 6.013e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.988e-01, tolerance: 6.053e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.706e+00, tolerance: 6.013e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+02, tolerance: 6.025e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.390e+01, tolerance: 6.060e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+02, tolerance: 6.053e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+02, tolerance: 6.021e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e+01, tolerance: 6.013e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.770e-01, tolerance: 6.053e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.709e+00, tolerance: 6.013e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'regressor__alpha': 0.001, 'scaler': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "ElasticNet_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocess_pipeline),\n",
    "    (\"scaler\", None),\n",
    "    (\"regressor\", ElasticNet())\n",
    "])\n",
    "\n",
    "ElasticNet_param_grid = {\n",
    "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "    \"regressor__alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(estimator=ElasticNet_pipeline,\n",
    "                      param_grid=ElasticNet_param_grid, scoring=\"r2\", cv=kFold)\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SVR RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__C': 1, 'regressor__gamma': 0.01}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "SVR_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocess_pipeline),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"regressor\", SVR(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "SVR_param_grid = {\n",
    "    \"regressor__C\": [0.01, 0.1, 1, 10, 100, 1000],\n",
    "    \"regressor__gamma\": [0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(estimator=SVR_pipeline,\n",
    "                      param_grid=SVR_param_grid, scoring=\"r2\", cv=kFold)\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Drzewo decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__criterion': 'friedman_mse',\n",
       " 'regressor__max_depth': 5,\n",
       " 'regressor__max_features': None,\n",
       " 'scaler': MinMaxScaler()}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DecisionTree_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocess_pipeline),\n",
    "    (\"scaler\", None),\n",
    "    (\"regressor\", DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "DecisionTree_param_grid = {\n",
    "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "    \"regressor__max_depth\": [None, 1, 2, 3, 4, 5],\n",
    "    \"regressor__max_features\": [None, \"auto\", \"sqrt\", \"log2\"],\n",
    "    \"regressor__criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(estimator=DecisionTree_pipeline,\n",
    "                      param_grid=DecisionTree_param_grid, scoring=\"r2\", cv=kFold)\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Liniowy SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'regressor__C': 0.1, 'scaler': MinMaxScaler()}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "LinearSVR_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocess_pipeline),\n",
    "    (\"scaler\", None),\n",
    "    (\"regressor\", LinearSVR())\n",
    "])\n",
    "\n",
    "LinearSVR_param_grid = {\n",
    "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "    \"regressor__C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "grid_4 = GridSearchCV(estimator=LinearSVR_pipeline,\n",
    "                      param_grid=LinearSVR_param_grid, scoring=\"r2\", cv=kFold)\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Regresja Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.153e+01, tolerance: 6.013e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+02, tolerance: 6.025e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.462e+01, tolerance: 6.060e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+02, tolerance: 6.053e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.425e+02, tolerance: 6.021e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'regressor__alpha': 0.001, 'scaler': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "Lasso_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocess_pipeline),\n",
    "    (\"scaler\", None),\n",
    "    (\"regressor\", Lasso())\n",
    "])\n",
    "\n",
    "Lasso_param_grid = {\n",
    "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
    "    \"regressor__alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "grid_5 = GridSearchCV(estimator=Lasso_pipeline,\n",
    "                      param_grid=Lasso_param_grid, scoring=\"r2\", cv=kFold)\n",
    "grid_5.fit(X_train, y_train)\n",
    "grid_5.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Porównanie płytkich modeli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>training score (r2)</th>\n",
       "      <th>test score (r2)</th>\n",
       "      <th>test score (mean squared error)</th>\n",
       "      <th>test score (max error)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.197765</td>\n",
       "      <td>0.206276</td>\n",
       "      <td>0.659564</td>\n",
       "      <td>4.374816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.229291</td>\n",
       "      <td>0.245390</td>\n",
       "      <td>0.627062</td>\n",
       "      <td>4.841273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.177988</td>\n",
       "      <td>0.174545</td>\n",
       "      <td>0.685932</td>\n",
       "      <td>4.215801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVR</td>\n",
       "      <td>0.190244</td>\n",
       "      <td>0.197078</td>\n",
       "      <td>0.667208</td>\n",
       "      <td>4.436693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.197216</td>\n",
       "      <td>0.204051</td>\n",
       "      <td>0.661413</td>\n",
       "      <td>4.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model name  training score (r2)  test score (r2)  \\\n",
       "0     ElasticNet             0.197765         0.206276   \n",
       "1            SVR             0.229291         0.245390   \n",
       "2  Decision Tree             0.177988         0.174545   \n",
       "3     Linear SVR             0.190244         0.197078   \n",
       "4          Lasso             0.197216         0.204051   \n",
       "\n",
       "   test score (mean squared error)  test score (max error)  \n",
       "0                         0.659564                4.374816  \n",
       "1                         0.627062                4.841273  \n",
       "2                         0.685932                4.215801  \n",
       "3                         0.667208                4.436693  \n",
       "4                         0.661413                4.375000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, max_error\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append((\"ElasticNet\", grid_1.best_score_, grid_1.best_estimator_))\n",
    "models.append((\"SVR\", grid_2.best_score_, grid_2.best_estimator_))\n",
    "models.append((\"Decision Tree\", grid_3.best_score_, grid_3.best_estimator_))\n",
    "models.append((\"Linear SVR\", grid_4.best_score_, grid_4.best_estimator_))\n",
    "models.append((\"Lasso\", grid_5.best_score_, grid_5.best_estimator_))\n",
    "\n",
    "names = []\n",
    "scores_train = []\n",
    "scores_test_r2 = []\n",
    "scores_test_mse = []\n",
    "scores_test_me = []\n",
    "\n",
    "for name, train_score, estimator in models:\n",
    "    names.append(name)\n",
    "    scores_train.append(train_score)\n",
    "\n",
    "    r2_test_score = r2_score(y_test, estimator.predict(X_test))\n",
    "    scores_test_r2.append(r2_test_score)\n",
    "\n",
    "    mse_test_score = mean_squared_error(y_test, estimator.predict(X_test))\n",
    "    scores_test_mse.append(mse_test_score)\n",
    "\n",
    "    me_test_score = max_error(y_test, estimator.predict(X_test))\n",
    "    scores_test_me.append(me_test_score)\n",
    "\n",
    "\n",
    "model_data = {\n",
    "    \"model name\": names,\n",
    "    \"training score (r2)\": scores_train,\n",
    "    \"test score (r2)\": scores_test_r2,\n",
    "    \"test score (mean squared error)\": scores_test_mse,\n",
    "    \"test score (max error)\": scores_test_me\n",
    "}\n",
    "table = pd.DataFrame(model_data)\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modele głębokie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8754, 66)\n",
      "(973, 66)\n"
     ]
    }
   ],
   "source": [
    "X_train_preprocessed = preprocess_pipeline.transform(X_train)\n",
    "X_test_preprocessed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_preprocessed)\n",
    "\n",
    "X_train_keras = scaler.transform(X_train_preprocessed)\n",
    "X_test_keras = scaler.transform(X_test_preprocessed)\n",
    "\n",
    "print(X_train_keras.shape)\n",
    "print(X_test_keras.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def keras_r2(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true-y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, activation=\"relu\", learning_rate=3e-3, input_shape=[66,]):\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation=\"relu\"))\n",
    "    # optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\", metrics=[keras_r2])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13176\\3463659828.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasClassifier at 0x175d8668250>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "keras_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Karas Randomized Search CV (liczba warstw + liczba neuronów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1576.7817 - keras_r2: -21.2653 - val_loss: 1056.6931 - val_keras_r2: -13.0870\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 446.9236 - keras_r2: -6.6031 - val_loss: 143.4822 - val_keras_r2: -0.8035\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 116.8785 - keras_r2: -1.4209 - val_loss: 107.9671 - val_keras_r2: -0.3156\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 96.8893 - keras_r2: -0.3854 - val_loss: 99.3815 - val_keras_r2: -0.1977\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 88.5856 - keras_r2: -0.1137 - val_loss: 95.1601 - val_keras_r2: -0.1397\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 83.1728 - keras_r2: -0.0463 - val_loss: 92.9270 - val_keras_r2: -0.1104\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 79.4646 - keras_r2: -0.0090 - val_loss: 90.6852 - val_keras_r2: -0.0817\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 76.6060 - keras_r2: 0.0433 - val_loss: 89.0787 - val_keras_r2: -0.0610\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 74.2667 - keras_r2: 0.0863 - val_loss: 87.4583 - val_keras_r2: -0.0395\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 72.3754 - keras_r2: 0.0907 - val_loss: 85.9488 - val_keras_r2: -0.0222\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 70.7048 - keras_r2: 0.1130 - val_loss: 85.2424 - val_keras_r2: -0.0124\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 69.3910 - keras_r2: 0.1224 - val_loss: 84.4311 - val_keras_r2: -5.8137e-04\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 68.2787 - keras_r2: 0.1576 - val_loss: 83.2630 - val_keras_r2: 0.0123\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 67.4466 - keras_r2: 0.1034 - val_loss: 83.1716 - val_keras_r2: 0.0128\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.7063 - keras_r2: 0.1809 - val_loss: 82.3221 - val_keras_r2: 0.0236\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.2727 - keras_r2: 0.1761 - val_loss: 81.6818 - val_keras_r2: 0.0340\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 65.6192 - keras_r2: 0.1456 - val_loss: 81.2845 - val_keras_r2: 0.0337\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 65.0115 - keras_r2: 0.1723 - val_loss: 80.5334 - val_keras_r2: 0.0446\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 64.6761 - keras_r2: 0.2042 - val_loss: 80.6156 - val_keras_r2: 0.0427\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 64.0099 - keras_r2: 0.2054 - val_loss: 80.4226 - val_keras_r2: 0.0437\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.8188 - keras_r2: 0.2197 - val_loss: 79.5459 - val_keras_r2: 0.0559\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.4737 - keras_r2: 0.2124 - val_loss: 79.0174 - val_keras_r2: 0.0613\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 63.2727 - keras_r2: 0.1566 - val_loss: 79.1209 - val_keras_r2: 0.0631\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 62.9045 - keras_r2: 0.2076 - val_loss: 78.2266 - val_keras_r2: 0.0705\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 62.8695 - keras_r2: 0.2210 - val_loss: 78.5169 - val_keras_r2: 0.0695\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 62.4174 - keras_r2: 0.2005 - val_loss: 78.3553 - val_keras_r2: 0.0671\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 62.4024 - keras_r2: 0.2301 - val_loss: 77.9297 - val_keras_r2: 0.0767\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.0962 - keras_r2: 0.2370 - val_loss: 77.4527 - val_keras_r2: 0.0824\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.8959 - keras_r2: 0.2480 - val_loss: 77.4313 - val_keras_r2: 0.0788\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.9978 - keras_r2: 0.2297 - val_loss: 77.8355 - val_keras_r2: 0.0763\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.6098 - keras_r2: 0.2281 - val_loss: 77.7072 - val_keras_r2: 0.0787\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 61.4601 - keras_r2: 0.1879 - val_loss: 77.8558 - val_keras_r2: 0.0774\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.3539 - keras_r2: -1.1387 - val_loss: 77.3974 - val_keras_r2: 0.0814\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 61.1335 - keras_r2: 0.2396 - val_loss: 77.9068 - val_keras_r2: 0.0776\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.9583 - keras_r2: 0.2512 - val_loss: 77.7469 - val_keras_r2: 0.0768\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.0468 - keras_r2: 0.2509 - val_loss: 77.7494 - val_keras_r2: 0.0784\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.7977 - keras_r2: 0.2450 - val_loss: 77.4489 - val_keras_r2: 0.0779\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.8914 - keras_r2: 0.2398 - val_loss: 77.5501 - val_keras_r2: 0.0776\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6549 - keras_r2: 0.1767 - val_loss: 77.0280 - val_keras_r2: 0.0867\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.4656 - keras_r2: -0.0954 - val_loss: 77.0787 - val_keras_r2: 0.0862\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.4122 - keras_r2: 0.2645 - val_loss: 77.0453 - val_keras_r2: 0.0866\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1908 - keras_r2: 0.2412 - val_loss: 77.0580 - val_keras_r2: 0.0840\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.1618 - keras_r2: 0.2618 - val_loss: 77.4295 - val_keras_r2: 0.0839\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.0860 - keras_r2: 0.2369 - val_loss: 76.6585 - val_keras_r2: 0.0914\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.9217 - keras_r2: 0.2481 - val_loss: 76.4626 - val_keras_r2: 0.0923\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.9005 - keras_r2: 0.2597 - val_loss: 76.8324 - val_keras_r2: 0.0883\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8727 - keras_r2: 0.2509 - val_loss: 77.4477 - val_keras_r2: 0.0821\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7392 - keras_r2: 0.0792 - val_loss: 77.7509 - val_keras_r2: 0.0784\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7954 - keras_r2: 0.2574 - val_loss: 76.8369 - val_keras_r2: 0.0897\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.6344 - keras_r2: 0.2638 - val_loss: 76.5677 - val_keras_r2: 0.0888\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.6271 - keras_r2: -1493402.6250 - val_loss: 76.6911 - val_keras_r2: 0.0906\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.5065 - keras_r2: 0.2708 - val_loss: 76.7159 - val_keras_r2: 0.0911\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.5885 - keras_r2: -2557695.0000 - val_loss: 76.1880 - val_keras_r2: 0.0965\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.3724 - keras_r2: 0.1084 - val_loss: 76.6472 - val_keras_r2: 0.0902\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.3636 - keras_r2: 0.1977 - val_loss: 76.3375 - val_keras_r2: 0.0957\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.2387 - keras_r2: 0.2533 - val_loss: 76.9770 - val_keras_r2: 0.0841\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.3843 - keras_r2: 0.2594 - val_loss: 76.5996 - val_keras_r2: 0.0915\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.1807 - keras_r2: 0.2709 - val_loss: 76.8503 - val_keras_r2: 0.0888\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.2200 - keras_r2: 0.2558 - val_loss: 76.8321 - val_keras_r2: 0.0900\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.1805 - keras_r2: 0.2766 - val_loss: 76.6552 - val_keras_r2: 0.0899\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.2490 - keras_r2: 0.2728 - val_loss: 76.3554 - val_keras_r2: 0.0946\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.0044 - keras_r2: 0.2667 - val_loss: 76.8335 - val_keras_r2: 0.0900\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 58.8808 - keras_r2: 0.1347 - val_loss: 76.3807 - val_keras_r2: 0.0934\n",
      "Epoch 63: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=12; total time=  33.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1609.0544 - keras_r2: -48.3284 - val_loss: 1166.4254 - val_keras_r2: -14.6171\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 525.6523 - keras_r2: -6.0229 - val_loss: 141.1813 - val_keras_r2: -0.7605\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 115.9259 - keras_r2: -0.4421 - val_loss: 105.7642 - val_keras_r2: -0.2802\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 96.8440 - keras_r2: -0.2655 - val_loss: 99.3160 - val_keras_r2: -0.1929\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 89.1476 - keras_r2: -0.3267 - val_loss: 95.3000 - val_keras_r2: -0.1406\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 84.2127 - keras_r2: -0.0872 - val_loss: 92.2716 - val_keras_r2: -0.1006\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 80.5004 - keras_r2: -0.6698 - val_loss: 90.1256 - val_keras_r2: -0.0731\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 77.5974 - keras_r2: -0.0523 - val_loss: 87.9583 - val_keras_r2: -0.0479\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 75.3642 - keras_r2: 0.0626 - val_loss: 86.4688 - val_keras_r2: -0.0279\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 73.6111 - keras_r2: -0.0155 - val_loss: 85.0177 - val_keras_r2: -0.0082\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 71.9563 - keras_r2: 0.0913 - val_loss: 83.9835 - val_keras_r2: 0.0037\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 70.6862 - keras_r2: 0.1025 - val_loss: 83.2881 - val_keras_r2: 0.0135\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 69.7663 - keras_r2: 0.1371 - val_loss: 82.7672 - val_keras_r2: 0.0202\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 68.7759 - keras_r2: 0.1346 - val_loss: 82.0657 - val_keras_r2: 0.0247\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 68.0932 - keras_r2: 0.1016 - val_loss: 80.8506 - val_keras_r2: 0.0416\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 67.4238 - keras_r2: 0.1288 - val_loss: 80.1482 - val_keras_r2: 0.0521\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.8923 - keras_r2: 0.1773 - val_loss: 80.0816 - val_keras_r2: 0.0536\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.4509 - keras_r2: 0.0945 - val_loss: 79.7521 - val_keras_r2: 0.0542\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.1151 - keras_r2: 0.1528 - val_loss: 79.9361 - val_keras_r2: 0.0516\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 65.5914 - keras_r2: 0.1910 - val_loss: 79.0628 - val_keras_r2: 0.0641\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 65.2169 - keras_r2: 0.2008 - val_loss: 78.9011 - val_keras_r2: 0.0681\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 65.0874 - keras_r2: -4429364.5000 - val_loss: 78.5477 - val_keras_r2: 0.0703\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.7423 - keras_r2: 0.2086 - val_loss: 78.0408 - val_keras_r2: 0.0747\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 64.4434 - keras_r2: 0.2067 - val_loss: 78.5755 - val_keras_r2: 0.0667\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.1745 - keras_r2: 0.2061 - val_loss: 77.5209 - val_keras_r2: 0.0815\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.9284 - keras_r2: 0.2236 - val_loss: 77.5482 - val_keras_r2: 0.0814\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.6406 - keras_r2: -4979819.5000 - val_loss: 78.0194 - val_keras_r2: 0.0751\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.5010 - keras_r2: 0.2245 - val_loss: 77.6950 - val_keras_r2: 0.0805\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.3713 - keras_r2: 0.2232 - val_loss: 77.5019 - val_keras_r2: 0.0785\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.1721 - keras_r2: 0.2148 - val_loss: 77.4425 - val_keras_r2: 0.0845\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.9171 - keras_r2: 0.2295 - val_loss: 76.7077 - val_keras_r2: 0.0924\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.7113 - keras_r2: 0.2314 - val_loss: 77.8862 - val_keras_r2: 0.0751\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.6339 - keras_r2: 0.2140 - val_loss: 76.9062 - val_keras_r2: 0.0895\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.6478 - keras_r2: -1681551.1250 - val_loss: 76.4448 - val_keras_r2: 0.0946\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.2441 - keras_r2: -0.4201 - val_loss: 77.2256 - val_keras_r2: 0.0846\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.2506 - keras_r2: 0.1646 - val_loss: 76.4568 - val_keras_r2: 0.0944\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.0799 - keras_r2: 0.2403 - val_loss: 76.3382 - val_keras_r2: 0.0945\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.9290 - keras_r2: 0.2249 - val_loss: 76.7026 - val_keras_r2: 0.0878\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 61.7817 - keras_r2: 0.2323 - val_loss: 76.4598 - val_keras_r2: 0.0962\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.6942 - keras_r2: 0.2398 - val_loss: 76.3119 - val_keras_r2: 0.0949\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.4930 - keras_r2: 0.2428 - val_loss: 76.2759 - val_keras_r2: 0.0958\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.4066 - keras_r2: 0.2534 - val_loss: 76.4176 - val_keras_r2: 0.0932\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.2640 - keras_r2: 0.2098 - val_loss: 76.6514 - val_keras_r2: 0.0925\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.2748 - keras_r2: 0.2425 - val_loss: 76.4621 - val_keras_r2: 0.0953\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.0015 - keras_r2: -0.2071 - val_loss: 76.6423 - val_keras_r2: 0.0931\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.1476 - keras_r2: 0.2517 - val_loss: 76.7918 - val_keras_r2: 0.0909\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.8848 - keras_r2: 0.2493 - val_loss: 76.5187 - val_keras_r2: 0.0896\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.7546 - keras_r2: 0.2565 - val_loss: 76.4449 - val_keras_r2: 0.0955\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6962 - keras_r2: 0.2532 - val_loss: 76.5854 - val_keras_r2: 0.0917\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.4911 - keras_r2: 0.2185 - val_loss: 75.7057 - val_keras_r2: 0.1027\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.5391 - keras_r2: 0.2498 - val_loss: 76.1902 - val_keras_r2: 0.0945\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.5237 - keras_r2: 0.2552 - val_loss: 75.9933 - val_keras_r2: 0.0981\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.3918 - keras_r2: 0.2507 - val_loss: 76.1677 - val_keras_r2: 0.0980\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.2446 - keras_r2: 0.2505 - val_loss: 76.3545 - val_keras_r2: 0.0930\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.1866 - keras_r2: -2892399.5000 - val_loss: 75.8669 - val_keras_r2: 0.1004\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.1904 - keras_r2: 0.0209 - val_loss: 75.3971 - val_keras_r2: 0.1060\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.0101 - keras_r2: 0.2701 - val_loss: 76.1999 - val_keras_r2: 0.0983\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.1798 - keras_r2: -22486992.0000 - val_loss: 76.0840 - val_keras_r2: 0.0981\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.0942 - keras_r2: 0.2598 - val_loss: 75.7334 - val_keras_r2: 0.0979\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.8496 - keras_r2: 0.2680 - val_loss: 76.4523 - val_keras_r2: 0.0938\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7567 - keras_r2: 0.2626 - val_loss: 76.3570 - val_keras_r2: 0.0947\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.7617 - keras_r2: 0.2607 - val_loss: 76.0335 - val_keras_r2: 0.0976\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.6412 - keras_r2: 0.2672 - val_loss: 75.7519 - val_keras_r2: 0.1019\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.5426 - keras_r2: 0.2702 - val_loss: 76.2776 - val_keras_r2: 0.0962\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.5331 - keras_r2: 0.2529 - val_loss: 76.3843 - val_keras_r2: 0.0944\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.6693 - keras_r2: 0.2587 - val_loss: 76.3813 - val_keras_r2: 0.0926\n",
      "Epoch 66: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=12; total time=  31.9s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1729.8467 - keras_r2: -21.5329 - val_loss: 1233.6809 - val_keras_r2: -15.4839\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 590.2877 - keras_r2: -6.7345 - val_loss: 169.7913 - val_keras_r2: -1.1585\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 125.9520 - keras_r2: -1.5384 - val_loss: 108.5375 - val_keras_r2: -0.3225\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 96.3370 - keras_r2: -0.1992 - val_loss: 99.2015 - val_keras_r2: -0.1951\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 86.5518 - keras_r2: -0.3859 - val_loss: 94.3930 - val_keras_r2: -0.1297\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 81.0768 - keras_r2: -0.0166 - val_loss: 91.9156 - val_keras_r2: -0.1007\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 77.3495 - keras_r2: 0.0356 - val_loss: 89.9127 - val_keras_r2: -0.0731\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 74.7872 - keras_r2: 0.0532 - val_loss: 87.6425 - val_keras_r2: -0.0436\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 72.8713 - keras_r2: 0.0936 - val_loss: 86.2499 - val_keras_r2: -0.0282\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 71.2775 - keras_r2: 0.0840 - val_loss: 85.5750 - val_keras_r2: -0.0203\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 70.1153 - keras_r2: 0.1333 - val_loss: 84.4431 - val_keras_r2: -0.0047\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 68.9565 - keras_r2: 0.0874 - val_loss: 83.4821 - val_keras_r2: 0.0073\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 68.0591 - keras_r2: 0.1102 - val_loss: 82.3260 - val_keras_r2: 0.0206\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 67.1560 - keras_r2: -1.2672 - val_loss: 82.0453 - val_keras_r2: 0.0253\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.5256 - keras_r2: 0.1212 - val_loss: 81.4690 - val_keras_r2: 0.0317\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.0795 - keras_r2: 0.1824 - val_loss: 80.6512 - val_keras_r2: 0.0409\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 65.4393 - keras_r2: 0.1967 - val_loss: 81.3393 - val_keras_r2: 0.0329\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 65.0606 - keras_r2: 0.2011 - val_loss: 79.9696 - val_keras_r2: 0.0516\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.6375 - keras_r2: 0.1821 - val_loss: 80.1071 - val_keras_r2: 0.0492\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 64.4711 - keras_r2: -1.7068 - val_loss: 80.2972 - val_keras_r2: 0.0488\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.8257 - keras_r2: 0.2068 - val_loss: 79.1154 - val_keras_r2: 0.0600\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.6178 - keras_r2: 0.1601 - val_loss: 79.0611 - val_keras_r2: 0.0612\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.2532 - keras_r2: 0.2323 - val_loss: 79.5134 - val_keras_r2: 0.0603\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 63.1765 - keras_r2: 0.2239 - val_loss: 78.5304 - val_keras_r2: 0.0689\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.9707 - keras_r2: -0.2323 - val_loss: 78.6407 - val_keras_r2: 0.0688\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.7664 - keras_r2: 0.1780 - val_loss: 78.4200 - val_keras_r2: 0.0703\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.4523 - keras_r2: 0.2296 - val_loss: 78.4964 - val_keras_r2: 0.0694\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.5928 - keras_r2: -1.0332 - val_loss: 78.5119 - val_keras_r2: 0.0710\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.0961 - keras_r2: 0.2485 - val_loss: 78.1397 - val_keras_r2: 0.0746\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.0133 - keras_r2: 0.2394 - val_loss: 78.8340 - val_keras_r2: 0.0666\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.8144 - keras_r2: 0.2243 - val_loss: 77.7228 - val_keras_r2: 0.0797\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.7612 - keras_r2: 0.2526 - val_loss: 78.0816 - val_keras_r2: 0.0737\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.6245 - keras_r2: -0.7026 - val_loss: 77.3783 - val_keras_r2: 0.0828\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.4624 - keras_r2: 0.2316 - val_loss: 78.1014 - val_keras_r2: 0.0711\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 61.9502 - keras_r2: 0.2507 - val_loss: 77.9989 - val_keras_r2: 0.0750\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.2169 - keras_r2: 0.0715 - val_loss: 77.4688 - val_keras_r2: 0.0802\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.0757 - keras_r2: 0.2681 - val_loss: 77.4684 - val_keras_r2: 0.0809\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.0551 - keras_r2: -4214801.0000 - val_loss: 76.8963 - val_keras_r2: 0.0903\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.1058 - keras_r2: 0.2418 - val_loss: 77.1598 - val_keras_r2: 0.0878\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.7362 - keras_r2: 0.2538 - val_loss: 77.5494 - val_keras_r2: 0.0813\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.8054 - keras_r2: 0.2485 - val_loss: 77.3702 - val_keras_r2: 0.0832\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.6876 - keras_r2: 0.2585 - val_loss: 77.1525 - val_keras_r2: 0.0864\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.4741 - keras_r2: 0.1707 - val_loss: 77.2070 - val_keras_r2: 0.0850\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 60.4902 - keras_r2: 0.2576 - val_loss: 78.2720 - val_keras_r2: 0.0748\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.3272 - keras_r2: 0.2652 - val_loss: 77.6560 - val_keras_r2: 0.0799\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.3521 - keras_r2: 0.2713 - val_loss: 77.1203 - val_keras_r2: 0.0865\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.2162 - keras_r2: -0.4333 - val_loss: 77.6522 - val_keras_r2: 0.0809\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1408 - keras_r2: 0.2565 - val_loss: 76.4424 - val_keras_r2: 0.0954\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1085 - keras_r2: 0.2727 - val_loss: 76.6227 - val_keras_r2: 0.0953\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.0714 - keras_r2: 0.2641 - val_loss: 76.9475 - val_keras_r2: 0.0881\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.0072 - keras_r2: 0.2697 - val_loss: 77.5778 - val_keras_r2: 0.0792\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.9273 - keras_r2: 0.2634 - val_loss: 77.3163 - val_keras_r2: 0.0819\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.8664 - keras_r2: 0.2439 - val_loss: 76.5148 - val_keras_r2: 0.0916\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7292 - keras_r2: 0.2690 - val_loss: 76.4858 - val_keras_r2: 0.0915\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7014 - keras_r2: 0.2617 - val_loss: 76.7079 - val_keras_r2: 0.0923\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7458 - keras_r2: 0.2783 - val_loss: 76.9989 - val_keras_r2: 0.0896\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.5024 - keras_r2: 0.2792 - val_loss: 77.0874 - val_keras_r2: 0.0873\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.4553 - keras_r2: 0.2473 - val_loss: 77.0462 - val_keras_r2: 0.0885\n",
      "Epoch 58: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=12; total time=  28.1s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1768.0413 - keras_r2: -22.7551 - val_loss: 1459.4922 - val_keras_r2: -18.4503\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 835.2267 - keras_r2: -10.3517 - val_loss: 287.5580 - val_keras_r2: -2.7619\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 142.6351 - keras_r2: -0.8405 - val_loss: 108.6856 - val_keras_r2: -0.3391\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 92.2166 - keras_r2: -0.1396 - val_loss: 97.4458 - val_keras_r2: -0.1829\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 83.9166 - keras_r2: -0.1390 - val_loss: 93.1740 - val_keras_r2: -0.1224\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 79.6044 - keras_r2: 0.0100 - val_loss: 90.7872 - val_keras_r2: -0.0891\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 76.6722 - keras_r2: 0.0686 - val_loss: 89.1779 - val_keras_r2: -0.0682\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 74.4742 - keras_r2: 0.0868 - val_loss: 87.3628 - val_keras_r2: -0.0439\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 72.7914 - keras_r2: 0.1162 - val_loss: 86.5071 - val_keras_r2: -0.0344\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 71.4322 - keras_r2: 0.1201 - val_loss: 85.3647 - val_keras_r2: -0.0180\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 70.2757 - keras_r2: 0.1403 - val_loss: 84.7378 - val_keras_r2: -0.0093\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 69.3031 - keras_r2: 0.1468 - val_loss: 83.6354 - val_keras_r2: 0.0044\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 68.4269 - keras_r2: 0.1440 - val_loss: 82.7183 - val_keras_r2: 0.0180\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 67.7479 - keras_r2: 0.1731 - val_loss: 82.1658 - val_keras_r2: 0.0242\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 67.1949 - keras_r2: 0.1816 - val_loss: 82.0314 - val_keras_r2: 0.0253\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.6353 - keras_r2: 0.1889 - val_loss: 80.8349 - val_keras_r2: 0.0405\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.1111 - keras_r2: -0.2024 - val_loss: 80.6146 - val_keras_r2: 0.0445\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.6892 - keras_r2: 0.0844 - val_loss: 79.7306 - val_keras_r2: 0.0553\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 65.2508 - keras_r2: 0.2143 - val_loss: 79.3914 - val_keras_r2: 0.0605\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.7998 - keras_r2: 0.2028 - val_loss: 79.0478 - val_keras_r2: 0.0650\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.6160 - keras_r2: 0.2050 - val_loss: 78.3367 - val_keras_r2: 0.0734\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.3092 - keras_r2: -0.1185 - val_loss: 78.0227 - val_keras_r2: 0.0784\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.0589 - keras_r2: 0.2188 - val_loss: 77.8021 - val_keras_r2: 0.0812\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.7014 - keras_r2: 0.2230 - val_loss: 77.3534 - val_keras_r2: 0.0855\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.4530 - keras_r2: 0.2283 - val_loss: 77.4735 - val_keras_r2: 0.0820\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.2492 - keras_r2: 0.2304 - val_loss: 77.4758 - val_keras_r2: 0.0827\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.1079 - keras_r2: 0.1844 - val_loss: 77.0394 - val_keras_r2: 0.0891\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.8194 - keras_r2: 0.2268 - val_loss: 76.8469 - val_keras_r2: 0.0931\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 62.8118 - keras_r2: -0.8587 - val_loss: 77.0044 - val_keras_r2: 0.0907\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.5979 - keras_r2: 0.2368 - val_loss: 76.9204 - val_keras_r2: 0.0919\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.4714 - keras_r2: 0.2357 - val_loss: 76.8749 - val_keras_r2: 0.0908\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.3445 - keras_r2: 0.2270 - val_loss: 76.7330 - val_keras_r2: 0.0926\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 62.0841 - keras_r2: 0.2377 - val_loss: 76.3290 - val_keras_r2: 0.0970\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.9991 - keras_r2: -1046861.3750 - val_loss: 76.3790 - val_keras_r2: 0.0975\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.7552 - keras_r2: 0.1829 - val_loss: 76.0878 - val_keras_r2: 0.0996\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.7746 - keras_r2: 0.2490 - val_loss: 76.0663 - val_keras_r2: 0.0988\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.4792 - keras_r2: 0.2009 - val_loss: 75.8991 - val_keras_r2: 0.1005\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.4572 - keras_r2: 0.2523 - val_loss: 76.1330 - val_keras_r2: 0.0998\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.3566 - keras_r2: 0.2139 - val_loss: 75.6184 - val_keras_r2: 0.1043\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 61.2229 - keras_r2: 0.2573 - val_loss: 76.2913 - val_keras_r2: 0.0969\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.9955 - keras_r2: 0.2461 - val_loss: 76.5172 - val_keras_r2: 0.0959\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.0472 - keras_r2: 0.2523 - val_loss: 76.0672 - val_keras_r2: 0.1006\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.8681 - keras_r2: 0.2566 - val_loss: 76.1522 - val_keras_r2: 0.1009\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.8213 - keras_r2: 0.2492 - val_loss: 75.9922 - val_keras_r2: 0.0990\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.8682 - keras_r2: 0.2618 - val_loss: 75.6139 - val_keras_r2: 0.1044\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.6455 - keras_r2: 0.2608 - val_loss: 75.6446 - val_keras_r2: 0.1034\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.5386 - keras_r2: 0.2379 - val_loss: 75.5796 - val_keras_r2: 0.1038\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.3429 - keras_r2: 0.2598 - val_loss: 75.5926 - val_keras_r2: 0.1050\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.2894 - keras_r2: 0.2763 - val_loss: 75.9632 - val_keras_r2: 0.0999\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.3441 - keras_r2: 0.1861 - val_loss: 75.9909 - val_keras_r2: 0.0979\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.2164 - keras_r2: 0.2603 - val_loss: 75.6846 - val_keras_r2: 0.1018\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 60.0639 - keras_r2: 0.1931 - val_loss: 76.0152 - val_keras_r2: 0.0975\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.0807 - keras_r2: 0.1923 - val_loss: 75.9684 - val_keras_r2: 0.0961\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.9197 - keras_r2: -1613055.8750 - val_loss: 75.3326 - val_keras_r2: 0.1042\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.0347 - keras_r2: 0.2702 - val_loss: 76.0038 - val_keras_r2: 0.0973\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.8454 - keras_r2: 0.2690 - val_loss: 75.6958 - val_keras_r2: 0.1011\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7826 - keras_r2: 0.2708 - val_loss: 75.4210 - val_keras_r2: 0.1036\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.6964 - keras_r2: 0.2690 - val_loss: 75.5036 - val_keras_r2: 0.1037\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.6862 - keras_r2: -101330.6172 - val_loss: 75.3675 - val_keras_r2: 0.1042\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6204 - keras_r2: 0.2705 - val_loss: 75.5536 - val_keras_r2: 0.0998\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.5158 - keras_r2: 0.2723 - val_loss: 75.3002 - val_keras_r2: 0.1062\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.4552 - keras_r2: -3587094.5000 - val_loss: 75.3676 - val_keras_r2: 0.1033\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.5500 - keras_r2: 0.2757 - val_loss: 75.6262 - val_keras_r2: 0.1015\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.3650 - keras_r2: 0.2778 - val_loss: 75.5511 - val_keras_r2: 0.0998\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.4240 - keras_r2: 0.2756 - val_loss: 75.6662 - val_keras_r2: 0.1009\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.2646 - keras_r2: 0.2542 - val_loss: 75.6274 - val_keras_r2: 0.1014\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.3217 - keras_r2: 0.2393 - val_loss: 75.8165 - val_keras_r2: 0.1002\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.1676 - keras_r2: 0.2693 - val_loss: 76.1712 - val_keras_r2: 0.0960\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 59.3951 - keras_r2: 0.2661 - val_loss: 75.3721 - val_keras_r2: 0.1036\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.2038 - keras_r2: 0.2660 - val_loss: 75.8168 - val_keras_r2: 0.0980\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.1823 - keras_r2: 0.2887 - val_loss: 75.8591 - val_keras_r2: 0.0974\n",
      "Epoch 71: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=12; total time=  34.3s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1507.2236 - keras_r2: -18.6021 - val_loss: 1041.3893 - val_keras_r2: -12.8505\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 424.4385 - keras_r2: -4.6031 - val_loss: 136.9530 - val_keras_r2: -0.7300\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 123.3689 - keras_r2: -0.6297 - val_loss: 108.1477 - val_keras_r2: -0.3594\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 98.9641 - keras_r2: -0.2770 - val_loss: 96.5769 - val_keras_r2: -0.2112\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 87.2659 - keras_r2: -0.0738 - val_loss: 89.1024 - val_keras_r2: -0.1186\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 80.6843 - keras_r2: 0.0035 - val_loss: 84.8719 - val_keras_r2: -0.0649\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 76.6374 - keras_r2: 0.0530 - val_loss: 81.6824 - val_keras_r2: -0.0236\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 73.6090 - keras_r2: 0.0421 - val_loss: 79.1450 - val_keras_r2: 0.0088\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 71.7611 - keras_r2: 0.1029 - val_loss: 77.4042 - val_keras_r2: 0.0315\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 70.0015 - keras_r2: 0.1444 - val_loss: 75.7941 - val_keras_r2: 0.0495\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 68.8957 - keras_r2: 0.1596 - val_loss: 74.3456 - val_keras_r2: 0.0689\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 67.8627 - keras_r2: 0.1671 - val_loss: 73.0501 - val_keras_r2: 0.0858\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.9516 - keras_r2: 0.1873 - val_loss: 72.3504 - val_keras_r2: 0.0927\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.1570 - keras_r2: 0.1249 - val_loss: 72.2046 - val_keras_r2: 0.0949\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 65.6616 - keras_r2: 0.1645 - val_loss: 71.1208 - val_keras_r2: 0.1071\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.8995 - keras_r2: 0.2026 - val_loss: 70.8728 - val_keras_r2: 0.1115\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.4350 - keras_r2: 0.1963 - val_loss: 70.0455 - val_keras_r2: 0.1206\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.9587 - keras_r2: 0.2196 - val_loss: 69.7873 - val_keras_r2: 0.1237\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.4497 - keras_r2: 0.2292 - val_loss: 69.2864 - val_keras_r2: 0.1325\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.1233 - keras_r2: 0.1309 - val_loss: 68.6880 - val_keras_r2: 0.1403\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.7204 - keras_r2: 0.2364 - val_loss: 68.7322 - val_keras_r2: 0.1379\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.4815 - keras_r2: 0.2333 - val_loss: 68.3199 - val_keras_r2: 0.1428\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.2135 - keras_r2: -0.0158 - val_loss: 68.2778 - val_keras_r2: 0.1470\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 61.8305 - keras_r2: 0.2314 - val_loss: 68.3568 - val_keras_r2: 0.1458\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.6333 - keras_r2: 0.2399 - val_loss: 68.1304 - val_keras_r2: 0.1476\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.6076 - keras_r2: 0.2548 - val_loss: 67.8546 - val_keras_r2: 0.1522\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.1542 - keras_r2: 0.2466 - val_loss: 67.5736 - val_keras_r2: 0.1555\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.1070 - keras_r2: 0.2541 - val_loss: 67.7204 - val_keras_r2: 0.1555\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.8987 - keras_r2: 0.1742 - val_loss: 68.2430 - val_keras_r2: 0.1448\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.8123 - keras_r2: 0.2524 - val_loss: 67.7958 - val_keras_r2: 0.1536\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 60.6737 - keras_r2: 0.2591 - val_loss: 68.0950 - val_keras_r2: 0.1490\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.7026 - keras_r2: 0.2518 - val_loss: 67.4735 - val_keras_r2: 0.1571\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.5784 - keras_r2: 0.2689 - val_loss: 67.6299 - val_keras_r2: 0.1564\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.4673 - keras_r2: 0.2686 - val_loss: 67.3811 - val_keras_r2: 0.1570\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.2682 - keras_r2: 0.2610 - val_loss: 68.2848 - val_keras_r2: 0.1439\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.2011 - keras_r2: 0.2665 - val_loss: 67.5793 - val_keras_r2: 0.1550\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 60.0894 - keras_r2: 0.2656 - val_loss: 67.6594 - val_keras_r2: 0.1542\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.9999 - keras_r2: 0.2580 - val_loss: 67.6491 - val_keras_r2: 0.1565\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.9930 - keras_r2: 0.2746 - val_loss: 67.6375 - val_keras_r2: 0.1561\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8346 - keras_r2: 0.2727 - val_loss: 67.5980 - val_keras_r2: 0.1571\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.6502 - keras_r2: 0.2591 - val_loss: 67.5949 - val_keras_r2: 0.1574\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.6486 - keras_r2: 0.2660 - val_loss: 67.6987 - val_keras_r2: 0.1548\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.6475 - keras_r2: 0.2704 - val_loss: 67.7628 - val_keras_r2: 0.1560\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.4826 - keras_r2: 0.2740 - val_loss: 67.7295 - val_keras_r2: 0.1560\n",
      "Epoch 44: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=12; total time=  22.5s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 6ms/step - loss: 441.6021 - keras_r2: -4.7385 - val_loss: 100.8262 - val_keras_r2: -0.1942\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 94.2823 - keras_r2: -0.1668 - val_loss: 82.1624 - val_keras_r2: 0.0350\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 71.6530 - keras_r2: 0.1331 - val_loss: 78.0290 - val_keras_r2: 0.0790\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 66.1563 - keras_r2: 0.1511 - val_loss: 78.3511 - val_keras_r2: 0.0775\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.6450 - keras_r2: 0.2025 - val_loss: 78.8032 - val_keras_r2: 0.0726\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.8003 - keras_r2: 0.2293 - val_loss: 77.2723 - val_keras_r2: 0.0872\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9008 - keras_r2: 0.2114 - val_loss: 76.8649 - val_keras_r2: 0.0796\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.6109 - keras_r2: 0.2437 - val_loss: 79.8240 - val_keras_r2: 0.0567\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 59.6671 - keras_r2: 0.2588 - val_loss: 81.1345 - val_keras_r2: 0.0413\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 59.6461 - keras_r2: 0.2617 - val_loss: 79.6099 - val_keras_r2: 0.0506\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 58.7439 - keras_r2: 0.2402 - val_loss: 78.9806 - val_keras_r2: 0.0454\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.5350 - keras_r2: 0.2798 - val_loss: 78.3093 - val_keras_r2: 0.0608\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.6426 - keras_r2: 0.2464 - val_loss: 81.0397 - val_keras_r2: 0.0131\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 57.4389 - keras_r2: 0.2158 - val_loss: 77.5104 - val_keras_r2: 0.0754\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 56.7674 - keras_r2: 0.2965 - val_loss: 77.0347 - val_keras_r2: 0.0718\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.1207 - keras_r2: 0.3097 - val_loss: 77.1326 - val_keras_r2: 0.0729\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 56.4830 - keras_r2: -0.6451 - val_loss: 76.8674 - val_keras_r2: 0.0763\n",
      "Epoch 17: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=71; total time=  13.8s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 525.9234 - keras_r2: -6.0799 - val_loss: 93.1736 - val_keras_r2: -0.1223\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 120.2663 - keras_r2: -0.7164 - val_loss: 81.5928 - val_keras_r2: 0.0237\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 76.5136 - keras_r2: 0.0284 - val_loss: 79.2559 - val_keras_r2: 0.0613\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 68.4167 - keras_r2: -0.7178 - val_loss: 79.4193 - val_keras_r2: 0.0606\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.2994 - keras_r2: -0.1619 - val_loss: 77.4647 - val_keras_r2: 0.0864\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.2901 - keras_r2: 0.2125 - val_loss: 80.8412 - val_keras_r2: 0.0353\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.1152 - keras_r2: 0.2405 - val_loss: 77.6231 - val_keras_r2: 0.0817\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.4285 - keras_r2: -0.2091 - val_loss: 76.8983 - val_keras_r2: 0.0864\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.5084 - keras_r2: 0.2605 - val_loss: 76.3393 - val_keras_r2: 0.0925\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6910 - keras_r2: 0.2570 - val_loss: 76.9221 - val_keras_r2: 0.0869\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.3921 - keras_r2: 0.2524 - val_loss: 76.9136 - val_keras_r2: 0.0859\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.7571 - keras_r2: 0.2814 - val_loss: 77.0725 - val_keras_r2: 0.0779\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.7260 - keras_r2: 0.0726 - val_loss: 84.0754 - val_keras_r2: -0.0227\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.4221 - keras_r2: 0.2414 - val_loss: 77.8836 - val_keras_r2: 0.0645\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.1626 - keras_r2: 0.2978 - val_loss: 77.9840 - val_keras_r2: 0.0693\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.9141 - keras_r2: -1.1030 - val_loss: 77.4896 - val_keras_r2: 0.0830\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.0845 - keras_r2: 0.2765 - val_loss: 84.3181 - val_keras_r2: -0.0329\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.4057 - keras_r2: 0.3065 - val_loss: 76.8037 - val_keras_r2: 0.0771\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.6995 - keras_r2: 0.3004 - val_loss: 75.7592 - val_keras_r2: 0.0985\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.2047 - keras_r2: 0.3183 - val_loss: 75.3420 - val_keras_r2: 0.1000\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.4110 - keras_r2: 0.2919 - val_loss: 76.0111 - val_keras_r2: 0.0855\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.9773 - keras_r2: 0.2844 - val_loss: 76.6362 - val_keras_r2: 0.0678\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.9348 - keras_r2: 0.3273 - val_loss: 75.8485 - val_keras_r2: 0.0905\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.1818 - keras_r2: 0.3395 - val_loss: 77.6021 - val_keras_r2: 0.0693\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.3321 - keras_r2: 0.3443 - val_loss: 80.2592 - val_keras_r2: 0.0427\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.0718 - keras_r2: 0.3360 - val_loss: 78.9221 - val_keras_r2: 0.0570\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.3552 - keras_r2: 0.3311 - val_loss: 77.3515 - val_keras_r2: 0.0613\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.1551 - keras_r2: 0.3488 - val_loss: 76.1455 - val_keras_r2: 0.0888\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 51.9388 - keras_r2: 0.3529 - val_loss: 77.0574 - val_keras_r2: 0.0742\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 52.1861 - keras_r2: -6948725.0000 - val_loss: 81.5256 - val_keras_r2: -0.0043\n",
      "Epoch 30: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=71; total time=  19.8s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 472.1722 - keras_r2: -4.7966 - val_loss: 86.1980 - val_keras_r2: -0.0336\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 102.9256 - keras_r2: -0.2091 - val_loss: 85.7718 - val_keras_r2: -0.0378\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 74.4734 - keras_r2: 0.0894 - val_loss: 79.1217 - val_keras_r2: 0.0653\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.0171 - keras_r2: 0.1275 - val_loss: 78.7372 - val_keras_r2: 0.0698\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.5820 - keras_r2: 0.1888 - val_loss: 78.0731 - val_keras_r2: 0.0632\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.4441 - keras_r2: 0.2340 - val_loss: 75.3379 - val_keras_r2: 0.1098\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.7846 - keras_r2: 0.2434 - val_loss: 77.5873 - val_keras_r2: 0.0757\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.6353 - keras_r2: -0.0161 - val_loss: 79.2647 - val_keras_r2: 0.0552\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9572 - keras_r2: 0.2605 - val_loss: 79.4049 - val_keras_r2: 0.0565\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1081 - keras_r2: 0.2597 - val_loss: 75.5981 - val_keras_r2: 0.1023\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1357 - keras_r2: 0.2547 - val_loss: 75.1873 - val_keras_r2: 0.1114\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.9081 - keras_r2: 0.2814 - val_loss: 75.4522 - val_keras_r2: 0.1070\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.7161 - keras_r2: -0.0054 - val_loss: 75.7251 - val_keras_r2: 0.1075\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.0691 - keras_r2: -3796432.0000 - val_loss: 77.7677 - val_keras_r2: 0.0704\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.3660 - keras_r2: 0.3000 - val_loss: 74.6849 - val_keras_r2: 0.1234\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.0628 - keras_r2: 0.3066 - val_loss: 76.8733 - val_keras_r2: 0.0895\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.2742 - keras_r2: 0.3016 - val_loss: 76.5665 - val_keras_r2: 0.0986\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.2947 - keras_r2: 0.3128 - val_loss: 74.6244 - val_keras_r2: 0.1100\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.7771 - keras_r2: -5800439.5000 - val_loss: 76.0484 - val_keras_r2: 0.0906\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.2809 - keras_r2: 0.2947 - val_loss: 81.4114 - val_keras_r2: 0.0349\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.5115 - keras_r2: 0.3006 - val_loss: 78.1210 - val_keras_r2: 0.0725\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.5976 - keras_r2: 0.3259 - val_loss: 78.0249 - val_keras_r2: 0.0823\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.7854 - keras_r2: 0.3232 - val_loss: 75.9461 - val_keras_r2: 0.0927\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.6094 - keras_r2: 0.3331 - val_loss: 76.3349 - val_keras_r2: 0.0875\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.1889 - keras_r2: 0.1591 - val_loss: 74.6920 - val_keras_r2: 0.1110\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.8195 - keras_r2: 0.3359 - val_loss: 76.1012 - val_keras_r2: 0.0982\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.9624 - keras_r2: 0.3148 - val_loss: 74.3529 - val_keras_r2: 0.1120\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.4107 - keras_r2: 0.3269 - val_loss: 82.9848 - val_keras_r2: 0.0087\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.6521 - keras_r2: -0.3961 - val_loss: 75.5678 - val_keras_r2: 0.0956\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 51.8722 - keras_r2: 0.3214 - val_loss: 77.0158 - val_keras_r2: 0.0747\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.2060 - keras_r2: 0.3572 - val_loss: 77.2847 - val_keras_r2: 0.0816\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 51.1049 - keras_r2: 0.3730 - val_loss: 78.2635 - val_keras_r2: 0.0624\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 51.5004 - keras_r2: 0.3651 - val_loss: 81.5159 - val_keras_r2: 0.0114\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 51.1323 - keras_r2: 0.3694 - val_loss: 73.9481 - val_keras_r2: 0.1062\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 50.1427 - keras_r2: 0.3819 - val_loss: 76.3750 - val_keras_r2: 0.0805\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 49.9980 - keras_r2: 0.3802 - val_loss: 76.8048 - val_keras_r2: 0.0720\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 50.1439 - keras_r2: 0.3840 - val_loss: 77.4907 - val_keras_r2: 0.0717\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 49.0945 - keras_r2: 0.3713 - val_loss: 76.6223 - val_keras_r2: 0.0812\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 48.7728 - keras_r2: 0.3947 - val_loss: 80.3381 - val_keras_r2: 0.0337\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 48.6109 - keras_r2: 0.4027 - val_loss: 77.6228 - val_keras_r2: 0.0704\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 48.5499 - keras_r2: -2664195.5000 - val_loss: 77.8371 - val_keras_r2: 0.0603\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 48.3703 - keras_r2: 0.4089 - val_loss: 78.0425 - val_keras_r2: 0.0583\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 48.4818 - keras_r2: 0.4025 - val_loss: 80.1724 - val_keras_r2: 0.0299\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 47.8039 - keras_r2: 0.3892 - val_loss: 80.3197 - val_keras_r2: 0.0379\n",
      "Epoch 44: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=71; total time=  27.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 464.4768 - keras_r2: -29655212.0000 - val_loss: 98.2525 - val_keras_r2: -0.1729\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 90.5249 - keras_r2: -0.1237 - val_loss: 112.4730 - val_keras_r2: -0.3998\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 70.7546 - keras_r2: -0.1664 - val_loss: 80.0723 - val_keras_r2: 0.0512\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.9049 - keras_r2: 0.1511 - val_loss: 76.4809 - val_keras_r2: 0.0996\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.5480 - keras_r2: 0.1619 - val_loss: 79.3584 - val_keras_r2: 0.0682\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.5769 - keras_r2: 0.2305 - val_loss: 79.3581 - val_keras_r2: 0.0617\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.9194 - keras_r2: 0.2379 - val_loss: 76.0362 - val_keras_r2: 0.0999\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.3779 - keras_r2: 0.2646 - val_loss: 76.2503 - val_keras_r2: 0.0982\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1748 - keras_r2: 0.1601 - val_loss: 75.8999 - val_keras_r2: 0.0913\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6007 - keras_r2: 0.2628 - val_loss: 76.7402 - val_keras_r2: 0.0864\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.5452 - keras_r2: -0.2049 - val_loss: 77.7837 - val_keras_r2: 0.0794\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.9733 - keras_r2: 0.2936 - val_loss: 84.2693 - val_keras_r2: -0.0155\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.3581 - keras_r2: 0.2845 - val_loss: 75.5783 - val_keras_r2: 0.1024\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.6272 - keras_r2: 0.2760 - val_loss: 79.1348 - val_keras_r2: 0.0626\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.9765 - keras_r2: 0.2718 - val_loss: 78.5673 - val_keras_r2: 0.0697\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.2007 - keras_r2: 0.3177 - val_loss: 78.7619 - val_keras_r2: 0.0565\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.4976 - keras_r2: 0.3152 - val_loss: 76.9307 - val_keras_r2: 0.0857\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.6571 - keras_r2: 0.3409 - val_loss: 78.5512 - val_keras_r2: 0.0632\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.7644 - keras_r2: 0.2751 - val_loss: 77.1164 - val_keras_r2: 0.0760\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.0348 - keras_r2: 0.3369 - val_loss: 77.6981 - val_keras_r2: 0.0746\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.6661 - keras_r2: 0.3436 - val_loss: 76.9145 - val_keras_r2: 0.0839\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.3322 - keras_r2: 0.3453 - val_loss: 76.3013 - val_keras_r2: 0.0912\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.8974 - keras_r2: 0.3229 - val_loss: 77.9098 - val_keras_r2: 0.0662\n",
      "Epoch 23: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=71; total time=  14.8s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 476.7670 - keras_r2: -5.2145 - val_loss: 102.0794 - val_keras_r2: -0.2816\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 104.0242 - keras_r2: -0.3115 - val_loss: 74.3102 - val_keras_r2: 0.0680\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 70.6904 - keras_r2: 0.1289 - val_loss: 70.5865 - val_keras_r2: 0.1098\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.1830 - keras_r2: 0.2070 - val_loss: 69.3420 - val_keras_r2: 0.1263\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4430 - keras_r2: 0.2135 - val_loss: 68.5869 - val_keras_r2: 0.1365\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.2799 - keras_r2: 0.2376 - val_loss: 70.6988 - val_keras_r2: 0.1042\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.3611 - keras_r2: 0.2433 - val_loss: 67.3074 - val_keras_r2: 0.1568\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.2560 - keras_r2: 0.2664 - val_loss: 67.0818 - val_keras_r2: 0.1560\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.1724 - keras_r2: 0.2750 - val_loss: 66.2503 - val_keras_r2: 0.1668\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.0210 - keras_r2: 0.2922 - val_loss: 67.0839 - val_keras_r2: 0.1554\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.0201 - keras_r2: 0.2821 - val_loss: 67.9077 - val_keras_r2: 0.1513\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.8143 - keras_r2: 0.2937 - val_loss: 67.8480 - val_keras_r2: 0.1466\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.1164 - keras_r2: 0.3054 - val_loss: 69.7994 - val_keras_r2: 0.1186\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.8828 - keras_r2: 0.0974 - val_loss: 68.9442 - val_keras_r2: 0.1374\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.3923 - keras_r2: 0.2809 - val_loss: 70.0156 - val_keras_r2: 0.1214\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.8582 - keras_r2: 0.3027 - val_loss: 65.9891 - val_keras_r2: 0.1695\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.4522 - keras_r2: 0.3122 - val_loss: 67.3947 - val_keras_r2: 0.1497\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.4169 - keras_r2: 0.3214 - val_loss: 71.6238 - val_keras_r2: 0.1013\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.1676 - keras_r2: 0.3387 - val_loss: 69.4317 - val_keras_r2: 0.1276\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.7738 - keras_r2: 0.3384 - val_loss: 67.9925 - val_keras_r2: 0.1355\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.0673 - keras_r2: 0.3139 - val_loss: 68.2569 - val_keras_r2: 0.1408\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.7297 - keras_r2: 0.2858 - val_loss: 70.3163 - val_keras_r2: 0.1153\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.5285 - keras_r2: 0.3441 - val_loss: 67.6257 - val_keras_r2: 0.1457\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.2677 - keras_r2: 0.3505 - val_loss: 75.4772 - val_keras_r2: 0.0371\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.5174 - keras_r2: 0.3589 - val_loss: 74.7546 - val_keras_r2: 0.0451\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.3125 - keras_r2: 0.3292 - val_loss: 73.6740 - val_keras_r2: 0.0572\n",
      "Epoch 26: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=71; total time=  16.9s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 434.1186 - keras_r2: -4.9450 - val_loss: 93.6361 - val_keras_r2: -0.1038\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 74.5659 - keras_r2: 0.0721 - val_loss: 79.9082 - val_keras_r2: 0.0606\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 67.7116 - keras_r2: 0.0977 - val_loss: 78.8206 - val_keras_r2: 0.0717\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.2262 - keras_r2: -0.3063 - val_loss: 77.8902 - val_keras_r2: 0.0869\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.9774 - keras_r2: 0.2044 - val_loss: 77.1446 - val_keras_r2: 0.0898\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.7526 - keras_r2: 0.2125 - val_loss: 77.1581 - val_keras_r2: 0.0885\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.4803 - keras_r2: 0.1877 - val_loss: 76.9809 - val_keras_r2: 0.0894\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.8244 - keras_r2: 0.2073 - val_loss: 77.3102 - val_keras_r2: 0.0788\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.8251 - keras_r2: 0.2699 - val_loss: 76.6476 - val_keras_r2: 0.0813\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.4154 - keras_r2: 0.2772 - val_loss: 77.0700 - val_keras_r2: 0.0838\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.0581 - keras_r2: 0.2598 - val_loss: 75.7134 - val_keras_r2: 0.0978\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.2555 - keras_r2: 0.3007 - val_loss: 79.5158 - val_keras_r2: 0.0356\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.5272 - keras_r2: 0.2960 - val_loss: 88.9368 - val_keras_r2: -0.0973\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.5113 - keras_r2: 0.2818 - val_loss: 75.8027 - val_keras_r2: 0.0972\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.7150 - keras_r2: 0.2347 - val_loss: 74.8019 - val_keras_r2: 0.1095\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.8578 - keras_r2: 0.1422 - val_loss: 78.8094 - val_keras_r2: 0.0576\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.2163 - keras_r2: 0.3212 - val_loss: 76.3964 - val_keras_r2: 0.0802\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.4185 - keras_r2: 0.3393 - val_loss: 79.0320 - val_keras_r2: 0.0523\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.7310 - keras_r2: 0.3010 - val_loss: 76.0638 - val_keras_r2: 0.0867\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.5081 - keras_r2: 0.2525 - val_loss: 77.8543 - val_keras_r2: 0.0622\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.0832 - keras_r2: 0.3499 - val_loss: 79.4118 - val_keras_r2: 0.0508\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.4609 - keras_r2: 0.3420 - val_loss: 76.7105 - val_keras_r2: 0.0816\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 52.1049 - keras_r2: 0.3544 - val_loss: 77.7340 - val_keras_r2: 0.0724\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 50.7096 - keras_r2: 0.3732 - val_loss: 78.6989 - val_keras_r2: 0.0566\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 50.3770 - keras_r2: -2394534.2500 - val_loss: 79.2509 - val_keras_r2: 0.0495\n",
      "Epoch 25: early stopping\n",
      "[CV] END ...........................n_hidden=5, n_neurons=69; total time=  17.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 443.0900 - keras_r2: -4.6138 - val_loss: 88.3291 - val_keras_r2: -0.0592\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 91.5301 - keras_r2: -0.1727 - val_loss: 75.2924 - val_keras_r2: 0.1047\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 69.6233 - keras_r2: 0.1103 - val_loss: 75.2639 - val_keras_r2: 0.1089\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.6730 - keras_r2: 0.0259 - val_loss: 76.3513 - val_keras_r2: 0.0817\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.3857 - keras_r2: -0.3973 - val_loss: 76.6589 - val_keras_r2: 0.0709\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.1465 - keras_r2: 0.1235 - val_loss: 81.7657 - val_keras_r2: 0.0234\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.6221 - keras_r2: 0.2266 - val_loss: 73.9859 - val_keras_r2: 0.1136\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.9195 - keras_r2: 0.2204 - val_loss: 72.2610 - val_keras_r2: 0.1327\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6236 - keras_r2: 0.2498 - val_loss: 82.2812 - val_keras_r2: 0.0142\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.5938 - keras_r2: 0.2576 - val_loss: 75.4778 - val_keras_r2: 0.0959\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6389 - keras_r2: 0.2585 - val_loss: 77.8290 - val_keras_r2: 0.0534\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.3738 - keras_r2: 0.0664 - val_loss: 73.8064 - val_keras_r2: 0.1208\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 57.6825 - keras_r2: 0.2484 - val_loss: 72.0772 - val_keras_r2: 0.1310\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.9417 - keras_r2: 0.2965 - val_loss: 76.3327 - val_keras_r2: 0.0872\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.0214 - keras_r2: 0.2940 - val_loss: 73.0091 - val_keras_r2: 0.1226\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.4204 - keras_r2: 0.2658 - val_loss: 73.6446 - val_keras_r2: 0.1111\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.7224 - keras_r2: 0.3041 - val_loss: 74.5690 - val_keras_r2: 0.1003\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.1307 - keras_r2: 0.1715 - val_loss: 75.0209 - val_keras_r2: 0.1011\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.1131 - keras_r2: 0.3212 - val_loss: 74.1224 - val_keras_r2: 0.1097\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.6455 - keras_r2: 0.3109 - val_loss: 73.6743 - val_keras_r2: 0.1081\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.9564 - keras_r2: 0.3154 - val_loss: 76.4104 - val_keras_r2: 0.0672\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.3359 - keras_r2: 0.3167 - val_loss: 73.7395 - val_keras_r2: 0.1126\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.8327 - keras_r2: 0.3204 - val_loss: 83.7886 - val_keras_r2: -0.0346\n",
      "Epoch 23: early stopping\n",
      "[CV] END ...........................n_hidden=5, n_neurons=69; total time=  16.1s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 393.6788 - keras_r2: -4.3668 - val_loss: 92.3565 - val_keras_r2: -0.1012\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 87.0069 - keras_r2: -0.0779 - val_loss: 83.8486 - val_keras_r2: -0.0048\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 70.4631 - keras_r2: 0.1364 - val_loss: 80.9652 - val_keras_r2: 0.0363\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.3898 - keras_r2: 0.1750 - val_loss: 76.8685 - val_keras_r2: 0.0831\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.2308 - keras_r2: 0.1813 - val_loss: 75.1689 - val_keras_r2: 0.1026\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.7129 - keras_r2: 0.2121 - val_loss: 75.1744 - val_keras_r2: 0.1028\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.0167 - keras_r2: 0.2227 - val_loss: 82.4537 - val_keras_r2: 0.0218\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.5062 - keras_r2: 0.2306 - val_loss: 77.4700 - val_keras_r2: 0.0879\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1481 - keras_r2: 0.2794 - val_loss: 76.4740 - val_keras_r2: 0.0922\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1346 - keras_r2: 0.2649 - val_loss: 79.0574 - val_keras_r2: 0.0580\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.0965 - keras_r2: 0.2714 - val_loss: 75.4056 - val_keras_r2: 0.0935\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 57.8233 - keras_r2: 0.3005 - val_loss: 75.8808 - val_keras_r2: 0.0925\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.3103 - keras_r2: -2.7435 - val_loss: 77.4776 - val_keras_r2: 0.0667\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.4102 - keras_r2: 0.2848 - val_loss: 76.1261 - val_keras_r2: 0.0982\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.0358 - keras_r2: 0.2841 - val_loss: 77.1225 - val_keras_r2: 0.0778\n",
      "Epoch 15: early stopping\n",
      "[CV] END ...........................n_hidden=5, n_neurons=69; total time=  11.0s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 1933.4991 - keras_r2: -24.5470 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.7548 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.6389 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.6801 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6210 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.8238 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -80.1648 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -56.1606 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.8816 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.1025 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.5635 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
      "Epoch 11: early stopping\n",
      "[CV] END ...........................n_hidden=5, n_neurons=69; total time=   8.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 449.7357 - keras_r2: -4.7753 - val_loss: 109.3556 - val_keras_r2: -0.4256\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 94.2794 - keras_r2: -0.1673 - val_loss: 75.6950 - val_keras_r2: 0.0390\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 72.3359 - keras_r2: 0.0950 - val_loss: 68.5596 - val_keras_r2: 0.1407\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 67.2263 - keras_r2: 0.1677 - val_loss: 68.0671 - val_keras_r2: 0.1490\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 64.2575 - keras_r2: 0.1932 - val_loss: 67.7963 - val_keras_r2: 0.1544\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.2800 - keras_r2: 0.2198 - val_loss: 66.6981 - val_keras_r2: 0.1764\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9835 - keras_r2: 0.2453 - val_loss: 66.4950 - val_keras_r2: 0.1729\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.4764 - keras_r2: 0.2571 - val_loss: 65.8605 - val_keras_r2: 0.1765\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.4972 - keras_r2: 0.2694 - val_loss: 66.1959 - val_keras_r2: 0.1735\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.0831 - keras_r2: 0.2737 - val_loss: 65.6334 - val_keras_r2: 0.1760\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.4061 - keras_r2: 0.2892 - val_loss: 64.9824 - val_keras_r2: 0.1900\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.8774 - keras_r2: 0.2396 - val_loss: 65.3579 - val_keras_r2: 0.1857\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.4470 - keras_r2: 0.3066 - val_loss: 67.7215 - val_keras_r2: 0.1477\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.7218 - keras_r2: 0.3000 - val_loss: 66.2024 - val_keras_r2: 0.1764\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.3706 - keras_r2: 0.3066 - val_loss: 64.8569 - val_keras_r2: 0.1906\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.3941 - keras_r2: 0.3121 - val_loss: 71.7710 - val_keras_r2: 0.1027\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.4271 - keras_r2: 0.3173 - val_loss: 65.9006 - val_keras_r2: 0.1736\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.2694 - keras_r2: 0.3227 - val_loss: 66.5766 - val_keras_r2: 0.1639\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.7964 - keras_r2: 0.3373 - val_loss: 71.8242 - val_keras_r2: 0.1059\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.7650 - keras_r2: 0.3262 - val_loss: 68.5703 - val_keras_r2: 0.1423\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.2929 - keras_r2: 0.3305 - val_loss: 68.8387 - val_keras_r2: 0.1308\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 53.6465 - keras_r2: 0.3426 - val_loss: 68.5703 - val_keras_r2: 0.1446\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.2255 - keras_r2: 0.3493 - val_loss: 70.8907 - val_keras_r2: 0.1063\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 52.6875 - keras_r2: 0.3487 - val_loss: 78.7413 - val_keras_r2: 0.0073\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 52.1076 - keras_r2: 0.3606 - val_loss: 69.0897 - val_keras_r2: 0.1267\n",
      "Epoch 25: early stopping\n",
      "[CV] END ...........................n_hidden=5, n_neurons=69; total time=  17.1s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 1143.4576 - keras_r2: -15.3645 - val_loss: 181.2167 - val_keras_r2: -1.2984\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 153.3763 - keras_r2: -1.1986 - val_loss: 100.7999 - val_keras_r2: -0.2262\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 107.5718 - keras_r2: -0.4318 - val_loss: 89.9734 - val_keras_r2: -0.0822\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 90.3201 - keras_r2: -0.2434 - val_loss: 86.2476 - val_keras_r2: -0.0308\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 80.5811 - keras_r2: -0.0191 - val_loss: 83.0831 - val_keras_r2: 0.0113\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 74.5336 - keras_r2: 0.0970 - val_loss: 80.9014 - val_keras_r2: 0.0419\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 70.4855 - keras_r2: 0.1230 - val_loss: 80.0289 - val_keras_r2: 0.0522\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 67.7088 - keras_r2: -0.0656 - val_loss: 78.9523 - val_keras_r2: 0.0686\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.5922 - keras_r2: 0.1930 - val_loss: 78.1662 - val_keras_r2: 0.0773\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.6122 - keras_r2: 0.2066 - val_loss: 77.5198 - val_keras_r2: 0.0865\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 63.2123 - keras_r2: 0.1882 - val_loss: 77.3755 - val_keras_r2: 0.0880\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.2636 - keras_r2: 0.2097 - val_loss: 76.6190 - val_keras_r2: 0.0966\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.7040 - keras_r2: 0.2427 - val_loss: 77.2117 - val_keras_r2: 0.0899\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.4132 - keras_r2: 0.2397 - val_loss: 76.0126 - val_keras_r2: 0.1035\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6969 - keras_r2: 0.2210 - val_loss: 76.0749 - val_keras_r2: 0.1056\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.2664 - keras_r2: 0.2455 - val_loss: 75.7364 - val_keras_r2: 0.1082\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.1792 - keras_r2: 0.2639 - val_loss: 76.3105 - val_keras_r2: 0.0982\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.7024 - keras_r2: 0.2701 - val_loss: 75.3628 - val_keras_r2: 0.1119\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.1471 - keras_r2: 0.1107 - val_loss: 75.9391 - val_keras_r2: 0.1076\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.9980 - keras_r2: 0.2116 - val_loss: 75.4056 - val_keras_r2: 0.1087\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.2784 - keras_r2: 0.2211 - val_loss: 75.0638 - val_keras_r2: 0.1168\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 58.4427 - keras_r2: -864996.1875 - val_loss: 75.4121 - val_keras_r2: 0.1120\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.1123 - keras_r2: 0.2843 - val_loss: 75.9152 - val_keras_r2: 0.1022\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.9736 - keras_r2: 0.2753 - val_loss: 73.9886 - val_keras_r2: 0.1280\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.7448 - keras_r2: 0.2822 - val_loss: 75.4669 - val_keras_r2: 0.1096\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.4835 - keras_r2: 0.2890 - val_loss: 75.4936 - val_keras_r2: 0.1097\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.2630 - keras_r2: 0.2921 - val_loss: 75.1403 - val_keras_r2: 0.1099\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.7467 - keras_r2: 0.2855 - val_loss: 76.1131 - val_keras_r2: 0.1032\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.9126 - keras_r2: 0.2787 - val_loss: 74.9128 - val_keras_r2: 0.1145\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.5052 - keras_r2: 0.3028 - val_loss: 76.4102 - val_keras_r2: 0.0911\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.1729 - keras_r2: -0.2834 - val_loss: 75.4867 - val_keras_r2: 0.1071\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.2504 - keras_r2: 0.2847 - val_loss: 75.0727 - val_keras_r2: 0.1134\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.9498 - keras_r2: 0.3118 - val_loss: 75.1708 - val_keras_r2: 0.1091\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.6121 - keras_r2: -0.2159 - val_loss: 75.3530 - val_keras_r2: 0.1054\n",
      "Epoch 34: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=37; total time=  20.6s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1040.0909 - keras_r2: -13.8177 - val_loss: 134.1576 - val_keras_r2: -0.6501\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 139.3443 - keras_r2: -0.7610 - val_loss: 86.7555 - val_keras_r2: -0.0394\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 99.5464 - keras_r2: -0.1803 - val_loss: 83.0460 - val_keras_r2: 0.0067\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 85.1113 - keras_r2: -0.4990 - val_loss: 80.7864 - val_keras_r2: 0.0357\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 77.5941 - keras_r2: 0.0226 - val_loss: 79.9096 - val_keras_r2: 0.0495\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 72.8801 - keras_r2: 0.0956 - val_loss: 78.8403 - val_keras_r2: 0.0643\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 69.7948 - keras_r2: -2359439.7500 - val_loss: 78.2249 - val_keras_r2: 0.0725\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 67.2654 - keras_r2: 0.1671 - val_loss: 77.6949 - val_keras_r2: 0.0793\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 65.6512 - keras_r2: 0.1935 - val_loss: 77.3843 - val_keras_r2: 0.0806\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.3569 - keras_r2: 0.2122 - val_loss: 78.1868 - val_keras_r2: 0.0655\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.2915 - keras_r2: 0.2104 - val_loss: 77.2211 - val_keras_r2: 0.0873\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.7371 - keras_r2: 0.2272 - val_loss: 76.3549 - val_keras_r2: 0.0954\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.7566 - keras_r2: 0.2407 - val_loss: 76.5018 - val_keras_r2: 0.0911\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.3011 - keras_r2: 0.2453 - val_loss: 76.4195 - val_keras_r2: 0.0911\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.9245 - keras_r2: 0.2200 - val_loss: 76.9994 - val_keras_r2: 0.0873\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.6355 - keras_r2: 0.2490 - val_loss: 76.1300 - val_keras_r2: 0.0991\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.3383 - keras_r2: 0.1240 - val_loss: 75.8048 - val_keras_r2: 0.0984\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.8033 - keras_r2: 0.2570 - val_loss: 75.5958 - val_keras_r2: 0.1031\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.7200 - keras_r2: 0.1994 - val_loss: 76.0862 - val_keras_r2: 0.0989\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.1806 - keras_r2: 0.2722 - val_loss: 75.6727 - val_keras_r2: 0.0983\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.0620 - keras_r2: 0.2596 - val_loss: 76.8814 - val_keras_r2: 0.0804\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.5626 - keras_r2: 0.2810 - val_loss: 75.5191 - val_keras_r2: 0.1013\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 58.2013 - keras_r2: 0.2712 - val_loss: 76.2084 - val_keras_r2: 0.0912\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.4257 - keras_r2: -3914522.2500 - val_loss: 75.2097 - val_keras_r2: 0.1027\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.7394 - keras_r2: 0.2389 - val_loss: 76.3015 - val_keras_r2: 0.0913\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 57.6767 - keras_r2: -1700494.0000 - val_loss: 75.9445 - val_keras_r2: 0.0957\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.5579 - keras_r2: 0.2918 - val_loss: 77.2479 - val_keras_r2: 0.0742\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.0355 - keras_r2: 0.2972 - val_loss: 77.2215 - val_keras_r2: 0.0788\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.9281 - keras_r2: 0.2953 - val_loss: 76.0986 - val_keras_r2: 0.0928\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 56.5161 - keras_r2: 0.2967 - val_loss: 77.5872 - val_keras_r2: 0.0684\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.0888 - keras_r2: 0.2932 - val_loss: 76.3098 - val_keras_r2: 0.0888\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.1108 - keras_r2: 0.3055 - val_loss: 76.5109 - val_keras_r2: 0.0869\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.9229 - keras_r2: -0.2855 - val_loss: 75.8153 - val_keras_r2: 0.0921\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.8341 - keras_r2: 0.2759 - val_loss: 75.8558 - val_keras_r2: 0.0917\n",
      "Epoch 34: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=37; total time=  19.6s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1212.4708 - keras_r2: -15.4544 - val_loss: 159.3136 - val_keras_r2: -1.0204\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 131.3757 - keras_r2: -0.9319 - val_loss: 91.6718 - val_keras_r2: -0.1031\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 95.9596 - keras_r2: -0.2205 - val_loss: 85.7679 - val_keras_r2: -0.0302\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 83.4723 - keras_r2: -0.0293 - val_loss: 83.5947 - val_keras_r2: 1.9247e-04\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 76.2054 - keras_r2: 0.0496 - val_loss: 80.7729 - val_keras_r2: 0.0413\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 71.7242 - keras_r2: 0.1286 - val_loss: 79.4819 - val_keras_r2: 0.0572\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.7258 - keras_r2: 0.1505 - val_loss: 78.5002 - val_keras_r2: 0.0714\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.8517 - keras_r2: -0.0989 - val_loss: 78.4449 - val_keras_r2: 0.0728\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.6307 - keras_r2: 0.1974 - val_loss: 77.5077 - val_keras_r2: 0.0864\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.1692 - keras_r2: 0.2221 - val_loss: 78.0588 - val_keras_r2: 0.0753\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4210 - keras_r2: 0.2194 - val_loss: 76.2616 - val_keras_r2: 0.1013\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.8767 - keras_r2: 0.1285 - val_loss: 77.1433 - val_keras_r2: 0.0899\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.1860 - keras_r2: 0.2270 - val_loss: 76.4733 - val_keras_r2: 0.0936\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.6982 - keras_r2: 0.2552 - val_loss: 77.3291 - val_keras_r2: 0.0917\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.0725 - keras_r2: 0.2027 - val_loss: 76.9530 - val_keras_r2: 0.0925\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6937 - keras_r2: 0.2633 - val_loss: 77.0303 - val_keras_r2: 0.0916\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.3142 - keras_r2: 0.2645 - val_loss: 75.5673 - val_keras_r2: 0.1084\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.0189 - keras_r2: 0.2734 - val_loss: 76.1565 - val_keras_r2: 0.1034\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.7743 - keras_r2: 0.2639 - val_loss: 75.4774 - val_keras_r2: 0.1119\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.5169 - keras_r2: 0.2759 - val_loss: 76.4120 - val_keras_r2: 0.1008\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.1707 - keras_r2: 0.2835 - val_loss: 76.3466 - val_keras_r2: 0.1020\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 58.8169 - keras_r2: 0.2771 - val_loss: 76.3163 - val_keras_r2: 0.1054\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.5640 - keras_r2: 0.2747 - val_loss: 76.0338 - val_keras_r2: 0.1002\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.3944 - keras_r2: 0.2909 - val_loss: 75.3995 - val_keras_r2: 0.1136\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.1314 - keras_r2: 0.2871 - val_loss: 76.8136 - val_keras_r2: 0.0972\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 58.0756 - keras_r2: 0.2821 - val_loss: 76.4144 - val_keras_r2: 0.1010\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 57.7433 - keras_r2: 0.2779 - val_loss: 76.5868 - val_keras_r2: 0.0980\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.5313 - keras_r2: 0.3015 - val_loss: 76.6162 - val_keras_r2: 0.0950\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.6988 - keras_r2: 0.2965 - val_loss: 75.9273 - val_keras_r2: 0.1033\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.2477 - keras_r2: 0.2967 - val_loss: 76.7175 - val_keras_r2: 0.0993\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.8721 - keras_r2: 0.2784 - val_loss: 76.1484 - val_keras_r2: 0.1035\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.7110 - keras_r2: 0.3043 - val_loss: 76.5415 - val_keras_r2: 0.0970\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.7271 - keras_r2: 0.3033 - val_loss: 76.7787 - val_keras_r2: 0.0975\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.0779 - keras_r2: 0.2999 - val_loss: 76.3650 - val_keras_r2: 0.1007\n",
      "Epoch 34: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=37; total time=  21.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 891.0856 - keras_r2: -11.3020 - val_loss: 115.7420 - val_keras_r2: -0.4055\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 117.3177 - keras_r2: -0.5760 - val_loss: 90.8562 - val_keras_r2: -0.0901\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 88.6553 - keras_r2: -0.0957 - val_loss: 85.1847 - val_keras_r2: -0.0185\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 77.6771 - keras_r2: 0.0212 - val_loss: 83.2347 - val_keras_r2: 0.0057\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 72.1513 - keras_r2: -0.1554 - val_loss: 80.9850 - val_keras_r2: 0.0356\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.8075 - keras_r2: 0.1202 - val_loss: 79.1901 - val_keras_r2: 0.0550\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.6230 - keras_r2: 0.1719 - val_loss: 79.1076 - val_keras_r2: 0.0535\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.9852 - keras_r2: 0.1315 - val_loss: 78.1764 - val_keras_r2: 0.0724\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.9574 - keras_r2: 0.2228 - val_loss: 77.0671 - val_keras_r2: 0.0851\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.9621 - keras_r2: 0.2292 - val_loss: 76.5064 - val_keras_r2: 0.0909\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.3631 - keras_r2: 0.2282 - val_loss: 76.9514 - val_keras_r2: 0.0860\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.8115 - keras_r2: 0.1153 - val_loss: 75.7032 - val_keras_r2: 0.1055\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.2643 - keras_r2: 0.2341 - val_loss: 75.7296 - val_keras_r2: 0.1033\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9142 - keras_r2: -0.3887 - val_loss: 75.7982 - val_keras_r2: 0.1034\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1230 - keras_r2: 0.2622 - val_loss: 75.1689 - val_keras_r2: 0.1046\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.8961 - keras_r2: 0.2682 - val_loss: 75.0603 - val_keras_r2: 0.1106\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.5352 - keras_r2: 0.2629 - val_loss: 74.8545 - val_keras_r2: 0.1100\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.1340 - keras_r2: 0.2762 - val_loss: 76.6191 - val_keras_r2: 0.0845\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.0523 - keras_r2: -0.7076 - val_loss: 75.0956 - val_keras_r2: 0.1089\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.8465 - keras_r2: 0.2798 - val_loss: 75.3929 - val_keras_r2: 0.1078\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.5484 - keras_r2: 0.2811 - val_loss: 76.4831 - val_keras_r2: 0.0979\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.2342 - keras_r2: 0.2926 - val_loss: 74.8602 - val_keras_r2: 0.1153\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.8364 - keras_r2: 0.2789 - val_loss: 74.6779 - val_keras_r2: 0.1148\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.5166 - keras_r2: 0.2916 - val_loss: 74.3522 - val_keras_r2: 0.1194\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.2848 - keras_r2: 0.2917 - val_loss: 75.2413 - val_keras_r2: 0.1021\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.0934 - keras_r2: -0.3866 - val_loss: 74.5394 - val_keras_r2: 0.1184\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.9364 - keras_r2: 0.3068 - val_loss: 73.9648 - val_keras_r2: 0.1226\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.4403 - keras_r2: 0.3123 - val_loss: 74.3656 - val_keras_r2: 0.1217\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.6160 - keras_r2: 0.2931 - val_loss: 74.1085 - val_keras_r2: 0.1220\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 56.4166 - keras_r2: -0.0587 - val_loss: 74.5446 - val_keras_r2: 0.1170\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.0217 - keras_r2: 0.2728 - val_loss: 74.4312 - val_keras_r2: 0.1156\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.8436 - keras_r2: 0.1135 - val_loss: 74.4512 - val_keras_r2: 0.1158\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.8512 - keras_r2: -0.8664 - val_loss: 74.5505 - val_keras_r2: 0.1168\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 55.8666 - keras_r2: 0.3059 - val_loss: 74.2835 - val_keras_r2: 0.1211\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.1517 - keras_r2: 0.3291 - val_loss: 74.5474 - val_keras_r2: 0.1151\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.3723 - keras_r2: 0.3198 - val_loss: 74.1047 - val_keras_r2: 0.1216\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.9898 - keras_r2: 0.3316 - val_loss: 74.3450 - val_keras_r2: 0.1201\n",
      "Epoch 37: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=37; total time=  22.1s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 922.0812 - keras_r2: -11.0779 - val_loss: 120.8155 - val_keras_r2: -0.5555\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 105.6800 - keras_r2: -0.2909 - val_loss: 85.3155 - val_keras_r2: -0.0800\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 81.4856 - keras_r2: -0.0252 - val_loss: 78.4553 - val_keras_r2: 0.0117\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 73.4526 - keras_r2: 0.0909 - val_loss: 75.3066 - val_keras_r2: 0.0528\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 69.1961 - keras_r2: 0.1509 - val_loss: 74.0322 - val_keras_r2: 0.0668\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.5915 - keras_r2: 0.1767 - val_loss: 72.1582 - val_keras_r2: 0.0918\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 64.9602 - keras_r2: 0.1863 - val_loss: 71.3847 - val_keras_r2: 0.1044\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4280 - keras_r2: 0.1417 - val_loss: 71.0129 - val_keras_r2: 0.1049\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.8048 - keras_r2: 0.1088 - val_loss: 69.9244 - val_keras_r2: 0.1229\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.7619 - keras_r2: 0.2349 - val_loss: 70.7108 - val_keras_r2: 0.1101\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.2038 - keras_r2: 0.2364 - val_loss: 70.0357 - val_keras_r2: 0.1167\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.5437 - keras_r2: 0.1407 - val_loss: 69.0243 - val_keras_r2: 0.1308\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.9873 - keras_r2: 0.2651 - val_loss: 69.0856 - val_keras_r2: 0.1307\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6629 - keras_r2: 0.2521 - val_loss: 68.2539 - val_keras_r2: 0.1417\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.3713 - keras_r2: 0.2715 - val_loss: 68.4542 - val_keras_r2: 0.1402\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.8864 - keras_r2: 0.2799 - val_loss: 68.0559 - val_keras_r2: 0.1448\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.7427 - keras_r2: 0.2676 - val_loss: 68.6087 - val_keras_r2: 0.1382\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.3820 - keras_r2: 0.2803 - val_loss: 67.9689 - val_keras_r2: 0.1468\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.2289 - keras_r2: 0.2432 - val_loss: 67.9116 - val_keras_r2: 0.1476\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.5153 - keras_r2: 0.2940 - val_loss: 67.9487 - val_keras_r2: 0.1445\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.3435 - keras_r2: 0.2990 - val_loss: 68.1802 - val_keras_r2: 0.1435\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.1302 - keras_r2: 0.3003 - val_loss: 67.9290 - val_keras_r2: 0.1478\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.8814 - keras_r2: 0.3115 - val_loss: 68.5088 - val_keras_r2: 0.1367\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.4494 - keras_r2: 0.2997 - val_loss: 68.4566 - val_keras_r2: 0.1422\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.5594 - keras_r2: 0.3094 - val_loss: 68.7542 - val_keras_r2: 0.1355\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.3078 - keras_r2: 0.2755 - val_loss: 68.6808 - val_keras_r2: 0.1400\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.2142 - keras_r2: 0.2999 - val_loss: 67.3898 - val_keras_r2: 0.1530\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.8763 - keras_r2: 0.3070 - val_loss: 67.7514 - val_keras_r2: 0.1480\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.7066 - keras_r2: 0.3202 - val_loss: 67.4843 - val_keras_r2: 0.1527\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.3949 - keras_r2: 0.3224 - val_loss: 68.1880 - val_keras_r2: 0.1426\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.2856 - keras_r2: 0.3121 - val_loss: 67.9240 - val_keras_r2: 0.1460\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.1004 - keras_r2: 0.3245 - val_loss: 68.1766 - val_keras_r2: 0.1455\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.9778 - keras_r2: 0.3246 - val_loss: 68.0057 - val_keras_r2: 0.1444\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.7080 - keras_r2: 0.3332 - val_loss: 68.6564 - val_keras_r2: 0.1385\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.3458 - keras_r2: 0.3410 - val_loss: 68.5635 - val_keras_r2: 0.1341\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.3794 - keras_r2: 0.3329 - val_loss: 67.7136 - val_keras_r2: 0.1469\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.2888 - keras_r2: 0.3301 - val_loss: 67.5632 - val_keras_r2: 0.1490\n",
      "Epoch 37: early stopping\n",
      "[CV] END ...........................n_hidden=2, n_neurons=37; total time=  23.1s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 402.2671 - keras_r2: -4.5819 - val_loss: 90.0900 - val_keras_r2: -0.0559\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 77.3180 - keras_r2: 0.0331 - val_loss: 75.4149 - val_keras_r2: 0.1023\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.3674 - keras_r2: -0.1954 - val_loss: 74.5416 - val_keras_r2: 0.1132\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.5344 - keras_r2: 0.1839 - val_loss: 73.4923 - val_keras_r2: 0.1207\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.2853 - keras_r2: -0.1608 - val_loss: 74.6652 - val_keras_r2: 0.1060\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.8175 - keras_r2: 0.2358 - val_loss: 74.4362 - val_keras_r2: 0.1016\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.7304 - keras_r2: -0.0563 - val_loss: 74.8243 - val_keras_r2: 0.0991\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.8896 - keras_r2: 0.2549 - val_loss: 74.9699 - val_keras_r2: 0.0975\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.3123 - keras_r2: 0.2560 - val_loss: 78.2965 - val_keras_r2: 0.0522\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.7147 - keras_r2: 0.2613 - val_loss: 73.6256 - val_keras_r2: 0.1188\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.2112 - keras_r2: 0.2805 - val_loss: 80.8749 - val_keras_r2: 0.0315\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.7595 - keras_r2: 0.2643 - val_loss: 74.9320 - val_keras_r2: 0.1028\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.1589 - keras_r2: 0.2935 - val_loss: 74.8761 - val_keras_r2: 0.0950\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.8502 - keras_r2: 0.3018 - val_loss: 74.5395 - val_keras_r2: 0.1067\n",
      "Epoch 14: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=92; total time=  10.4s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 424.9016 - keras_r2: -4.5533 - val_loss: 80.4490 - val_keras_r2: 0.0305\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 96.1089 - keras_r2: -0.2435 - val_loss: 75.6571 - val_keras_r2: 0.0868\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 70.1478 - keras_r2: 0.1303 - val_loss: 74.1225 - val_keras_r2: 0.1044\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.8209 - keras_r2: 0.1616 - val_loss: 73.4511 - val_keras_r2: 0.1109\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.3650 - keras_r2: 0.1826 - val_loss: 75.3963 - val_keras_r2: 0.0861\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.1173 - keras_r2: -0.6682 - val_loss: 72.3940 - val_keras_r2: 0.1279\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.0386 - keras_r2: 0.2298 - val_loss: 72.6219 - val_keras_r2: 0.1193\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.1480 - keras_r2: 0.2569 - val_loss: 75.8143 - val_keras_r2: 0.0709\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.8083 - keras_r2: 0.2654 - val_loss: 72.1889 - val_keras_r2: 0.1328\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6261 - keras_r2: 0.2674 - val_loss: 71.2214 - val_keras_r2: 0.1346\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.4455 - keras_r2: 0.2827 - val_loss: 74.7776 - val_keras_r2: 0.1004\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.1502 - keras_r2: 0.2781 - val_loss: 73.0978 - val_keras_r2: 0.1197\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.4303 - keras_r2: 0.2966 - val_loss: 74.2961 - val_keras_r2: 0.1027\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.7835 - keras_r2: 0.3037 - val_loss: 72.4394 - val_keras_r2: 0.1202\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.8673 - keras_r2: 0.2951 - val_loss: 78.7807 - val_keras_r2: 0.0443\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.3154 - keras_r2: 0.1972 - val_loss: 73.2157 - val_keras_r2: 0.1108\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.5407 - keras_r2: 0.2948 - val_loss: 76.2095 - val_keras_r2: 0.0750\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.4296 - keras_r2: 0.3037 - val_loss: 80.8970 - val_keras_r2: -0.0035\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.4828 - keras_r2: 0.1992 - val_loss: 74.2811 - val_keras_r2: 0.0965\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.4160 - keras_r2: 0.3281 - val_loss: 72.6969 - val_keras_r2: 0.1165\n",
      "Epoch 20: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=92; total time=  14.3s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 6ms/step - loss: 432.2566 - keras_r2: -4.4596 - val_loss: 95.3032 - val_keras_r2: -0.1631\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 78.0212 - keras_r2: -0.2315 - val_loss: 78.9722 - val_keras_r2: 0.0583\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.7715 - keras_r2: 0.1230 - val_loss: 83.8303 - val_keras_r2: -0.0106\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.5156 - keras_r2: 0.1915 - val_loss: 75.8562 - val_keras_r2: 0.1030\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.5821 - keras_r2: 0.2129 - val_loss: 74.9906 - val_keras_r2: 0.1084\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.2781 - keras_r2: -0.7533 - val_loss: 74.6098 - val_keras_r2: 0.1148\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.1407 - keras_r2: 0.2544 - val_loss: 75.2180 - val_keras_r2: 0.1118\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.1132 - keras_r2: 0.2592 - val_loss: 74.6668 - val_keras_r2: 0.1112\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.1177 - keras_r2: 0.2729 - val_loss: 76.1102 - val_keras_r2: 0.0932\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.9545 - keras_r2: 0.1866 - val_loss: 75.4161 - val_keras_r2: 0.1020\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.8877 - keras_r2: 0.2263 - val_loss: 76.2521 - val_keras_r2: 0.0785\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.4413 - keras_r2: -0.1589 - val_loss: 75.4086 - val_keras_r2: 0.0991\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.8940 - keras_r2: 0.2898 - val_loss: 75.7439 - val_keras_r2: 0.0833\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.5609 - keras_r2: 0.3027 - val_loss: 75.5263 - val_keras_r2: 0.0931\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.2833 - keras_r2: 0.2872 - val_loss: 75.3402 - val_keras_r2: 0.1053\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.3466 - keras_r2: -0.9449 - val_loss: 84.5780 - val_keras_r2: -0.0074\n",
      "Epoch 16: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=92; total time=  11.7s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 414.6355 - keras_r2: -4.2087 - val_loss: 92.9144 - val_keras_r2: -0.1217\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 91.2804 - keras_r2: -0.1884 - val_loss: 80.3442 - val_keras_r2: 0.0382\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 70.7685 - keras_r2: 0.1201 - val_loss: 77.9786 - val_keras_r2: 0.0720\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.2819 - keras_r2: 0.1723 - val_loss: 77.9764 - val_keras_r2: 0.0726\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.6054 - keras_r2: 0.2183 - val_loss: 78.4507 - val_keras_r2: 0.0648\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.8638 - keras_r2: -0.0533 - val_loss: 74.8673 - val_keras_r2: 0.1063\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.0808 - keras_r2: -4145088.2500 - val_loss: 77.2966 - val_keras_r2: 0.0821\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.3064 - keras_r2: 0.2565 - val_loss: 77.0782 - val_keras_r2: 0.0724\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.5109 - keras_r2: 0.2723 - val_loss: 78.2767 - val_keras_r2: 0.0707\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.6731 - keras_r2: 0.2864 - val_loss: 76.1867 - val_keras_r2: 0.0935\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.8665 - keras_r2: 0.1666 - val_loss: 76.1471 - val_keras_r2: 0.0930\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.3889 - keras_r2: 0.2977 - val_loss: 84.6840 - val_keras_r2: -0.0349\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.5530 - keras_r2: 0.2387 - val_loss: 77.7830 - val_keras_r2: 0.0725\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.4664 - keras_r2: 0.2903 - val_loss: 77.2514 - val_keras_r2: 0.0752\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.9233 - keras_r2: 0.3000 - val_loss: 82.1855 - val_keras_r2: 0.0205\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 55.7081 - keras_r2: 0.3163 - val_loss: 92.2919 - val_keras_r2: -0.1035\n",
      "Epoch 16: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=92; total time=  11.9s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 359.5237 - keras_r2: -3.8111 - val_loss: 114.2506 - val_keras_r2: -0.3996\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 96.6831 - keras_r2: -0.1667 - val_loss: 73.9538 - val_keras_r2: 0.0767\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 68.6352 - keras_r2: 0.1482 - val_loss: 68.3049 - val_keras_r2: 0.1506\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.5481 - keras_r2: 0.2031 - val_loss: 65.8202 - val_keras_r2: 0.1801\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.8175 - keras_r2: 0.2334 - val_loss: 66.5796 - val_keras_r2: 0.1644\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.0811 - keras_r2: 0.2134 - val_loss: 68.5019 - val_keras_r2: 0.1328\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.2703 - keras_r2: 0.2522 - val_loss: 65.7654 - val_keras_r2: 0.1748\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.0556 - keras_r2: 0.2579 - val_loss: 65.5562 - val_keras_r2: 0.1788\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.8817 - keras_r2: 0.2731 - val_loss: 66.0723 - val_keras_r2: 0.1689\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.7184 - keras_r2: 0.3008 - val_loss: 68.1267 - val_keras_r2: 0.1431\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.6423 - keras_r2: 0.2987 - val_loss: 78.6974 - val_keras_r2: 0.0136\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.2336 - keras_r2: 0.2851 - val_loss: 68.2916 - val_keras_r2: 0.1404\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.4814 - keras_r2: 0.3070 - val_loss: 67.1397 - val_keras_r2: 0.1583\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.6903 - keras_r2: 0.2987 - val_loss: 68.8499 - val_keras_r2: 0.1301\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.5636 - keras_r2: 0.3004 - val_loss: 69.1034 - val_keras_r2: 0.1309\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.8259 - keras_r2: 0.3342 - val_loss: 69.3926 - val_keras_r2: 0.1271\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.2699 - keras_r2: 0.3424 - val_loss: 68.7869 - val_keras_r2: 0.1342\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 53.0101 - keras_r2: 0.0644 - val_loss: 68.3286 - val_keras_r2: 0.1378\n",
      "Epoch 18: early stopping\n",
      "[CV] END ...........................n_hidden=4, n_neurons=92; total time=  13.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1499.4368 - keras_r2: -19.2566 - val_loss: 353.9469 - val_keras_r2: -3.5928\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 172.1395 - keras_r2: -1.1607 - val_loss: 113.7897 - val_keras_r2: -0.3375\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 108.0536 - keras_r2: -0.3821 - val_loss: 100.6415 - val_keras_r2: -0.1779\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 91.3693 - keras_r2: -0.2258 - val_loss: 94.6012 - val_keras_r2: -0.1111\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 82.6499 - keras_r2: -0.0477 - val_loss: 91.6504 - val_keras_r2: -0.0825\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 77.3437 - keras_r2: 0.0551 - val_loss: 88.0912 - val_keras_r2: -0.0370\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 74.1648 - keras_r2: 0.0562 - val_loss: 86.9431 - val_keras_r2: -0.0225\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 71.1907 - keras_r2: 0.0297 - val_loss: 85.2797 - val_keras_r2: -0.0056\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 69.5050 - keras_r2: -0.0068 - val_loss: 83.9675 - val_keras_r2: 0.0136\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 68.0440 - keras_r2: -0.8993 - val_loss: 82.7896 - val_keras_r2: 0.0290\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.8900 - keras_r2: 0.1624 - val_loss: 82.0261 - val_keras_r2: 0.0348\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.0119 - keras_r2: 0.1833 - val_loss: 81.6900 - val_keras_r2: 0.0428\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.3593 - keras_r2: 0.1096 - val_loss: 80.5835 - val_keras_r2: 0.0555\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.6129 - keras_r2: 0.1594 - val_loss: 81.0935 - val_keras_r2: 0.0413\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.1012 - keras_r2: -3165338.5000 - val_loss: 79.6830 - val_keras_r2: 0.0614\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4072 - keras_r2: 0.2141 - val_loss: 79.5616 - val_keras_r2: 0.0662\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.1093 - keras_r2: 0.2225 - val_loss: 79.5351 - val_keras_r2: 0.0653\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.5327 - keras_r2: 0.2267 - val_loss: 79.0608 - val_keras_r2: 0.0692\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.6744 - keras_r2: 0.2229 - val_loss: 78.3875 - val_keras_r2: 0.0793\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.8757 - keras_r2: 0.2361 - val_loss: 78.5445 - val_keras_r2: 0.0781\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.6895 - keras_r2: -2189911.5000 - val_loss: 77.8588 - val_keras_r2: 0.0789\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.4158 - keras_r2: -0.1207 - val_loss: 78.1511 - val_keras_r2: 0.0784\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.2014 - keras_r2: 0.2527 - val_loss: 77.7523 - val_keras_r2: 0.0835\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 60.9653 - keras_r2: 0.1353 - val_loss: 78.6850 - val_keras_r2: 0.0674\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.9978 - keras_r2: 0.2230 - val_loss: 77.3145 - val_keras_r2: 0.0889\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6925 - keras_r2: 0.2450 - val_loss: 76.9622 - val_keras_r2: 0.0926\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.4551 - keras_r2: 0.1789 - val_loss: 78.5081 - val_keras_r2: 0.0749\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.4987 - keras_r2: 0.2486 - val_loss: 78.0261 - val_keras_r2: 0.0819\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.5678 - keras_r2: 0.2572 - val_loss: 77.4492 - val_keras_r2: 0.0863\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.0977 - keras_r2: 0.2459 - val_loss: 78.2131 - val_keras_r2: 0.0742\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8963 - keras_r2: 0.2679 - val_loss: 77.2419 - val_keras_r2: 0.0887\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.2398 - keras_r2: 0.2483 - val_loss: 78.3577 - val_keras_r2: 0.0781\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8376 - keras_r2: 0.2478 - val_loss: 77.2979 - val_keras_r2: 0.0891\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.9036 - keras_r2: -2883941.5000 - val_loss: 78.6050 - val_keras_r2: 0.0717\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.6484 - keras_r2: 0.2171 - val_loss: 77.1962 - val_keras_r2: 0.0889\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.9058 - keras_r2: 0.2508 - val_loss: 78.2850 - val_keras_r2: 0.0764\n",
      "Epoch 36: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=15; total time=  21.9s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 10ms/step - loss: 1288.3240 - keras_r2: -16.3605 - val_loss: 220.0773 - val_keras_r2: -1.7784\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 152.9275 - keras_r2: -1.1328 - val_loss: 109.9482 - val_keras_r2: -0.3131\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 95.7013 - keras_r2: -0.3333 - val_loss: 95.2914 - val_keras_r2: -0.1368\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 82.3717 - keras_r2: -0.0283 - val_loss: 88.6205 - val_keras_r2: -0.0520\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 75.9692 - keras_r2: 0.0519 - val_loss: 84.9716 - val_keras_r2: -0.0130\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 72.4332 - keras_r2: 0.0870 - val_loss: 82.9185 - val_keras_r2: 0.0118\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 69.9308 - keras_r2: 0.0569 - val_loss: 81.2468 - val_keras_r2: 0.0326\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.0908 - keras_r2: 0.1555 - val_loss: 80.8895 - val_keras_r2: 0.0373\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 67.1987 - keras_r2: 0.1704 - val_loss: 79.3720 - val_keras_r2: 0.0486\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.1922 - keras_r2: 0.1855 - val_loss: 79.0235 - val_keras_r2: 0.0558\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.4491 - keras_r2: -0.0682 - val_loss: 78.3843 - val_keras_r2: 0.0628\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.8084 - keras_r2: 0.1931 - val_loss: 78.5271 - val_keras_r2: 0.0638\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 64.1666 - keras_r2: 0.0630 - val_loss: 77.8225 - val_keras_r2: 0.0704\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.1115 - keras_r2: 0.1700 - val_loss: 77.7764 - val_keras_r2: 0.0641\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4753 - keras_r2: 0.2004 - val_loss: 77.9308 - val_keras_r2: 0.0698\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.1230 - keras_r2: 0.2256 - val_loss: 76.7353 - val_keras_r2: 0.0801\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.6767 - keras_r2: 0.2280 - val_loss: 77.5068 - val_keras_r2: 0.0675\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.4667 - keras_r2: 0.1929 - val_loss: 77.2322 - val_keras_r2: 0.0735\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.8667 - keras_r2: 0.2265 - val_loss: 77.5237 - val_keras_r2: 0.0668\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.1195 - keras_r2: 0.2271 - val_loss: 76.7593 - val_keras_r2: 0.0806\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.7040 - keras_r2: 0.2433 - val_loss: 77.1550 - val_keras_r2: 0.0760\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.4077 - keras_r2: 0.2037 - val_loss: 76.3404 - val_keras_r2: 0.0809\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.2670 - keras_r2: 0.2162 - val_loss: 76.8147 - val_keras_r2: 0.0800\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.0361 - keras_r2: 0.2471 - val_loss: 75.9336 - val_keras_r2: 0.0891\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.0004 - keras_r2: 0.2519 - val_loss: 76.5392 - val_keras_r2: 0.0815\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9163 - keras_r2: 0.2453 - val_loss: 76.2051 - val_keras_r2: 0.0836\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6993 - keras_r2: 0.2548 - val_loss: 76.2157 - val_keras_r2: 0.0830\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.5110 - keras_r2: 0.2601 - val_loss: 77.0437 - val_keras_r2: 0.0743\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6361 - keras_r2: 0.1877 - val_loss: 77.5913 - val_keras_r2: 0.0695\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.2690 - keras_r2: 0.2528 - val_loss: 78.4868 - val_keras_r2: 0.0585\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.2065 - keras_r2: -793511.1875 - val_loss: 76.9924 - val_keras_r2: 0.0768\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1089 - keras_r2: 0.1071 - val_loss: 77.2665 - val_keras_r2: 0.0637\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8911 - keras_r2: 0.2373 - val_loss: 76.5854 - val_keras_r2: 0.0770\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.6876 - keras_r2: 0.2709 - val_loss: 76.3827 - val_keras_r2: 0.0786\n",
      "Epoch 34: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=15; total time=  22.2s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1400.7937 - keras_r2: -17.2841 - val_loss: 236.1644 - val_keras_r2: -2.0002\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 153.0857 - keras_r2: -1.0459 - val_loss: 102.7304 - val_keras_r2: -0.2379\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 99.4260 - keras_r2: -0.2659 - val_loss: 93.5010 - val_keras_r2: -0.1099\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 86.9373 - keras_r2: -0.0664 - val_loss: 89.0416 - val_keras_r2: -0.0520\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 80.2572 - keras_r2: 0.0027 - val_loss: 87.0489 - val_keras_r2: -0.0287\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 76.3348 - keras_r2: 0.0620 - val_loss: 85.3128 - val_keras_r2: -0.0038\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 73.6037 - keras_r2: 0.0882 - val_loss: 83.9800 - val_keras_r2: 0.0127\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 71.3349 - keras_r2: -6114259.0000 - val_loss: 82.9369 - val_keras_r2: 0.0261\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 69.9881 - keras_r2: 0.1353 - val_loss: 82.2980 - val_keras_r2: 0.0388\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 68.3562 - keras_r2: 0.1432 - val_loss: 81.0606 - val_keras_r2: 0.0523\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 67.4406 - keras_r2: 0.1714 - val_loss: 80.6112 - val_keras_r2: 0.0585\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.5836 - keras_r2: 0.1823 - val_loss: 80.7033 - val_keras_r2: 0.0538\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 66.0231 - keras_r2: -0.0270 - val_loss: 78.7969 - val_keras_r2: 0.0794\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.5027 - keras_r2: 0.1982 - val_loss: 78.9594 - val_keras_r2: 0.0801\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 64.6890 - keras_r2: 0.2054 - val_loss: 79.7440 - val_keras_r2: 0.0715\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.3244 - keras_r2: 0.1425 - val_loss: 79.5228 - val_keras_r2: 0.0736\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.8994 - keras_r2: 0.2119 - val_loss: 77.7661 - val_keras_r2: 0.0940\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.4150 - keras_r2: 0.1912 - val_loss: 77.9747 - val_keras_r2: 0.0895\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4747 - keras_r2: -4138630.5000 - val_loss: 78.0490 - val_keras_r2: 0.0923\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.6577 - keras_r2: 0.2341 - val_loss: 77.5214 - val_keras_r2: 0.0971\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.2421 - keras_r2: 0.1432 - val_loss: 79.5235 - val_keras_r2: 0.0743\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.1287 - keras_r2: 0.2511 - val_loss: 77.3267 - val_keras_r2: 0.0991\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.8332 - keras_r2: 0.2329 - val_loss: 77.2610 - val_keras_r2: 0.0978\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.6815 - keras_r2: 0.2359 - val_loss: 76.5678 - val_keras_r2: 0.1064\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.2876 - keras_r2: 0.2439 - val_loss: 76.9882 - val_keras_r2: 0.0997\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.4259 - keras_r2: 0.2379 - val_loss: 77.3766 - val_keras_r2: 0.1005\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.7797 - keras_r2: 0.2334 - val_loss: 77.7220 - val_keras_r2: 0.0887\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.8430 - keras_r2: 0.2408 - val_loss: 77.3423 - val_keras_r2: 0.0980\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.7212 - keras_r2: 0.2553 - val_loss: 77.2933 - val_keras_r2: 0.0998\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.4491 - keras_r2: 0.1579 - val_loss: 77.3476 - val_keras_r2: 0.0968\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1827 - keras_r2: -0.0874 - val_loss: 78.1095 - val_keras_r2: 0.0844\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.1923 - keras_r2: -2.1670 - val_loss: 78.1017 - val_keras_r2: 0.0936\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1592 - keras_r2: 0.2673 - val_loss: 76.9322 - val_keras_r2: 0.1011\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.1056 - keras_r2: 0.2586 - val_loss: 76.4015 - val_keras_r2: 0.1103\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.6992 - keras_r2: 0.2582 - val_loss: 77.0490 - val_keras_r2: 0.0989\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.5530 - keras_r2: -2943432.5000 - val_loss: 76.6339 - val_keras_r2: 0.1053\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.3250 - keras_r2: 0.2742 - val_loss: 76.9598 - val_keras_r2: 0.1010\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.4866 - keras_r2: 0.2701 - val_loss: 76.6927 - val_keras_r2: 0.1067\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.3888 - keras_r2: 0.2844 - val_loss: 77.8454 - val_keras_r2: 0.0966\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.2065 - keras_r2: 0.2850 - val_loss: 77.6101 - val_keras_r2: 0.0959\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.0514 - keras_r2: 0.2811 - val_loss: 76.8082 - val_keras_r2: 0.1029\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.9131 - keras_r2: 0.2819 - val_loss: 76.7162 - val_keras_r2: 0.1039\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.3002 - keras_r2: -3412419.2500 - val_loss: 78.4084 - val_keras_r2: 0.0911\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.7084 - keras_r2: 0.2846 - val_loss: 77.4407 - val_keras_r2: 0.1019\n",
      "Epoch 44: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=15; total time=  27.4s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1218.9742 - keras_r2: -15.0898 - val_loss: 179.2620 - val_keras_r2: -1.2562\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 151.1974 - keras_r2: -1.2843 - val_loss: 107.6819 - val_keras_r2: -0.3153\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 105.0995 - keras_r2: -0.5140 - val_loss: 95.2535 - val_keras_r2: -0.1491\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 88.8668 - keras_r2: -0.1075 - val_loss: 89.1606 - val_keras_r2: -0.0689\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 79.9899 - keras_r2: 0.0126 - val_loss: 85.9970 - val_keras_r2: -0.0304\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 74.3807 - keras_r2: -3429535.2500 - val_loss: 84.2916 - val_keras_r2: -0.0100\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 71.2463 - keras_r2: 0.1225 - val_loss: 81.6205 - val_keras_r2: 0.0255\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 69.0965 - keras_r2: 0.1566 - val_loss: 80.4459 - val_keras_r2: 0.0426\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 67.3314 - keras_r2: -0.0828 - val_loss: 79.0835 - val_keras_r2: 0.0599\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.3002 - keras_r2: -1.4107 - val_loss: 78.3549 - val_keras_r2: 0.0715\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.5789 - keras_r2: 0.1853 - val_loss: 77.7772 - val_keras_r2: 0.0786\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.8260 - keras_r2: 0.2107 - val_loss: 77.1966 - val_keras_r2: 0.0854\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.1626 - keras_r2: 0.2017 - val_loss: 76.5359 - val_keras_r2: 0.0929\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.8592 - keras_r2: 0.2149 - val_loss: 77.2887 - val_keras_r2: 0.0830\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.4028 - keras_r2: 0.2346 - val_loss: 76.4942 - val_keras_r2: 0.0954\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.0634 - keras_r2: 0.2273 - val_loss: 76.1776 - val_keras_r2: 0.1022\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.5006 - keras_r2: 0.2238 - val_loss: 76.4253 - val_keras_r2: 0.0974\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.4749 - keras_r2: 0.2407 - val_loss: 75.7060 - val_keras_r2: 0.1073\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.1206 - keras_r2: 0.1165 - val_loss: 75.3246 - val_keras_r2: 0.1091\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.9558 - keras_r2: 0.2442 - val_loss: 75.4302 - val_keras_r2: 0.1088\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.9879 - keras_r2: 0.1977 - val_loss: 74.9769 - val_keras_r2: 0.1172\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.4660 - keras_r2: 0.2361 - val_loss: 75.3219 - val_keras_r2: 0.1100\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.1628 - keras_r2: 0.2616 - val_loss: 74.9179 - val_keras_r2: 0.1191\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.9824 - keras_r2: 0.2606 - val_loss: 75.1557 - val_keras_r2: 0.1147\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.8566 - keras_r2: 0.2585 - val_loss: 74.9493 - val_keras_r2: 0.1158\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6544 - keras_r2: 0.2577 - val_loss: 75.2040 - val_keras_r2: 0.1096\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.5045 - keras_r2: 0.2633 - val_loss: 74.8035 - val_keras_r2: 0.1179\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.3857 - keras_r2: 0.2544 - val_loss: 75.3773 - val_keras_r2: 0.1131\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.3950 - keras_r2: 0.2667 - val_loss: 74.9975 - val_keras_r2: 0.1141\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.1429 - keras_r2: 0.2648 - val_loss: 74.9823 - val_keras_r2: 0.1164\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.0714 - keras_r2: 0.1762 - val_loss: 74.7215 - val_keras_r2: 0.1186\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.9128 - keras_r2: -1.2632 - val_loss: 74.5237 - val_keras_r2: 0.1226\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8548 - keras_r2: 0.2680 - val_loss: 75.2837 - val_keras_r2: 0.1096\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.9283 - keras_r2: 0.2723 - val_loss: 74.8481 - val_keras_r2: 0.1147\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.9475 - keras_r2: 0.2700 - val_loss: 75.0394 - val_keras_r2: 0.1178\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.4156 - keras_r2: 0.2718 - val_loss: 76.3779 - val_keras_r2: 0.0919\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.4540 - keras_r2: 0.2681 - val_loss: 74.5805 - val_keras_r2: 0.1212\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.5148 - keras_r2: 0.2721 - val_loss: 75.0462 - val_keras_r2: 0.1174\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.2280 - keras_r2: 0.2668 - val_loss: 75.2725 - val_keras_r2: 0.1095\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.2939 - keras_r2: 0.1767 - val_loss: 75.2356 - val_keras_r2: 0.1137\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.3371 - keras_r2: 0.2771 - val_loss: 75.7140 - val_keras_r2: 0.1014\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.0695 - keras_r2: 0.2782 - val_loss: 75.0808 - val_keras_r2: 0.1124\n",
      "Epoch 42: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=15; total time=  26.6s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 1191.9597 - keras_r2: -14.2316 - val_loss: 163.3168 - val_keras_r2: -1.1616\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 131.5353 - keras_r2: -0.6874 - val_loss: 94.6605 - val_keras_r2: -0.2181\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 96.6338 - keras_r2: -0.2127 - val_loss: 87.5409 - val_keras_r2: -0.1191\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 86.1328 - keras_r2: -0.0765 - val_loss: 82.9717 - val_keras_r2: -0.0573\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 80.1431 - keras_r2: -0.1364 - val_loss: 80.0520 - val_keras_r2: -0.0181\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 76.1968 - keras_r2: 0.0553 - val_loss: 78.3250 - val_keras_r2: 0.0031\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 73.2527 - keras_r2: 0.1042 - val_loss: 76.6053 - val_keras_r2: 0.0271\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 71.2511 - keras_r2: 0.0401 - val_loss: 75.2500 - val_keras_r2: 0.0451\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 69.6725 - keras_r2: 0.1229 - val_loss: 74.0436 - val_keras_r2: 0.0597\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 68.6097 - keras_r2: 0.1167 - val_loss: 73.3763 - val_keras_r2: 0.0723\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 67.6230 - keras_r2: 0.1598 - val_loss: 72.5564 - val_keras_r2: 0.0801\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.6038 - keras_r2: 0.1862 - val_loss: 72.4237 - val_keras_r2: 0.0808\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 65.8134 - keras_r2: 0.1879 - val_loss: 71.9741 - val_keras_r2: 0.0900\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.3773 - keras_r2: 0.1909 - val_loss: 71.9168 - val_keras_r2: 0.0872\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.7786 - keras_r2: 0.2112 - val_loss: 71.5950 - val_keras_r2: 0.0878\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 64.3180 - keras_r2: 0.1746 - val_loss: 70.0901 - val_keras_r2: 0.1110\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.7485 - keras_r2: 0.2289 - val_loss: 70.2852 - val_keras_r2: 0.1099\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.5172 - keras_r2: -0.4803 - val_loss: 69.9972 - val_keras_r2: 0.1132\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.3438 - keras_r2: 0.2274 - val_loss: 70.4178 - val_keras_r2: 0.1048\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.8706 - keras_r2: 0.2119 - val_loss: 69.8973 - val_keras_r2: 0.1174\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.6222 - keras_r2: 0.2051 - val_loss: 69.4387 - val_keras_r2: 0.1226\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.2593 - keras_r2: 0.2382 - val_loss: 68.8386 - val_keras_r2: 0.1259\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.0789 - keras_r2: 0.2228 - val_loss: 69.4404 - val_keras_r2: 0.1227\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.8889 - keras_r2: 0.2442 - val_loss: 69.1922 - val_keras_r2: 0.1260\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.7475 - keras_r2: 0.2437 - val_loss: 68.5262 - val_keras_r2: 0.1316\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.4518 - keras_r2: 0.2450 - val_loss: 69.6361 - val_keras_r2: 0.1131\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.9676 - keras_r2: 0.2120 - val_loss: 67.8180 - val_keras_r2: 0.1402\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9007 - keras_r2: 0.2432 - val_loss: 67.9445 - val_keras_r2: 0.1392\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.6849 - keras_r2: 0.2573 - val_loss: 67.7543 - val_keras_r2: 0.1423\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.4902 - keras_r2: 0.2615 - val_loss: 67.6207 - val_keras_r2: 0.1425\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.3621 - keras_r2: 0.2358 - val_loss: 67.4287 - val_keras_r2: 0.1450\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.3564 - keras_r2: 0.2610 - val_loss: 67.4327 - val_keras_r2: 0.1466\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.9688 - keras_r2: 0.2643 - val_loss: 67.3645 - val_keras_r2: 0.1457\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.7745 - keras_r2: 0.2685 - val_loss: 68.2909 - val_keras_r2: 0.1351\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8822 - keras_r2: 0.2571 - val_loss: 66.5434 - val_keras_r2: 0.1562\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.6608 - keras_r2: 0.2720 - val_loss: 66.9149 - val_keras_r2: 0.1518\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.7021 - keras_r2: 0.2731 - val_loss: 67.2672 - val_keras_r2: 0.1482\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.7573 - keras_r2: 0.2360 - val_loss: 66.8723 - val_keras_r2: 0.1518\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.4036 - keras_r2: 0.2751 - val_loss: 67.1938 - val_keras_r2: 0.1480\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.1946 - keras_r2: 0.2261 - val_loss: 66.7510 - val_keras_r2: 0.1552\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.2076 - keras_r2: 0.2767 - val_loss: 66.6820 - val_keras_r2: 0.1570\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.0100 - keras_r2: 0.2757 - val_loss: 66.9418 - val_keras_r2: 0.1527\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 59.0062 - keras_r2: 0.2725 - val_loss: 66.8299 - val_keras_r2: 0.1540\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.9932 - keras_r2: 0.2865 - val_loss: 66.6893 - val_keras_r2: 0.1553\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.7042 - keras_r2: 0.2821 - val_loss: 66.5500 - val_keras_r2: 0.1582\n",
      "Epoch 45: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=15; total time=  29.1s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 644.5032 - keras_r2: -7.5185 - val_loss: 108.5144 - val_keras_r2: -0.3039\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 126.9653 - keras_r2: -0.6266 - val_loss: 88.7890 - val_keras_r2: -0.0580\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 86.9912 - keras_r2: -0.6024 - val_loss: 84.1151 - val_keras_r2: 3.8387e-04\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 74.9841 - keras_r2: -2.0801 - val_loss: 80.9113 - val_keras_r2: 0.0463\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 69.5152 - keras_r2: 0.1410 - val_loss: 79.9934 - val_keras_r2: 0.0568\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.8726 - keras_r2: 0.1532 - val_loss: 79.3327 - val_keras_r2: 0.0659\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 64.8542 - keras_r2: 0.2046 - val_loss: 79.2399 - val_keras_r2: 0.0635\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 63.4681 - keras_r2: 0.2073 - val_loss: 81.6077 - val_keras_r2: 0.0375\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 62.7991 - keras_r2: 0.2259 - val_loss: 77.9716 - val_keras_r2: 0.0767\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.8637 - keras_r2: 0.2009 - val_loss: 78.0470 - val_keras_r2: 0.0746\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.0996 - keras_r2: -0.2950 - val_loss: 76.8358 - val_keras_r2: 0.0934\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 60.9124 - keras_r2: 0.2487 - val_loss: 76.2031 - val_keras_r2: 0.0999\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.4464 - keras_r2: 0.2455 - val_loss: 77.1329 - val_keras_r2: 0.0869\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.4122 - keras_r2: 0.2629 - val_loss: 77.2105 - val_keras_r2: 0.0830\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.1635 - keras_r2: 0.2791 - val_loss: 77.4774 - val_keras_r2: 0.0802\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.5806 - keras_r2: -0.5236 - val_loss: 80.7485 - val_keras_r2: 0.0451\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.3990 - keras_r2: 0.2876 - val_loss: 76.8125 - val_keras_r2: 0.0901\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.9247 - keras_r2: 0.2913 - val_loss: 76.3562 - val_keras_r2: 0.0906\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.7189 - keras_r2: 0.2796 - val_loss: 76.2097 - val_keras_r2: 0.0964\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.2090 - keras_r2: 0.2971 - val_loss: 76.7985 - val_keras_r2: 0.0828\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.9867 - keras_r2: 0.2627 - val_loss: 77.1388 - val_keras_r2: 0.0810\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.3414 - keras_r2: 0.3050 - val_loss: 78.4607 - val_keras_r2: 0.0662\n",
      "Epoch 22: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=36; total time=  15.6s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 795.3879 - keras_r2: -9.7449 - val_loss: 104.6226 - val_keras_r2: -0.2786\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 113.5584 - keras_r2: -0.4063 - val_loss: 86.9216 - val_keras_r2: -0.0499\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 84.4008 - keras_r2: -0.0538 - val_loss: 85.4366 - val_keras_r2: -0.0320\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 75.1058 - keras_r2: 0.0750 - val_loss: 81.4256 - val_keras_r2: 0.0310\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 71.2300 - keras_r2: 0.1217 - val_loss: 79.5593 - val_keras_r2: 0.0545\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 68.4048 - keras_r2: 0.1676 - val_loss: 79.1067 - val_keras_r2: 0.0558\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 66.3088 - keras_r2: 0.1777 - val_loss: 78.7531 - val_keras_r2: 0.0658\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.4528 - keras_r2: 0.1764 - val_loss: 77.4553 - val_keras_r2: 0.0789\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 64.0374 - keras_r2: 0.2134 - val_loss: 76.4325 - val_keras_r2: 0.0918\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 63.2094 - keras_r2: 0.1804 - val_loss: 77.4108 - val_keras_r2: 0.0813\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 62.5579 - keras_r2: 0.2300 - val_loss: 76.4430 - val_keras_r2: 0.0838\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.6311 - keras_r2: 0.2352 - val_loss: 77.0507 - val_keras_r2: 0.0858\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 61.7722 - keras_r2: 0.2396 - val_loss: 76.0733 - val_keras_r2: 0.0908\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 61.5163 - keras_r2: 0.2363 - val_loss: 75.2921 - val_keras_r2: 0.1023\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 60.6631 - keras_r2: 0.2538 - val_loss: 76.4098 - val_keras_r2: 0.0826\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 59.8671 - keras_r2: -0.4425 - val_loss: 74.5248 - val_keras_r2: 0.1070\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 59.8727 - keras_r2: 0.2573 - val_loss: 76.3390 - val_keras_r2: 0.0918\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 59.6273 - keras_r2: 0.2465 - val_loss: 74.9564 - val_keras_r2: 0.1055\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.9139 - keras_r2: 0.2717 - val_loss: 74.8571 - val_keras_r2: 0.1052\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.8286 - keras_r2: 0.2610 - val_loss: 75.2386 - val_keras_r2: 0.1026\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 58.6098 - keras_r2: 0.1894 - val_loss: 77.2211 - val_keras_r2: 0.0653\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.8993 - keras_r2: 0.2614 - val_loss: 76.8572 - val_keras_r2: 0.0758\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 57.9920 - keras_r2: 0.2866 - val_loss: 75.1517 - val_keras_r2: 0.1028\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.9372 - keras_r2: 0.2860 - val_loss: 74.8399 - val_keras_r2: 0.1057\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.7391 - keras_r2: 0.2771 - val_loss: 77.0492 - val_keras_r2: 0.0644\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 57.8174 - keras_r2: 0.2841 - val_loss: 76.2113 - val_keras_r2: 0.0809\n",
      "Epoch 26: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=36; total time=  19.7s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 7ms/step - loss: 810.8517 - keras_r2: -9.4113 - val_loss: 105.7011 - val_keras_r2: -0.2525\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 106.4176 - keras_r2: -0.3662 - val_loss: 86.0090 - val_keras_r2: -0.0128\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 79.7182 - keras_r2: 0.0310 - val_loss: 81.0751 - val_keras_r2: 0.0510\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 71.4529 - keras_r2: 0.1108 - val_loss: 80.2319 - val_keras_r2: 0.0542\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 67.5860 - keras_r2: 0.1015 - val_loss: 79.8232 - val_keras_r2: 0.0674\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 65.7422 - keras_r2: 0.1725 - val_loss: 77.3731 - val_keras_r2: 0.0903\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 63.8656 - keras_r2: 0.2155 - val_loss: 77.0035 - val_keras_r2: 0.0929\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 62.6154 - keras_r2: 0.2295 - val_loss: 76.5485 - val_keras_r2: 0.1073\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.8684 - keras_r2: 0.0947 - val_loss: 77.1061 - val_keras_r2: 0.0926\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 61.5151 - keras_r2: 0.2509 - val_loss: 75.3884 - val_keras_r2: 0.1184\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.9459 - keras_r2: 0.2427 - val_loss: 75.7310 - val_keras_r2: 0.1133\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.6121 - keras_r2: 0.2411 - val_loss: 76.3818 - val_keras_r2: 0.1068\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.8069 - keras_r2: -0.1282 - val_loss: 78.5438 - val_keras_r2: 0.0844\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7295 - keras_r2: 0.2601 - val_loss: 75.0755 - val_keras_r2: 0.1155\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 59.7649 - keras_r2: 0.2641 - val_loss: 75.3868 - val_keras_r2: 0.1193\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 58.9387 - keras_r2: 0.2768 - val_loss: 75.8759 - val_keras_r2: 0.1073\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 58.6151 - keras_r2: 0.2894 - val_loss: 75.1426 - val_keras_r2: 0.1190\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 58.2446 - keras_r2: 0.2911 - val_loss: 75.3911 - val_keras_r2: 0.1169\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 58.0588 - keras_r2: 0.2881 - val_loss: 75.7657 - val_keras_r2: 0.1133\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.6575 - keras_r2: 0.2982 - val_loss: 74.9782 - val_keras_r2: 0.1138\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.7702 - keras_r2: 0.2784 - val_loss: 75.4481 - val_keras_r2: 0.1154\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.1859 - keras_r2: 0.2687 - val_loss: 75.4794 - val_keras_r2: 0.1078\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 57.5835 - keras_r2: 0.2970 - val_loss: 74.5098 - val_keras_r2: 0.1226\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 57.3294 - keras_r2: 0.2879 - val_loss: 76.1388 - val_keras_r2: 0.1057\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.7861 - keras_r2: 0.3121 - val_loss: 75.5730 - val_keras_r2: 0.1079\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.8750 - keras_r2: 0.3106 - val_loss: 75.0033 - val_keras_r2: 0.1168\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 56.1921 - keras_r2: 0.2424 - val_loss: 75.8700 - val_keras_r2: 0.1120\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 55.9048 - keras_r2: 0.3092 - val_loss: 75.4551 - val_keras_r2: 0.1120\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 56.0190 - keras_r2: 0.3185 - val_loss: 74.4893 - val_keras_r2: 0.1232\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 56.2607 - keras_r2: 0.3002 - val_loss: 74.9823 - val_keras_r2: 0.1159\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.4289 - keras_r2: 0.3254 - val_loss: 75.3001 - val_keras_r2: 0.1135\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 55.1309 - keras_r2: 0.3283 - val_loss: 75.8225 - val_keras_r2: 0.1080\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.9455 - keras_r2: 0.3186 - val_loss: 74.7741 - val_keras_r2: 0.1175\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 55.4519 - keras_r2: -0.8120 - val_loss: 75.3863 - val_keras_r2: 0.1077\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 54.7263 - keras_r2: 0.2463 - val_loss: 75.5836 - val_keras_r2: 0.1041\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.9428 - keras_r2: -13482375.0000 - val_loss: 76.9541 - val_keras_r2: 0.0963\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 54.5617 - keras_r2: 0.3286 - val_loss: 75.5267 - val_keras_r2: 0.1069\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 53.6997 - keras_r2: 0.3430 - val_loss: 75.8382 - val_keras_r2: 0.1072\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 53.6504 - keras_r2: 0.3450 - val_loss: 78.6870 - val_keras_r2: 0.0712\n",
      "Epoch 39: early stopping\n",
      "[CV] END ...........................n_hidden=3, n_neurons=36; total time=  27.3s\n",
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 5ms/step - loss: 765.1931 - keras_r2: -9.1223 - val_loss: 114.5013 - val_keras_r2: -0.3467\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 127.8482 - keras_r2: -0.6974 - val_loss: 87.5148 - val_keras_r2: -0.0404\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 87.4463 - keras_r2: -0.2848 - val_loss: 83.8485 - val_keras_r2: 0.0025\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 75.9540 - keras_r2: 0.0638 - val_loss: 81.8939 - val_keras_r2: 0.0287\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 70.7522 - keras_r2: 0.1051 - val_loss: 81.4398 - val_keras_r2: 0.0369\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 68.4165 - keras_r2: 0.1675 - val_loss: 79.0609 - val_keras_r2: 0.0636\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 65.9226 - keras_r2: 0.0436 - val_loss: 78.8989 - val_keras_r2: 0.0682\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 64.4791 - keras_r2: 0.1973 - val_loss: 78.4278 - val_keras_r2: 0.0619\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 63.6666 - keras_r2: 0.2186 - val_loss: 77.7838 - val_keras_r2: 0.0741\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 62.5774 - keras_r2: 0.2207 - val_loss: 77.4040 - val_keras_r2: 0.0858\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 61.9880 - keras_r2: 0.2236 - val_loss: 76.7661 - val_keras_r2: 0.0943\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 61.2782 - keras_r2: 0.2551 - val_loss: 76.4793 - val_keras_r2: 0.0956\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 60.5482 - keras_r2: 0.2256 - val_loss: 77.2637 - val_keras_r2: 0.0831\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 59.9209 - keras_r2: 0.2719 - val_loss: 77.2934 - val_keras_r2: 0.0779\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 59.7050 - keras_r2: 0.2720 - val_loss: 75.5769 - val_keras_r2: 0.1046\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 2s 11ms/step - loss: 59.6781 - keras_r2: 0.2692 - val_loss: 76.3103 - val_keras_r2: 0.0939\n",
      "Epoch 17/100\n",
      "162/176 [==========================>...] - ETA: 0s - loss: 58.8827 - keras_r2: 0.2695"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "param_distribs_1 = {\n",
    "    \"n_hidden\": [1, 2, 3, 4, 5],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "}\n",
    "\n",
    "rnd_search_cv_1 = RandomizedSearchCV(keras_class, param_distribs_1, n_iter=10, cv=kFold, verbose=2, scoring=\"r2\")\n",
    "rnd_search_cv_1.fit(X_train_keras, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
    "rnd_search_cv_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_174 (Dense)           (None, 89)                5963      \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 89)                8010      \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 1)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,063\n",
      "Trainable params: 14,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = History()\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(keras.layers.InputLayer(input_shape=X_train_keras.shape[1],))\n",
    "model_1.add(Dense(89,activation=\"relu\"))\n",
    "model_1.add(Dense(89,activation=\"relu\"))\n",
    "model_1.add(Dense(1,activation=\"relu\"))\n",
    "model_1.summary()\n",
    "\n",
    "model_1.compile(loss=\"mean_squared_error\",optimizer=\"Adam\", metrics=[keras_r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6448 - keras_r2: 0.2101 - val_loss: 0.6556 - val_keras_r2: 0.1717\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6465 - keras_r2: 0.2172 - val_loss: 0.6985 - val_keras_r2: 0.0974\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6534 - keras_r2: 0.2130 - val_loss: 0.7119 - val_keras_r2: 0.0870\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6220 - keras_r2: 0.2380 - val_loss: 0.6926 - val_keras_r2: 0.1165\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6158 - keras_r2: 0.2458 - val_loss: 0.7264 - val_keras_r2: 0.0737\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6178 - keras_r2: 0.2584 - val_loss: 0.6536 - val_keras_r2: 0.1641\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6108 - keras_r2: 0.2580 - val_loss: 0.6748 - val_keras_r2: 0.1307\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.6099 - keras_r2: 0.2527 - val_loss: 0.6702 - val_keras_r2: 0.1291\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5927 - keras_r2: 0.2739 - val_loss: 0.6455 - val_keras_r2: 0.1792\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5854 - keras_r2: 0.2912 - val_loss: 0.6506 - val_keras_r2: 0.1678\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5783 - keras_r2: 0.2960 - val_loss: 0.6733 - val_keras_r2: 0.1201\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5744 - keras_r2: 0.2913 - val_loss: 0.6809 - val_keras_r2: 0.1085\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5733 - keras_r2: 0.2954 - val_loss: 0.6806 - val_keras_r2: 0.1221\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5661 - keras_r2: 0.3117 - val_loss: 0.6564 - val_keras_r2: 0.1592\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.5615 - keras_r2: 0.3230 - val_loss: 0.6672 - val_keras_r2: 0.1455\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.5585 - keras_r2: 0.3153 - val_loss: 0.6453 - val_keras_r2: 0.1606\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5512 - keras_r2: 0.3246 - val_loss: 0.6820 - val_keras_r2: 0.1270\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5550 - keras_r2: 0.3237 - val_loss: 0.6638 - val_keras_r2: 0.1332\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5458 - keras_r2: 0.3347 - val_loss: 0.6789 - val_keras_r2: 0.1201\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5344 - keras_r2: 0.3485 - val_loss: 0.6696 - val_keras_r2: 0.1370\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5264 - keras_r2: 0.3589 - val_loss: 0.6811 - val_keras_r2: 0.1180\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5266 - keras_r2: 0.3550 - val_loss: 0.7049 - val_keras_r2: 0.0704\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5231 - keras_r2: 0.3574 - val_loss: 0.6557 - val_keras_r2: 0.1463\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5156 - keras_r2: 0.3765 - val_loss: 0.6805 - val_keras_r2: 0.1118\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5218 - keras_r2: 0.3682 - val_loss: 0.6652 - val_keras_r2: 0.1399\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 0.5079 - keras_r2: 0.3795 - val_loss: 0.7012 - val_keras_r2: 0.0858\n",
      "Epoch 26: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(X_train_keras, y_train, validation_data=(\n",
    "    X_test_keras, y_test), batch_size=32, epochs=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7012 - keras_r2: 0.0858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7012064456939697, 0.08582678437232971]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_test_keras, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'keras_r2', 'val_loss', 'val_keras_r2'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_1.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim(ymin=0, ymax=1)\n",
    "\n",
    "plt.plot(history_1.history['loss'], label=\"loss\")\n",
    "plt.plot(history_1.history['val_loss'], label=\"val_loss \")\n",
    "\n",
    "plt.plot(history_1.history['keras_r2'], label=\"r2\")\n",
    "plt.plot(history_1.history['val_keras_r2'], label=\"val_r2\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
