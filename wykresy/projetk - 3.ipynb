{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": "OK"
            }
          }
        },
        "id": "JcmFU6mZysV_",
        "outputId": "77761a44-9d46-4f92-925f-453e02dd6b19"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9f2b7eb-fbdb-43b6-8ff7-4325bf8afa27\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9f2b7eb-fbdb-43b6-8ff7-4325bf8afa27\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving mymoviedb.csv to mymoviedb (1).csv\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# import io\n",
        "\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7abducvtyrUc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CR9iwtESyrUh"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv(\"mymoviedb.csv\", lineterminator=\"\\n\")\n",
        "# movies = pd.read_csv(io.StringIO(uploaded[\"mymoviedb.csv\"].decode(\"utf-8\")), lineterminator=\"\\n\")\n",
        "movies.drop(movies[movies[\"Vote_Count\"] == 0].index,\n",
        "            inplace=True)  # usun filmy z przyszlosci\n",
        "movies.drop([\"Overview\", \"Popularity\", \"Vote_Count\",\n",
        "            \"Poster_Url\"], axis=1, inplace=True)\n",
        "\n",
        "X = movies.drop(\"Vote_Average\", axis=1)\n",
        "y = movies[\"Vote_Average\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UguCTm5WyrUj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.10, random_state=42)\n",
        "kFold = KFold(n_splits=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8JtAuLDmyrUl"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A6QCs_HAyrUn"
      },
      "outputs": [],
      "source": [
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
        "                                        index=X.columns)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.most_frequent_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG96bRl0yrUp",
        "outputId": "428ec5d5-cfe3-4736-f343-fa698bb3faf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "simple_cat_pipeline = Pipeline([\n",
        "    (\"select_cat\", DataFrameSelector([\"Original_Language\"])),\n",
        "    (\"imputer\", MostFrequentImputer()),\n",
        "    (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
        "])\n",
        "\n",
        "simple_cat_pipeline.fit_transform(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TLXbWimSyrUs"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class DateEncoder(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        cols = []\n",
        "        for col_name in X.columns:\n",
        "            cols.append(X[col_name].map(\n",
        "                lambda x: datetime.strptime(x, \"%Y-%m-%d\").year))\n",
        "            cols.append(X[col_name].map(\n",
        "                lambda x: datetime.strptime(x, \"%Y-%m-%d\").month))\n",
        "        return np.c_[cols].T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ghaoIVyrUu",
        "outputId": "28fe6f91-33ce-4a92-b762-093ff0d24fe5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2015,    1],\n",
              "       [2005,    9],\n",
              "       [1992,    4],\n",
              "       ...,\n",
              "       [1983,    7],\n",
              "       [2015,    7],\n",
              "       [2007,    3]], dtype=int64)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_pipeline = Pipeline([\n",
        "    (\"select_date\", DataFrameSelector([\"Release_Date\"])),\n",
        "    (\"imputer\", MostFrequentImputer()),\n",
        "    (\"date_encoder\", DateEncoder()),\n",
        "])\n",
        "\n",
        "date_pipeline.fit_transform(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zo0dAap8yrUw"
      },
      "outputs": [],
      "source": [
        "class GenreEncoder(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None, delimeter=\",\"):\n",
        "        self.genres = {}\n",
        "        for col in X.columns:\n",
        "            self.genres[col] = set()\n",
        "            for index, row in X.iterrows():\n",
        "                self.genres[col] |= set(\n",
        "                    map(lambda x: x.strip(), row[col].split(delimeter)))\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        encoded = []\n",
        "        returned = []\n",
        "        for col, curr_genres in self.genres.items():\n",
        "            for genre in curr_genres:\n",
        "                encoded.append(X[col].str.contains(genre).astype(int))\n",
        "            returned.append(pd.DataFrame(data=np.c_[encoded].T, columns=self.genres[col]))\n",
        "        return pd.concat(returned, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "xaBWb-_IyrUy",
        "outputId": "21d25fe3-3de0-4d9b-e6c6-6232dfb08656"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Western</th>\n",
              "      <th>Documentary</th>\n",
              "      <th>Crime</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>History</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Science Fiction</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>Music</th>\n",
              "      <th>TV Movie</th>\n",
              "      <th>Family</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Comedy</th>\n",
              "      <th>War</th>\n",
              "      <th>Drama</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8749</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8750</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8751</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8752</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8753</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8754 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Western  Documentary  Crime  Thriller  History  Adventure  \\\n",
              "0           0            0      0         0        0          1   \n",
              "1           0            0      1         1        0          0   \n",
              "2           0            0      0         1        0          0   \n",
              "3           0            0      0         1        0          0   \n",
              "4           0            0      0         0        0          1   \n",
              "...       ...          ...    ...       ...      ...        ...   \n",
              "8749        0            0      1         0        0          1   \n",
              "8750        0            0      0         1        0          0   \n",
              "8751        0            0      1         0        0          1   \n",
              "8752        0            0      0         0        0          0   \n",
              "8753        0            0      0         1        0          0   \n",
              "\n",
              "      Science Fiction  Fantasy  Music  TV Movie  Family  Mystery  Animation  \\\n",
              "0                   1        0      0         0       0        0          0   \n",
              "1                   0        0      0         0       0        0          0   \n",
              "2                   0        1      0         0       0        0          0   \n",
              "3                   0        0      0         0       0        0          0   \n",
              "4                   0        1      0         0       0        0          1   \n",
              "...               ...      ...    ...       ...     ...      ...        ...   \n",
              "8749                0        1      0         0       0        0          0   \n",
              "8750                1        0      0         0       0        0          0   \n",
              "8751                0        0      0         0       0        0          0   \n",
              "8752                0        1      0         0       0        0          1   \n",
              "8753                1        1      0         1       0        0          1   \n",
              "\n",
              "      Horror  Romance  Comedy  War  Drama  Action  \n",
              "0          0        0       0    0      0       1  \n",
              "1          0        0       0    0      1       0  \n",
              "2          1        0       0    0      0       0  \n",
              "3          1        0       0    0      0       0  \n",
              "4          0        0       0    0      0       1  \n",
              "...      ...      ...     ...  ...    ...     ...  \n",
              "8749       0        0       1    0      0       0  \n",
              "8750       0        0       0    0      0       1  \n",
              "8751       0        0       1    0      0       1  \n",
              "8752       0        0       1    0      0       0  \n",
              "8753       1        0       0    0      0       1  \n",
              "\n",
              "[8754 rows x 19 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "genre_pipeline = Pipeline([\n",
        "    (\"select_genre\", DataFrameSelector([\"Genre\"])),\n",
        "    (\"imputer\", MostFrequentImputer()),\n",
        "    (\"genre_encoder\", GenreEncoder()),\n",
        "])\n",
        "\n",
        "genre_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QxHtI7d5yrUz"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from itertools import chain\n",
        "\n",
        "class TitleEncoder(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.genres = {}\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        encoded = []\n",
        "        returned = []\n",
        "        for col in X.columns:\n",
        "            encoded.append(X[col].map(lambda x: bool(re.search(r'\\d', x))).astype(int))  # cyfry w tytule\n",
        "            encoded.append(X[col].map(lambda x: len(x.split()))) # ilosc slow w tytule\n",
        "            encoded.append(X[col].str.contains(\":\").astype(int))  # dwukropek w tytule\n",
        "            encoded.append(X[col].str.contains(\"-\").astype(int))  # pauza w tytule\n",
        "            returned.append(pd.DataFrame(data=np.c_[encoded].T, columns=[f\"{col}_Numbers\", f\"{col}_Len\", f\"{col}_Colon\", f\"{col}_Dash\"]))\n",
        "\n",
        "        return pd.concat(returned, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHOrnr4ByrU1",
        "outputId": "c6ff03ef-f668-4109-c9b3-daa31351b363"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title_Numbers</th>\n",
              "      <th>Title_Len</th>\n",
              "      <th>Title_Colon</th>\n",
              "      <th>Title_Dash</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8749</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8750</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8751</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8752</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8753</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8754 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Title_Numbers  Title_Len  Title_Colon  Title_Dash\n",
              "0                 0          2            0           0\n",
              "1                 0          4            0           0\n",
              "2                 0          1            0           0\n",
              "3                 0          3            0           0\n",
              "4                 0          6            1           0\n",
              "...             ...        ...          ...         ...\n",
              "8749              0          2            0           0\n",
              "8750              0          2            0           0\n",
              "8751              0          3            0           0\n",
              "8752              0          5            1           0\n",
              "8753              0          5            1           0\n",
              "\n",
              "[8754 rows x 4 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "title_pipeline = Pipeline([\n",
        "    (\"select_title\", DataFrameSelector([\"Title\"])),\n",
        "    (\"imputer\", MostFrequentImputer()),\n",
        "    (\"title_encoder\", TitleEncoder()),\n",
        "])\n",
        "\n",
        "title_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1Bzmw2iLyrU1"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
        "    (\"simple_cat_pipeline\", simple_cat_pipeline),\n",
        "    (\"date_pipeline\", date_pipeline),\n",
        "    (\"genre_pipeline\", genre_pipeline),\n",
        "    (\"title_pipeline\", title_pipeline),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imS6o3LWyrU2",
        "outputId": "1185a712-79f6-4751-c053-f3daf313189f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8754, 66)\n",
            "[[0. 0. 0. ... 2. 0. 0.]\n",
            " [0. 0. 0. ... 4. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 3. 0. 0.]\n",
            " [0. 0. 0. ... 5. 1. 0.]\n",
            " [0. 0. 0. ... 5. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(preprocess_pipeline.transform(X_train).shape)\n",
        "print(preprocess_pipeline.transform(X_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSFtlX9M9qdb"
      },
      "source": [
        "**Wizualizacja danych**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIhY1EelOeqD"
      },
      "source": [
        "1. Ilość wystąpień poszczególnych gatunków"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "KCRu_zne9wht",
        "outputId": "dd6587e8-a9cf-4f6a-9c6b-2fa955eb87c0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "genres_data = genre_pipeline.transform(movies).sum().to_frame().sort_values(0, ascending=False).transpose()\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.barh(y=genres_data.columns, width=genres_data.iloc[0])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jak widać, najpopularniejszym gatunkiem (lub jednym z gatunków) dla filmów ze zbioru danych jest dramat (ok. 42% filmów), na drugim miejscu jest komedia (ok. 35% filmów) natomiast na trzecim filmy akcji (ok. 31% filmów).\n",
        "\n",
        "Jeśli chodzi o najmniej popularne gatunki to western, film dokumentalny oraz film telewizyjny - każdy z nich występuje jedynie w ok. 1% filmów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-aIx3K9Pahx"
      },
      "source": [
        "2. Ilość filmów w (oryginalnie) poszczególnych językach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RRzi_fl4PlMT",
        "outputId": "dd470097-50e7-4e5c-dc63-e6266b3670fb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "lang_data = pd.get_dummies(movies[\"Original_Language\"]).sum().to_frame().sort_values(0, ascending=False).transpose()\n",
        "\n",
        "plt.figure(figsize=(6,10))\n",
        "plt.barh(lang_data.columns, lang_data.iloc[0])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jak wynika z wykresu, przeważająca większość filmów w zbiorze danych jest oryginalnie w języku angielskim. Oznacza to, że ilość danych treningowych z innymi językami będzie stosunkowo mała, a co za tym idzie dowolny model będzie prawdopodobnie miał problemy z przewidywaniem w przypadku filmów z językiem oryginalnym innym niż angielski."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-AlrsvwOp5L"
      },
      "source": [
        "3. Średnie oceny filmów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5e6l6hzxOpMc",
        "outputId": "5ef9b7d5-99f0-41d8-e7b0-8cc20269b1c8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAD4CAYAAAAKL5jcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAANIklEQVR4nO3dcaid913H8fdnqVHXjan0MmaS7gYNlTCm3a5ZVZiytZBZSQarLIONFjqCsLjqJpqiFIkgnZPiwKALtVp1Lqtx4NVF4+gmIriR2650S2JorLW5sbO329xEcV3Y1z/uyY/T603uuck557n33PcLLjm/5/nxnG+Scz7n9/ye33NuqgpJAnhZ1wVIWjsMBEmNgSCpMRAkNQaCpOa6rp74hhtuqOnp6a6eXtqwHnvssReqamq5fZ0FwvT0NHNzc109vbRhJfm3y+3zlEFSYyBIagwESY2BIKkxECQ1BoKkxkCQ1BgIkhoDQVJjIGispg9+iumDn+q6DF2GgSCpMRAkNZ3d3KSNxdOE9cERgjrhXMLaZCBoTTIwumEgSGoGCoQku5OcTXIuycFl9t+VZCHJE72f9w6/VG0Ejgy6teKkYpJNwGHgNmAeOJlktqpOL+n6iao6MIIaJY3JICOEXcC5qnq6ql4EjgJ7R1uWpC4MEghbgPN97fnetqXekeTJJMeSbFvuQEn2J5lLMrewsHAV5WrSeIqwtgxrUvGvgOmqej3waeDh5TpV1ZGqmqmqmampZb/0VVKHBgmEC0D/J/7W3ramqr5SVd/sNR8E3jic8iSN0yCBcBLYkWR7ks3APmC2v0OS1/Q19wBnhleipHFZ8SpDVV1McgA4AWwCHqqqU0kOAXNVNQu8P8ke4CLwVeCuEdYsaUQGupehqo4Dx5dsu6/v8b3AvcMtTdK4uVJRUmMgSGoMBEmNgSCpMRAkNQaC1hWXOo+WX6GmkfLNu74YCFoXDJbx8JRBUmMgSGoMBEmNcwha05w7GC8DQSPhG3l98pRB65rrEobLQJDUGAiSGgNBUmMgSGoMBEmNgaBr4iz/ZDEQJDUGgqTGQJDUGAiSGgNBUmMgSGoMBEmNgSCpMRA0FC5QmgwGgqRmoEBIsjvJ2STnkhy8Qr93JKkkM8MrUdK4rBgISTYBh4G3ATuBdyXZuUy/VwL3AJ8fdpGSxmOQEcIu4FxVPV1VLwJHgb3L9PsN4EPA/w6xPkljNEggbAHO97Xne9uaJG8AtlXVFWeVkuxPMpdkbmFhYdXFShqta55UTPIy4AHggyv1raojVTVTVTNTU1PX+tRS41WO4RgkEC4A2/raW3vbLnkl8Drg75M8A9wCzDqxKK0/gwTCSWBHku1JNgP7gNlLO6vq61V1Q1VNV9U08DlgT1XNjaRiSSOzYiBU1UXgAHACOAM8UlWnkhxKsmfUBUoan4F+c1NVHQeOL9l232X6/tS1lyWpC65UlNQYCJIaA0FSYyBIagwESY2BIKkxECQ1BoImivc0XBsDQVJjIEhqDARJjYEgqTEQJDUGgqTGQJDUGAiSGgNBE8kFSldnoG9MkpbyzTaZHCFIagwESY2BIKkxECQ1BoKkxkCQ1BgIkhoDQVJjIEhqDARJjYEgqTEQJDUGgqRmoEBIsjvJ2STnkhxcZv/PJflikieS/GOSncMvVdKorXj7c5JNwGHgNmAeOJlktqpO93X7s6r6/V7/PcADwO4R1KuOedvzZBtkhLALOFdVT1fVi8BRYG9/h6r6Rl/zeqCGV6KkcRnkC1K2AOf72vPAm5Z2SvI+4APAZuAtyx0oyX5gP8CNN9642loljdjQJhWr6nBV/QDwK8CvXabPkaqaqaqZqampYT21pCEZJBAuANv62lt72y7nKPD2a6hJUkcGCYSTwI4k25NsBvYBs/0dkuzoa94OPDW8EiWNy4pzCFV1MckB4ASwCXioqk4lOQTMVdUscCDJrcC3gK8Bd46yaEmjMdC3LlfVceD4km339T2+Z8h1SeqAKxU10fz9DKtjIEhqDARJjYEgqTEQJDUGgqTGQJDUGAiSGgNBUmMgSGoMBEmNgSCpMRB0Rd4LsLEYCJIaA0FSYyBIagwESc1A35gkObG4MThCkNQYCJIaA0FSYyBIagwESY2BoJdwqfLGZiBIagwEbQiOfAZjIEhqDARJjYEgqfFeBgHeq6BFA40QkuxOcjbJuSQHl9n/gSSnkzyZ5NEkrx1+qZJGbcVASLIJOAy8DdgJvCvJziXdvgDMVNXrgWPAbw27UEmjN8gIYRdwrqqerqoXgaPA3v4OVfXZqvqfXvNzwNbhlilpHAYJhC3A+b72fG/b5dwN/M1yO5LsTzKXZG5hYWHwKqUhc13C8oZ6lSHJu4EZ4MPL7a+qI1U1U1UzU1NTw3xqSUMwyFWGC8C2vvbW3raXSHIr8KvAT1bVN4dTnqRxGmSEcBLYkWR7ks3APmC2v0OSm4GPAnuq6vnhlylpHFYMhKq6CBwATgBngEeq6lSSQ0n29Lp9GHgF8OdJnkgye5nDSVrDBlqYVFXHgeNLtt3X9/jWIdclqQMuXZbUGAiSGgNBUmMgSGoMBEmNgSCpMRAkNQaCNjRvcnopA0FSYyBIagwESY2BIKkxECQ1BoKkxt/LsIF5uU1LOUKQcD3CJQaCpMZAkNQYCJIaA0FSYyBIagwESY2BIKkxECQ1BoKkxkCQ1BgIG4jLc7USA0FSYyBIagwESc1AgZBkd5KzSc4lObjM/jcneTzJxSR3DL9MaTw2+jzLil+QkmQTcBi4DZgHTiaZrarTfd2eBe4CfmkURWq4NvILXlc2yDcm7QLOVdXTAEmOAnuBFghV9Uxv37dHUKOkMRnklGELcL6vPd/btmpJ9ieZSzK3sLBwNYeQNEJjnVSsqiNVNVNVM1NTU+N8akkDGCQQLgDb+tpbe9skTZhBAuEksCPJ9iSbgX3A7GjLktSFFQOhqi4CB4ATwBngkao6leRQkj0ASX40yTzws8BHk5waZdGSRmOg38tQVceB40u23df3+CSLpxKS1jFXKkpq/M1N0jL6F289c//tHVYyXo4QJtBGX36rq+cIYQMwHDQoRwiSGgNBUmMgSGoMBEmNgSCp8SrDBPAqwnhc+nee5HUJjhAkNQaCpMZAkNQYCNIqTfLScCcV17FJfVGqO44QJDUGgqTGQJDUGAiSGicV1yEnEzUqjhCkqzSJlx8dIawhS19cl9bMb4Q19FobDIQ1bNI+fbT2ecogqTEQJDUTEwiTOMEjjdvEBIKka2cgSGq8yrAGeKqjtcIRwgg5r7ExTNL/s4EgqRnolCHJbuAjwCbgwaq6f8n+7wT+GHgj8BXgnVX1zHBLXb8ut9JwUj5VtGgSVpSuGAhJNgGHgduAeeBkktmqOt3X7W7ga1X1g0n2AR8C3jmKgteiQd/Yk/CC0epdbkn6WjTICGEXcK6qngZIchTYC/QHwl7g13uPjwG/myRVVdda4Eqfriv94y7X73Jv4NV+gq/l/1h1Z6XX5rADYpgfNFnpPZvkDmB3Vb23134P8KaqOtDX50u9PvO99r/0+ryw5Fj7gf295k3A2Wv+G/x/NwAvrNhr7bL+7qzn2mHw+l9bVVPL7RjrZceqOgIcGeVzJJmrqplRPscoWX931nPtMJz6B7nKcAHY1tfe2tu2bJ8k1wGvYnFyUdI6MkggnAR2JNmeZDOwD5hd0mcWuLP3+A7gM8OYP5A0XiueMlTVxSQHgBMsXnZ8qKpOJTkEzFXVLPAHwJ8kOQd8lcXQ6MpIT0nGwPq7s55rhyHUv+KkoqSNw5WKkhoDQVIzMYGQZFuSzyY5neRUknu6rmm1kmxK8oUkf911LauV5HuSHEvyz0nOJPmxrmtajSS/2HvdfCnJx5N8V9c1XUmSh5I831sDdGnb9yX5dJKnen9+72qPOzGBAFwEPlhVO4FbgPcl2dlxTat1D3Cm6yKu0keAv62qHwJ+mHX090iyBXg/MFNVr2Nx8rzLifFB/BGwe8m2g8CjVbUDeLTXXpWJCYSqeq6qHu89/i8WX5Bbuq1qcEm2ArcDD3Zdy2oleRXwZhavNlFVL1bVf3Za1OpdB3x3bx3Ny4F/77ieK6qqf2Dxil6/vcDDvccPA29f7XEnJhD6JZkGbgY+33Epq/E7wC8D3+64jquxHVgA/rB3yvNgkuu7LmpQVXUB+G3gWeA54OtV9XfdVnVVXl1Vz/Uefxl49WoPMHGBkOQVwF8Av1BV3+i6nkEk+Rng+ap6rOtartJ1wBuA36uqm4H/5iqGq13pnWvvZTHYvh+4Psm7u63q2vQWBq56TcFEBUKS72AxDD5WVZ/sup5V+AlgT5JngKPAW5L8abclrco8MF9Vl0Zkx1gMiPXiVuBfq2qhqr4FfBL48Y5ruhr/keQ1AL0/n1/tASYmEJKExXPYM1X1QNf1rEZV3VtVW6tqmsXJrM9U1br5hKqqLwPnk9zU2/RWXnp7/Fr3LHBLkpf3XkdvZR1Nivbpv4XgTuAvV3uAiQkEFj9l38Pip+sTvZ+f7rqoDeTngY8leRL4EeA3uy1ncL2RzTHgceCLLL4v1vQy5iQfB/4JuCnJfJK7gfuB25I8xeKo5/4rHWPZ47p0WdIlkzRCkHSNDARJjYEgqTEQJDUGgqTGQJDUGAiSmv8DGV+PdQ48ZD0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "avg_votes = movies[\"Vote_Average\"]\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.hist(avg_votes, bins=100, density=True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rozkład średnich ocen, jak można się było spodziewać jest rozkładem normalnym o średniej ok. 7. Warto zauważyć, że o ile prawie nie ma filmów o średniej ocen równej 10, to dużo większa niż można by się tego było spodziewać liczba filmów ma średnią ocen nieco poniżej 2. Może to mieć znaczenie, jeśli chcielibyśmy używać przy uczeniu modelu metryk typu maksymalny błąd."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Rozkład długości tytułów filmów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "title_len = title_pipeline.transform(movies)[\"Title_Len\"]\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.hist(title_len, bins=20, density=True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Długość tytułów filmów zdaje się być dana rozkładem Poissona. Większość filmów ma długość mniejszą, niż 5 słów, a co za tym idzie wytrenowane modele, będą miały potencjalnie problemy z filmami, których tytuły są długie (powyżej 7-8 słów)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Procent filmów zawierających cyfry / dwukropki / myślniki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.lines import Line2D\n",
        "\n",
        "titles_data = title_pipeline.transform(movies)\n",
        "\n",
        "titles_has_numbers = titles_data[\"Title_Numbers\"].sum()\n",
        "titles_has_no_numbers = len(titles_data[\"Title_Numbers\"]) - titles_has_numbers\n",
        "\n",
        "titles_has_colon = titles_data[\"Title_Colon\"].sum()\n",
        "titles_has_no_colon = len(titles_data[\"Title_Colon\"]) - titles_has_colon\n",
        "\n",
        "titles_has_dash = titles_data[\"Title_Dash\"].sum()\n",
        "titles_has_no_dash = len(titles_data[\"Title_Dash\"]) - titles_has_dash\n",
        "\n",
        "labels = [\"Zawiera\", \"Nie zawiera\"]\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "titles_numbers = [titles_has_numbers, titles_has_no_numbers]\n",
        "titles_colons = [titles_has_colon, titles_has_no_colon]\n",
        "titles_dashes = [titles_has_dash, titles_has_no_dash]\n",
        "\n",
        "ax = plt.subplot(111)\n",
        "ax.bar(x - 0.2, titles_numbers, width=0.2, color='b', align='center')\n",
        "ax.bar(x, titles_colons, width=0.2, color='g', align='center', tick_label=labels)\n",
        "ax.bar(x+0.2, titles_dashes, width=0.2, color='r', align='center')\n",
        "\n",
        "custom_legend = [\n",
        "    Line2D([0], [0], marker='o', color='w', label='Cyfry', markerfacecolor='b', markersize=15),\n",
        "    Line2D([0], [0], marker='o', color='w', label='Dwukropki', markerfacecolor='g', markersize=15),\n",
        "    Line2D([0], [0], marker='o', color='w', label='Myślniki', markerfacecolor='r', markersize=15),\n",
        "]\n",
        "ax.legend(handles=custom_legend)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jak widać większość tytułów filmów nie zawiera cyfr, dwukropków czy średników. Jest to o tyle istotna obserwacja, że często sequele filmów są odbierane gorzej niż film, po którym następuje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLYtz9TiyrU3"
      },
      "source": [
        "**MODELE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "9RMpW7HPyrVB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enIb5UhZyrVC"
      },
      "source": [
        "1. ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vVdKUmqyrVD",
        "outputId": "ff2e7ee0-4c6c-4872-dc98-b8315fee6c23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.250e+01, tolerance: 6.013e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 6.053e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.710e+00, tolerance: 6.013e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+02, tolerance: 6.025e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.390e+01, tolerance: 6.060e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+02, tolerance: 6.053e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.646e+02, tolerance: 6.021e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.238e+01, tolerance: 6.013e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.967e-01, tolerance: 6.053e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.741e+00, tolerance: 6.013e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.155e-01, tolerance: 6.060e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'regressor__alpha': 0.001, 'scaler': None}"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "ElasticNet_pipeline = Pipeline([\n",
        "    (\"preprocessing\", preprocess_pipeline),\n",
        "    (\"scaler\", None),\n",
        "    (\"regressor\", ElasticNet())\n",
        "])\n",
        "\n",
        "ElasticNet_param_grid = {\n",
        "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
        "    \"regressor__alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
        "}\n",
        "\n",
        "grid_1 = GridSearchCV(estimator=ElasticNet_pipeline,\n",
        "                      param_grid=ElasticNet_param_grid, scoring=\"r2\", cv=kFold)\n",
        "grid_1.fit(X_train, y_train)\n",
        "grid_1.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6bAHi2OyrVF"
      },
      "source": [
        "2. SVR RBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "tFuj9gWbyrVF",
        "outputId": "d1fa7018-b758-4617-bead-2e6e01af15f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'regressor__C': 1, 'regressor__gamma': 0.01}"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "SVR_pipeline = Pipeline([\n",
        "    (\"preprocessing\", preprocess_pipeline),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"regressor\", SVR(kernel=\"rbf\"))\n",
        "])\n",
        "\n",
        "SVR_param_grid = {\n",
        "    \"regressor__C\": [0.01, 0.1, 1, 10, 100, 1000],\n",
        "    \"regressor__gamma\": [0.001, 0.01, 0.1, 1],\n",
        "}\n",
        "\n",
        "grid_2 = GridSearchCV(estimator=SVR_pipeline,\n",
        "                      param_grid=SVR_param_grid, scoring=\"r2\", cv=kFold)\n",
        "grid_2.fit(X_train, y_train)\n",
        "grid_2.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IvidvEjyrVG"
      },
      "source": [
        "3. Drzewo decyzyjne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "UdYTK_kbyrVH",
        "outputId": "1a94691b-7db8-4fcb-fee4-3217eba9a9a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'regressor__criterion': 'friedman_mse',\n",
              " 'regressor__max_depth': 5,\n",
              " 'regressor__max_features': None,\n",
              " 'scaler': None}"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "DecisionTree_pipeline = Pipeline([\n",
        "    (\"preprocessing\", preprocess_pipeline),\n",
        "    (\"scaler\", None),\n",
        "    (\"regressor\", DecisionTreeRegressor())\n",
        "])\n",
        "\n",
        "DecisionTree_param_grid = {\n",
        "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
        "    \"regressor__max_depth\": [None, 1, 2, 3, 4, 5],\n",
        "    \"regressor__max_features\": [None, \"auto\", \"sqrt\", \"log2\"],\n",
        "    \"regressor__criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
        "}\n",
        "\n",
        "grid_3 = GridSearchCV(estimator=DecisionTree_pipeline,\n",
        "                      param_grid=DecisionTree_param_grid, scoring=\"r2\", cv=kFold)\n",
        "grid_3.fit(X_train, y_train)\n",
        "grid_3.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv9TMgt2yrVI"
      },
      "source": [
        "4. Liniowy SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "i4HTvKKPyrVJ",
        "outputId": "f0230dc9-cc56-4439-eeb3-eeedb3898331"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'regressor__C': 0.1, 'scaler': MinMaxScaler()}"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "LinearSVR_pipeline = Pipeline([\n",
        "    (\"preprocessing\", preprocess_pipeline),\n",
        "    (\"scaler\", None),\n",
        "    (\"regressor\", LinearSVR())\n",
        "])\n",
        "\n",
        "LinearSVR_param_grid = {\n",
        "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
        "    \"regressor__C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "}\n",
        "\n",
        "grid_4 = GridSearchCV(estimator=LinearSVR_pipeline,\n",
        "                      param_grid=LinearSVR_param_grid, scoring=\"r2\", cv=kFold)\n",
        "grid_4.fit(X_train, y_train)\n",
        "grid_4.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pYvoXjoyrVL"
      },
      "source": [
        "5. Regresja Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "yj5eo6pfyrVL",
        "outputId": "c9e91b71-f807-4fa3-ac8e-56598457a207"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.153e+01, tolerance: 6.013e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+02, tolerance: 6.025e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.462e+01, tolerance: 6.060e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+02, tolerance: 6.053e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.425e+02, tolerance: 6.021e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'regressor__alpha': 0.001, 'scaler': None}"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "Lasso_pipeline = Pipeline([\n",
        "    (\"preprocessing\", preprocess_pipeline),\n",
        "    (\"scaler\", None),\n",
        "    (\"regressor\", Lasso())\n",
        "])\n",
        "\n",
        "Lasso_param_grid = {\n",
        "    \"scaler\": [None, StandardScaler(), MinMaxScaler()],\n",
        "    \"regressor__alpha\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
        "}\n",
        "\n",
        "grid_5 = GridSearchCV(estimator=Lasso_pipeline,\n",
        "                      param_grid=Lasso_param_grid, scoring=\"r2\", cv=kFold)\n",
        "grid_5.fit(X_train, y_train)\n",
        "grid_5.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfxW9D4OyrVM"
      },
      "source": [
        "**Porównanie płytkich modeli**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "ihzx79EkyrVN",
        "outputId": "ef7ddc3e-32f8-4419-c747-0719554b11aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model name</th>\n",
              "      <th>training score (r2)</th>\n",
              "      <th>test score (r2)</th>\n",
              "      <th>test score (mean squared error)</th>\n",
              "      <th>test score (max error)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ElasticNet</td>\n",
              "      <td>0.197765</td>\n",
              "      <td>0.206277</td>\n",
              "      <td>0.659564</td>\n",
              "      <td>4.374806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVR</td>\n",
              "      <td>0.229291</td>\n",
              "      <td>0.245390</td>\n",
              "      <td>0.627062</td>\n",
              "      <td>4.841273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.177975</td>\n",
              "      <td>0.174545</td>\n",
              "      <td>0.685932</td>\n",
              "      <td>4.215801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Linear SVR</td>\n",
              "      <td>0.190060</td>\n",
              "      <td>0.197382</td>\n",
              "      <td>0.666955</td>\n",
              "      <td>4.429653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lasso</td>\n",
              "      <td>0.197216</td>\n",
              "      <td>0.204051</td>\n",
              "      <td>0.661413</td>\n",
              "      <td>4.374988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      model name  training score (r2)  test score (r2)  \\\n",
              "0     ElasticNet             0.197765         0.206277   \n",
              "1            SVR             0.229291         0.245390   \n",
              "2  Decision Tree             0.177975         0.174545   \n",
              "3     Linear SVR             0.190060         0.197382   \n",
              "4          Lasso             0.197216         0.204051   \n",
              "\n",
              "   test score (mean squared error)  test score (max error)  \n",
              "0                         0.659564                4.374806  \n",
              "1                         0.627062                4.841273  \n",
              "2                         0.685932                4.215801  \n",
              "3                         0.666955                4.429653  \n",
              "4                         0.661413                4.374988  "
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, max_error\n",
        "\n",
        "models = []\n",
        "\n",
        "models.append((\"ElasticNet\", grid_1.best_score_, grid_1.best_estimator_))\n",
        "models.append((\"SVR\", grid_2.best_score_, grid_2.best_estimator_))\n",
        "models.append((\"Decision Tree\", grid_3.best_score_, grid_3.best_estimator_))\n",
        "models.append((\"Linear SVR\", grid_4.best_score_, grid_4.best_estimator_))\n",
        "models.append((\"Lasso\", grid_5.best_score_, grid_5.best_estimator_))\n",
        "\n",
        "names = []\n",
        "scores_train = []\n",
        "scores_test_r2 = []\n",
        "scores_test_mse = []\n",
        "scores_test_me = []\n",
        "\n",
        "for name, train_score, estimator in models:\n",
        "    names.append(name)\n",
        "    scores_train.append(train_score)\n",
        "\n",
        "    r2_test_score = r2_score(y_test, estimator.predict(X_test))\n",
        "    scores_test_r2.append(r2_test_score)\n",
        "\n",
        "    mse_test_score = mean_squared_error(y_test, estimator.predict(X_test))\n",
        "    scores_test_mse.append(mse_test_score)\n",
        "\n",
        "    me_test_score = max_error(y_test, estimator.predict(X_test))\n",
        "    scores_test_me.append(me_test_score)\n",
        "\n",
        "\n",
        "model_data = {\n",
        "    \"model name\": names,\n",
        "    \"training score (r2)\": scores_train,\n",
        "    \"test score (r2)\": scores_test_r2,\n",
        "    \"test score (mean squared error)\": scores_test_mse,\n",
        "    \"test score (max error)\": scores_test_me\n",
        "}\n",
        "table = pd.DataFrame(model_data)\n",
        "table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prawdziwy rozkład\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: ElasticNet\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: SVR\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Decision Tree\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Linear SVR\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Lasso\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "print(f\"Prawdziwy rozkład\")\n",
        "plt.hist(y_test, bins=30, density=True)\n",
        "plt.show()\n",
        "\n",
        "for name, _, estimator in models:\n",
        "    print(f\"model: {name}\")\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.xlim((0,10))\n",
        "    plt.hist(estimator.predict(X_test), bins=30, density=True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jak widać, wszystkie modele płytkie (poza drzewem decyzyjnym) przewidują oceny o rozkładzie (w przybliżeniu) normalnym. Rozkład ten ma średnią zbliżoną do średniej z prawdziwych wyników, ale zdecydowanie mniejsze odchylenie standardowe.\n",
        "\n",
        "Najlepszy pod kątem wyniku r^2 model, którym jest SVR z jądrem RBF, ma rozkład najbardziej zbliżony do danych prawdziwych (w szczególności warto zwrócić uwagę na większą częstość wyników ok. wartości 6 i 7, która jest wynikiem losowego wybrania danych testowych)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHytE6JSyrVN"
      },
      "source": [
        "**Modele głębokie**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqXPp3sMyrVO",
        "outputId": "f968a458-efbe-4a1d-de13-314ff08b4502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oKdg4EWyrVO",
        "outputId": "42b096c9-9b70-4e0f-e06a-124fc5248665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8754, 66)\n",
            "(973, 66)\n"
          ]
        }
      ],
      "source": [
        "X_train_preprocessed = preprocess_pipeline.transform(X_train)\n",
        "X_test_preprocessed = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_preprocessed)\n",
        "\n",
        "X_train_keras = scaler.transform(X_train_preprocessed)\n",
        "X_test_keras = scaler.transform(X_test_preprocessed)\n",
        "\n",
        "print(X_train_keras.shape)\n",
        "print(X_test_keras.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "iXXsshZQyrVP"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "\n",
        "from keras.callbacks import History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "rg2cNL6VyrVP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "zO4dHKg7yrVQ"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def keras_r2(y_true, y_pred):\n",
        "    SS_res = K.sum(K.square(y_true-y_pred))\n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
        "    return (1 - SS_res/(SS_tot + K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "sf1WJPeFyrVR"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping_grid_search = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "YM4M3bhFyrVR"
      },
      "outputs": [],
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, activation=\"relu\", dropout=None, batch_normalization=False, learning_rate=3e-3, input_shape=[66,]):\n",
        "    model = keras.models.Sequential()\n",
        "\n",
        "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "\n",
        "    for layer in range(n_hidden):\n",
        "        if dropout or batch_normalization:\n",
        "          model.add(keras.layers.Dense(n_neurons))\n",
        "        else:\n",
        "          model.add(keras.layers.Dense(n_neurons, use_bias=False))\n",
        "        \n",
        "        if batch_normalization:\n",
        "          model.add(keras.layers.BatchNormalization())\n",
        "        \n",
        "        model.add(keras.layers.Activation(activation))\n",
        "\n",
        "        if dropout:\n",
        "          model.add(keras.layers.Dropout(dropout))\n",
        "\n",
        "    \n",
        "    model.add(keras.layers.Dense(1, activation=\"relu\"))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[keras_r2])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4cr7x42yrVR",
        "outputId": "04536a62-a80d-4551-df2b-d9e909280a73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8548\\3463659828.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.wrappers.scikit_learn.KerasClassifier at 0x19d280a60d0>"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
        "keras_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgUcogqLyrVS"
      },
      "source": [
        "1. Karas Randomized Search CV (liczba warstw + liczba neuronów)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AkSH07_yrVS",
        "outputId": "8ab60de9-4ecc-47a5-dc35-0665ac8f6d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5646 - keras_r2: 0.1158 - val_loss: 125.8454 - val_keras_r2: -0.5337\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.1342 - keras_r2: 0.0494 - val_loss: 112.8989 - val_keras_r2: -0.4047\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.2118 - keras_r2: 0.1115 - val_loss: 78.1986 - val_keras_r2: 0.0730\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.3083 - keras_r2: 0.0812 - val_loss: 77.5881 - val_keras_r2: 0.0905\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.8234 - keras_r2: -0.0014 - val_loss: 76.2159 - val_keras_r2: 0.1047\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.4278 - keras_r2: 0.1138 - val_loss: 86.3537 - val_keras_r2: -0.0222\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5889 - keras_r2: 0.1137 - val_loss: 77.1083 - val_keras_r2: 0.0937\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2377 - keras_r2: 0.0958 - val_loss: 262.0333 - val_keras_r2: -2.4042\n",
            "Epoch 25: early stopping\n",
            "[CV] END ............................n_hidden=2, n_neurons=2; total time=  10.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.2164 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -34.4557 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -27.1818 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.2317 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -26.9939 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.2465 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.1945 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.7583 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.9622 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.2689 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -38.9541 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ............................n_hidden=2, n_neurons=2; total time=   5.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 467.8740 - keras_r2: -5.1655 - val_loss: 1421.2832 - val_keras_r2: -18.0231\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 476.6673 - keras_r2: -5.1377 - val_loss: 270.6587 - val_keras_r2: -2.5942\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 190.9160 - keras_r2: -1.4511 - val_loss: 150.4881 - val_keras_r2: -0.9502\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 125.0224 - keras_r2: -0.6059 - val_loss: 110.4423 - val_keras_r2: -0.3989\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 101.6192 - keras_r2: -0.2519 - val_loss: 96.5548 - val_keras_r2: -0.2199\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.5695 - keras_r2: -0.1354 - val_loss: 89.7520 - val_keras_r2: -0.1244\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.4071 - keras_r2: -0.0812 - val_loss: 87.7877 - val_keras_r2: -0.0984\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 86.6206 - keras_r2: -0.0881 - val_loss: 87.5298 - val_keras_r2: -0.0959\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.9223 - keras_r2: -0.0428 - val_loss: 84.9329 - val_keras_r2: -0.0497\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6158 - keras_r2: -0.0490 - val_loss: 85.0411 - val_keras_r2: -0.0497\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3558 - keras_r2: -0.0445 - val_loss: 83.5840 - val_keras_r2: -0.0357\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2621 - keras_r2: -0.0556 - val_loss: 83.4456 - val_keras_r2: -0.0322\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1966 - keras_r2: -0.0358 - val_loss: 83.6985 - val_keras_r2: -0.0391\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.9318 - keras_r2: -0.0306 - val_loss: 84.0646 - val_keras_r2: -0.0450\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5330 - keras_r2: -0.0270 - val_loss: 82.9295 - val_keras_r2: -0.0254\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.9909 - keras_r2: -0.0288 - val_loss: 82.3689 - val_keras_r2: -0.0171\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.2511 - keras_r2: -0.0121 - val_loss: 81.5123 - val_keras_r2: -0.0072\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.0845 - keras_r2: 0.0076 - val_loss: 80.3056 - val_keras_r2: 0.0071\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.7176 - keras_r2: -0.0473 - val_loss: 79.8878 - val_keras_r2: 0.0098\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.7673 - keras_r2: 0.0281 - val_loss: 79.1945 - val_keras_r2: 0.0209\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.8953 - keras_r2: 0.0409 - val_loss: 81.6953 - val_keras_r2: -0.0124\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.0619 - keras_r2: 0.0402 - val_loss: 77.6644 - val_keras_r2: 0.0367\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.6473 - keras_r2: 0.0479 - val_loss: 265.5613 - val_keras_r2: -2.4732\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.6993 - keras_r2: -0.0301 - val_loss: 77.4756 - val_keras_r2: 0.0368\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.2767 - keras_r2: 0.0722 - val_loss: 77.7440 - val_keras_r2: 0.0321\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.7506 - keras_r2: 0.0677 - val_loss: 81.7871 - val_keras_r2: -0.0232\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.3714 - keras_r2: 0.0822 - val_loss: 77.5803 - val_keras_r2: 0.0327\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.0345 - keras_r2: 0.0928 - val_loss: 75.2244 - val_keras_r2: 0.0638\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.7756 - keras_r2: 0.0471 - val_loss: 75.5211 - val_keras_r2: 0.0602\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.8523 - keras_r2: 0.0501 - val_loss: 75.0243 - val_keras_r2: 0.0675\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.6310 - keras_r2: 0.0886 - val_loss: 74.4009 - val_keras_r2: 0.0748\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.8466 - keras_r2: 0.1005 - val_loss: 88.4009 - val_keras_r2: -0.1112\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.5710 - keras_r2: 0.1006 - val_loss: 74.3433 - val_keras_r2: 0.0771\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.7705 - keras_r2: 0.0945 - val_loss: 77.7872 - val_keras_r2: 0.0298\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.0109 - keras_r2: 0.1157 - val_loss: 83.7020 - val_keras_r2: -0.0489\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.0810 - keras_r2: 0.1159 - val_loss: 73.6240 - val_keras_r2: 0.0862\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.7682 - keras_r2: 0.1133 - val_loss: 75.6938 - val_keras_r2: 0.0575\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.7973 - keras_r2: 0.1109 - val_loss: 75.2112 - val_keras_r2: 0.0635\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2935 - keras_r2: 0.1173 - val_loss: 72.3647 - val_keras_r2: 0.1011\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0822 - keras_r2: 0.1229 - val_loss: 104.2645 - val_keras_r2: -0.3259\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.8489 - keras_r2: 0.1012 - val_loss: 73.1651 - val_keras_r2: 0.0879\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2645 - keras_r2: 0.1188 - val_loss: 72.9444 - val_keras_r2: 0.0939\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5077 - keras_r2: 0.1169 - val_loss: 73.2826 - val_keras_r2: 0.0882\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.4672 - keras_r2: 0.1222 - val_loss: 72.5153 - val_keras_r2: 0.0984\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.1699 - keras_r2: 0.1206 - val_loss: 72.9198 - val_keras_r2: 0.0932\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9001 - keras_r2: 0.1295 - val_loss: 77.5053 - val_keras_r2: 0.0323\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.8136 - keras_r2: 0.1172 - val_loss: 89.1462 - val_keras_r2: -0.1242\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5773 - keras_r2: 0.1100 - val_loss: 73.4975 - val_keras_r2: 0.0845\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.8576 - keras_r2: 0.1327 - val_loss: 74.0626 - val_keras_r2: 0.0775\n",
            "Epoch 49: early stopping\n",
            "[CV] END ............................n_hidden=2, n_neurons=2; total time=  21.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 486.4784 - keras_r2: -5.4839 - val_loss: 77.7755 - val_keras_r2: 0.0861\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.5302 - keras_r2: 0.0629 - val_loss: 100.7355 - val_keras_r2: -0.2440\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.6748 - keras_r2: 0.1186 - val_loss: 78.6505 - val_keras_r2: 0.0696\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.3920 - keras_r2: 0.1389 - val_loss: 93.3168 - val_keras_r2: -0.1515\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7638 - keras_r2: -0.9022 - val_loss: 147.5757 - val_keras_r2: -0.8193\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9445 - keras_r2: 0.1666 - val_loss: 128.3661 - val_keras_r2: -0.6339\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9047 - keras_r2: 0.2031 - val_loss: 101.2308 - val_keras_r2: -0.2170\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5746 - keras_r2: 0.1970 - val_loss: 74.5007 - val_keras_r2: 0.1166\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6710 - keras_r2: 0.1679 - val_loss: 154.7666 - val_keras_r2: -0.9952\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4147 - keras_r2: 0.2074 - val_loss: 76.3508 - val_keras_r2: 0.0862\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1601 - keras_r2: 0.2226 - val_loss: 92.7559 - val_keras_r2: -0.1140\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7763 - keras_r2: 0.2084 - val_loss: 90.5685 - val_keras_r2: -0.0791\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8122 - keras_r2: 0.1873 - val_loss: 109.4283 - val_keras_r2: -0.3276\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5630 - keras_r2: 0.1155 - val_loss: 113.5420 - val_keras_r2: -0.3799\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1086 - keras_r2: 0.1715 - val_loss: 73.9911 - val_keras_r2: 0.1269\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8866 - keras_r2: -726413.9375 - val_loss: 82.7008 - val_keras_r2: -0.0056\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7699 - keras_r2: 0.1914 - val_loss: 83.8887 - val_keras_r2: -0.0214\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7825 - keras_r2: 0.2060 - val_loss: 77.5696 - val_keras_r2: 0.0854\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5662 - keras_r2: 0.2182 - val_loss: 75.5804 - val_keras_r2: 0.0965\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.3670 - keras_r2: -0.8728 - val_loss: 103.8474 - val_keras_r2: -0.3008\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2518 - keras_r2: 0.2336 - val_loss: 89.8495 - val_keras_r2: -0.0703\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2655 - keras_r2: 0.2408 - val_loss: 84.4029 - val_keras_r2: -0.0293\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2399 - keras_r2: 0.2385 - val_loss: 90.4691 - val_keras_r2: -0.1149\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0702 - keras_r2: 0.1986 - val_loss: 332.6183 - val_keras_r2: -3.4111\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5962 - keras_r2: 0.2034 - val_loss: 78.7339 - val_keras_r2: 0.0698\n",
            "Epoch 25: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=31; total time=  11.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 354.2814 - keras_r2: -3.4640 - val_loss: 82.6739 - val_keras_r2: -0.0084\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.8096 - keras_r2: 0.1404 - val_loss: 138.0581 - val_keras_r2: -0.7172\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.8023 - keras_r2: 0.1653 - val_loss: 101.4358 - val_keras_r2: -0.2291\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0873 - keras_r2: 0.1876 - val_loss: 93.8544 - val_keras_r2: -0.1313\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.0781 - keras_r2: 0.2100 - val_loss: 103.6233 - val_keras_r2: -0.2935\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4532 - keras_r2: 0.0172 - val_loss: 94.6492 - val_keras_r2: -0.1300\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5684 - keras_r2: 0.2143 - val_loss: 88.1347 - val_keras_r2: -0.0316\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9492 - keras_r2: 0.2339 - val_loss: 76.9758 - val_keras_r2: 0.0799\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.3647 - keras_r2: 0.2464 - val_loss: 151.0960 - val_keras_r2: -0.8953\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.3077 - keras_r2: 0.2179 - val_loss: 91.3265 - val_keras_r2: -0.1077\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.4961 - keras_r2: 0.2299 - val_loss: 86.2472 - val_keras_r2: -0.0344\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.1109 - keras_r2: 0.2516 - val_loss: 77.9429 - val_keras_r2: 0.0695\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0261 - keras_r2: 0.1914 - val_loss: 76.4738 - val_keras_r2: 0.0713\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.1816 - keras_r2: 0.0056 - val_loss: 75.2976 - val_keras_r2: 0.0968\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 116.9728 - keras_r2: -0.4947 - val_loss: 197.2963 - val_keras_r2: -1.5405\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 115.5947 - keras_r2: -0.4672 - val_loss: 162.5950 - val_keras_r2: -1.0415\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 97.6003 - keras_r2: -0.3801 - val_loss: 132.0131 - val_keras_r2: -0.6569\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 196.7720 - keras_r2: -1.4981 - val_loss: 381.5976 - val_keras_r2: -3.9909\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 214.9383 - keras_r2: -1.7773 - val_loss: 141.0453 - val_keras_r2: -0.7915\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 120.2710 - keras_r2: -0.5119 - val_loss: 121.4037 - val_keras_r2: -0.5150\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 97.4281 - keras_r2: -0.2179 - val_loss: 107.4156 - val_keras_r2: -0.3319\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.3977 - keras_r2: -0.1195 - val_loss: 101.6024 - val_keras_r2: -0.2551\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.8308 - keras_r2: -0.0911 - val_loss: 112.8478 - val_keras_r2: -0.4119\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 90.7497 - keras_r2: -0.1318 - val_loss: 106.4650 - val_keras_r2: -0.2936\n",
            "Epoch 24: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=31; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 315.1665 - keras_r2: -3.3121 - val_loss: 88.7794 - val_keras_r2: -0.0614\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.9781 - keras_r2: 0.1339 - val_loss: 81.7556 - val_keras_r2: 0.0302\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.1447 - keras_r2: -6639702.5000 - val_loss: 91.0221 - val_keras_r2: -0.0873\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1295 - keras_r2: 0.1312 - val_loss: 71.9824 - val_keras_r2: 0.1485\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8077 - keras_r2: 0.1774 - val_loss: 101.7397 - val_keras_r2: -0.2621\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9518 - keras_r2: 0.1898 - val_loss: 78.9913 - val_keras_r2: 0.0682\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8667 - keras_r2: 0.2097 - val_loss: 76.0523 - val_keras_r2: 0.1044\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.6472 - keras_r2: 0.2487 - val_loss: 74.2344 - val_keras_r2: 0.1252\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0180 - keras_r2: -1.0822 - val_loss: 97.5521 - val_keras_r2: -0.2081\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.7686 - keras_r2: 0.2535 - val_loss: 100.6611 - val_keras_r2: -0.2091\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.8398 - keras_r2: 0.2491 - val_loss: 73.6444 - val_keras_r2: 0.1290\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.9258 - keras_r2: 0.2739 - val_loss: 126.8466 - val_keras_r2: -0.6198\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.8421 - keras_r2: 0.2266 - val_loss: 87.9138 - val_keras_r2: -0.0460\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.5767 - keras_r2: 0.2733 - val_loss: 92.6647 - val_keras_r2: -0.1376\n",
            "Epoch 14: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=31; total time=   6.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 407.3897 - keras_r2: -4.4881 - val_loss: 107.9951 - val_keras_r2: -0.3379\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.2545 - keras_r2: -0.2284 - val_loss: 96.6694 - val_keras_r2: -0.1581\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.2941 - keras_r2: 0.1011 - val_loss: 84.1764 - val_keras_r2: -0.0132\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.2382 - keras_r2: -2.4879 - val_loss: 208.4166 - val_keras_r2: -1.5928\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.9412 - keras_r2: 0.0699 - val_loss: 79.8633 - val_keras_r2: 0.0593\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4838 - keras_r2: 0.1452 - val_loss: 378.5356 - val_keras_r2: -3.6004\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.4265 - keras_r2: 0.0550 - val_loss: 364.1362 - val_keras_r2: -3.5035\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.3562 - keras_r2: 0.1265 - val_loss: 99.9308 - val_keras_r2: -0.2243\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 779.7197 - keras_r2: -33.7326 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.0620 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.6774 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -58.0685 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.6410 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.8940 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.9500 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 15: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=31; total time=   7.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 610.6049 - keras_r2: -6.8704 - val_loss: 105.7111 - val_keras_r2: -0.3509\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.7122 - keras_r2: -0.0145 - val_loss: 95.9039 - val_keras_r2: -0.1937\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.4704 - keras_r2: 0.0279 - val_loss: 80.1829 - val_keras_r2: -0.0077\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.3743 - keras_r2: 0.0980 - val_loss: 88.6132 - val_keras_r2: -0.1023\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.8835 - keras_r2: -0.7469 - val_loss: 74.5008 - val_keras_r2: 0.0747\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7022 - keras_r2: 0.1499 - val_loss: 70.1509 - val_keras_r2: 0.1257\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5157 - keras_r2: 0.1535 - val_loss: 73.9541 - val_keras_r2: 0.0733\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1074 - keras_r2: 0.1776 - val_loss: 70.2577 - val_keras_r2: 0.1225\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.4777 - keras_r2: 0.1430 - val_loss: 78.5142 - val_keras_r2: 0.0180\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.3064 - keras_r2: 0.1382 - val_loss: 74.8555 - val_keras_r2: 0.0641\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9300 - keras_r2: 0.1727 - val_loss: 69.6995 - val_keras_r2: 0.1326\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7437 - keras_r2: 0.1731 - val_loss: 75.4328 - val_keras_r2: 0.0537\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.3801 - keras_r2: 0.1672 - val_loss: 77.8491 - val_keras_r2: 0.0326\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8733 - keras_r2: 0.1683 - val_loss: 78.8925 - val_keras_r2: 0.0151\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3733 - keras_r2: 0.1881 - val_loss: 75.8928 - val_keras_r2: 0.0349\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5179 - keras_r2: 0.2049 - val_loss: 73.8059 - val_keras_r2: 0.0656\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7129 - keras_r2: 0.1777 - val_loss: 97.7891 - val_keras_r2: -0.2530\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4485 - keras_r2: 0.1929 - val_loss: 76.4777 - val_keras_r2: 0.0287\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4643 - keras_r2: 0.0514 - val_loss: 73.2032 - val_keras_r2: 0.0759\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.1776 - keras_r2: -0.6351 - val_loss: 98.2948 - val_keras_r2: -0.2197\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2351 - keras_r2: 0.1751 - val_loss: 73.8139 - val_keras_r2: 0.0696\n",
            "Epoch 21: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=31; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 834.0272 - keras_r2: -10.3673 - val_loss: 152.2188 - val_keras_r2: -0.8857\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.5645 - keras_r2: -5.4370e-04 - val_loss: 151.2383 - val_keras_r2: -0.8773\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9363 - keras_r2: 0.1065 - val_loss: 74.6994 - val_keras_r2: 0.1188\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8259 - keras_r2: 0.1923 - val_loss: 73.5110 - val_keras_r2: 0.1274\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9243 - keras_r2: 0.2072 - val_loss: 89.3378 - val_keras_r2: -0.0707\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3902 - keras_r2: 0.1990 - val_loss: 95.3642 - val_keras_r2: -0.1787\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7020 - keras_r2: 0.2061 - val_loss: 130.3795 - val_keras_r2: -0.6457\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6768 - keras_r2: 0.2007 - val_loss: 80.3773 - val_keras_r2: 0.0320\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1600 - keras_r2: 0.2345 - val_loss: 72.2860 - val_keras_r2: 0.1420\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5243 - keras_r2: -2410460.2500 - val_loss: 74.3720 - val_keras_r2: 0.1093\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.0397 - keras_r2: 0.2410 - val_loss: 86.4164 - val_keras_r2: -0.0512\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.3469 - keras_r2: 0.2405 - val_loss: 87.2866 - val_keras_r2: -0.0589\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.0227 - keras_r2: 0.2471 - val_loss: 72.2295 - val_keras_r2: 0.1390\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.4613 - keras_r2: 0.2426 - val_loss: 111.2400 - val_keras_r2: -0.3876\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.3012 - keras_r2: 0.2304 - val_loss: 73.9622 - val_keras_r2: 0.1146\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.6253 - keras_r2: 0.2660 - val_loss: 74.4991 - val_keras_r2: 0.1155\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.1367 - keras_r2: 0.1271 - val_loss: 105.7982 - val_keras_r2: -0.2853\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.3817 - keras_r2: 0.2088 - val_loss: 197.7471 - val_keras_r2: -1.4837\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6877 - keras_r2: 0.1698 - val_loss: 74.9425 - val_keras_r2: 0.1134\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.3033 - keras_r2: 0.2526 - val_loss: 97.7388 - val_keras_r2: -0.2055\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.1800 - keras_r2: 0.1561 - val_loss: 75.9364 - val_keras_r2: 0.0897\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.2609 - keras_r2: 0.2782 - val_loss: 79.4697 - val_keras_r2: 0.0353\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.2245 - keras_r2: -37850.0039 - val_loss: 75.7358 - val_keras_r2: 0.0909\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=22; total time=  10.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 448.8004 - keras_r2: -5.0069 - val_loss: 86.9826 - val_keras_r2: -0.0668\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.4219 - keras_r2: 0.1275 - val_loss: 74.3808 - val_keras_r2: 0.1052\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.8218 - keras_r2: 0.1360 - val_loss: 90.3491 - val_keras_r2: -0.0948\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.9347 - keras_r2: 0.1210 - val_loss: 90.9888 - val_keras_r2: -0.1384\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9266 - keras_r2: 0.1552 - val_loss: 115.1748 - val_keras_r2: -0.4627\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5037 - keras_r2: 0.1148 - val_loss: 95.6063 - val_keras_r2: -0.1712\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2570 - keras_r2: 0.1457 - val_loss: 77.2497 - val_keras_r2: 0.0638\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.2212 - keras_r2: 0.1885 - val_loss: 100.4246 - val_keras_r2: -0.2397\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9141 - keras_r2: 0.2038 - val_loss: 74.9920 - val_keras_r2: 0.0987\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0500 - keras_r2: 0.2074 - val_loss: 79.8331 - val_keras_r2: 0.0468\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.8949 - keras_r2: 0.2335 - val_loss: 78.2683 - val_keras_r2: 0.0682\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2428 - keras_r2: 0.2410 - val_loss: 125.0756 - val_keras_r2: -0.5574\n",
            "Epoch 12: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=22; total time=  11.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 332.0619 - keras_r2: -3.5114 - val_loss: 80.5416 - val_keras_r2: 0.0327\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.0841 - keras_r2: 0.0227 - val_loss: 1417.1719 - val_keras_r2: -17.3256\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.3522 - keras_r2: -0.0378 - val_loss: 74.9963 - val_keras_r2: 0.1088\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.1671 - keras_r2: 0.1317 - val_loss: 129.0228 - val_keras_r2: -0.5794\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9249 - keras_r2: -0.1045 - val_loss: 77.5731 - val_keras_r2: 0.0735\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2461 - keras_r2: 0.1980 - val_loss: 85.3553 - val_keras_r2: -0.0135\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4586 - keras_r2: 0.1312 - val_loss: 92.3787 - val_keras_r2: -0.1011\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8908 - keras_r2: 0.2224 - val_loss: 78.1678 - val_keras_r2: 0.0771\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.4319 - keras_r2: 0.1554 - val_loss: 74.5316 - val_keras_r2: 0.1224\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.6126 - keras_r2: 0.2388 - val_loss: 85.0445 - val_keras_r2: -0.0140\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5910 - keras_r2: 0.1904 - val_loss: 123.1605 - val_keras_r2: -0.5068\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7865 - keras_r2: 0.1466 - val_loss: 72.8551 - val_keras_r2: 0.1387\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.7118 - keras_r2: 0.2579 - val_loss: 100.0431 - val_keras_r2: -0.2271\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.7464 - keras_r2: 0.2408 - val_loss: 78.5374 - val_keras_r2: 0.0801\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.6768 - keras_r2: -0.6674 - val_loss: 430.8412 - val_keras_r2: -4.6629\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9690 - keras_r2: 0.1917 - val_loss: 75.8234 - val_keras_r2: 0.0974\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.6271 - keras_r2: 0.2502 - val_loss: 284.6180 - val_keras_r2: -2.5475\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.1772 - keras_r2: -12758924.0000 - val_loss: 161.4593 - val_keras_r2: -1.0020\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1584 - keras_r2: 0.2111 - val_loss: 94.1784 - val_keras_r2: -0.1571\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1132 - keras_r2: 0.1396 - val_loss: 79.6079 - val_keras_r2: 0.0586\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.9262 - keras_r2: 0.2238 - val_loss: 99.6044 - val_keras_r2: -0.2350\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1934 - keras_r2: 0.2359 - val_loss: 77.3373 - val_keras_r2: 0.0827\n",
            "Epoch 22: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=22; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 259.6126 - keras_r2: -2.0364 - val_loss: 76.5143 - val_keras_r2: 0.0931\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.8026 - keras_r2: 0.0923 - val_loss: 87.1475 - val_keras_r2: -0.0640\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9592 - keras_r2: 0.1482 - val_loss: 115.9210 - val_keras_r2: -0.4524\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3729 - keras_r2: 0.1747 - val_loss: 93.8555 - val_keras_r2: -0.1582\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7825 - keras_r2: 0.1936 - val_loss: 80.8853 - val_keras_r2: 0.0336\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6056 - keras_r2: 0.1942 - val_loss: 100.9214 - val_keras_r2: -0.2158\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6982 - keras_r2: 0.2120 - val_loss: 117.5529 - val_keras_r2: -0.4212\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5464 - keras_r2: 0.1830 - val_loss: 74.6643 - val_keras_r2: 0.1231\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1606 - keras_r2: 0.1841 - val_loss: 83.7221 - val_keras_r2: -0.0060\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9772 - keras_r2: 0.2347 - val_loss: 111.9915 - val_keras_r2: -0.3568\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.3936 - keras_r2: 0.2337 - val_loss: 77.3933 - val_keras_r2: 0.0728\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5083 - keras_r2: 0.2572 - val_loss: 76.4520 - val_keras_r2: 0.0951\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.7787 - keras_r2: 0.2493 - val_loss: 159.9017 - val_keras_r2: -1.0523\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9231 - keras_r2: 0.1854 - val_loss: 80.0911 - val_keras_r2: 0.0493\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9650 - keras_r2: 0.2113 - val_loss: 83.5541 - val_keras_r2: -0.0129\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0189 - keras_r2: 0.2420 - val_loss: 78.6485 - val_keras_r2: 0.0594\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.4419 - keras_r2: 0.2387 - val_loss: 124.0517 - val_keras_r2: -0.5647\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.3684 - keras_r2: 0.2524 - val_loss: 98.9003 - val_keras_r2: -0.2093\n",
            "Epoch 18: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=22; total time=   8.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 453.4349 - keras_r2: -4.9096 - val_loss: 75.6258 - val_keras_r2: 0.0652\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2311 - keras_r2: 0.1228 - val_loss: 82.8494 - val_keras_r2: -0.0499\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.9260 - keras_r2: 0.1319 - val_loss: 156.7425 - val_keras_r2: -1.0435\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.3994 - keras_r2: 0.1370 - val_loss: 71.5101 - val_keras_r2: 0.1072\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1260 - keras_r2: 0.1845 - val_loss: 67.5921 - val_keras_r2: 0.1595\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2694 - keras_r2: 0.0829 - val_loss: 76.6315 - val_keras_r2: 0.0552\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.3599 - keras_r2: 0.1568 - val_loss: 91.2423 - val_keras_r2: -0.1674\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0221 - keras_r2: 0.1657 - val_loss: 149.3099 - val_keras_r2: -0.9319\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9850 - keras_r2: 0.1730 - val_loss: 67.7492 - val_keras_r2: 0.1612\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.6580 - keras_r2: 0.1777 - val_loss: 84.0721 - val_keras_r2: -0.0654\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7617 - keras_r2: 0.2055 - val_loss: 78.1410 - val_keras_r2: 0.0113\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9055 - keras_r2: 0.2024 - val_loss: 68.2831 - val_keras_r2: 0.1476\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2793 - keras_r2: 0.2135 - val_loss: 72.0736 - val_keras_r2: 0.0882\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2679 - keras_r2: 0.2308 - val_loss: 77.8299 - val_keras_r2: 0.0233\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1104 - keras_r2: 0.2217 - val_loss: 242.3652 - val_keras_r2: -2.1901\n",
            "Epoch 15: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=22; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 615.9591 - keras_r2: -7.0836 - val_loss: 206.8746 - val_keras_r2: -1.6713\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 181.0746 - keras_r2: -6.6025 - val_loss: 496.0199 - val_keras_r2: -5.5462\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 120.0218 - keras_r2: -13229603.0000 - val_loss: 371.9953 - val_keras_r2: -3.8129\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 113.3707 - keras_r2: -0.4127 - val_loss: 160.8284 - val_keras_r2: -0.9907\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4795 - keras_r2: -0.1008 - val_loss: 579.0921 - val_keras_r2: -6.3456\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 91.0582 - keras_r2: -0.1726 - val_loss: 284.5543 - val_keras_r2: -2.6041\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5013 - keras_r2: -0.0768 - val_loss: 113.3753 - val_keras_r2: -0.3925\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.4539 - keras_r2: -0.9667 - val_loss: 134.5175 - val_keras_r2: -0.7064\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.2741 - keras_r2: -0.0374 - val_loss: 230.7981 - val_keras_r2: -1.8086\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.3657 - keras_r2: -0.0181 - val_loss: 123.7660 - val_keras_r2: -0.4930\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.1489 - keras_r2: -0.0239 - val_loss: 94.2415 - val_keras_r2: -0.1240\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.0925 - keras_r2: 0.0060 - val_loss: 334.3227 - val_keras_r2: -3.3709\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.7048 - keras_r2: -0.1727 - val_loss: 187.6119 - val_keras_r2: -1.3342\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 120.5655 - keras_r2: -0.7966 - val_loss: 154.3691 - val_keras_r2: -0.9114\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.9188 - keras_r2: -0.3032 - val_loss: 105.0554 - val_keras_r2: -0.2436\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.8338 - keras_r2: 0.0081 - val_loss: 89.9831 - val_keras_r2: -0.0645\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.3556 - keras_r2: -0.0130 - val_loss: 91.5287 - val_keras_r2: -0.0960\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.8615 - keras_r2: -681263.3125 - val_loss: 88.7048 - val_keras_r2: -0.0532\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.0565 - keras_r2: 0.0326 - val_loss: 110.9704 - val_keras_r2: -0.3623\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9130 - keras_r2: -0.5306 - val_loss: 104.2764 - val_keras_r2: -0.2440\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4015 - keras_r2: 0.0408 - val_loss: 128.5256 - val_keras_r2: -0.5500\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.0819 - keras_r2: 0.0395 - val_loss: 121.4724 - val_keras_r2: -0.4915\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4508 - keras_r2: 0.0577 - val_loss: 110.2887 - val_keras_r2: -0.3254\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.6755 - keras_r2: 0.0801 - val_loss: 291.0725 - val_keras_r2: -2.6905\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.5306 - keras_r2: 0.0454 - val_loss: 93.7491 - val_keras_r2: -0.1175\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.4797 - keras_r2: 0.0843 - val_loss: 113.2100 - val_keras_r2: -0.3771\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.8968 - keras_r2: 0.0397 - val_loss: 91.1215 - val_keras_r2: -0.0926\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.7265 - keras_r2: 0.0929 - val_loss: 93.0494 - val_keras_r2: -0.1167\n",
            "Epoch 28: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=51; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 311.3048 - keras_r2: -3.0435 - val_loss: 307.2018 - val_keras_r2: -3.0615\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 530.1671 - keras_r2: -6.5321 - val_loss: 650.6044 - val_keras_r2: -7.7016\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 249.3307 - keras_r2: -2.5428 - val_loss: 476.4021 - val_keras_r2: -5.3178\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 177.4356 - keras_r2: -847402.6250 - val_loss: 165.0983 - val_keras_r2: -1.1422\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 166.2533 - keras_r2: -1.0651 - val_loss: 158.2642 - val_keras_r2: -1.0243\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 157.2733 - keras_r2: -1.0295 - val_loss: 269.0230 - val_keras_r2: -2.5574\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 155.1593 - keras_r2: -0.9852 - val_loss: 186.6601 - val_keras_r2: -1.4135\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 152.2003 - keras_r2: -0.9430 - val_loss: 170.3283 - val_keras_r2: -1.2375\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 149.3477 - keras_r2: -0.9249 - val_loss: 248.1404 - val_keras_r2: -2.2789\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 150.3703 - keras_r2: -0.8813 - val_loss: 194.7917 - val_keras_r2: -1.5448\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 147.3194 - keras_r2: -0.9175 - val_loss: 161.7956 - val_keras_r2: -1.0934\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 145.8708 - keras_r2: -0.8787 - val_loss: 198.0402 - val_keras_r2: -1.6073\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 148.5869 - keras_r2: -0.9084 - val_loss: 503.9620 - val_keras_r2: -4.7990\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 160.9364 - keras_r2: -1.3651 - val_loss: 285.6292 - val_keras_r2: -2.7927\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 148.2366 - keras_r2: -997040.2500 - val_loss: 169.6957 - val_keras_r2: -1.2142\n",
            "Epoch 15: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=51; total time=   7.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 366.2816 - keras_r2: -3.7477 - val_loss: 123.4246 - val_keras_r2: -0.4955\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 188.3410 - keras_r2: -1.6371 - val_loss: 1516.2445 - val_keras_r2: -18.7400\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 141.5630 - keras_r2: -0.7604 - val_loss: 102.0390 - val_keras_r2: -0.2327\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 212.2197 - keras_r2: -1.6057 - val_loss: 95.1815 - val_keras_r2: -0.1745\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 100.2841 - keras_r2: -0.2677 - val_loss: 177.2674 - val_keras_r2: -1.2983\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.9387 - keras_r2: -0.1459 - val_loss: 99.0713 - val_keras_r2: -0.2212\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 91.5643 - keras_r2: -0.1341 - val_loss: 90.1584 - val_keras_r2: -0.1034\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.0997 - keras_r2: -0.1554 - val_loss: 89.7876 - val_keras_r2: -0.0964\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 112.5299 - keras_r2: -0.4737 - val_loss: 146.8279 - val_keras_r2: -0.8771\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 197.5671 - keras_r2: -7.8721 - val_loss: 305.4955 - val_keras_r2: -2.9435\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 225.7514 - keras_r2: -3.4771 - val_loss: 1230.3580 - val_keras_r2: -15.3827\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 251.1144 - keras_r2: -2.1933 - val_loss: 149.9192 - val_keras_r2: -0.9387\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 117.4902 - keras_r2: -0.5084 - val_loss: 882.0646 - val_keras_r2: -10.6876\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 238.0216 - keras_r2: -2.1479 - val_loss: 154.0083 - val_keras_r2: -0.9774\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 155.8707 - keras_r2: -1.8796 - val_loss: 117.2813 - val_keras_r2: -0.4750\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 104.0733 - keras_r2: -0.3198 - val_loss: 102.4021 - val_keras_r2: -0.2770\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 108.2052 - keras_r2: -0.3892 - val_loss: 145.9944 - val_keras_r2: -0.8666\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 102.5763 - keras_r2: -0.2921 - val_loss: 96.8674 - val_keras_r2: -0.2000\n",
            "Epoch 18: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=51; total time=   8.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 352.8648 - keras_r2: -3.8351 - val_loss: 170.9547 - val_keras_r2: -1.1377\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1717.4880 - keras_r2: -26.3324 - val_loss: 1694.3419 - val_keras_r2: -21.6573\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1630.0327 - keras_r2: -20.7099 - val_loss: 1807.3569 - val_keras_r2: -23.0807\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1589.6000 - keras_r2: -26.7371 - val_loss: 1598.7345 - val_keras_r2: -20.3346\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1484.7891 - keras_r2: -103322056.0000 - val_loss: 1464.4331 - val_keras_r2: -18.5244\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1463.8126 - keras_r2: -18.7072 - val_loss: 1433.7875 - val_keras_r2: -18.1111\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1392.6218 - keras_r2: -19.3639 - val_loss: 1407.9230 - val_keras_r2: -17.7337\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1331.5155 - keras_r2: -16.7019 - val_loss: 1267.9158 - val_keras_r2: -15.9588\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1294.8989 - keras_r2: -15.8769 - val_loss: 1253.4601 - val_keras_r2: -15.7367\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 968.2255 - keras_r2: -34.1503 - val_loss: 471.5329 - val_keras_r2: -5.2393\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 480.9043 - keras_r2: -5.2706 - val_loss: 315.3783 - val_keras_r2: -3.1757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=51; total time=   5.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 283.4454 - keras_r2: -2.7549 - val_loss: 152.4205 - val_keras_r2: -1.0669\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 18429.5000 - keras_r2: -229.1596 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -28.4424 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.1143 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.5245 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.6406 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -21.8988 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.1933 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -376534112.0000 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.3716 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -21.9682 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=51; total time=   5.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 199.0779 - keras_r2: -1.4739 - val_loss: 87.0304 - val_keras_r2: -0.0446\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.1167 - keras_r2: -0.3969 - val_loss: 172.8804 - val_keras_r2: -1.2118\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.2453 - keras_r2: -0.0063 - val_loss: 84.8569 - val_keras_r2: -0.0053\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9832 - keras_r2: 0.0358 - val_loss: 118.6583 - val_keras_r2: -0.4449\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.5968 - keras_r2: -0.5785 - val_loss: 97.7660 - val_keras_r2: -0.1944\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.8911 - keras_r2: -0.0119 - val_loss: 119.3719 - val_keras_r2: -0.4627\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.7744 - keras_r2: 0.0914 - val_loss: 88.2835 - val_keras_r2: -0.0694\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.7614 - keras_r2: 0.0994 - val_loss: 79.7676 - val_keras_r2: 0.0530\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5457 - keras_r2: 0.1263 - val_loss: 79.1750 - val_keras_r2: 0.0614\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.1224 - keras_r2: 0.1123 - val_loss: 87.3624 - val_keras_r2: -0.0327\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2841 - keras_r2: 0.1249 - val_loss: 93.1898 - val_keras_r2: -0.1339\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7501 - keras_r2: 0.1204 - val_loss: 92.0318 - val_keras_r2: -0.1329\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.3608 - keras_r2: 0.1306 - val_loss: 81.2263 - val_keras_r2: 0.0481\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4336 - keras_r2: 0.1536 - val_loss: 155.4933 - val_keras_r2: -0.9885\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.8630 - keras_r2: 0.1098 - val_loss: 94.1828 - val_keras_r2: -0.1206\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9622 - keras_r2: 0.1568 - val_loss: 96.5980 - val_keras_r2: -0.1960\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9293 - keras_r2: 0.1452 - val_loss: 79.0529 - val_keras_r2: 0.0590\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2607 - keras_r2: 0.1619 - val_loss: 100.0764 - val_keras_r2: -0.2326\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5058 - keras_r2: 0.1455 - val_loss: 89.6305 - val_keras_r2: -0.0846\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9271 - keras_r2: 0.0822 - val_loss: 271.7122 - val_keras_r2: -2.5462\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.0851 - keras_r2: 0.0332 - val_loss: 81.3916 - val_keras_r2: 0.0370\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8205 - keras_r2: -2545233.7500 - val_loss: 85.7517 - val_keras_r2: -0.0195\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1084 - keras_r2: 0.1751 - val_loss: 79.5117 - val_keras_r2: 0.0685\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3244 - keras_r2: 0.1493 - val_loss: 94.3965 - val_keras_r2: -0.1566\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4179 - keras_r2: 0.1938 - val_loss: 85.9304 - val_keras_r2: -0.0176\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4593 - keras_r2: 0.1506 - val_loss: 104.0230 - val_keras_r2: -0.3043\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9319 - keras_r2: 0.1865 - val_loss: 94.6646 - val_keras_r2: -0.1489\n",
            "Epoch 27: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=81; total time=  11.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 172.9601 - keras_r2: -1.2638 - val_loss: 91.4285 - val_keras_r2: -0.1190\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.7290 - keras_r2: -0.0407 - val_loss: 86.5120 - val_keras_r2: -0.0492\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.0567 - keras_r2: 0.0150 - val_loss: 87.5165 - val_keras_r2: -0.0629\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.5310 - keras_r2: 0.0219 - val_loss: 79.0939 - val_keras_r2: 0.0513\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.0974 - keras_r2: 0.0362 - val_loss: 77.0170 - val_keras_r2: 0.0834\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4855 - keras_r2: 0.0636 - val_loss: 95.2354 - val_keras_r2: -0.1895\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.7837 - keras_r2: 0.0650 - val_loss: 112.5958 - val_keras_r2: -0.4020\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.1685 - keras_r2: -0.9674 - val_loss: 116.9354 - val_keras_r2: -0.5491\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.9127 - keras_r2: -0.0075 - val_loss: 76.6634 - val_keras_r2: 0.0778\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9857 - keras_r2: 0.1112 - val_loss: 91.8676 - val_keras_r2: -0.1392\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9299 - keras_r2: 0.0718 - val_loss: 86.9698 - val_keras_r2: -0.0537\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.8972 - keras_r2: 0.0954 - val_loss: 79.8304 - val_keras_r2: 0.0290\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.7971 - keras_r2: -1.6055 - val_loss: 130.6249 - val_keras_r2: -0.6219\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.4680 - keras_r2: 0.1163 - val_loss: 79.0689 - val_keras_r2: 0.0510\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.8002 - keras_r2: 0.1136 - val_loss: 79.5977 - val_keras_r2: 0.0271\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5279 - keras_r2: 0.1241 - val_loss: 76.6256 - val_keras_r2: 0.0649\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2033 - keras_r2: 0.1177 - val_loss: 78.4781 - val_keras_r2: 0.0452\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7693 - keras_r2: 0.1283 - val_loss: 82.8568 - val_keras_r2: -0.0111\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4243 - keras_r2: 0.1397 - val_loss: 92.8965 - val_keras_r2: -0.1283\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.2966 - keras_r2: 0.1363 - val_loss: 88.0645 - val_keras_r2: -0.0842\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1444 - keras_r2: 0.1361 - val_loss: 83.6487 - val_keras_r2: -0.0161\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.2126 - keras_r2: 0.1245 - val_loss: 84.8465 - val_keras_r2: -0.0401\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.8831 - keras_r2: 0.1304 - val_loss: 87.1526 - val_keras_r2: -0.0858\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.6225 - keras_r2: 0.1417 - val_loss: 80.0408 - val_keras_r2: 0.0278\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7529 - keras_r2: 0.1644 - val_loss: 107.7098 - val_keras_r2: -0.3655\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.2102 - keras_r2: 0.1535 - val_loss: 81.8401 - val_keras_r2: 0.0106\n",
            "Epoch 26: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=81; total time=  11.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 190.5527 - keras_r2: -1.4510 - val_loss: 101.5608 - val_keras_r2: -0.2358\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.6934 - keras_r2: -0.0108 - val_loss: 101.8215 - val_keras_r2: -0.1966\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.0264 - keras_r2: 0.0470 - val_loss: 93.3916 - val_keras_r2: -0.1061\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.3117 - keras_r2: -0.0957 - val_loss: 127.4754 - val_keras_r2: -0.5356\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0263 - keras_r2: 0.1176 - val_loss: 105.4077 - val_keras_r2: -0.2396\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.1779 - keras_r2: 0.1130 - val_loss: 92.9049 - val_keras_r2: -0.0899\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7786 - keras_r2: 0.0453 - val_loss: 125.4366 - val_keras_r2: -0.5269\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9917 - keras_r2: 0.1490 - val_loss: 98.2116 - val_keras_r2: -0.1835\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.5850 - keras_r2: 0.1287 - val_loss: 93.1457 - val_keras_r2: -0.1165\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0476 - keras_r2: 0.1385 - val_loss: 110.4045 - val_keras_r2: -0.2983\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3046 - keras_r2: 0.1680 - val_loss: 86.3276 - val_keras_r2: -0.0174\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.0439 - keras_r2: 0.1395 - val_loss: 90.8963 - val_keras_r2: -0.0912\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.4363 - keras_r2: -0.2407 - val_loss: 123.4681 - val_keras_r2: -0.4961\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3206 - keras_r2: 0.1314 - val_loss: 109.7432 - val_keras_r2: -0.3537\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0430 - keras_r2: 0.1967 - val_loss: 82.0069 - val_keras_r2: 0.0390\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7298 - keras_r2: 0.1892 - val_loss: 99.5970 - val_keras_r2: -0.2288\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1378 - keras_r2: 0.1782 - val_loss: 110.1744 - val_keras_r2: -0.3582\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7301 - keras_r2: 0.1762 - val_loss: 84.6124 - val_keras_r2: -0.0021\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0365 - keras_r2: 0.2089 - val_loss: 84.1199 - val_keras_r2: 0.0059\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3401 - keras_r2: 0.2098 - val_loss: 86.5384 - val_keras_r2: -0.0227\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8857 - keras_r2: 0.1977 - val_loss: 112.3970 - val_keras_r2: -0.3947\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3421 - keras_r2: -0.4213 - val_loss: 116.9585 - val_keras_r2: -0.4028\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7327 - keras_r2: 0.0469 - val_loss: 81.6291 - val_keras_r2: 0.0346\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7661 - keras_r2: 0.2254 - val_loss: 90.9320 - val_keras_r2: -0.0771\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8703 - keras_r2: 0.2053 - val_loss: 93.0127 - val_keras_r2: -0.0928\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2565 - keras_r2: 0.1974 - val_loss: 78.7807 - val_keras_r2: 0.0567\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.8999 - keras_r2: 0.2274 - val_loss: 80.7255 - val_keras_r2: 0.0427\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1266 - keras_r2: 0.2095 - val_loss: 189.4554 - val_keras_r2: -1.4572\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5003 - keras_r2: 0.1222 - val_loss: 83.9152 - val_keras_r2: 0.0053\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.3588 - keras_r2: 0.2081 - val_loss: 162.4924 - val_keras_r2: -1.0660\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9547 - keras_r2: 0.1881 - val_loss: 115.2735 - val_keras_r2: -0.3971\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4829 - keras_r2: 0.1941 - val_loss: 85.1614 - val_keras_r2: -0.0168\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.8734 - keras_r2: -0.4758 - val_loss: 140.1808 - val_keras_r2: -0.6837\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2153 - keras_r2: 0.2236 - val_loss: 92.4824 - val_keras_r2: -0.1151\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7162 - keras_r2: 0.2052 - val_loss: 86.8451 - val_keras_r2: -0.0292\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.7683 - keras_r2: 0.2011 - val_loss: 128.7084 - val_keras_r2: -0.6286\n",
            "Epoch 36: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=81; total time=  15.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 175.3143 - keras_r2: -1.1282 - val_loss: 101.9274 - val_keras_r2: -0.1947\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.7621 - keras_r2: -0.0695 - val_loss: 115.2468 - val_keras_r2: -0.3552\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.0030 - keras_r2: 0.0321 - val_loss: 94.0881 - val_keras_r2: -0.1039\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.3250 - keras_r2: -0.7619 - val_loss: 195.1085 - val_keras_r2: -1.4169\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.3832 - keras_r2: -764728.1875 - val_loss: 91.8979 - val_keras_r2: -0.0795\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.7776 - keras_r2: 0.1144 - val_loss: 90.4010 - val_keras_r2: -0.0528\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9397 - keras_r2: 0.1070 - val_loss: 102.4369 - val_keras_r2: -0.1937\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.3201 - keras_r2: 0.1364 - val_loss: 105.6482 - val_keras_r2: -0.2810\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7211 - keras_r2: 0.1315 - val_loss: 90.8972 - val_keras_r2: -0.0711\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4727 - keras_r2: 0.1478 - val_loss: 92.4646 - val_keras_r2: -0.0772\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7096 - keras_r2: 0.1385 - val_loss: 143.6590 - val_keras_r2: -0.7311\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9155 - keras_r2: 0.1462 - val_loss: 89.9117 - val_keras_r2: -0.0596\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5198 - keras_r2: 0.1681 - val_loss: 93.2078 - val_keras_r2: -0.1095\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9117 - keras_r2: 0.1593 - val_loss: 165.6988 - val_keras_r2: -1.0425\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3624 - keras_r2: 0.1841 - val_loss: 195.2675 - val_keras_r2: -1.5464\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3863 - keras_r2: -0.3153 - val_loss: 156.5931 - val_keras_r2: -0.9029\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.4157 - keras_r2: 0.1731 - val_loss: 88.0659 - val_keras_r2: -0.0264\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9349 - keras_r2: 0.1904 - val_loss: 89.5503 - val_keras_r2: -0.0585\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4719 - keras_r2: 0.1993 - val_loss: 118.0057 - val_keras_r2: -0.4116\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9821 - keras_r2: -0.4470 - val_loss: 117.3604 - val_keras_r2: -0.4072\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2282 - keras_r2: 0.2079 - val_loss: 88.6781 - val_keras_r2: -0.0534\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3728 - keras_r2: 0.2093 - val_loss: 92.8278 - val_keras_r2: -0.1203\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2952 - keras_r2: 0.2093 - val_loss: 91.0439 - val_keras_r2: -0.0701\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2326 - keras_r2: 0.1899 - val_loss: 122.6088 - val_keras_r2: -0.4975\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9528 - keras_r2: 0.1714 - val_loss: 152.2246 - val_keras_r2: -0.9553\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7534 - keras_r2: -4310419.0000 - val_loss: 107.7309 - val_keras_r2: -0.3357\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5708 - keras_r2: 0.1655 - val_loss: 90.4321 - val_keras_r2: -0.0800\n",
            "Epoch 27: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=81; total time=  12.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 158.3278 - keras_r2: -1.1102 - val_loss: 92.8799 - val_keras_r2: -0.1638\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.0191 - keras_r2: 0.0649 - val_loss: 104.0431 - val_keras_r2: -0.3163\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.1688 - keras_r2: 0.0992 - val_loss: 106.2402 - val_keras_r2: -0.3202\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.9832 - keras_r2: 0.1156 - val_loss: 99.1744 - val_keras_r2: -0.1990\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.7850 - keras_r2: 0.1425 - val_loss: 103.4426 - val_keras_r2: -0.2481\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.2103 - keras_r2: 0.1548 - val_loss: 88.0116 - val_keras_r2: -0.0782\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1764 - keras_r2: 0.1848 - val_loss: 111.9814 - val_keras_r2: -0.3637\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0603 - keras_r2: 0.1648 - val_loss: 98.8065 - val_keras_r2: -0.2152\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0670 - keras_r2: 0.1867 - val_loss: 95.8577 - val_keras_r2: -0.1622\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3836 - keras_r2: 0.2207 - val_loss: 87.5355 - val_keras_r2: -0.0499\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9942 - keras_r2: 0.2139 - val_loss: 83.6790 - val_keras_r2: -0.0145\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6448 - keras_r2: 0.2161 - val_loss: 89.7273 - val_keras_r2: -0.0959\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9906 - keras_r2: 0.2301 - val_loss: 91.0290 - val_keras_r2: -0.0902\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1069 - keras_r2: 0.2082 - val_loss: 89.1686 - val_keras_r2: -0.0857\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.8743 - keras_r2: 0.1453 - val_loss: 95.3027 - val_keras_r2: -0.1434\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.7771 - keras_r2: 0.2112 - val_loss: 104.9796 - val_keras_r2: -0.3146\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2374 - keras_r2: 0.2271 - val_loss: 85.3206 - val_keras_r2: -0.0365\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.8203 - keras_r2: 0.2143 - val_loss: 87.7363 - val_keras_r2: -0.0615\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0231 - keras_r2: 0.2264 - val_loss: 89.2016 - val_keras_r2: -0.0733\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5774 - keras_r2: 0.2254 - val_loss: 92.6451 - val_keras_r2: -0.1188\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.9589 - keras_r2: 0.2377 - val_loss: 85.3507 - val_keras_r2: -0.0320\n",
            "Epoch 21: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=81; total time=   9.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 277.8425 - keras_r2: -3.9143 - val_loss: 439.9408 - val_keras_r2: -4.6383\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 2827.6453 - keras_r2: -29.2987 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.2977 - keras_r2: -24.8711 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.0128 - keras_r2: -24.7742 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.6124 - keras_r2: -25.2611 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.5182 - keras_r2: -24.8118 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.5190 - keras_r2: -24.7129 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.5190 - keras_r2: -37.7266 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.5190 - keras_r2: -25.2530 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.5190 - keras_r2: -25.9361 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1932.5189 - keras_r2: -24.5520 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=29; total time=   5.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 407.0810 - keras_r2: -4.2001 - val_loss: 248.6968 - val_keras_r2: -2.1858\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 177.8653 - keras_r2: -1.3848 - val_loss: 865.4967 - val_keras_r2: -10.6271\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 252.2012 - keras_r2: -2.9746 - val_loss: 738.2454 - val_keras_r2: -8.6562\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 149.9188 - keras_r2: -0.9752 - val_loss: 450.2590 - val_keras_r2: -4.9954\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 212.8564 - keras_r2: -3.4048 - val_loss: 765.0730 - val_keras_r2: -9.1562\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 919.9899 - keras_r2: -12.4982 - val_loss: 540.8181 - val_keras_r2: -6.2014\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 286.7563 - keras_r2: -2.7100 - val_loss: 150.9071 - val_keras_r2: -0.9288\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 122.0102 - keras_r2: -0.5424 - val_loss: 103.2591 - val_keras_r2: -0.2749\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 101.1720 - keras_r2: -0.2620 - val_loss: 97.6712 - val_keras_r2: -0.1943\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 98.7540 - keras_r2: -0.8556 - val_loss: 97.0175 - val_keras_r2: -0.1837\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.5906 - keras_r2: -9254418.0000 - val_loss: 96.8847 - val_keras_r2: -0.1810\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.4076 - keras_r2: -0.2190 - val_loss: 96.8673 - val_keras_r2: -0.1805\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3877 - keras_r2: -1.1375 - val_loss: 96.8657 - val_keras_r2: -0.1803\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3854 - keras_r2: -0.2173 - val_loss: 96.8658 - val_keras_r2: -0.1802\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3943 - keras_r2: -0.2096 - val_loss: 96.8670 - val_keras_r2: -0.1805\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3863 - keras_r2: -0.2794 - val_loss: 96.8681 - val_keras_r2: -0.1805\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3810 - keras_r2: -0.2198 - val_loss: 96.8661 - val_keras_r2: -0.1804\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3872 - keras_r2: -0.2218 - val_loss: 96.8662 - val_keras_r2: -0.1803\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3801 - keras_r2: -0.2214 - val_loss: 96.8662 - val_keras_r2: -0.1803\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3894 - keras_r2: -0.2549 - val_loss: 96.8698 - val_keras_r2: -0.1801\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3839 - keras_r2: -0.2093 - val_loss: 96.8668 - val_keras_r2: -0.1802\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3825 - keras_r2: -0.2262 - val_loss: 96.8677 - val_keras_r2: -0.1805\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.3846 - keras_r2: -0.2189 - val_loss: 96.8660 - val_keras_r2: -0.1803\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=29; total time=  10.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 358.4059 - keras_r2: -3.9284 - val_loss: 546.9224 - val_keras_r2: -6.1455\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 169.4331 - keras_r2: -1.3759 - val_loss: 477.2448 - val_keras_r2: -5.1648\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 106.9311 - keras_r2: -0.3450 - val_loss: 87.3878 - val_keras_r2: -0.0501\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 262.5204 - keras_r2: -2.6381 - val_loss: 1090.1156 - val_keras_r2: -13.5578\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 233.2978 - keras_r2: -1.9829 - val_loss: 411.7619 - val_keras_r2: -4.3884\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 136.2342 - keras_r2: -0.7821 - val_loss: 302.1986 - val_keras_r2: -2.9443\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 159.0930 - keras_r2: -8.9049 - val_loss: 108.8978 - val_keras_r2: -0.3461\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 109.9792 - keras_r2: -0.3868 - val_loss: 269.4821 - val_keras_r2: -2.5372\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 164.8680 - keras_r2: -1.1019 - val_loss: 164.5198 - val_keras_r2: -1.0645\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 196.1736 - keras_r2: -1.5606 - val_loss: 287.7930 - val_keras_r2: -2.6566\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 117.8792 - keras_r2: -0.4995 - val_loss: 125.4444 - val_keras_r2: -0.5554\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 99.3870 - keras_r2: -0.2833 - val_loss: 191.9257 - val_keras_r2: -1.4769\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 91.8734 - keras_r2: -1142698.8750 - val_loss: 138.1334 - val_keras_r2: -0.6893\n",
            "Epoch 13: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=29; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 738.4088 - keras_r2: -8.3603 - val_loss: 203.2157 - val_keras_r2: -1.5724\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 145.5573 - keras_r2: -0.9720 - val_loss: 236.4712 - val_keras_r2: -2.0781\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 2699.7874 - keras_r2: -29.2002 - val_loss: 1351.0343 - val_keras_r2: -17.0484\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1159.7986 - keras_r2: -14.2106 - val_loss: 1036.8015 - val_keras_r2: -12.8842\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 938.1362 - keras_r2: -11.2630 - val_loss: 918.8500 - val_keras_r2: -11.2443\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 856.7056 - keras_r2: -11.9436 - val_loss: 827.3264 - val_keras_r2: -10.0574\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 826.4583 - keras_r2: -9.8225 - val_loss: 774.1039 - val_keras_r2: -9.3171\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 788.0401 - keras_r2: -9.3370 - val_loss: 771.1509 - val_keras_r2: -9.2767\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 786.2145 - keras_r2: -11.6423 - val_loss: 769.9046 - val_keras_r2: -9.2595\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 785.4423 - keras_r2: -9.3455 - val_loss: 769.5226 - val_keras_r2: -9.2533\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 785.1927 - keras_r2: -9.4360 - val_loss: 769.2455 - val_keras_r2: -9.2494\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=29; total time=   5.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 260.1805 - keras_r2: -2.3227 - val_loss: 142.8127 - val_keras_r2: -0.8128\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 173.0425 - keras_r2: -1.9427 - val_loss: 185.4931 - val_keras_r2: -1.3387\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 142.6152 - keras_r2: -0.8155 - val_loss: 93.8909 - val_keras_r2: -0.2051\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 112.1475 - keras_r2: -0.4062 - val_loss: 98.1066 - val_keras_r2: -0.2876\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 106.3903 - keras_r2: -0.3045 - val_loss: 105.2136 - val_keras_r2: -0.3497\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 152.9258 - keras_r2: -1.8211 - val_loss: 1799.1713 - val_keras_r2: -23.0571\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1760.0020 - keras_r2: -22.5826 - val_loss: 1799.4926 - val_keras_r2: -23.0620\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1759.8728 - keras_r2: -22.6648 - val_loss: 1799.2882 - val_keras_r2: -23.0651\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1759.5968 - keras_r2: -22.2134 - val_loss: 1798.8853 - val_keras_r2: -23.0603\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1759.7833 - keras_r2: -22.6339 - val_loss: 1800.1110 - val_keras_r2: -23.0731\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1693.9952 - keras_r2: -21.2774 - val_loss: 1080.2894 - val_keras_r2: -13.5279\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 965.7416 - keras_r2: -30.8205 - val_loss: 904.0956 - val_keras_r2: -11.1393\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1593.4846 - keras_r2: -22.5505 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 13: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=29; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2348.4919 - keras_r2: -29.2401 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.7975 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -60.0285 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -27.8183 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -24.6405 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -24.5684 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -343750016.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -24.7183 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.6594 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -56.4975 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.0631 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=49; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 863.5969 - keras_r2: -10.4923 - val_loss: 311.0114 - val_keras_r2: -3.0994\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 179.0960 - keras_r2: -1.3062 - val_loss: 112.0849 - val_keras_r2: -0.4055\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.4552 - keras_r2: -0.1833 - val_loss: 89.1651 - val_keras_r2: -0.0878\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.8621 - keras_r2: -0.0559 - val_loss: 86.5090 - val_keras_r2: -0.0485\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.7089 - keras_r2: -0.0372 - val_loss: 86.1856 - val_keras_r2: -0.0428\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5429 - keras_r2: -0.0281 - val_loss: 86.1523 - val_keras_r2: -0.0418\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5303 - keras_r2: -0.0880 - val_loss: 86.1539 - val_keras_r2: -0.0419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5350 - keras_r2: -11707985.0000 - val_loss: 86.1542 - val_keras_r2: -0.0419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5327 - keras_r2: -0.0390 - val_loss: 86.1527 - val_keras_r2: -0.0416\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5272 - keras_r2: -0.2833 - val_loss: 86.1535 - val_keras_r2: -0.0416\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5307 - keras_r2: -0.0347 - val_loss: 86.1526 - val_keras_r2: -0.0416\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5344 - keras_r2: -0.0368 - val_loss: 86.1534 - val_keras_r2: -0.0416\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5313 - keras_r2: -0.0659 - val_loss: 86.1683 - val_keras_r2: -0.0423\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5409 - keras_r2: -0.0419 - val_loss: 86.1531 - val_keras_r2: -0.0416\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5313 - keras_r2: -0.0356 - val_loss: 86.1555 - val_keras_r2: -0.0416\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5316 - keras_r2: -0.0384 - val_loss: 86.1542 - val_keras_r2: -0.0416\n",
            "Epoch 16: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=49; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1248.5198 - keras_r2: -15.9161 - val_loss: 412.2171 - val_keras_r2: -4.4382\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 166.6976 - keras_r2: -1.1406 - val_loss: 88.3885 - val_keras_r2: -0.0695\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.8689 - keras_r2: 0.0484 - val_loss: 98.3750 - val_keras_r2: -0.2103\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.2858 - keras_r2: 0.0996 - val_loss: 171.6939 - val_keras_r2: -1.1560\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.7094 - keras_r2: 0.0955 - val_loss: 75.5411 - val_keras_r2: 0.1083\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.5795 - keras_r2: 0.1462 - val_loss: 88.4782 - val_keras_r2: -0.0794\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.0886 - keras_r2: 0.1696 - val_loss: 107.2919 - val_keras_r2: -0.3342\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.8803 - keras_r2: 0.2064 - val_loss: 79.5605 - val_keras_r2: 0.0463\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.6160 - keras_r2: 0.2220 - val_loss: 73.0825 - val_keras_r2: 0.1396\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.0347 - keras_r2: 0.0375 - val_loss: 78.8190 - val_keras_r2: 0.0692\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.4286 - keras_r2: 0.2356 - val_loss: 115.7569 - val_keras_r2: -0.4248\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.5036 - keras_r2: 0.2532 - val_loss: 76.4913 - val_keras_r2: 0.0890\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.0471 - keras_r2: 0.2545 - val_loss: 91.8846 - val_keras_r2: -0.1333\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.4635 - keras_r2: -14879389.0000 - val_loss: 94.5185 - val_keras_r2: -0.1383\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.6969 - keras_r2: -4617768.5000 - val_loss: 76.0934 - val_keras_r2: 0.0904\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.6918 - keras_r2: 0.2619 - val_loss: 80.1607 - val_keras_r2: 0.0270\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.9288 - keras_r2: 0.2665 - val_loss: 95.4845 - val_keras_r2: -0.1639\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.5494 - keras_r2: 0.2446 - val_loss: 72.9182 - val_keras_r2: 0.1288\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.7806 - keras_r2: 0.1910 - val_loss: 79.0954 - val_keras_r2: 0.0567\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.5606 - keras_r2: 0.2824 - val_loss: 74.2997 - val_keras_r2: 0.1168\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.7674 - keras_r2: 0.2828 - val_loss: 74.1853 - val_keras_r2: 0.1169\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.6132 - keras_r2: 0.2975 - val_loss: 75.0468 - val_keras_r2: 0.1101\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 56.5906 - keras_r2: 0.3097 - val_loss: 247.3582 - val_keras_r2: -2.1674\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.3706 - keras_r2: 0.2440 - val_loss: 115.2006 - val_keras_r2: -0.4221\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 56.6587 - keras_r2: 0.2971 - val_loss: 183.5741 - val_keras_r2: -1.3360\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.0973 - keras_r2: 0.2634 - val_loss: 171.1239 - val_keras_r2: -1.1629\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.5260 - keras_r2: 0.2768 - val_loss: 81.6451 - val_keras_r2: 0.0206\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.1595 - keras_r2: 0.3313 - val_loss: 74.6057 - val_keras_r2: 0.1096\n",
            "Epoch 28: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=49; total time=  14.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2191.3064 - keras_r2: -28.3344 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.8020 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.7263 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.4793 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -38.3951 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -181818208.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.5568 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -28.6099 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.9117 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.6273 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.7049 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=49; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 434.4657 - keras_r2: -4.8521 - val_loss: 86.9014 - val_keras_r2: -0.0623\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.3048 - keras_r2: -0.1080 - val_loss: 72.6845 - val_keras_r2: 0.0984\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.7824 - keras_r2: 0.0263 - val_loss: 198.9063 - val_keras_r2: -1.4864\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.4618 - keras_r2: -0.1520 - val_loss: 120.7008 - val_keras_r2: -0.5711\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.5050 - keras_r2: 0.1471 - val_loss: 107.7287 - val_keras_r2: -0.3641\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.8104 - keras_r2: 0.1776 - val_loss: 68.4670 - val_keras_r2: 0.1405\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.9726 - keras_r2: 0.1922 - val_loss: 71.4677 - val_keras_r2: 0.1149\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4990 - keras_r2: 0.2253 - val_loss: 70.0445 - val_keras_r2: 0.1390\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.3899 - keras_r2: 0.2038 - val_loss: 114.9686 - val_keras_r2: -0.4946\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.3115 - keras_r2: 0.2351 - val_loss: 72.1802 - val_keras_r2: 0.0919\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.6731 - keras_r2: 0.2597 - val_loss: 85.3115 - val_keras_r2: -0.0909\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.9365 - keras_r2: 0.2481 - val_loss: 74.0885 - val_keras_r2: 0.0714\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.5386 - keras_r2: 0.2475 - val_loss: 126.0593 - val_keras_r2: -0.6478\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.6346 - keras_r2: 0.2397 - val_loss: 107.9042 - val_keras_r2: -0.3607\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.0852 - keras_r2: 0.1349 - val_loss: 72.9984 - val_keras_r2: 0.0863\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.3863 - keras_r2: 0.2925 - val_loss: 71.3100 - val_keras_r2: 0.0952\n",
            "Epoch 16: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=49; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2085.7515 - keras_r2: -30.8296 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.9989 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.5412 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.3033 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -26.0076 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.3325 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.6641 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -30.8702 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -30.6751 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.7607 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -26.5800 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=84; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2109.5479 - keras_r2: -27.2246 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.8602 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.9285 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.6832 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7718 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.9900 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -33.6519 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.4362 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -27.5113 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.5032 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.9763 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=84; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2800.2688 - keras_r2: -36.4438 - val_loss: 1770.8738 - val_keras_r2: -22.6083\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1441.3416 - keras_r2: -19.1067 - val_loss: 1144.5602 - val_keras_r2: -14.1063\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1052.1748 - keras_r2: -12.7960 - val_loss: 967.8250 - val_keras_r2: -11.7086\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 942.2681 - keras_r2: -11.5911 - val_loss: 914.6414 - val_keras_r2: -10.9792\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 914.7963 - keras_r2: -11.4649 - val_loss: 884.5124 - val_keras_r2: -10.6866\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 890.4573 - keras_r2: -10.9679 - val_loss: 880.9933 - val_keras_r2: -10.6368\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 888.4084 - keras_r2: -12.4213 - val_loss: 880.0411 - val_keras_r2: -10.6225\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.8126 - keras_r2: -11.1302 - val_loss: 879.8072 - val_keras_r2: -10.6187\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.6525 - keras_r2: -10.5278 - val_loss: 879.7382 - val_keras_r2: -10.6173\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 887.6024 - keras_r2: -11.7945 - val_loss: 879.7270 - val_keras_r2: -10.6169\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5867 - keras_r2: -16.6841 - val_loss: 879.7278 - val_keras_r2: -10.6167\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5839 - keras_r2: -10.6026 - val_loss: 879.7271 - val_keras_r2: -10.6168\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5853 - keras_r2: -18.5500 - val_loss: 879.7308 - val_keras_r2: -10.6167\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5850 - keras_r2: -10.6942 - val_loss: 879.7365 - val_keras_r2: -10.6167\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5825 - keras_r2: -10.7035 - val_loss: 879.7299 - val_keras_r2: -10.6167\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5849 - keras_r2: -12.0630 - val_loss: 879.7302 - val_keras_r2: -10.6167\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5833 - keras_r2: -10.6868 - val_loss: 879.7267 - val_keras_r2: -10.6168\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5850 - keras_r2: -10.5873 - val_loss: 879.7315 - val_keras_r2: -10.6167\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5842 - keras_r2: -68.3072 - val_loss: 879.7314 - val_keras_r2: -10.6167\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5825 - keras_r2: -10.5028 - val_loss: 879.7382 - val_keras_r2: -10.6167\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5848 - keras_r2: -10.9770 - val_loss: 879.7335 - val_keras_r2: -10.6167\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5867 - keras_r2: -10.7442 - val_loss: 879.7297 - val_keras_r2: -10.6167\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5851 - keras_r2: -10.6863 - val_loss: 879.7326 - val_keras_r2: -10.6167\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5839 - keras_r2: -57.4548 - val_loss: 879.7338 - val_keras_r2: -10.6167\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 887.5850 - keras_r2: -120666648.0000 - val_loss: 879.7347 - val_keras_r2: -10.6167\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5845 - keras_r2: -11.0818 - val_loss: 879.7357 - val_keras_r2: -10.6167\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 887.5846 - keras_r2: -13.7305 - val_loss: 879.7365 - val_keras_r2: -10.6167\n",
            "Epoch 27: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=84; total time=  21.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 8353.0420 - keras_r2: -123.8706 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.8563 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -29.0044 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.9785 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -181818208.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -26.2606 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.8981 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6143 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.3518 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -27.0853 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -210113648.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=84; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 907.7855 - keras_r2: -11.1654 - val_loss: 360.2965 - val_keras_r2: -3.7885\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 151.7866 - keras_r2: -0.9114 - val_loss: 94.2591 - val_keras_r2: -0.1434\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1623.4875 - keras_r2: -20.4273 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -24.2126 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -21.9878 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.2483 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.9222 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.5491 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.4343 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.0325 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.0123 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.2175 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 12: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=84; total time=   7.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 246.6002 - keras_r2: -2.4006 - val_loss: 84.1549 - val_keras_r2: 0.0014\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 91.5373 - keras_r2: -0.1821 - val_loss: 287.9047 - val_keras_r2: -2.7615\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.4670 - keras_r2: 0.0124 - val_loss: 94.7958 - val_keras_r2: -0.0892\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 108.4766 - keras_r2: -0.4132 - val_loss: 259.3162 - val_keras_r2: -2.3556\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 93.7490 - keras_r2: -0.1767 - val_loss: 106.5983 - val_keras_r2: -0.2861\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 135.0487 - keras_r2: -0.6424 - val_loss: 119.0521 - val_keras_r2: -0.4667\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0987 - keras_r2: -0.0714 - val_loss: 118.2534 - val_keras_r2: -0.4483\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.6993 - keras_r2: 0.0322 - val_loss: 91.9259 - val_keras_r2: -0.1257\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.0013 - keras_r2: -0.0024 - val_loss: 138.7962 - val_keras_r2: -0.7093\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9207 - keras_r2: 0.0372 - val_loss: 97.3639 - val_keras_r2: -0.1776\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.3965 - keras_r2: 0.0359 - val_loss: 101.1755 - val_keras_r2: -0.2275\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=10; total time=   5.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 250.6699 - keras_r2: -2.7145 - val_loss: 271.6844 - val_keras_r2: -2.5014\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 110.7101 - keras_r2: -0.4091 - val_loss: 207.7961 - val_keras_r2: -1.6422\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 924.1573 - keras_r2: -10.1787 - val_loss: 1831.6836 - val_keras_r2: -23.6039\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 2173.8450 - keras_r2: -29.5992 - val_loss: 1849.4243 - val_keras_r2: -23.7654\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1828.7506 - keras_r2: -23.5405 - val_loss: 1800.5878 - val_keras_r2: -23.0995\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1811.8683 - keras_r2: -23.6628 - val_loss: 1817.7288 - val_keras_r2: -23.3739\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1802.7582 - keras_r2: -24.9563 - val_loss: 1824.0958 - val_keras_r2: -23.4311\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1818.5190 - keras_r2: -23.4775 - val_loss: 1808.1917 - val_keras_r2: -23.2203\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1815.0328 - keras_r2: -22.9865 - val_loss: 1800.3485 - val_keras_r2: -23.1014\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1812.6787 - keras_r2: -24.2810 - val_loss: 1810.2793 - val_keras_r2: -23.2358\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1791.2428 - keras_r2: -23.9421 - val_loss: 1751.2426 - val_keras_r2: -22.4151\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1747.3309 - keras_r2: -22.7626 - val_loss: 1697.3644 - val_keras_r2: -21.8079\n",
            "Epoch 12: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=10; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 438.4552 - keras_r2: -4.6658 - val_loss: 435.1758 - val_keras_r2: -4.8066\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 422.8802 - keras_r2: -4.6122 - val_loss: 375.3688 - val_keras_r2: -3.8863\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 271.6117 - keras_r2: -2.5256 - val_loss: 297.8258 - val_keras_r2: -2.8889\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 190.8591 - keras_r2: -1.3874 - val_loss: 173.7028 - val_keras_r2: -1.2060\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 156.1362 - keras_r2: -0.9738 - val_loss: 163.9124 - val_keras_r2: -1.0859\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 130.0319 - keras_r2: -0.7384 - val_loss: 123.5064 - val_keras_r2: -0.5294\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 110.2619 - keras_r2: -0.3795 - val_loss: 112.8334 - val_keras_r2: -0.3828\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 95.1282 - keras_r2: -0.2035 - val_loss: 98.0054 - val_keras_r2: -0.1944\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.2067 - keras_r2: -0.1667 - val_loss: 128.1056 - val_keras_r2: -0.5755\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.2724 - keras_r2: -0.0289 - val_loss: 89.9543 - val_keras_r2: -0.0984\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.8106 - keras_r2: 0.0029 - val_loss: 84.9072 - val_keras_r2: -0.0261\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.7665 - keras_r2: 0.0646 - val_loss: 83.2100 - val_keras_r2: -9.7141e-04\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.3036 - keras_r2: 0.0700 - val_loss: 87.4875 - val_keras_r2: -0.0672\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2941 - keras_r2: 0.0984 - val_loss: 167.3756 - val_keras_r2: -1.0945\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.0909 - keras_r2: 0.1261 - val_loss: 79.4587 - val_keras_r2: 0.0491\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.0707 - keras_r2: 0.1459 - val_loss: 78.7868 - val_keras_r2: 0.0539\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.8170 - keras_r2: 0.1709 - val_loss: 77.4891 - val_keras_r2: 0.0730\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9820 - keras_r2: 0.1520 - val_loss: 79.8677 - val_keras_r2: 0.0370\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3349 - keras_r2: 0.1128 - val_loss: 76.7870 - val_keras_r2: 0.0766\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8262 - keras_r2: -0.1183 - val_loss: 76.6386 - val_keras_r2: 0.0849\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1604 - keras_r2: 0.2074 - val_loss: 76.6894 - val_keras_r2: 0.0898\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9312 - keras_r2: 0.1633 - val_loss: 74.9524 - val_keras_r2: 0.1107\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7252 - keras_r2: 0.2063 - val_loss: 75.2742 - val_keras_r2: 0.1079\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.4845 - keras_r2: 0.2162 - val_loss: 75.9340 - val_keras_r2: 0.0991\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9658 - keras_r2: 0.1923 - val_loss: 75.0640 - val_keras_r2: 0.1062\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7752 - keras_r2: 0.0494 - val_loss: 77.8317 - val_keras_r2: 0.0782\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.3021 - keras_r2: 0.2203 - val_loss: 75.9788 - val_keras_r2: 0.0950\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5069 - keras_r2: 0.2200 - val_loss: 76.3240 - val_keras_r2: 0.0892\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0604 - keras_r2: 0.2312 - val_loss: 75.1515 - val_keras_r2: 0.1065\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0636 - keras_r2: 0.2297 - val_loss: 74.6131 - val_keras_r2: 0.1136\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9448 - keras_r2: 0.2414 - val_loss: 82.7326 - val_keras_r2: -7.1078e-04\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9120 - keras_r2: 0.2311 - val_loss: 74.5284 - val_keras_r2: 0.1132\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.5435 - keras_r2: 0.1703 - val_loss: 79.1865 - val_keras_r2: 0.0455\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7128 - keras_r2: 0.2107 - val_loss: 74.7840 - val_keras_r2: 0.1069\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.4434 - keras_r2: 0.2155 - val_loss: 75.3919 - val_keras_r2: 0.1042\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.5149 - keras_r2: 0.2259 - val_loss: 72.8957 - val_keras_r2: 0.1333\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2945 - keras_r2: 0.1817 - val_loss: 74.2784 - val_keras_r2: 0.1176\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.2774 - keras_r2: 0.0744 - val_loss: 73.8424 - val_keras_r2: 0.1244\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2270 - keras_r2: 0.2374 - val_loss: 75.6666 - val_keras_r2: 0.0957\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0291 - keras_r2: 0.2468 - val_loss: 76.3530 - val_keras_r2: 0.0864\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9236 - keras_r2: 0.2454 - val_loss: 76.8805 - val_keras_r2: 0.0780\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0521 - keras_r2: 0.2446 - val_loss: 80.1993 - val_keras_r2: 0.0396\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0076 - keras_r2: 0.2104 - val_loss: 78.3268 - val_keras_r2: 0.0678\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.7421 - keras_r2: 0.2486 - val_loss: 74.4339 - val_keras_r2: 0.1106\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5369 - keras_r2: 0.1036 - val_loss: 75.6263 - val_keras_r2: 0.0928\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.4629 - keras_r2: 0.2355 - val_loss: 77.9028 - val_keras_r2: 0.0614\n",
            "Epoch 46: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=10; total time=  21.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 305.5441 - keras_r2: -6600927.5000 - val_loss: 123.6175 - val_keras_r2: -0.4842\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 232.2927 - keras_r2: -1.7715 - val_loss: 677.9419 - val_keras_r2: -8.0295\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 182.2189 - keras_r2: -1.3653 - val_loss: 419.8245 - val_keras_r2: -4.4102\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 121.6220 - keras_r2: -0.5025 - val_loss: 173.7042 - val_keras_r2: -1.2307\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.7574 - keras_r2: 0.0146 - val_loss: 358.6228 - val_keras_r2: -3.5206\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.2109 - keras_r2: 0.0941 - val_loss: 79.3480 - val_keras_r2: 0.0536\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 547.0300 - keras_r2: -6.4355 - val_loss: 401.7048 - val_keras_r2: -4.2853\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 203.9574 - keras_r2: -1.6799 - val_loss: 196.9308 - val_keras_r2: -1.5528\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 174.4694 - keras_r2: -1.2377 - val_loss: 207.5831 - val_keras_r2: -1.6886\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 103.7185 - keras_r2: -0.3512 - val_loss: 88.3341 - val_keras_r2: -0.1036\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.5341 - keras_r2: -0.0965 - val_loss: 157.2522 - val_keras_r2: -1.0004\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3125 - keras_r2: -0.0861 - val_loss: 87.1289 - val_keras_r2: -0.0741\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.0494 - keras_r2: -0.0206 - val_loss: 86.8411 - val_keras_r2: -0.0719\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.9225 - keras_r2: -0.0190 - val_loss: 108.0432 - val_keras_r2: -0.3532\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.1724 - keras_r2: -0.0645 - val_loss: 121.8929 - val_keras_r2: -0.5194\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 97.6336 - keras_r2: -0.2293 - val_loss: 148.6644 - val_keras_r2: -0.8575\n",
            "Epoch 16: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=10; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 447.5648 - keras_r2: -5.0029 - val_loss: 474.9148 - val_keras_r2: -5.3326\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 535.7599 - keras_r2: -6.0564 - val_loss: 22883.3027 - val_keras_r2: -306.4842\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 657.0532 - keras_r2: -7.4664 - val_loss: 199.5045 - val_keras_r2: -1.6231\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 133.0316 - keras_r2: -0.6713 - val_loss: 99.4043 - val_keras_r2: -0.2620\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.6252 - keras_r2: -0.1835 - val_loss: 86.3354 - val_keras_r2: -0.0787\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.0719 - keras_r2: -0.0614 - val_loss: 84.1745 - val_keras_r2: -0.0466\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.5518 - keras_r2: -0.0602 - val_loss: 83.7325 - val_keras_r2: -0.0398\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.4577 - keras_r2: -0.0651 - val_loss: 83.5788 - val_keras_r2: -0.0373\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4390 - keras_r2: -0.0549 - val_loss: 83.5137 - val_keras_r2: -0.0362\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.4324 - keras_r2: -0.0618 - val_loss: 83.5164 - val_keras_r2: -0.0362\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4313 - keras_r2: -0.0737 - val_loss: 83.3927 - val_keras_r2: -0.0340\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4402 - keras_r2: -0.0638 - val_loss: 83.4611 - val_keras_r2: -0.0353\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.4360 - keras_r2: -0.0665 - val_loss: 83.4262 - val_keras_r2: -0.0346\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.4394 - keras_r2: -0.0695 - val_loss: 83.4557 - val_keras_r2: -0.0352\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4301 - keras_r2: -0.0589 - val_loss: 83.3963 - val_keras_r2: -0.0341\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4383 - keras_r2: -0.0607 - val_loss: 83.4670 - val_keras_r2: -0.0354\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4369 - keras_r2: -0.0635 - val_loss: 83.4498 - val_keras_r2: -0.0351\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4330 - keras_r2: -0.0885 - val_loss: 83.5338 - val_keras_r2: -0.0365\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4377 - keras_r2: -0.0612 - val_loss: 83.5066 - val_keras_r2: -0.0360\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4352 - keras_r2: -0.0846 - val_loss: 83.5611 - val_keras_r2: -0.0370\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.4377 - keras_r2: -0.0672 - val_loss: 83.5319 - val_keras_r2: -0.0365\n",
            "Epoch 21: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=10; total time=  10.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 1933.4823 - keras_r2: -24.7919 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -27.7990 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.2860 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -29.2602 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -35.2944 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.0096 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.1768 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.4432 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -240454560.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.2488 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -30.2573 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ............................n_hidden=5, n_neurons=5; total time=   6.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 861.2131 - keras_r2: -10.3217 - val_loss: 307.8920 - val_keras_r2: -3.0573\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 177.6601 - keras_r2: -1.3490 - val_loss: 112.6270 - val_keras_r2: -0.4129\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.6832 - keras_r2: -0.2130 - val_loss: 89.0555 - val_keras_r2: -0.0862\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.8056 - keras_r2: -0.0648 - val_loss: 86.4685 - val_keras_r2: -0.0478\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6711 - keras_r2: -0.0667 - val_loss: 86.1610 - val_keras_r2: -0.0421\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5364 - keras_r2: -0.3270 - val_loss: 86.1533 - val_keras_r2: -0.0418\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5344 - keras_r2: -0.0497 - val_loss: 86.1562 - val_keras_r2: -0.0420\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5348 - keras_r2: -0.0766 - val_loss: 86.1521 - val_keras_r2: -0.0417\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5309 - keras_r2: -0.0728 - val_loss: 86.1543 - val_keras_r2: -0.0419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5330 - keras_r2: -0.0570 - val_loss: 86.1526 - val_keras_r2: -0.0416\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5319 - keras_r2: -0.0339 - val_loss: 86.1549 - val_keras_r2: -0.0416\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5297 - keras_r2: -0.0344 - val_loss: 86.1536 - val_keras_r2: -0.0416\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5324 - keras_r2: -0.0364 - val_loss: 86.1534 - val_keras_r2: -0.0416\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5312 - keras_r2: -0.1924 - val_loss: 86.1528 - val_keras_r2: -0.0416\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5286 - keras_r2: -0.0521 - val_loss: 86.1532 - val_keras_r2: -0.0416\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5327 - keras_r2: -0.0946 - val_loss: 86.1524 - val_keras_r2: -0.0418\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5329 - keras_r2: -0.0411 - val_loss: 86.1539 - val_keras_r2: -0.0416\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5328 - keras_r2: -0.0367 - val_loss: 86.1540 - val_keras_r2: -0.0416\n",
            "Epoch 18: early stopping\n",
            "[CV] END ............................n_hidden=5, n_neurons=5; total time=   9.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2062.8806 - keras_r2: -26.4864 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -25.9626 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -65.3494 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -25.6656 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -27.1032 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -26.6726 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -26.4442 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -26.1222 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 2035.2001 - keras_r2: -25.7192 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -35.4727 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -27.9150 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ............................n_hidden=5, n_neurons=5; total time=   6.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1961.4209 - keras_r2: -25.7707 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -69.5577 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.2917 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.8215 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -27.1197 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.6231 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -63.5089 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -28.7223 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -36.8288 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.5452 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.4644 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ............................n_hidden=5, n_neurons=5; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2650.8789 - keras_r2: -31.4961 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.3838 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.6971 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.2371 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -21.9161 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.0843 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3027 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.7390 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.2937 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.8894 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.4038 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ............................n_hidden=5, n_neurons=5; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4341.8149 - keras_r2: -63.5626 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -26.0348 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -191022736.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.5385 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.6354 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.8760 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -25.2623 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.6732 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -37.4291 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.2412 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -35.5966 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=95; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 10080.9785 - keras_r2: -203.4763 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8361 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.1410 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -34.7470 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.6253 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.1455 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -89.0095 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7525 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -59.3165 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -26.0615 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -25.3280 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=95; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4868.1729 - keras_r2: -63.6101 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.0968 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.6292 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -25.7581 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.3667 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -28.3383 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.9896 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -37.7571 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.5730 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.8012 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -68.4696 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=95; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3657.5886 - keras_r2: -49.6785 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.4961 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6883 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6946 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -30.9586 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.2477 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -35.6693 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -27.7057 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.2738 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.8624 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -26.8099 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=95; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1908.7975 - keras_r2: -24.6806 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.9067 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.4155 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.2489 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3132 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3761 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6013 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.7225 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -39.0686 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6842 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.6032 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=95; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 86531.3281 - keras_r2: -1886.1415 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.2475 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -24.9932 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -24.9679 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -38.5534 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -89.8341 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.3278 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -26.5970 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.6524 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -26.8723 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -24.8858 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=37; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2592.2983 - keras_r2: -30.6480 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.7997 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.1950 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -60.9719 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.2962 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -25.0695 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -343750016.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -47.8074 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.7445 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -29.8147 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.2156 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=37; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 531.4437 - keras_r2: -6.5303 - val_loss: 275.6078 - val_keras_r2: -2.5211\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.2420 - keras_r2: -0.1453 - val_loss: 133.8405 - val_keras_r2: -0.6360\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 171.6747 - keras_r2: -1.0808 - val_loss: 252.5620 - val_keras_r2: -2.1560\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.8448 - keras_r2: 0.1039 - val_loss: 92.4956 - val_keras_r2: -0.1364\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.7333 - keras_r2: 0.1628 - val_loss: 88.6758 - val_keras_r2: -0.0776\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.4824 - keras_r2: 0.1726 - val_loss: 86.3453 - val_keras_r2: -0.0256\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.7076 - keras_r2: 0.1605 - val_loss: 74.0251 - val_keras_r2: 0.1282\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.2250 - keras_r2: 0.0428 - val_loss: 122.0682 - val_keras_r2: -0.5372\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 66.3332 - keras_r2: 0.1874 - val_loss: 83.1906 - val_keras_r2: -9.7847e-04\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.4504 - keras_r2: 0.2100 - val_loss: 74.3893 - val_keras_r2: 0.1176\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.1003 - keras_r2: 0.1967 - val_loss: 74.9799 - val_keras_r2: 0.1069\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9279 - keras_r2: -0.0902 - val_loss: 110.2535 - val_keras_r2: -0.3308\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5238 - keras_r2: 0.2017 - val_loss: 142.3703 - val_keras_r2: -0.8214\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4531 - keras_r2: 0.2276 - val_loss: 77.4981 - val_keras_r2: 0.0708\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.9843 - keras_r2: 0.2426 - val_loss: 78.4909 - val_keras_r2: 0.0751\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.7553 - keras_r2: -0.4881 - val_loss: 97.9956 - val_keras_r2: -0.1783\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.6110 - keras_r2: 0.2349 - val_loss: 123.4546 - val_keras_r2: -0.5571\n",
            "Epoch 17: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=37; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 968.7735 - keras_r2: -11.7012 - val_loss: 342.7274 - val_keras_r2: -3.5048\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 190.7053 - keras_r2: -1.4614 - val_loss: 118.7260 - val_keras_r2: -0.4829\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 97.8087 - keras_r2: -0.2144 - val_loss: 91.1408 - val_keras_r2: -0.1024\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.7451 - keras_r2: 0.0058 - val_loss: 88.6354 - val_keras_r2: -0.0686\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.3084 - keras_r2: 0.0634 - val_loss: 75.6257 - val_keras_r2: 0.1076\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2919 - keras_r2: 0.0711 - val_loss: 83.4665 - val_keras_r2: -0.0032\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9897 - keras_r2: 0.1395 - val_loss: 111.9627 - val_keras_r2: -0.3492\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.3148 - keras_r2: 0.1648 - val_loss: 76.6282 - val_keras_r2: 0.0951\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.1617 - keras_r2: 0.1870 - val_loss: 75.5916 - val_keras_r2: 0.1066\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.3602 - keras_r2: 0.1829 - val_loss: 112.8830 - val_keras_r2: -0.3808\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.0283 - keras_r2: 0.1747 - val_loss: 80.7573 - val_keras_r2: 0.0345\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.9882 - keras_r2: 0.2114 - val_loss: 73.3336 - val_keras_r2: 0.1303\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.2327 - keras_r2: 0.2167 - val_loss: 77.0006 - val_keras_r2: 0.0798\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5990 - keras_r2: 0.1355 - val_loss: 87.2061 - val_keras_r2: -0.0571\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.4748 - keras_r2: 0.2285 - val_loss: 79.7339 - val_keras_r2: 0.0626\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.1694 - keras_r2: 0.2314 - val_loss: 73.6444 - val_keras_r2: 0.1273\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.0057 - keras_r2: 0.2312 - val_loss: 74.5424 - val_keras_r2: 0.1194\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.1755 - keras_r2: 0.2351 - val_loss: 75.4148 - val_keras_r2: 0.1063\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.0474 - keras_r2: -0.3578 - val_loss: 79.5451 - val_keras_r2: 0.0511\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.0825 - keras_r2: 0.2251 - val_loss: 73.0713 - val_keras_r2: 0.1405\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.1419 - keras_r2: 0.2345 - val_loss: 75.8433 - val_keras_r2: 0.1058\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.4234 - keras_r2: -2185567.0000 - val_loss: 78.1245 - val_keras_r2: 0.0691\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.0490 - keras_r2: 0.2370 - val_loss: 86.5825 - val_keras_r2: -0.0286\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.2322 - keras_r2: 0.2657 - val_loss: 90.7478 - val_keras_r2: -0.0815\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.2048 - keras_r2: -0.3519 - val_loss: 91.3337 - val_keras_r2: -0.1120\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.1345 - keras_r2: 0.2853 - val_loss: 187.2763 - val_keras_r2: -1.3273\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.6534 - keras_r2: 0.2887 - val_loss: 74.7913 - val_keras_r2: 0.1142\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.1844 - keras_r2: 0.2925 - val_loss: 75.4622 - val_keras_r2: 0.1063\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.4570 - keras_r2: 0.3016 - val_loss: 79.5053 - val_keras_r2: 0.0550\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.0528 - keras_r2: 0.2990 - val_loss: 81.3122 - val_keras_r2: 0.0339\n",
            "Epoch 30: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=37; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 499.4094 - keras_r2: -5.7252 - val_loss: 111.9695 - val_keras_r2: -0.4432\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.8153 - keras_r2: -0.0620 - val_loss: 81.3788 - val_keras_r2: -0.0027\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.8648 - keras_r2: -0.0073 - val_loss: 71.1522 - val_keras_r2: 0.1129\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.9773 - keras_r2: 0.0948 - val_loss: 135.1215 - val_keras_r2: -0.7660\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.9957 - keras_r2: 0.0788 - val_loss: 79.4534 - val_keras_r2: 0.0018\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.4598 - keras_r2: 0.1110 - val_loss: 78.6295 - val_keras_r2: 0.0074\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6298 - keras_r2: 0.1297 - val_loss: 92.7255 - val_keras_r2: -0.1556\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.4741 - keras_r2: 0.1743 - val_loss: 94.5290 - val_keras_r2: -0.1772\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.9220 - keras_r2: 0.1813 - val_loss: 118.1121 - val_keras_r2: -0.5290\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.3637 - keras_r2: 0.1759 - val_loss: 81.3668 - val_keras_r2: -0.0336\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.5603 - keras_r2: 0.2103 - val_loss: 79.9865 - val_keras_r2: 0.0138\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.9538 - keras_r2: 0.1287 - val_loss: 82.4643 - val_keras_r2: -0.0199\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.7150 - keras_r2: 0.2035 - val_loss: 78.0153 - val_keras_r2: 0.0154\n",
            "Epoch 13: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=37; total time=   7.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 208.5607 - keras_r2: -1.5453 - val_loss: 113.7628 - val_keras_r2: -0.3158\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 158.6687 - keras_r2: -1.1612 - val_loss: 315.1929 - val_keras_r2: -3.0256\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 101.7998 - keras_r2: -0.2756 - val_loss: 104.4909 - val_keras_r2: -0.2425\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.5382 - keras_r2: -0.0219 - val_loss: 99.1266 - val_keras_r2: -0.1453\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.2052 - keras_r2: -0.4818 - val_loss: 128.4932 - val_keras_r2: -0.5499\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.7115 - keras_r2: 0.0412 - val_loss: 96.0572 - val_keras_r2: -0.1258\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.3693 - keras_r2: -0.0181 - val_loss: 106.2324 - val_keras_r2: -0.2558\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.2851 - keras_r2: 0.0797 - val_loss: 96.1481 - val_keras_r2: -0.1302\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4402 - keras_r2: 0.0721 - val_loss: 83.6565 - val_keras_r2: 0.0189\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.3735 - keras_r2: 0.1047 - val_loss: 86.7975 - val_keras_r2: -0.0177\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.1394 - keras_r2: 0.0918 - val_loss: 124.8480 - val_keras_r2: -0.5675\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.7399 - keras_r2: 0.0546 - val_loss: 115.6361 - val_keras_r2: -0.3607\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.7418 - keras_r2: 0.0518 - val_loss: 136.6326 - val_keras_r2: -0.6184\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.0491 - keras_r2: 0.0684 - val_loss: 83.5340 - val_keras_r2: 0.0145\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.6711 - keras_r2: 0.0932 - val_loss: 86.6359 - val_keras_r2: -0.0367\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.4333 - keras_r2: -0.5273 - val_loss: 195.9931 - val_keras_r2: -1.4308\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.9001 - keras_r2: 0.1116 - val_loss: 120.0710 - val_keras_r2: -0.4462\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.8951 - keras_r2: 0.0707 - val_loss: 85.2607 - val_keras_r2: -0.0083\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.0984 - keras_r2: 0.0976 - val_loss: 93.7578 - val_keras_r2: -0.1423\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3331 - keras_r2: 0.0969 - val_loss: 217.0729 - val_keras_r2: -1.7925\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.3731 - keras_r2: 0.0640 - val_loss: 96.5851 - val_keras_r2: -0.1832\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.4119 - keras_r2: 0.1186 - val_loss: 159.8996 - val_keras_r2: -0.9883\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6314 - keras_r2: 0.1157 - val_loss: 99.0644 - val_keras_r2: -0.1539\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6063 - keras_r2: 0.1352 - val_loss: 84.3403 - val_keras_r2: -0.0035\n",
            "Epoch 24: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=14; total time=  11.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 196.2197 - keras_r2: -1.4973 - val_loss: 94.6034 - val_keras_r2: -0.1417\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.2509 - keras_r2: -0.1262 - val_loss: 174.3025 - val_keras_r2: -1.2207\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.7880 - keras_r2: 0.0198 - val_loss: 144.7855 - val_keras_r2: -0.8531\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.6030 - keras_r2: 0.0845 - val_loss: 94.5927 - val_keras_r2: -0.1470\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7601 - keras_r2: 0.1058 - val_loss: 189.9277 - val_keras_r2: -1.3115\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3649 - keras_r2: 0.1296 - val_loss: 87.1081 - val_keras_r2: -0.0487\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0633 - keras_r2: 0.1592 - val_loss: 94.7801 - val_keras_r2: -0.1659\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.3476 - keras_r2: 0.1053 - val_loss: 96.4260 - val_keras_r2: -0.1887\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9682 - keras_r2: 0.1566 - val_loss: 91.6944 - val_keras_r2: -0.1105\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5935 - keras_r2: 0.1707 - val_loss: 83.7497 - val_keras_r2: -4.9331e-04\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.5199 - keras_r2: 0.1718 - val_loss: 92.9493 - val_keras_r2: -0.1149\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.3435 - keras_r2: 0.1963 - val_loss: 91.2677 - val_keras_r2: -0.0845\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.0641 - keras_r2: 0.1695 - val_loss: 83.8725 - val_keras_r2: -6.5808e-04\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.3801 - keras_r2: 0.1569 - val_loss: 107.6750 - val_keras_r2: -0.3053\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.5854 - keras_r2: 0.1793 - val_loss: 89.5828 - val_keras_r2: -0.0700\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.2385 - keras_r2: -0.0523 - val_loss: 93.8136 - val_keras_r2: -0.1439\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5139 - keras_r2: 0.1887 - val_loss: 102.2517 - val_keras_r2: -0.2074\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2267 - keras_r2: 0.2071 - val_loss: 110.3073 - val_keras_r2: -0.3406\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5356 - keras_r2: 0.2241 - val_loss: 86.0495 - val_keras_r2: -0.0240\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7153 - keras_r2: 0.2057 - val_loss: 104.9594 - val_keras_r2: -0.2555\n",
            "Epoch 20: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=14; total time=  10.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 192.8405 - keras_r2: -1.5270 - val_loss: 96.4762 - val_keras_r2: -0.1715\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.8444 - keras_r2: -0.0745 - val_loss: 108.6656 - val_keras_r2: -0.3412\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4032 - keras_r2: 0.0676 - val_loss: 84.9539 - val_keras_r2: -0.0110\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.6625 - keras_r2: 0.1443 - val_loss: 89.8337 - val_keras_r2: -0.0762\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1047 - keras_r2: 0.1551 - val_loss: 84.3797 - val_keras_r2: 0.0098\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.4697 - keras_r2: 0.1602 - val_loss: 78.3064 - val_keras_r2: 0.0781\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9096 - keras_r2: 0.1803 - val_loss: 82.9617 - val_keras_r2: 0.0291\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.5085 - keras_r2: 0.1689 - val_loss: 103.3922 - val_keras_r2: -0.2236\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.2315 - keras_r2: 0.1902 - val_loss: 130.5137 - val_keras_r2: -0.5887\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.5704 - keras_r2: 0.1305 - val_loss: 93.3520 - val_keras_r2: -0.1316\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.2545 - keras_r2: 0.2041 - val_loss: 79.6556 - val_keras_r2: 0.0671\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.4771 - keras_r2: 0.1805 - val_loss: 140.1132 - val_keras_r2: -0.7057\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3465 - keras_r2: 0.1933 - val_loss: 99.6649 - val_keras_r2: -0.1693\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.8227 - keras_r2: 0.1981 - val_loss: 75.2445 - val_keras_r2: 0.1185\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9585 - keras_r2: 0.2215 - val_loss: 96.9583 - val_keras_r2: -0.1478\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.2320 - keras_r2: 0.2131 - val_loss: 84.7215 - val_keras_r2: -0.0246\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.5043 - keras_r2: 0.1394 - val_loss: 87.5954 - val_keras_r2: -0.0327\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.3089 - keras_r2: 0.2309 - val_loss: 78.8215 - val_keras_r2: 0.0797\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.9077 - keras_r2: -2.5449 - val_loss: 120.3064 - val_keras_r2: -0.4938\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2136 - keras_r2: -387019.4688 - val_loss: 77.7259 - val_keras_r2: 0.0803\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1247 - keras_r2: 0.2178 - val_loss: 79.1240 - val_keras_r2: 0.0788\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.7633 - keras_r2: 0.2394 - val_loss: 124.7048 - val_keras_r2: -0.5070\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.5561 - keras_r2: 0.1756 - val_loss: 83.3700 - val_keras_r2: 0.0175\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8928 - keras_r2: 0.2153 - val_loss: 113.1525 - val_keras_r2: -0.3836\n",
            "Epoch 24: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=14; total time=  11.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 200.4030 - keras_r2: -1.4046 - val_loss: 163.3525 - val_keras_r2: -1.0720\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.6120 - keras_r2: -0.0704 - val_loss: 103.0060 - val_keras_r2: -0.2331\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.9812 - keras_r2: -0.0322 - val_loss: 102.7557 - val_keras_r2: -0.2373\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.6358 - keras_r2: 0.0990 - val_loss: 81.9289 - val_keras_r2: 0.0285\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.4851 - keras_r2: 0.0891 - val_loss: 107.3650 - val_keras_r2: -0.3245\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6858 - keras_r2: -0.1825 - val_loss: 88.1740 - val_keras_r2: -0.0441\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5243 - keras_r2: 0.1687 - val_loss: 140.8425 - val_keras_r2: -0.7990\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5919 - keras_r2: 0.1759 - val_loss: 79.9102 - val_keras_r2: 0.0407\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.9130 - keras_r2: 0.0824 - val_loss: 83.9921 - val_keras_r2: 0.0018\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.7202 - keras_r2: 0.1935 - val_loss: 110.0997 - val_keras_r2: -0.3196\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.7327 - keras_r2: 0.1883 - val_loss: 108.7945 - val_keras_r2: -0.3505\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4307 - keras_r2: 0.2031 - val_loss: 119.2730 - val_keras_r2: -0.4281\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.1115 - keras_r2: 0.1867 - val_loss: 89.5892 - val_keras_r2: -0.0679\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5258 - keras_r2: 0.2119 - val_loss: 80.5075 - val_keras_r2: 0.0596\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.4863 - keras_r2: 0.1988 - val_loss: 105.7047 - val_keras_r2: -0.3176\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.8708 - keras_r2: 0.1807 - val_loss: 84.7080 - val_keras_r2: -0.0201\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9255 - keras_r2: 0.2009 - val_loss: 160.3733 - val_keras_r2: -1.0336\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2412 - keras_r2: 0.2000 - val_loss: 98.6935 - val_keras_r2: -0.1784\n",
            "Epoch 18: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=14; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 206.9321 - keras_r2: -1.8417 - val_loss: 147.5979 - val_keras_r2: -0.9394\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 96.4486 - keras_r2: -0.2418 - val_loss: 148.3644 - val_keras_r2: -0.9093\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.4841 - keras_r2: -0.0185 - val_loss: 84.5557 - val_keras_r2: -0.0675\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.8114 - keras_r2: 0.0394 - val_loss: 97.4322 - val_keras_r2: -0.2580\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.5903 - keras_r2: 0.0440 - val_loss: 87.7788 - val_keras_r2: -0.0937\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.5213 - keras_r2: 0.0687 - val_loss: 90.1519 - val_keras_r2: -0.1064\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9230 - keras_r2: 0.0928 - val_loss: 83.4983 - val_keras_r2: -0.0392\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.3952 - keras_r2: -0.0095 - val_loss: 77.9229 - val_keras_r2: 0.0366\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.8629 - keras_r2: 0.1014 - val_loss: 79.4449 - val_keras_r2: 4.0934e-04\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.6248 - keras_r2: 0.1101 - val_loss: 105.7437 - val_keras_r2: -0.3157\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.8978 - keras_r2: 0.0579 - val_loss: 75.4339 - val_keras_r2: 0.0683\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.9115 - keras_r2: 0.1217 - val_loss: 82.9989 - val_keras_r2: -0.0597\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9161 - keras_r2: 0.1167 - val_loss: 85.2067 - val_keras_r2: -0.0858\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.2965 - keras_r2: 0.1082 - val_loss: 77.2150 - val_keras_r2: 0.0347\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.4828 - keras_r2: 0.1119 - val_loss: 78.0527 - val_keras_r2: 0.0336\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.2838 - keras_r2: 0.1092 - val_loss: 74.8188 - val_keras_r2: 0.0704\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6868 - keras_r2: 0.1004 - val_loss: 107.9337 - val_keras_r2: -0.3500\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6845 - keras_r2: 0.1296 - val_loss: 78.8170 - val_keras_r2: 0.0291\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6354 - keras_r2: 0.1241 - val_loss: 84.9360 - val_keras_r2: -0.0795\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.1856 - keras_r2: 0.1192 - val_loss: 215.6447 - val_keras_r2: -1.8649\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.0843 - keras_r2: 0.1194 - val_loss: 79.3678 - val_keras_r2: 0.0040\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.0112 - keras_r2: 0.1423 - val_loss: 109.2384 - val_keras_r2: -0.3644\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.1281 - keras_r2: 0.1129 - val_loss: 93.2275 - val_keras_r2: -0.1914\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.1944 - keras_r2: 0.1106 - val_loss: 101.8642 - val_keras_r2: -0.2840\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3581 - keras_r2: 0.1295 - val_loss: 101.6900 - val_keras_r2: -0.3165\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.5502 - keras_r2: 0.1295 - val_loss: 76.3020 - val_keras_r2: 0.0513\n",
            "Epoch 26: early stopping\n",
            "[CV] END ...........................n_hidden=1, n_neurons=14; total time=  13.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 466.2863 - keras_r2: -5.1444 - val_loss: 102.3403 - val_keras_r2: -0.2792\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 178.2473 - keras_r2: -1.4159 - val_loss: 352.2891 - val_keras_r2: -3.6535\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 108.7678 - keras_r2: -0.4041 - val_loss: 193.8201 - val_keras_r2: -1.3901\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 98.3248 - keras_r2: -0.2569 - val_loss: 171.7556 - val_keras_r2: -1.1865\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 251.2407 - keras_r2: -2.5657 - val_loss: 221.2194 - val_keras_r2: -1.8400\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 147.3810 - keras_r2: -0.9363 - val_loss: 149.1374 - val_keras_r2: -0.8807\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 134.1321 - keras_r2: -0.7695 - val_loss: 290.9409 - val_keras_r2: -2.8111\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 131.5040 - keras_r2: -0.6734 - val_loss: 199.8264 - val_keras_r2: -1.6030\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 127.8868 - keras_r2: -186721.5938 - val_loss: 125.2870 - val_keras_r2: -0.5618\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 125.3436 - keras_r2: -0.5831 - val_loss: 292.1799 - val_keras_r2: -2.8322\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 126.6917 - keras_r2: -0.7474 - val_loss: 301.3712 - val_keras_r2: -2.8740\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=79; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 311.3824 - keras_r2: -3.0121 - val_loss: 98.7145 - val_keras_r2: -0.2216\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 129.7506 - keras_r2: -0.6326 - val_loss: 165.8663 - val_keras_r2: -1.0807\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 109.5115 - keras_r2: -0.3931 - val_loss: 97.4530 - val_keras_r2: -0.2055\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 102.2318 - keras_r2: -0.2789 - val_loss: 86.6277 - val_keras_r2: -0.0594\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.9118 - keras_r2: -5.0535 - val_loss: 794.3873 - val_keras_r2: -9.4278\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 99.8007 - keras_r2: -1.2512 - val_loss: 163.9139 - val_keras_r2: -1.0939\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1390.7681 - keras_r2: -18.2184 - val_loss: 1275.8951 - val_keras_r2: -15.9860\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 889.5029 - keras_r2: -11.0799 - val_loss: 765.9662 - val_keras_r2: -9.1781\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 719.8854 - keras_r2: -79363560.0000 - val_loss: 652.1964 - val_keras_r2: -7.6789\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 513.7212 - keras_r2: -5.6107 - val_loss: 1013.4038 - val_keras_r2: -12.4260\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 374.2541 - keras_r2: -3.8996 - val_loss: 424.3325 - val_keras_r2: -4.5720\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 297.6188 - keras_r2: -2.8958 - val_loss: 292.6224 - val_keras_r2: -2.8282\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 258.9493 - keras_r2: -2.4124 - val_loss: 281.3341 - val_keras_r2: -2.6906\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 242.6603 - keras_r2: -2.1980 - val_loss: 233.8999 - val_keras_r2: -2.0338\n",
            "Epoch 14: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=79; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 897.0776 - keras_r2: -10.5929 - val_loss: 188.3284 - val_keras_r2: -1.3715\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 119.9144 - keras_r2: -0.5173 - val_loss: 90.0984 - val_keras_r2: -0.0809\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 131.2763 - keras_r2: -0.5926 - val_loss: 598.2213 - val_keras_r2: -6.7248\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.5732 - keras_r2: -0.1919 - val_loss: 90.4183 - val_keras_r2: -0.0823\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.7237 - keras_r2: -0.0318 - val_loss: 1276.9100 - val_keras_r2: -15.6591\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 113.8457 - keras_r2: -0.4912 - val_loss: 110.9518 - val_keras_r2: -0.3988\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.4176 - keras_r2: 0.1001 - val_loss: 130.7388 - val_keras_r2: -0.6493\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.1968 - keras_r2: 0.0264 - val_loss: 87.6610 - val_keras_r2: -0.0483\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.9034 - keras_r2: 0.0890 - val_loss: 81.5996 - val_keras_r2: 0.0191\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.8496 - keras_r2: 0.1131 - val_loss: 91.8125 - val_keras_r2: -0.1299\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.8890 - keras_r2: 0.0874 - val_loss: 195.1801 - val_keras_r2: -1.4452\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.4683 - keras_r2: 0.1056 - val_loss: 83.4002 - val_keras_r2: -0.0049\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8556 - keras_r2: 0.1536 - val_loss: 80.4422 - val_keras_r2: 0.0442\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.5029 - keras_r2: 0.0664 - val_loss: 168.3757 - val_keras_r2: -1.1024\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.2343 - keras_r2: 0.1541 - val_loss: 90.0322 - val_keras_r2: -0.0961\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.3815 - keras_r2: 0.0798 - val_loss: 172.9664 - val_keras_r2: -1.1290\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.8762 - keras_r2: 0.0807 - val_loss: 130.0547 - val_keras_r2: -0.5950\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 67.6714 - keras_r2: -6359909.0000 - val_loss: 125.4538 - val_keras_r2: -0.5379\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.7273 - keras_r2: 0.1675 - val_loss: 80.3737 - val_keras_r2: 0.0399\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.4114 - keras_r2: -0.4672 - val_loss: 109.8974 - val_keras_r2: -0.3241\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.9357 - keras_r2: 0.1643 - val_loss: 241.4661 - val_keras_r2: -2.0408\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.3131 - keras_r2: 0.1673 - val_loss: 188.1760 - val_keras_r2: -1.3414\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.7497 - keras_r2: 0.1768 - val_loss: 88.7923 - val_keras_r2: -0.0752\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.1050 - keras_r2: 0.2121 - val_loss: 81.2312 - val_keras_r2: 0.0300\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.3587 - keras_r2: 0.2040 - val_loss: 88.6842 - val_keras_r2: -0.0711\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.8648 - keras_r2: 0.1746 - val_loss: 203.8172 - val_keras_r2: -1.6547\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9842 - keras_r2: 0.2125 - val_loss: 117.8820 - val_keras_r2: -0.4273\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.2452 - keras_r2: 0.2044 - val_loss: 164.7756 - val_keras_r2: -1.0322\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.7326 - keras_r2: 0.1616 - val_loss: 86.2051 - val_keras_r2: -0.0200\n",
            "Epoch 29: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=79; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 341.1753 - keras_r2: -3.4789 - val_loss: 126.4472 - val_keras_r2: -0.6021\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 149.6516 - keras_r2: -0.8584 - val_loss: 152.5487 - val_keras_r2: -0.8560\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 109.8694 - keras_r2: -0.3838 - val_loss: 390.0933 - val_keras_r2: -4.0167\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 107.8626 - keras_r2: -0.4574 - val_loss: 193.2646 - val_keras_r2: -1.3961\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 103.2374 - keras_r2: -0.2924 - val_loss: 261.1434 - val_keras_r2: -2.4041\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 101.7488 - keras_r2: -0.3221 - val_loss: 124.7122 - val_keras_r2: -0.5088\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 99.0265 - keras_r2: -0.3093 - val_loss: 191.2930 - val_keras_r2: -1.4562\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 98.4507 - keras_r2: -0.2411 - val_loss: 113.8773 - val_keras_r2: -0.3838\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.9570 - keras_r2: -0.2254 - val_loss: 107.4286 - val_keras_r2: -0.2974\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.5629 - keras_r2: -0.2075 - val_loss: 115.0049 - val_keras_r2: -0.3967\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.6938 - keras_r2: -0.2110 - val_loss: 142.7929 - val_keras_r2: -0.7553\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 96.7486 - keras_r2: -0.2466 - val_loss: 121.6993 - val_keras_r2: -0.5069\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.2865 - keras_r2: -0.2010 - val_loss: 226.0772 - val_keras_r2: -1.7730\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.6543 - keras_r2: -0.2133 - val_loss: 116.8827 - val_keras_r2: -0.4480\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 94.0370 - keras_r2: -0.2207 - val_loss: 375.5945 - val_keras_r2: -3.8000\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.0102 - keras_r2: -0.2154 - val_loss: 117.6568 - val_keras_r2: -0.4519\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 94.4165 - keras_r2: -0.1624 - val_loss: 228.0454 - val_keras_r2: -1.8600\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 92.9668 - keras_r2: -0.2335 - val_loss: 219.1620 - val_keras_r2: -1.6889\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 94.9322 - keras_r2: -0.1802 - val_loss: 117.4104 - val_keras_r2: -0.4411\n",
            "Epoch 19: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=79; total time=  11.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 339.0111 - keras_r2: -3.3212 - val_loss: 170.8038 - val_keras_r2: -1.2135\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 228.9076 - keras_r2: -2.6084 - val_loss: 168.6435 - val_keras_r2: -1.2145\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1916.1034 - keras_r2: -24.1778 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.5762 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.3993 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3620 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.2691 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.8016 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.2400 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.1815 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -21.8652 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.7690 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 12: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=79; total time=   6.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 337.1349 - keras_r2: -3.3862 - val_loss: 410.2429 - val_keras_r2: -4.2882\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 121.1043 - keras_r2: -0.5218 - val_loss: 164.9549 - val_keras_r2: -1.0915\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2653.2649 - keras_r2: -37.3370 - val_loss: 517.0032 - val_keras_r2: -5.8422\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 462.6136 - keras_r2: -4.9209 - val_loss: 171.5360 - val_keras_r2: -1.1987\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 120.8484 - keras_r2: -0.5528 - val_loss: 98.1394 - val_keras_r2: -0.2000\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.5253 - keras_r2: -0.1329 - val_loss: 88.6901 - val_keras_r2: -0.0668\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.5244 - keras_r2: -0.1856 - val_loss: 87.4901 - val_keras_r2: -0.0482\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2963 - keras_r2: -0.0695 - val_loss: 87.2412 - val_keras_r2: -0.0441\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2270 - keras_r2: -0.0655 - val_loss: 87.1969 - val_keras_r2: -0.0431\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2519 - keras_r2: -0.0567 - val_loss: 87.1893 - val_keras_r2: -0.0428\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2492 - keras_r2: -0.1960 - val_loss: 87.1904 - val_keras_r2: -0.0428\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.2453 - keras_r2: -0.0559 - val_loss: 87.2057 - val_keras_r2: -0.0432\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 86.2470 - keras_r2: -0.0541 - val_loss: 87.2028 - val_keras_r2: -0.0431\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2489 - keras_r2: -0.1084 - val_loss: 87.1946 - val_keras_r2: -0.0429\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2446 - keras_r2: -0.0941 - val_loss: 87.1957 - val_keras_r2: -0.0429\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.4719 - keras_r2: -0.0559 - val_loss: 87.1995 - val_keras_r2: -0.0430\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.4771 - keras_r2: -0.0779 - val_loss: 87.1951 - val_keras_r2: -0.0429\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.4731 - keras_r2: -0.0626 - val_loss: 87.2021 - val_keras_r2: -0.0431\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.4735 - keras_r2: -0.0614 - val_loss: 87.2074 - val_keras_r2: -0.0432\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.4721 - keras_r2: -0.0627 - val_loss: 87.2126 - val_keras_r2: -0.0433\n",
            "Epoch 20: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=27; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 470.4409 - keras_r2: -5.6580 - val_loss: 1580.2856 - val_keras_r2: -19.2043\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1207.9061 - keras_r2: -15.6636 - val_loss: 362.7081 - val_keras_r2: -3.7918\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 210.5163 - keras_r2: -1.7138 - val_loss: 121.4693 - val_keras_r2: -0.5247\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 101.6767 - keras_r2: -0.2830 - val_loss: 93.6035 - val_keras_r2: -0.1395\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.0409 - keras_r2: -0.1117 - val_loss: 90.4528 - val_keras_r2: -0.0933\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.6961 - keras_r2: -0.0931 - val_loss: 90.1071 - val_keras_r2: -0.0874\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5514 - keras_r2: -0.1060 - val_loss: 90.0793 - val_keras_r2: -0.0868\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.5390 - keras_r2: -0.7490 - val_loss: 90.0474 - val_keras_r2: -0.0859\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5199 - keras_r2: -0.2150 - val_loss: 90.0479 - val_keras_r2: -0.0856\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5140 - keras_r2: -0.0980 - val_loss: 90.0468 - val_keras_r2: -0.0857\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5205 - keras_r2: -0.0839 - val_loss: 90.0459 - val_keras_r2: -0.0857\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5136 - keras_r2: -1977173.8750 - val_loss: 90.0461 - val_keras_r2: -0.0857\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5222 - keras_r2: -0.0735 - val_loss: 90.0461 - val_keras_r2: -0.0857\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5140 - keras_r2: -0.1125 - val_loss: 90.0477 - val_keras_r2: -0.0856\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5068 - keras_r2: -0.0978 - val_loss: 90.0597 - val_keras_r2: -0.0859\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5127 - keras_r2: -0.0846 - val_loss: 90.0632 - val_keras_r2: -0.0860\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.5930 - keras_r2: -0.7563 - val_loss: 90.0459 - val_keras_r2: -0.0858\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5647 - keras_r2: -0.0954 - val_loss: 90.0462 - val_keras_r2: -0.0857\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5222 - keras_r2: -0.1044 - val_loss: 90.0457 - val_keras_r2: -0.0857\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5193 - keras_r2: -0.0834 - val_loss: 90.0459 - val_keras_r2: -0.0857\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5223 - keras_r2: -0.0986 - val_loss: 90.0494 - val_keras_r2: -0.0856\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5191 - keras_r2: -0.0966 - val_loss: 90.0457 - val_keras_r2: -0.0857\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5207 - keras_r2: -0.1536 - val_loss: 90.0497 - val_keras_r2: -0.0856\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5212 - keras_r2: -0.1208 - val_loss: 90.0497 - val_keras_r2: -0.0856\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5189 - keras_r2: -0.0920 - val_loss: 90.0458 - val_keras_r2: -0.0857\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5203 - keras_r2: -1.2216 - val_loss: 90.0488 - val_keras_r2: -0.0859\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5205 - keras_r2: -0.0922 - val_loss: 90.0488 - val_keras_r2: -0.0856\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5190 - keras_r2: -0.1009 - val_loss: 90.0458 - val_keras_r2: -0.0857\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5193 - keras_r2: -0.0804 - val_loss: 90.0465 - val_keras_r2: -0.0856\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5219 - keras_r2: -0.0889 - val_loss: 90.0465 - val_keras_r2: -0.0856\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5234 - keras_r2: -1.1051 - val_loss: 90.0457 - val_keras_r2: -0.0857\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5187 - keras_r2: -0.1017 - val_loss: 90.0457 - val_keras_r2: -0.0857\n",
            "Epoch 32: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=27; total time=  21.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 362.7993 - keras_r2: -3.6783 - val_loss: 357.2157 - val_keras_r2: -3.7327\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 374.5638 - keras_r2: -4.2556 - val_loss: 1203.7252 - val_keras_r2: -14.8744\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 3122.2888 - keras_r2: -36.1108 - val_loss: 419.2578 - val_keras_r2: -4.5383\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 219.9396 - keras_r2: -1.8135 - val_loss: 147.2455 - val_keras_r2: -0.8567\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 121.0296 - keras_r2: -0.5338 - val_loss: 95.7008 - val_keras_r2: -0.1607\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.4308 - keras_r2: -0.0644 - val_loss: 89.4582 - val_keras_r2: -0.0704\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.1337 - keras_r2: -4485.8726 - val_loss: 87.6230 - val_keras_r2: -0.0337\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.3519 - keras_r2: 0.0115 - val_loss: 86.8876 - val_keras_r2: -0.0223\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.1583 - keras_r2: 0.0335 - val_loss: 84.2153 - val_keras_r2: 0.0019\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.3689 - keras_r2: 0.0558 - val_loss: 83.7924 - val_keras_r2: 0.0092\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.5377 - keras_r2: 0.0574 - val_loss: 82.4950 - val_keras_r2: 0.0331\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.8745 - keras_r2: 0.0358 - val_loss: 83.2753 - val_keras_r2: 0.0179\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.9587 - keras_r2: -2.6350 - val_loss: 81.9161 - val_keras_r2: 0.0339\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.3196 - keras_r2: 0.0471 - val_loss: 82.3731 - val_keras_r2: 0.0273\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6365 - keras_r2: 0.0930 - val_loss: 82.5446 - val_keras_r2: 0.0186\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2361 - keras_r2: 0.0945 - val_loss: 84.8104 - val_keras_r2: 0.0024\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.7944 - keras_r2: 0.1028 - val_loss: 86.4785 - val_keras_r2: -0.0427\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.4702 - keras_r2: 0.1046 - val_loss: 83.6906 - val_keras_r2: -0.0027\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.1155 - keras_r2: -948120.0000 - val_loss: 82.9843 - val_keras_r2: 0.0166\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0703 - keras_r2: 0.0954 - val_loss: 90.0609 - val_keras_r2: -0.0649\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9883 - keras_r2: 0.1089 - val_loss: 81.9938 - val_keras_r2: 0.0221\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8622 - keras_r2: 0.0983 - val_loss: 240.4104 - val_keras_r2: -2.1353\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.1847 - keras_r2: 0.1022 - val_loss: 85.6352 - val_keras_r2: -0.0368\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=27; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 417.6546 - keras_r2: -4.5200 - val_loss: 1324.1979 - val_keras_r2: -16.6639\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 497.6231 - keras_r2: -5.2720 - val_loss: 1059.2245 - val_keras_r2: -13.1078\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 377.4443 - keras_r2: -6.9660 - val_loss: 3129.7961 - val_keras_r2: -40.6591\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 275.4657 - keras_r2: -9507006.0000 - val_loss: 360.0675 - val_keras_r2: -3.6442\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 130.1472 - keras_r2: -0.6237 - val_loss: 102.1681 - val_keras_r2: -0.2598\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.5871 - keras_r2: -0.1498 - val_loss: 154.2430 - val_keras_r2: -0.9763\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.8640 - keras_r2: -0.1063 - val_loss: 187.2818 - val_keras_r2: -1.4145\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.4517 - keras_r2: -0.2678 - val_loss: 91.2943 - val_keras_r2: -0.0741\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 129.3040 - keras_r2: -3.6199 - val_loss: 135.1102 - val_keras_r2: -0.7079\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.3956 - keras_r2: -0.0601 - val_loss: 204.1689 - val_keras_r2: -1.5169\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.0611 - keras_r2: 0.1251 - val_loss: 77.0980 - val_keras_r2: 0.0880\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8284 - keras_r2: 0.1396 - val_loss: 74.6645 - val_keras_r2: 0.1101\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 99.0595 - keras_r2: -0.2275 - val_loss: 92.9953 - val_keras_r2: -0.1296\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.3041 - keras_r2: -1.8445 - val_loss: 88.3101 - val_keras_r2: -0.0619\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.6812 - keras_r2: -0.0977 - val_loss: 87.9577 - val_keras_r2: -0.0556\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.2327 - keras_r2: -0.0834 - val_loss: 87.8809 - val_keras_r2: -0.0540\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.7004 - keras_r2: -0.0550 - val_loss: 87.8696 - val_keras_r2: -0.0537\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.7039 - keras_r2: -0.1731 - val_loss: 87.8546 - val_keras_r2: -0.0533\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.6973 - keras_r2: -0.0605 - val_loss: 87.8541 - val_keras_r2: -0.0533\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.6972 - keras_r2: -0.0522 - val_loss: 87.8582 - val_keras_r2: -0.0534\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.6957 - keras_r2: -0.0641 - val_loss: 87.8790 - val_keras_r2: -0.0540\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.6945 - keras_r2: -0.0598 - val_loss: 87.8582 - val_keras_r2: -0.0535\n",
            "Epoch 22: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=27; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 252.7095 - keras_r2: -2.3468 - val_loss: 684.8154 - val_keras_r2: -8.1353\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 128.3868 - keras_r2: -0.6771 - val_loss: 409.6526 - val_keras_r2: -3.8972\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 161.2479 - keras_r2: -1.0343 - val_loss: 290.7341 - val_keras_r2: -2.6862\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 292.2273 - keras_r2: -2.9200 - val_loss: 380.2941 - val_keras_r2: -4.1034\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 737.9223 - keras_r2: -9.1102 - val_loss: 1386.0515 - val_keras_r2: -17.5278\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 410.3901 - keras_r2: -4.3939 - val_loss: 380.8003 - val_keras_r2: -4.0506\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 213.2598 - keras_r2: -1.7217 - val_loss: 141.2844 - val_keras_r2: -0.8153\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 105.4767 - keras_r2: -0.3359 - val_loss: 91.6541 - val_keras_r2: -0.1671\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 91.1862 - keras_r2: -0.1201 - val_loss: 87.0023 - val_keras_r2: -0.1003\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.7095 - keras_r2: -0.1011 - val_loss: 86.0839 - val_keras_r2: -0.0861\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.5149 - keras_r2: -0.0989 - val_loss: 85.7619 - val_keras_r2: -0.0811\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.4850 - keras_r2: -0.0919 - val_loss: 85.7472 - val_keras_r2: -0.0811\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.4868 - keras_r2: -0.0939 - val_loss: 85.7124 - val_keras_r2: -0.0805\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.4829 - keras_r2: -0.1010 - val_loss: 85.6354 - val_keras_r2: -0.0793\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.5505 - keras_r2: -0.0882 - val_loss: 85.7468 - val_keras_r2: -0.0803\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.8194 - keras_r2: -0.0886 - val_loss: 85.5916 - val_keras_r2: -0.0780\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.7414 - keras_r2: -0.0867 - val_loss: 85.6154 - val_keras_r2: -0.0785\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.7079 - keras_r2: -0.0774 - val_loss: 85.6652 - val_keras_r2: -0.0793\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.6555 - keras_r2: -0.0901 - val_loss: 85.6260 - val_keras_r2: -0.0781\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.6317 - keras_r2: -0.0700 - val_loss: 85.6075 - val_keras_r2: -0.0784\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.5776 - keras_r2: -0.0773 - val_loss: 85.6712 - val_keras_r2: -0.0793\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.3799 - keras_r2: -0.0787 - val_loss: 85.4970 - val_keras_r2: -0.0768\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.4158 - keras_r2: -0.0736 - val_loss: 85.8992 - val_keras_r2: -0.0829\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.3324 - keras_r2: -0.0817 - val_loss: 85.5417 - val_keras_r2: -0.0779\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.3297 - keras_r2: -0.0721 - val_loss: 85.5151 - val_keras_r2: -0.0779\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.2428 - keras_r2: -0.0760 - val_loss: 85.5342 - val_keras_r2: -0.0782\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.1667 - keras_r2: -0.3013 - val_loss: 85.5958 - val_keras_r2: -0.0791\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.0279 - keras_r2: -0.0801 - val_loss: 85.5364 - val_keras_r2: -0.0781\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.4879 - keras_r2: -0.0806 - val_loss: 85.4445 - val_keras_r2: -0.0775\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.9974 - keras_r2: -0.0735 - val_loss: 85.3612 - val_keras_r2: -0.0762\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.9470 - keras_r2: -0.0687 - val_loss: 85.2939 - val_keras_r2: -0.0758\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.8586 - keras_r2: -0.0757 - val_loss: 85.4277 - val_keras_r2: -0.0774\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.7384 - keras_r2: -0.0954 - val_loss: 85.2519 - val_keras_r2: -0.0752\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.7788 - keras_r2: -0.0633 - val_loss: 85.1218 - val_keras_r2: -0.0742\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.7785 - keras_r2: -0.0454 - val_loss: 84.3562 - val_keras_r2: -0.0649\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2854 - keras_r2: -0.0367 - val_loss: 84.2271 - val_keras_r2: -0.0653\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.4760 - keras_r2: -0.0271 - val_loss: 83.8983 - val_keras_r2: -0.0644\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.6660 - keras_r2: -0.0192 - val_loss: 83.2820 - val_keras_r2: -0.0529\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.3166 - keras_r2: -0.0151 - val_loss: 82.5757 - val_keras_r2: -0.0438\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.5789 - keras_r2: -0.0015 - val_loss: 82.5075 - val_keras_r2: -0.0431\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.0444 - keras_r2: -0.0079 - val_loss: 82.2590 - val_keras_r2: -0.0421\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.0207 - keras_r2: -0.0054 - val_loss: 82.1949 - val_keras_r2: -0.0435\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.8068 - keras_r2: 0.0219 - val_loss: 81.3240 - val_keras_r2: -0.0268\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.4729 - keras_r2: 0.0432 - val_loss: 80.2945 - val_keras_r2: -0.0223\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.3774 - keras_r2: 0.0526 - val_loss: 81.4378 - val_keras_r2: -0.0424\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.4669 - keras_r2: 0.0707 - val_loss: 79.2677 - val_keras_r2: -0.0116\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.4103 - keras_r2: 0.0746 - val_loss: 79.3211 - val_keras_r2: -0.0132\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.9045 - keras_r2: -0.1034 - val_loss: 83.3320 - val_keras_r2: -0.0474\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6956 - keras_r2: 0.0885 - val_loss: 76.9841 - val_keras_r2: 0.0223\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.8167 - keras_r2: 0.0924 - val_loss: 86.6641 - val_keras_r2: -0.1208\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.7605 - keras_r2: 0.0647 - val_loss: 77.0885 - val_keras_r2: 0.0192\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9499 - keras_r2: 0.1018 - val_loss: 77.4942 - val_keras_r2: 0.0134\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9542 - keras_r2: 0.0940 - val_loss: 77.4851 - val_keras_r2: 0.0128\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.8167 - keras_r2: 0.0967 - val_loss: 76.4561 - val_keras_r2: 0.0315\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.8951 - keras_r2: 0.0881 - val_loss: 98.2929 - val_keras_r2: -0.2794\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.0084 - keras_r2: 0.0763 - val_loss: 77.0881 - val_keras_r2: 0.0189\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1917 - keras_r2: 0.1172 - val_loss: 78.1697 - val_keras_r2: 0.0013\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.2273 - keras_r2: 0.0997 - val_loss: 81.0037 - val_keras_r2: -0.0181\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.7383 - keras_r2: 0.1118 - val_loss: 75.5994 - val_keras_r2: 0.0436\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1632 - keras_r2: 0.1100 - val_loss: 76.3983 - val_keras_r2: 0.0348\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9255 - keras_r2: 0.1170 - val_loss: 76.0371 - val_keras_r2: 0.0379\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.6604 - keras_r2: 0.1032 - val_loss: 75.8762 - val_keras_r2: 0.0375\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.0581 - keras_r2: 0.1262 - val_loss: 76.2792 - val_keras_r2: 0.0361\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.7432 - keras_r2: 0.1129 - val_loss: 76.1312 - val_keras_r2: 0.0323\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3890 - keras_r2: 0.1308 - val_loss: 74.5045 - val_keras_r2: 0.0584\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.4358 - keras_r2: 0.0996 - val_loss: 77.5786 - val_keras_r2: 0.0216\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0274 - keras_r2: 0.1320 - val_loss: 74.2196 - val_keras_r2: 0.0679\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.7301 - keras_r2: 0.1529 - val_loss: 79.9859 - val_keras_r2: -0.0238\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.8496 - keras_r2: 0.1388 - val_loss: 72.6455 - val_keras_r2: 0.0818\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8669 - keras_r2: 0.1605 - val_loss: 90.7933 - val_keras_r2: -0.1470\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.6319 - keras_r2: 0.1559 - val_loss: 72.2882 - val_keras_r2: 0.0899\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.6244 - keras_r2: 0.1792 - val_loss: 73.4627 - val_keras_r2: 0.0733\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.6319 - keras_r2: 0.1762 - val_loss: 72.5973 - val_keras_r2: 0.0826\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.6245 - keras_r2: 0.1683 - val_loss: 73.9709 - val_keras_r2: 0.0547\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.3431 - keras_r2: 0.1675 - val_loss: 84.7785 - val_keras_r2: -0.0987\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.4029 - keras_r2: 0.1649 - val_loss: 73.8892 - val_keras_r2: 0.0654\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.7965 - keras_r2: 0.1735 - val_loss: 86.8475 - val_keras_r2: -0.1020\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.5705 - keras_r2: 0.1364 - val_loss: 72.7072 - val_keras_r2: 0.0813\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1526 - keras_r2: 0.1679 - val_loss: 73.0107 - val_keras_r2: 0.0718\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5010 - keras_r2: 0.1438 - val_loss: 75.8365 - val_keras_r2: 0.0461\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.7755 - keras_r2: 0.1825 - val_loss: 73.3817 - val_keras_r2: 0.0731\n",
            "Epoch 81: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=27; total time= 1.4min\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2274.2266 - keras_r2: -29.0536 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.9631 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -26.6557 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.2014 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -74.0001 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -29.9395 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.1294 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.5203 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.9006 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.6779 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -29.0112 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=12; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1881.0105 - keras_r2: -32.6883 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.1680 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -25.7234 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.3713 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -35.3012 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -27.0210 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.9305 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.2307 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -172840928.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7530 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.8787 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=12; total time=   7.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3106.9246 - keras_r2: -36.5347 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.7220 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.0693 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.9437 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.0642 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -33.6819 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.0410 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -38.5701 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.9088 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.6155 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.2917 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=12; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2588.4021 - keras_r2: -38.1302 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.2475 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -96.8639 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.4606 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -29.1797 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.8481 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -76.0826 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.2632 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -26.1992 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -26.2234 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6965 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=12; total time=   7.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 6ms/step - loss: 397.8536 - keras_r2: -4.2821 - val_loss: 205.1228 - val_keras_r2: -1.6095\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.8723 - keras_r2: -0.1234 - val_loss: 109.3528 - val_keras_r2: -0.3577\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.6590 - keras_r2: -0.0597 - val_loss: 94.3900 - val_keras_r2: -0.1922\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.3909 - keras_r2: -0.0625 - val_loss: 84.7950 - val_keras_r2: -0.0560\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2714 - keras_r2: -0.0456 - val_loss: 83.2735 - val_keras_r2: -0.0290\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.3389 - keras_r2: -0.0567 - val_loss: 88.8959 - val_keras_r2: -0.1150\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.9512 - keras_r2: -0.0464 - val_loss: 86.1545 - val_keras_r2: -0.0758\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.1724 - keras_r2: -0.0544 - val_loss: 87.1814 - val_keras_r2: -0.0906\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 86.1346 - keras_r2: -0.0426 - val_loss: 83.1573 - val_keras_r2: -0.0302\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.8716 - keras_r2: -0.0439 - val_loss: 83.4528 - val_keras_r2: -0.0353\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.0281 - keras_r2: -0.0489 - val_loss: 86.2590 - val_keras_r2: -0.0772\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.8229 - keras_r2: -0.0466 - val_loss: 83.0510 - val_keras_r2: -0.0280\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.8204 - keras_r2: -0.0448 - val_loss: 83.1781 - val_keras_r2: -0.0277\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.6169 - keras_r2: -0.0444 - val_loss: 98.0101 - val_keras_r2: -0.2418\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.8787 - keras_r2: -0.0910 - val_loss: 110.4368 - val_keras_r2: -0.4127\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.0624 - keras_r2: -0.0936 - val_loss: 101.0520 - val_keras_r2: -0.2858\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.4507 - keras_r2: -0.0232 - val_loss: 81.9675 - val_keras_r2: -0.0161\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.2825 - keras_r2: -0.0194 - val_loss: 104.1129 - val_keras_r2: -0.3296\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.4150 - keras_r2: -0.0402 - val_loss: 85.1102 - val_keras_r2: -0.0608\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.4107 - keras_r2: 0.0040 - val_loss: 77.2747 - val_keras_r2: 0.0461\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.1135 - keras_r2: 0.0314 - val_loss: 129.1983 - val_keras_r2: -0.6241\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.1189 - keras_r2: -0.1295 - val_loss: 105.0176 - val_keras_r2: -0.3270\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.7878 - keras_r2: 0.0963 - val_loss: 90.6325 - val_keras_r2: -0.1204\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9361 - keras_r2: 0.0984 - val_loss: 200.3550 - val_keras_r2: -1.5627\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.3873 - keras_r2: 0.0287 - val_loss: 75.2208 - val_keras_r2: 0.0615\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.8680 - keras_r2: 0.0879 - val_loss: 75.6329 - val_keras_r2: 0.0577\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9012 - keras_r2: 0.1051 - val_loss: 72.6356 - val_keras_r2: 0.1012\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.4232 - keras_r2: 0.1192 - val_loss: 73.7974 - val_keras_r2: 0.0917\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.7509 - keras_r2: 0.1314 - val_loss: 77.6009 - val_keras_r2: 0.0426\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5401 - keras_r2: 0.1153 - val_loss: 75.9067 - val_keras_r2: 0.0664\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.6405 - keras_r2: 0.1179 - val_loss: 77.4037 - val_keras_r2: 0.0458\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6342 - keras_r2: 0.1372 - val_loss: 80.7455 - val_keras_r2: 0.0024\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.2572 - keras_r2: 0.0540 - val_loss: 94.6016 - val_keras_r2: -0.1836\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.8977 - keras_r2: 0.0754 - val_loss: 74.6106 - val_keras_r2: 0.0695\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.5116 - keras_r2: 0.1287 - val_loss: 74.8543 - val_keras_r2: 0.0706\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3227 - keras_r2: 0.1392 - val_loss: 83.3512 - val_keras_r2: -0.0476\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.4861 - keras_r2: 0.1099 - val_loss: 76.4509 - val_keras_r2: 0.0562\n",
            "Epoch 37: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=12; total time=  21.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1382.1202 - keras_r2: -18.5856 - val_loss: 381.8154 - val_keras_r2: -4.0299\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 206.3264 - keras_r2: -1.6985 - val_loss: 122.5254 - val_keras_r2: -0.5347\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 89.5770 - keras_r2: -0.1054 - val_loss: 83.2135 - val_keras_r2: 0.0161\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.6452 - keras_r2: 0.1112 - val_loss: 76.2530 - val_keras_r2: 0.0985\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.8392 - keras_r2: 0.1927 - val_loss: 71.9290 - val_keras_r2: 0.1539\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 64.1065 - keras_r2: 0.1857 - val_loss: 110.6587 - val_keras_r2: -0.3617\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 63.3896 - keras_r2: 0.2145 - val_loss: 83.3534 - val_keras_r2: -0.0069\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.2702 - keras_r2: 0.2426 - val_loss: 73.4980 - val_keras_r2: 0.1367\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 61.2620 - keras_r2: 0.0563 - val_loss: 72.5620 - val_keras_r2: 0.1398\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 60.3283 - keras_r2: -152442.9531 - val_loss: 71.1813 - val_keras_r2: 0.1590\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.7567 - keras_r2: -778232.4375 - val_loss: 72.4327 - val_keras_r2: 0.1401\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 58.7553 - keras_r2: 0.2845 - val_loss: 74.6491 - val_keras_r2: 0.1071\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.1769 - keras_r2: 0.2843 - val_loss: 78.1718 - val_keras_r2: 0.0732\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.8328 - keras_r2: 0.0476 - val_loss: 81.2012 - val_keras_r2: 0.0169\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 57.5567 - keras_r2: 0.2962 - val_loss: 82.0229 - val_keras_r2: 0.0043\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.6773 - keras_r2: 0.2842 - val_loss: 74.7830 - val_keras_r2: 0.1032\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.5889 - keras_r2: 0.2687 - val_loss: 79.0316 - val_keras_r2: 0.0541\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 56.5119 - keras_r2: 0.3043 - val_loss: 73.0286 - val_keras_r2: 0.1305\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 55.4237 - keras_r2: 0.3162 - val_loss: 72.9474 - val_keras_r2: 0.1333\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 55.3513 - keras_r2: 0.3174 - val_loss: 75.0792 - val_keras_r2: 0.1050\n",
            "Epoch 20: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=87; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2084.2693 - keras_r2: -27.1259 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.7292 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.5292 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -25.2976 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.1005 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -181818208.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.9694 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.0200 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.2579 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.2951 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.5795 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=87; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 614.0754 - keras_r2: -7.2533 - val_loss: 162.6255 - val_keras_r2: -1.0212\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 99.9822 - keras_r2: -0.2514 - val_loss: 78.4953 - val_keras_r2: 0.0676\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.7302 - keras_r2: -0.1148 - val_loss: 85.9691 - val_keras_r2: -0.0212\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 74.9897 - keras_r2: 0.0093 - val_loss: 99.6125 - val_keras_r2: -0.2262\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 75.1393 - keras_r2: -0.1797 - val_loss: 76.4080 - val_keras_r2: 0.0978\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.9067 - keras_r2: 0.1480 - val_loss: 442.1394 - val_keras_r2: -4.6305\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.0551 - keras_r2: -0.5872 - val_loss: 99.4310 - val_keras_r2: -0.2027\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6096 - keras_r2: 0.1592 - val_loss: 78.4671 - val_keras_r2: 0.0728\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.6253 - keras_r2: 0.2091 - val_loss: 97.6823 - val_keras_r2: -0.1835\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.8875 - keras_r2: -0.4208 - val_loss: 93.2895 - val_keras_r2: -0.1437\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 61.9815 - keras_r2: 0.2414 - val_loss: 105.3142 - val_keras_r2: -0.2994\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.9094 - keras_r2: 0.2503 - val_loss: 75.2482 - val_keras_r2: 0.1037\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5916 - keras_r2: 0.2636 - val_loss: 84.9576 - val_keras_r2: -0.0172\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.5290 - keras_r2: 0.2722 - val_loss: 74.2004 - val_keras_r2: 0.1163\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 58.0562 - keras_r2: 0.2991 - val_loss: 75.9984 - val_keras_r2: 0.1014\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 57.6224 - keras_r2: 0.2872 - val_loss: 89.0948 - val_keras_r2: -0.0746\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.4251 - keras_r2: 0.2916 - val_loss: 102.9815 - val_keras_r2: -0.2818\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 57.4648 - keras_r2: 0.2952 - val_loss: 95.6094 - val_keras_r2: -0.1791\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 57.5175 - keras_r2: 0.2971 - val_loss: 81.2445 - val_keras_r2: 0.0114\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.1119 - keras_r2: -0.0342 - val_loss: 103.3467 - val_keras_r2: -0.2626\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 55.7010 - keras_r2: -13909389.0000 - val_loss: 117.7238 - val_keras_r2: -0.4239\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.3812 - keras_r2: 0.3174 - val_loss: 93.7618 - val_keras_r2: -0.1346\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 55.7180 - keras_r2: -0.4455 - val_loss: 78.1446 - val_keras_r2: 0.0544\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 55.2283 - keras_r2: 0.3117 - val_loss: 90.3041 - val_keras_r2: -0.0744\n",
            "Epoch 24: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=87; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2091.2512 - keras_r2: -26.4520 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -25.3996 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.5402 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -181818208.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -25.3362 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.4102 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.4673 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.4743 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -35.9042 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -30.3902 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.7142 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=87; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1955.0236 - keras_r2: -25.5730 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6952 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6828 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -21.9765 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.4413 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.1976 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.3366 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.5981 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.6374 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.4476 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6439 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=87; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 440.2855 - keras_r2: -4.9951 - val_loss: 131.0107 - val_keras_r2: -0.6445\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.2198 - keras_r2: 0.0593 - val_loss: 91.6036 - val_keras_r2: -0.1122\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0476 - keras_r2: 0.1217 - val_loss: 132.2668 - val_keras_r2: -0.6602\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9731 - keras_r2: 0.1303 - val_loss: 79.6197 - val_keras_r2: 0.0581\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.3937 - keras_r2: 0.1277 - val_loss: 142.4392 - val_keras_r2: -0.8036\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6799 - keras_r2: 0.1499 - val_loss: 180.5209 - val_keras_r2: -1.3035\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.3944 - keras_r2: 0.1744 - val_loss: 126.7150 - val_keras_r2: -0.5550\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.2299 - keras_r2: 0.1918 - val_loss: 77.4164 - val_keras_r2: 0.0863\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.3263 - keras_r2: 0.1818 - val_loss: 80.2156 - val_keras_r2: 0.0479\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.4950 - keras_r2: 0.2231 - val_loss: 90.9226 - val_keras_r2: -0.0859\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.4552 - keras_r2: 0.2270 - val_loss: 85.0922 - val_keras_r2: -0.0347\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.7877 - keras_r2: 0.2048 - val_loss: 82.4025 - val_keras_r2: 0.0018\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.1243 - keras_r2: 0.2366 - val_loss: 82.6848 - val_keras_r2: 0.0091\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.4290 - keras_r2: 0.2502 - val_loss: 84.1399 - val_keras_r2: 4.9968e-04\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.0749 - keras_r2: 0.2213 - val_loss: 76.3713 - val_keras_r2: 0.0927\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.2189 - keras_r2: 0.2510 - val_loss: 138.2351 - val_keras_r2: -0.7465\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.1643 - keras_r2: 0.2250 - val_loss: 79.3611 - val_keras_r2: 0.0626\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 746.5963 - keras_r2: -7.7214 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -65.5009 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.2641 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.9976 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -31.9502 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -27.1242 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.0294 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -26.2453 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 25: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=45; total time=  14.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 452.9124 - keras_r2: -4.7562 - val_loss: 78.8770 - val_keras_r2: 0.0434\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 458037.4688 - keras_r2: -5662.0513 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -50.6587 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -33.7750 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8057 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.8029 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.6344 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -26.2164 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.6954 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -26.3180 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.4708 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=45; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1838.4393 - keras_r2: -23.5431 - val_loss: 1000.1912 - val_keras_r2: -12.3180\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 332.9123 - keras_r2: -3.2622 - val_loss: 105.6875 - val_keras_r2: -0.2672\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.7739 - keras_r2: -3.4744 - val_loss: 82.5411 - val_keras_r2: 0.0266\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.1757 - keras_r2: 0.1409 - val_loss: 74.5834 - val_keras_r2: 0.1172\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.9045 - keras_r2: 0.1466 - val_loss: 81.2553 - val_keras_r2: 0.0302\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.4436 - keras_r2: 0.1677 - val_loss: 75.0413 - val_keras_r2: 0.1080\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.7847 - keras_r2: 0.1893 - val_loss: 89.9310 - val_keras_r2: -0.1045\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.7891 - keras_r2: 0.0745 - val_loss: 76.6803 - val_keras_r2: 0.0901\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.4779 - keras_r2: 0.2271 - val_loss: 100.1853 - val_keras_r2: -0.2186\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1227 - keras_r2: 0.2258 - val_loss: 74.3404 - val_keras_r2: 0.1216\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 61.3783 - keras_r2: 0.2463 - val_loss: 75.0136 - val_keras_r2: 0.1182\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.1823 - keras_r2: 0.2468 - val_loss: 76.3240 - val_keras_r2: 0.1026\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.8717 - keras_r2: 0.2447 - val_loss: 76.3945 - val_keras_r2: 0.0828\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.6999 - keras_r2: 0.2185 - val_loss: 76.9711 - val_keras_r2: 0.0820\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.8431 - keras_r2: 0.2672 - val_loss: 75.0667 - val_keras_r2: 0.1095\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.2299 - keras_r2: 0.2650 - val_loss: 89.2173 - val_keras_r2: -0.0985\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.5971 - keras_r2: 0.2536 - val_loss: 74.2993 - val_keras_r2: 0.1182\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.9233 - keras_r2: 0.2706 - val_loss: 212.8175 - val_keras_r2: -1.6658\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.8133 - keras_r2: 0.2818 - val_loss: 80.2852 - val_keras_r2: 0.0428\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.0487 - keras_r2: 0.3021 - val_loss: 74.8866 - val_keras_r2: 0.1081\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.0736 - keras_r2: 0.3072 - val_loss: 85.5507 - val_keras_r2: -0.0372\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.8563 - keras_r2: 0.3088 - val_loss: 74.2545 - val_keras_r2: 0.1151\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.9142 - keras_r2: 0.3200 - val_loss: 77.5959 - val_keras_r2: 0.0713\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.6847 - keras_r2: -9497004.0000 - val_loss: 106.8649 - val_keras_r2: -0.3226\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.3848 - keras_r2: -2884815.7500 - val_loss: 80.1168 - val_keras_r2: 0.0413\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.6551 - keras_r2: 0.3000 - val_loss: 74.4482 - val_keras_r2: 0.1059\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.0808 - keras_r2: -0.7439 - val_loss: 94.3485 - val_keras_r2: -0.1568\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.6568 - keras_r2: 0.3025 - val_loss: 78.3163 - val_keras_r2: 0.0650\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.9771 - keras_r2: 0.2962 - val_loss: 83.3895 - val_keras_r2: 5.0593e-04\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.2918 - keras_r2: 0.3390 - val_loss: 75.5743 - val_keras_r2: 0.0931\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.9143 - keras_r2: 0.3339 - val_loss: 80.5422 - val_keras_r2: 0.0252\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.9273 - keras_r2: 0.3350 - val_loss: 78.1762 - val_keras_r2: 0.0680\n",
            "Epoch 32: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=45; total time=  18.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 639.3882 - keras_r2: -7.3912 - val_loss: 86.7665 - val_keras_r2: -0.0310\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2561 - keras_r2: 0.0878 - val_loss: 94.2641 - val_keras_r2: -0.1251\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1934 - keras_r2: 0.0983 - val_loss: 110.7919 - val_keras_r2: -0.3818\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.7912 - keras_r2: 0.1564 - val_loss: 95.6178 - val_keras_r2: -0.1608\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.5629 - keras_r2: 0.1858 - val_loss: 138.7178 - val_keras_r2: -0.6920\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.4506 - keras_r2: 0.1990 - val_loss: 74.8880 - val_keras_r2: 0.1197\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.2207 - keras_r2: 0.2222 - val_loss: 79.6049 - val_keras_r2: 0.0601\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.4727 - keras_r2: 0.2285 - val_loss: 87.2463 - val_keras_r2: -0.0529\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.6340 - keras_r2: 0.1179 - val_loss: 76.2983 - val_keras_r2: 0.0948\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.2115 - keras_r2: 0.2410 - val_loss: 91.7832 - val_keras_r2: -0.1202\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7753 - keras_r2: 0.2546 - val_loss: 102.7174 - val_keras_r2: -0.2368\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.4935 - keras_r2: -0.0532 - val_loss: 75.7311 - val_keras_r2: 0.1082\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5358 - keras_r2: 0.1448 - val_loss: 91.5117 - val_keras_r2: -0.1167\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.6215 - keras_r2: 0.2519 - val_loss: 78.3831 - val_keras_r2: 0.0699\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.8170 - keras_r2: 0.2699 - val_loss: 77.1835 - val_keras_r2: 0.0742\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.8693 - keras_r2: 0.2771 - val_loss: 77.4128 - val_keras_r2: 0.0724\n",
            "Epoch 16: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=45; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 384.5996 - keras_r2: -3.8917 - val_loss: 70.4225 - val_keras_r2: 0.1231\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0543 - keras_r2: 0.0183 - val_loss: 70.9090 - val_keras_r2: 0.1139\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.1244 - keras_r2: 0.1938 - val_loss: 80.7854 - val_keras_r2: -4.9958e-04\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.3209 - keras_r2: 0.1878 - val_loss: 64.3662 - val_keras_r2: 0.1998\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.6219 - keras_r2: 0.2311 - val_loss: 71.6878 - val_keras_r2: 0.0990\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8210 - keras_r2: 0.2454 - val_loss: 87.9314 - val_keras_r2: -0.0998\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.6131 - keras_r2: 0.2182 - val_loss: 73.9957 - val_keras_r2: 0.0634\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.3345 - keras_r2: 0.2503 - val_loss: 79.1698 - val_keras_r2: -0.0101\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.7944 - keras_r2: 0.2337 - val_loss: 87.6102 - val_keras_r2: -0.1382\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.4857 - keras_r2: 0.2018 - val_loss: 76.8360 - val_keras_r2: 0.0194\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.8785 - keras_r2: 0.2285 - val_loss: 80.7558 - val_keras_r2: -0.0357\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 97.2440 - keras_r2: -1.1204 - val_loss: 1313.1033 - val_keras_r2: -16.4892\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 3142.0293 - keras_r2: -38.5441 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3316 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 14: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=45; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2242.4685 - keras_r2: -36.2957 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -80.4762 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -24.7569 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.2408 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -26.5647 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -30.3316 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -58.7834 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -37.2206 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.4670 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -34.4625 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.1857 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=78; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 2817.9512 - keras_r2: -36.4257 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.0868 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -66.6426 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.7224 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.5890 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -35.0388 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.8332 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.0464 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7077 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.6686 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -25.7001 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=78; total time=   8.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2403.1440 - keras_r2: -31.2254 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -28.5998 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -25.2328 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -29.2225 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -27.6659 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.1078 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -27.1342 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -26.3451 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.8381 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -25.8039 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -26.1205 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=78; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4102.2134 - keras_r2: -49.6893 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.4404 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -32.6644 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -29.4272 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.7131 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.1575 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -33.8323 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.7761 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6235 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -26.3888 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.7184 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=78; total time=   7.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 16068.3994 - keras_r2: -237.6792 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.1149 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.4137 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.5001 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.0890 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.8817 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.3878 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.5744 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.5235 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -21.9964 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.0209 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=78; total time=   7.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1934.6057 - keras_r2: -25.0345 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -28.1853 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.0138 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.1220 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.0269 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4823 - keras_r2: -25.1919 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -38.8080 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.0166 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.4364 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.3232 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.8446 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=57; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 354.5365 - keras_r2: -4.0504 - val_loss: 117.4489 - val_keras_r2: -0.4432\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.1778 - keras_r2: 0.1216 - val_loss: 91.0145 - val_keras_r2: -0.1229\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5873 - keras_r2: 0.1269 - val_loss: 147.4440 - val_keras_r2: -0.8737\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.9197 - keras_r2: 0.1691 - val_loss: 85.2667 - val_keras_r2: -0.0439\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.7109 - keras_r2: 0.0748 - val_loss: 77.7003 - val_keras_r2: 0.0575\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.5929 - keras_r2: 0.1696 - val_loss: 187.0798 - val_keras_r2: -1.4313\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.2694 - keras_r2: -1.1301 - val_loss: 81.9344 - val_keras_r2: 0.0155\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.6207 - keras_r2: 0.2204 - val_loss: 80.5836 - val_keras_r2: 0.0439\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.9957 - keras_r2: 0.2335 - val_loss: 78.8165 - val_keras_r2: 0.0446\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.0462 - keras_r2: 0.2455 - val_loss: 93.7672 - val_keras_r2: -0.1361\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.9454 - keras_r2: -0.3282 - val_loss: 102.4387 - val_keras_r2: -0.2526\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.4740 - keras_r2: -0.6465 - val_loss: 140.0267 - val_keras_r2: -0.8056\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.0334 - keras_r2: 0.2135 - val_loss: 75.4407 - val_keras_r2: 0.0927\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.0086 - keras_r2: 0.2647 - val_loss: 83.0235 - val_keras_r2: -0.0011\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.6354 - keras_r2: 0.2595 - val_loss: 86.8279 - val_keras_r2: -0.0633\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.3649 - keras_r2: 0.2867 - val_loss: 91.6785 - val_keras_r2: -0.1250\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.4184 - keras_r2: -638337.6250 - val_loss: 76.2024 - val_keras_r2: 0.0861\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.7281 - keras_r2: 0.2827 - val_loss: 80.1633 - val_keras_r2: 0.0285\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.9042 - keras_r2: 0.3032 - val_loss: 79.7948 - val_keras_r2: 0.0499\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.7031 - keras_r2: 0.3020 - val_loss: 89.5127 - val_keras_r2: -0.0955\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.6232 - keras_r2: 0.2869 - val_loss: 95.3949 - val_keras_r2: -0.1582\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.3790 - keras_r2: 0.3170 - val_loss: 138.0905 - val_keras_r2: -0.7249\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.2043 - keras_r2: 0.2830 - val_loss: 86.0429 - val_keras_r2: -0.0524\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=57; total time=  13.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 346.4875 - keras_r2: -3.6635 - val_loss: 177.9990 - val_keras_r2: -1.2743\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.0913 - keras_r2: -2.0683 - val_loss: 91.4642 - val_keras_r2: -0.0798\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.1413 - keras_r2: 0.0641 - val_loss: 105.7448 - val_keras_r2: -0.2971\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5909 - keras_r2: 0.0903 - val_loss: 90.7020 - val_keras_r2: -0.0560\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2657 - keras_r2: 0.0903 - val_loss: 95.0187 - val_keras_r2: -0.1584\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.7820 - keras_r2: 0.0846 - val_loss: 91.3032 - val_keras_r2: -0.0756\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7578 - keras_r2: 0.1206 - val_loss: 92.8587 - val_keras_r2: -0.0960\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.1763 - keras_r2: 0.1612 - val_loss: 82.6376 - val_keras_r2: 0.0243\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.2558 - keras_r2: 0.1203 - val_loss: 91.3343 - val_keras_r2: -0.0877\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.1089 - keras_r2: 0.1540 - val_loss: 79.4645 - val_keras_r2: 0.0609\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1047 - keras_r2: 0.1800 - val_loss: 83.2073 - val_keras_r2: 0.0129\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.0866 - keras_r2: 0.1794 - val_loss: 86.9779 - val_keras_r2: -0.0414\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.6418 - keras_r2: 0.1814 - val_loss: 122.0271 - val_keras_r2: -0.4682\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.8918 - keras_r2: 0.1832 - val_loss: 78.7017 - val_keras_r2: 0.0792\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.0929 - keras_r2: 0.1994 - val_loss: 141.1211 - val_keras_r2: -0.7919\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8531 - keras_r2: 0.0578 - val_loss: 114.3570 - val_keras_r2: -0.4289\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5048 - keras_r2: 0.2153 - val_loss: 85.8178 - val_keras_r2: -0.0257\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.7552 - keras_r2: 0.1748 - val_loss: 99.8461 - val_keras_r2: -0.1818\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.4000 - keras_r2: -9.5541 - val_loss: 432.3571 - val_keras_r2: -4.6875\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.9667 - keras_r2: 0.0834 - val_loss: 83.5550 - val_keras_r2: -0.0047\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.2610 - keras_r2: 0.1944 - val_loss: 84.4325 - val_keras_r2: -0.0198\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.7092 - keras_r2: 0.2025 - val_loss: 94.2473 - val_keras_r2: -0.1214\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.0816 - keras_r2: 0.2209 - val_loss: 81.0368 - val_keras_r2: 0.0316\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.7188 - keras_r2: 0.1852 - val_loss: 238.2699 - val_keras_r2: -2.0035\n",
            "Epoch 24: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=57; total time=  14.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 372.2738 - keras_r2: -4.0790 - val_loss: 76.3858 - val_keras_r2: 0.1005\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8987 - keras_r2: -0.8769 - val_loss: 97.7328 - val_keras_r2: -0.1743\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6557 - keras_r2: 0.1325 - val_loss: 126.4552 - val_keras_r2: -0.5378\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.8851 - keras_r2: -0.6476 - val_loss: 81.8798 - val_keras_r2: 0.0337\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.2162 - keras_r2: 0.1755 - val_loss: 114.1882 - val_keras_r2: -0.4328\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.4987 - keras_r2: 0.1700 - val_loss: 78.8953 - val_keras_r2: 0.0580\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.1262 - keras_r2: 0.1804 - val_loss: 90.2246 - val_keras_r2: -0.1004\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8009 - keras_r2: -0.9293 - val_loss: 88.4603 - val_keras_r2: -0.0868\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.6622 - keras_r2: 0.2025 - val_loss: 73.2011 - val_keras_r2: 0.1333\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.2186 - keras_r2: 0.2353 - val_loss: 75.9965 - val_keras_r2: 0.0835\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.3345 - keras_r2: 0.2596 - val_loss: 113.8445 - val_keras_r2: -0.4296\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.4701 - keras_r2: 0.2620 - val_loss: 80.3635 - val_keras_r2: 0.0518\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.1100 - keras_r2: 0.2604 - val_loss: 107.8020 - val_keras_r2: -0.2988\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.0027 - keras_r2: 0.1701 - val_loss: 112.5833 - val_keras_r2: -0.4240\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.8260 - keras_r2: 0.2748 - val_loss: 106.5384 - val_keras_r2: -0.2797\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.4493 - keras_r2: -1.8272 - val_loss: 138.2823 - val_keras_r2: -0.7497\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.2917 - keras_r2: -0.0223 - val_loss: 103.4179 - val_keras_r2: -0.2335\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5276 - keras_r2: -19862730.0000 - val_loss: 136.8928 - val_keras_r2: -0.7343\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.5995 - keras_r2: 0.2747 - val_loss: 185.6669 - val_keras_r2: -1.4125\n",
            "Epoch 19: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=57; total time=  21.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1200.1157 - keras_r2: -14.7610 - val_loss: 127.2030 - val_keras_r2: -0.6426\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.3938 - keras_r2: 0.0571 - val_loss: 71.5434 - val_keras_r2: 0.1192\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.4069 - keras_r2: 0.1385 - val_loss: 218.0276 - val_keras_r2: -1.8198\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5803 - keras_r2: 0.1245 - val_loss: 67.7218 - val_keras_r2: 0.1521\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.0794 - keras_r2: 0.1858 - val_loss: 87.3151 - val_keras_r2: -0.1099\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.0364 - keras_r2: 0.2086 - val_loss: 84.1357 - val_keras_r2: -0.0832\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1245.5695 - keras_r2: -15.5830 - val_loss: 1800.3741 - val_keras_r2: -23.0829\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1607.6841 - keras_r2: -19.9923 - val_loss: 525.8358 - val_keras_r2: -5.9486\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 287.5180 - keras_r2: -2.7409 - val_loss: 138.4987 - val_keras_r2: -0.7968\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 105.2986 - keras_r2: -0.3031 - val_loss: 91.4838 - val_keras_r2: -0.1518\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.5874 - keras_r2: -0.0834 - val_loss: 85.1021 - val_keras_r2: -0.0607\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.5483 - keras_r2: -0.0401 - val_loss: 83.9322 - val_keras_r2: -0.0430\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2686 - keras_r2: -0.0577 - val_loss: 83.5616 - val_keras_r2: -0.0370\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2107 - keras_r2: -0.0359 - val_loss: 83.4549 - val_keras_r2: -0.0351\n",
            "Epoch 14: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=57; total time=   8.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 288.4994 - keras_r2: -2.9205 - val_loss: 146.5336 - val_keras_r2: -0.8377\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 177.7366 - keras_r2: -1.2049 - val_loss: 436.0824 - val_keras_r2: -4.7333\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1382.1133 - keras_r2: -220000016.0000 - val_loss: 1595.5328 - val_keras_r2: -20.1821\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1451.5511 - keras_r2: -18.3935 - val_loss: 7843.1387 - val_keras_r2: -106.0875\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1320.6356 - keras_r2: -17.3610 - val_loss: 8509.2559 - val_keras_r2: -114.5474\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1113.3564 - keras_r2: -3899343.7500 - val_loss: 993.2924 - val_keras_r2: -12.0702\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 943.2767 - keras_r2: -11.5188 - val_loss: 1078.3451 - val_keras_r2: -13.2655\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 765.0565 - keras_r2: -9.2329 - val_loss: 614.3846 - val_keras_r2: -7.0220\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 409.0190 - keras_r2: -4.2552 - val_loss: 333.0052 - val_keras_r2: -3.2093\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 273.8439 - keras_r2: -2.9946 - val_loss: 305.8744 - val_keras_r2: -2.8471\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 265.4742 - keras_r2: -2.4759 - val_loss: 218.7199 - val_keras_r2: -1.7715\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=50; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 329.7084 - keras_r2: -3.2127 - val_loss: 98.1070 - val_keras_r2: -0.2117\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75453.1875 - keras_r2: -935.2920 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8501 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.5183 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.8807 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.4336 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.0036 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.5820 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -38.4995 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -116363656.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8799 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=50; total time=   6.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 560.6707 - keras_r2: -6.2362 - val_loss: 801.9623 - val_keras_r2: -9.3622\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 182.4734 - keras_r2: -1.3631 - val_loss: 133.6867 - val_keras_r2: -0.6898\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 426.8375 - keras_r2: -4.3218 - val_loss: 1198.2594 - val_keras_r2: -14.8532\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 580.3844 - keras_r2: -6.6150 - val_loss: 926.0123 - val_keras_r2: -11.3323\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 406.8217 - keras_r2: -4.2425 - val_loss: 370.1357 - val_keras_r2: -3.8755\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 200.7526 - keras_r2: -1.5640 - val_loss: 194.3725 - val_keras_r2: -1.5151\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 137.8914 - keras_r2: -0.7434 - val_loss: 108.6531 - val_keras_r2: -0.3505\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 113.7197 - keras_r2: -0.5138 - val_loss: 98.0752 - val_keras_r2: -0.2186\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.2214 - keras_r2: -0.2185 - val_loss: 91.6262 - val_keras_r2: -0.1212\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.4036 - keras_r2: -0.1926 - val_loss: 116.9876 - val_keras_r2: -0.4704\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.9380 - keras_r2: -7015432.0000 - val_loss: 126.5783 - val_keras_r2: -0.5598\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.6783 - keras_r2: -0.2041 - val_loss: 133.4175 - val_keras_r2: -0.6467\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.0593 - keras_r2: -0.0882 - val_loss: 98.5585 - val_keras_r2: -0.2200\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.5685 - keras_r2: -0.0788 - val_loss: 89.2232 - val_keras_r2: -0.0858\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.1213 - keras_r2: -0.2884 - val_loss: 107.3138 - val_keras_r2: -0.3085\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.3602 - keras_r2: -0.0856 - val_loss: 99.8122 - val_keras_r2: -0.2182\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.0291 - keras_r2: -0.2239 - val_loss: 88.8816 - val_keras_r2: -0.0778\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2490 - keras_r2: -0.0726 - val_loss: 92.1871 - val_keras_r2: -0.1315\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.0840 - keras_r2: -0.0474 - val_loss: 196.3604 - val_keras_r2: -1.5357\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.0013 - keras_r2: -0.2370 - val_loss: 91.1540 - val_keras_r2: -0.1138\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.9322 - keras_r2: -0.0715 - val_loss: 115.1981 - val_keras_r2: -0.4021\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6745 - keras_r2: -0.1721 - val_loss: 90.8764 - val_keras_r2: -0.1157\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.1399 - keras_r2: -0.0307 - val_loss: 125.8650 - val_keras_r2: -0.5423\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.3708 - keras_r2: -0.0351 - val_loss: 112.6662 - val_keras_r2: -0.4088\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.4905 - keras_r2: -0.0577 - val_loss: 91.7019 - val_keras_r2: -0.1136\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.1301 - keras_r2: -0.0355 - val_loss: 95.3232 - val_keras_r2: -0.1751\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.2726 - keras_r2: -0.4907 - val_loss: 199.5330 - val_keras_r2: -1.5032\n",
            "Epoch 27: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=50; total time=  15.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 453.5541 - keras_r2: -5.2667 - val_loss: 105.3940 - val_keras_r2: -0.3005\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 107.6441 - keras_r2: -0.3327 - val_loss: 127.2686 - val_keras_r2: -0.6155\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 109.8984 - keras_r2: -0.3717 - val_loss: 109.1875 - val_keras_r2: -0.3515\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.8744 - keras_r2: -0.0949 - val_loss: 98.6302 - val_keras_r2: -0.2068\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 113.4639 - keras_r2: -0.6606 - val_loss: 98.8110 - val_keras_r2: -0.1850\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.2805 - keras_r2: -0.1123 - val_loss: 117.4383 - val_keras_r2: -0.4366\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.8570 - keras_r2: -0.0935 - val_loss: 89.9034 - val_keras_r2: -0.0714\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.3640 - keras_r2: -0.0483 - val_loss: 91.7023 - val_keras_r2: -0.0961\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 92.4674 - keras_r2: -0.2254 - val_loss: 128.0092 - val_keras_r2: -0.6061\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.3905 - keras_r2: 0.0077 - val_loss: 81.6230 - val_keras_r2: 0.0325\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 94.3987 - keras_r2: -0.1732 - val_loss: 88.8421 - val_keras_r2: -0.0510\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.0080 - keras_r2: 0.0055 - val_loss: 88.7491 - val_keras_r2: -0.0545\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.6756 - keras_r2: 0.0085 - val_loss: 372.5555 - val_keras_r2: -3.8999\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.0110 - keras_r2: -0.0161 - val_loss: 87.3354 - val_keras_r2: -0.0310\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.0266 - keras_r2: 0.0321 - val_loss: 116.0595 - val_keras_r2: -0.3914\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.3929 - keras_r2: -0.0500 - val_loss: 109.4270 - val_keras_r2: -0.3566\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.9277 - keras_r2: -0.0725 - val_loss: 133.4262 - val_keras_r2: -0.6676\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.3976 - keras_r2: 0.0366 - val_loss: 90.4261 - val_keras_r2: -0.0595\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.0756 - keras_r2: 0.0210 - val_loss: 100.1888 - val_keras_r2: -0.2154\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.7128 - keras_r2: 0.0089 - val_loss: 147.6180 - val_keras_r2: -0.8038\n",
            "Epoch 20: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=50; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 388.3882 - keras_r2: -4.4891 - val_loss: 236.3750 - val_keras_r2: -2.1335\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1903.3871 - keras_r2: -20.0285 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.5088 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.1816 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.1620 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -24.7843 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.1882 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -25.7898 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -26.1788 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.5380 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.5022 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=2, n_neurons=50; total time=   6.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 275.1913 - keras_r2: -2.6070 - val_loss: 110.4474 - val_keras_r2: -0.3450\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.3371 - keras_r2: 0.0683 - val_loss: 83.6345 - val_keras_r2: -0.0110\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.6248 - keras_r2: 0.1913 - val_loss: 101.2833 - val_keras_r2: -0.2556\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.0453 - keras_r2: 0.2017 - val_loss: 113.4533 - val_keras_r2: -0.3997\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.9753 - keras_r2: 0.1946 - val_loss: 75.7287 - val_keras_r2: 0.0981\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5780 - keras_r2: 0.2003 - val_loss: 81.3160 - val_keras_r2: 0.0397\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.2602 - keras_r2: 0.2238 - val_loss: 81.5752 - val_keras_r2: 0.0302\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.1757 - keras_r2: 0.2136 - val_loss: 121.0747 - val_keras_r2: -0.4782\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.6451 - keras_r2: 0.2158 - val_loss: 130.7471 - val_keras_r2: -0.6105\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.8103 - keras_r2: 0.2622 - val_loss: 100.6376 - val_keras_r2: -0.2591\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.2002 - keras_r2: 0.2755 - val_loss: 225.3744 - val_keras_r2: -1.7978\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.4741 - keras_r2: 0.2469 - val_loss: 80.1341 - val_keras_r2: 0.0285\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.2640 - keras_r2: 0.0165 - val_loss: 104.7336 - val_keras_r2: -0.2648\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.9118 - keras_r2: 0.2768 - val_loss: 76.3516 - val_keras_r2: 0.0823\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.3251 - keras_r2: 0.2905 - val_loss: 74.0928 - val_keras_r2: 0.1147\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.5420 - keras_r2: 0.2869 - val_loss: 80.5309 - val_keras_r2: 0.0197\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.0863 - keras_r2: 0.3180 - val_loss: 91.9603 - val_keras_r2: -0.1057\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.7004 - keras_r2: 0.3262 - val_loss: 89.9489 - val_keras_r2: -0.0843\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.4626 - keras_r2: 0.3250 - val_loss: 117.0921 - val_keras_r2: -0.4503\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.8251 - keras_r2: 0.2878 - val_loss: 80.4565 - val_keras_r2: 0.0475\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.2999 - keras_r2: -0.0417 - val_loss: 179.3299 - val_keras_r2: -1.2618\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.1170 - keras_r2: 0.2874 - val_loss: 177.9893 - val_keras_r2: -1.2750\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.7038 - keras_r2: 0.3261 - val_loss: 78.4612 - val_keras_r2: 0.0515\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.3376 - keras_r2: 0.3443 - val_loss: 82.6214 - val_keras_r2: -0.0011\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 52.2232 - keras_r2: 0.3488 - val_loss: 81.7982 - val_keras_r2: -9.1234e-04\n",
            "Epoch 25: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=55; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 485.5759 - keras_r2: -5.6475 - val_loss: 97.2508 - val_keras_r2: -0.2015\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4517 - keras_r2: 0.0712 - val_loss: 71.8150 - val_keras_r2: 0.1415\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 374.1671 - keras_r2: -3.8574 - val_loss: 83.9578 - val_keras_r2: -0.0161\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 96.9693 - keras_r2: -0.3115 - val_loss: 126.4781 - val_keras_r2: -0.5855\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.1390 - keras_r2: -0.2916 - val_loss: 98.8023 - val_keras_r2: -0.1980\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.5577 - keras_r2: -0.0034 - val_loss: 92.3853 - val_keras_r2: -0.1236\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.2255 - keras_r2: 0.0605 - val_loss: 77.6611 - val_keras_r2: 0.0609\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.5691 - keras_r2: -1.5781 - val_loss: 104.8924 - val_keras_r2: -0.2815\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.2620 - keras_r2: 0.0598 - val_loss: 118.5116 - val_keras_r2: -0.4971\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.0038 - keras_r2: 0.0885 - val_loss: 83.8868 - val_keras_r2: -0.0161\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0955 - keras_r2: 0.0691 - val_loss: 74.8048 - val_keras_r2: 0.0888\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9972 - keras_r2: 0.1139 - val_loss: 77.8064 - val_keras_r2: 0.0587\n",
            "Epoch 12: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=55; total time=   7.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 320.4487 - keras_r2: -3.0907 - val_loss: 87.0705 - val_keras_r2: -0.0618\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6452 - keras_r2: 0.0252 - val_loss: 79.1204 - val_keras_r2: 0.0616\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.6656 - keras_r2: -0.0129 - val_loss: 137.8780 - val_keras_r2: -0.7473\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.6975 - keras_r2: 0.1351 - val_loss: 102.9417 - val_keras_r2: -0.2199\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.3905 - keras_r2: -0.6354 - val_loss: 78.2158 - val_keras_r2: 0.0571\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.0301 - keras_r2: 0.2229 - val_loss: 122.4173 - val_keras_r2: -0.5030\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1790 - keras_r2: 0.2222 - val_loss: 98.6262 - val_keras_r2: -0.2265\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.3189 - keras_r2: 0.2313 - val_loss: 111.1530 - val_keras_r2: -0.3621\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.3201 - keras_r2: 0.1481 - val_loss: 72.8532 - val_keras_r2: 0.1355\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.8053 - keras_r2: 0.2526 - val_loss: 83.2259 - val_keras_r2: -0.0143\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7937 - keras_r2: 0.2142 - val_loss: 78.3142 - val_keras_r2: 0.0817\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.7873 - keras_r2: 0.2673 - val_loss: 83.3058 - val_keras_r2: -0.0148\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.7089 - keras_r2: 0.2124 - val_loss: 73.3843 - val_keras_r2: 0.1400\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.3238 - keras_r2: 0.2569 - val_loss: 291.3849 - val_keras_r2: -2.7786\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.9695 - keras_r2: 0.0770 - val_loss: 102.6770 - val_keras_r2: -0.2822\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.2398 - keras_r2: 0.2590 - val_loss: 72.3431 - val_keras_r2: 0.1444\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.4564 - keras_r2: 0.2860 - val_loss: 146.9388 - val_keras_r2: -0.7979\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.5359 - keras_r2: 0.2717 - val_loss: 72.1759 - val_keras_r2: 0.1426\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.3190 - keras_r2: 0.2911 - val_loss: 116.5770 - val_keras_r2: -0.4209\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.5610 - keras_r2: 0.2869 - val_loss: 150.7225 - val_keras_r2: -0.8796\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.9822 - keras_r2: -0.0544 - val_loss: 87.2690 - val_keras_r2: -0.0698\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.4190 - keras_r2: 0.2471 - val_loss: 71.9600 - val_keras_r2: 0.1419\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.2399 - keras_r2: 0.2862 - val_loss: 74.6394 - val_keras_r2: 0.1164\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.7969 - keras_r2: 0.3157 - val_loss: 80.1961 - val_keras_r2: 0.0248\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.2404 - keras_r2: 0.3313 - val_loss: 101.4910 - val_keras_r2: -0.2686\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.3687 - keras_r2: 0.3221 - val_loss: 75.0070 - val_keras_r2: 0.1071\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 54.2817 - keras_r2: 0.3403 - val_loss: 71.2208 - val_keras_r2: 0.1479\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 53.2695 - keras_r2: 0.3404 - val_loss: 82.9011 - val_keras_r2: -0.0098\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.8224 - keras_r2: 0.3352 - val_loss: 85.7460 - val_keras_r2: -0.0133\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 53.2762 - keras_r2: 0.3532 - val_loss: 95.2463 - val_keras_r2: -0.1680\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 52.6940 - keras_r2: 0.3293 - val_loss: 199.1669 - val_keras_r2: -1.5025\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.0638 - keras_r2: 0.3264 - val_loss: 97.3225 - val_keras_r2: -0.2098\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.1793 - keras_r2: 0.3220 - val_loss: 75.5474 - val_keras_r2: 0.0949\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 51.1613 - keras_r2: 0.3780 - val_loss: 125.0925 - val_keras_r2: -0.5437\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 51.7672 - keras_r2: -0.4253 - val_loss: 91.1343 - val_keras_r2: -0.0956\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 50.3280 - keras_r2: 0.3697 - val_loss: 239.2745 - val_keras_r2: -2.1222\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.3256 - keras_r2: 0.3445 - val_loss: 82.0008 - val_keras_r2: 0.0231\n",
            "Epoch 37: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=55; total time=  21.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1372.9830 - keras_r2: -17.1090 - val_loss: 91.7614 - val_keras_r2: -0.1121\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.7103 - keras_r2: 0.0123 - val_loss: 79.5619 - val_keras_r2: 0.0582\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.3900 - keras_r2: 0.0759 - val_loss: 128.5574 - val_keras_r2: -0.5897\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5457 - keras_r2: 0.1032 - val_loss: 79.1656 - val_keras_r2: 0.0537\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5603 - keras_r2: 0.1492 - val_loss: 75.6763 - val_keras_r2: 0.0970\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0636 - keras_r2: 0.1424 - val_loss: 85.9327 - val_keras_r2: -0.0495\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.4916 - keras_r2: 0.1522 - val_loss: 118.9036 - val_keras_r2: -0.4705\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.5489 - keras_r2: 0.1491 - val_loss: 83.8238 - val_keras_r2: -0.0202\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.0581 - keras_r2: 0.1663 - val_loss: 75.5108 - val_keras_r2: 0.0953\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.9220 - keras_r2: 0.1963 - val_loss: 245.2949 - val_keras_r2: -2.1992\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5958 - keras_r2: 0.2152 - val_loss: 74.6373 - val_keras_r2: 0.1043\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.6969 - keras_r2: 0.2248 - val_loss: 83.4214 - val_keras_r2: 8.6680e-04\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.4697 - keras_r2: 0.2245 - val_loss: 94.5507 - val_keras_r2: -0.1531\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5814 - keras_r2: 0.2212 - val_loss: 75.3171 - val_keras_r2: 0.0955\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.3871 - keras_r2: 0.2101 - val_loss: 74.7760 - val_keras_r2: 0.1091\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.1863 - keras_r2: 0.1739 - val_loss: 102.0020 - val_keras_r2: -0.2799\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.0581 - keras_r2: 0.1895 - val_loss: 86.6348 - val_keras_r2: -0.0383\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5655 - keras_r2: 0.1551 - val_loss: 102.4813 - val_keras_r2: -0.2515\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.0114 - keras_r2: 0.2065 - val_loss: 85.6827 - val_keras_r2: -0.0184\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8363 - keras_r2: 0.2416 - val_loss: 110.4702 - val_keras_r2: -0.3742\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.4583 - keras_r2: 0.2604 - val_loss: 84.4551 - val_keras_r2: -0.0294\n",
            "Epoch 21: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=55; total time=  12.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 662.4868 - keras_r2: -7.7104 - val_loss: 105.3495 - val_keras_r2: -0.3593\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.7509 - keras_r2: -0.0543 - val_loss: 77.1428 - val_keras_r2: 0.0336\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2624 - keras_r2: 0.1251 - val_loss: 89.0723 - val_keras_r2: -0.1091\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.1464 - keras_r2: 0.1697 - val_loss: 74.1139 - val_keras_r2: 0.0755\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.6315 - keras_r2: 0.1779 - val_loss: 70.3879 - val_keras_r2: 0.1302\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.5042 - keras_r2: 0.1512 - val_loss: 78.5660 - val_keras_r2: 0.0066\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.4904 - keras_r2: 0.2058 - val_loss: 117.0283 - val_keras_r2: -0.4852\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3256 - keras_r2: 0.2009 - val_loss: 79.7208 - val_keras_r2: -0.0071\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.7139 - keras_r2: 0.0701 - val_loss: 105.0902 - val_keras_r2: -0.3489\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5078 - keras_r2: 0.2101 - val_loss: 68.0559 - val_keras_r2: 0.1507\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.6391 - keras_r2: 0.2449 - val_loss: 73.0429 - val_keras_r2: 0.0896\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.1422 - keras_r2: 0.2763 - val_loss: 76.3888 - val_keras_r2: 0.0363\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.6262 - keras_r2: 0.2695 - val_loss: 67.0757 - val_keras_r2: 0.1632\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.4675 - keras_r2: 0.2697 - val_loss: 108.6187 - val_keras_r2: -0.4041\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3879 - keras_r2: 0.1300 - val_loss: 87.3281 - val_keras_r2: -0.0946\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0138 - keras_r2: 0.1611 - val_loss: 75.9373 - val_keras_r2: 0.0556\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.6435 - keras_r2: 0.2074 - val_loss: 74.2598 - val_keras_r2: 0.0732\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.5359 - keras_r2: 0.1042 - val_loss: 73.9287 - val_keras_r2: 0.0866\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.0466 - keras_r2: 0.2506 - val_loss: 92.0119 - val_keras_r2: -0.1844\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.7608 - keras_r2: 0.2657 - val_loss: 85.3264 - val_keras_r2: -0.0719\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.3090 - keras_r2: 0.2735 - val_loss: 88.0169 - val_keras_r2: -0.0879\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.9553 - keras_r2: 0.2812 - val_loss: 108.0526 - val_keras_r2: -0.3944\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.7485 - keras_r2: 0.2867 - val_loss: 80.1698 - val_keras_r2: -0.0238\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=3, n_neurons=55; total time=  21.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 883.7587 - keras_r2: -10.7734 - val_loss: 88.1412 - val_keras_r2: -0.0538\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.8670 - keras_r2: -0.0218 - val_loss: 137.4404 - val_keras_r2: -0.7348\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.7298 - keras_r2: 0.0158 - val_loss: 95.4944 - val_keras_r2: -0.1463\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.8276 - keras_r2: 0.0858 - val_loss: 211.8476 - val_keras_r2: -1.7242\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.2336 - keras_r2: 0.0014 - val_loss: 95.3820 - val_keras_r2: -0.1431\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2087 - keras_r2: 0.1260 - val_loss: 92.6353 - val_keras_r2: -0.1276\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9257 - keras_r2: 0.1348 - val_loss: 79.7492 - val_keras_r2: 0.0614\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2437 - keras_r2: 0.1316 - val_loss: 104.4039 - val_keras_r2: -0.2702\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8453 - keras_r2: -0.1706 - val_loss: 75.7450 - val_keras_r2: 0.1068\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9090 - keras_r2: 0.1362 - val_loss: 107.4039 - val_keras_r2: -0.2983\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.5466 - keras_r2: 0.1650 - val_loss: 79.2349 - val_keras_r2: 0.0637\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.9775 - keras_r2: 0.1636 - val_loss: 78.9142 - val_keras_r2: 0.0633\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8421 - keras_r2: 0.1483 - val_loss: 100.3546 - val_keras_r2: -0.2300\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.9964 - keras_r2: 0.1407 - val_loss: 131.3224 - val_keras_r2: -0.6579\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.2953 - keras_r2: 0.1682 - val_loss: 82.4682 - val_keras_r2: 0.0164\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.7122 - keras_r2: 0.1772 - val_loss: 86.8702 - val_keras_r2: -0.0400\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.3852 - keras_r2: 0.0596 - val_loss: 126.7191 - val_keras_r2: -0.5953\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0982 - keras_r2: -0.3062 - val_loss: 79.7978 - val_keras_r2: 0.0389\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.1251 - keras_r2: 0.1852 - val_loss: 88.5721 - val_keras_r2: -0.0813\n",
            "Epoch 19: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=22; total time=  11.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 685.0573 - keras_r2: -7.9358 - val_loss: 84.1478 - val_keras_r2: -0.0196\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.3708 - keras_r2: -0.2036 - val_loss: 198.4754 - val_keras_r2: -1.5830\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.9006 - keras_r2: -0.1170 - val_loss: 290.2920 - val_keras_r2: -2.7150\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.2798 - keras_r2: -0.0691 - val_loss: 276.6185 - val_keras_r2: -2.6480\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.9193 - keras_r2: -0.6800 - val_loss: 129.3050 - val_keras_r2: -0.6484\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.8299 - keras_r2: 0.0104 - val_loss: 100.5831 - val_keras_r2: -0.2484\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.2946 - keras_r2: -0.0250 - val_loss: 158.2742 - val_keras_r2: -0.9775\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.1290 - keras_r2: 0.0721 - val_loss: 103.5625 - val_keras_r2: -0.2986\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5789 - keras_r2: 0.0976 - val_loss: 119.3046 - val_keras_r2: -0.5142\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0803 - keras_r2: 0.1599 - val_loss: 90.8785 - val_keras_r2: -0.1213\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.5128 - keras_r2: -0.7321 - val_loss: 73.7595 - val_keras_r2: 0.1123\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.9324 - keras_r2: 0.1936 - val_loss: 88.9836 - val_keras_r2: -0.1046\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5846 - keras_r2: -1479321.8750 - val_loss: 73.2291 - val_keras_r2: 0.1247\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.0728 - keras_r2: 0.2152 - val_loss: 135.7900 - val_keras_r2: -0.7429\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1693 - keras_r2: 0.1783 - val_loss: 128.5109 - val_keras_r2: -0.5837\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.8000 - keras_r2: 0.1857 - val_loss: 84.9392 - val_keras_r2: -0.0519\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.0740 - keras_r2: 0.1357 - val_loss: 73.8398 - val_keras_r2: 0.1135\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.8709 - keras_r2: 0.2202 - val_loss: 81.6092 - val_keras_r2: 0.0235\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.2977 - keras_r2: 0.2095 - val_loss: 105.1735 - val_keras_r2: -0.2833\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.3255 - keras_r2: 0.2155 - val_loss: 74.1300 - val_keras_r2: 0.1136\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.3735 - keras_r2: 0.1097 - val_loss: 74.1859 - val_keras_r2: 0.1106\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.8869 - keras_r2: 0.2291 - val_loss: 99.4162 - val_keras_r2: -0.2294\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.7333 - keras_r2: 0.2163 - val_loss: 225.6689 - val_keras_r2: -1.8620\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=22; total time=  21.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2491.7686 - keras_r2: -30.7930 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -70.9006 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -27.3334 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -29.5402 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.9607 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -29.0409 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.7987 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.8946 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.1837 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.4206 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -28.9182 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=22; total time=   7.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1502.5900 - keras_r2: -19.6001 - val_loss: 599.4203 - val_keras_r2: -6.9491\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 297.3923 - keras_r2: -2.8877 - val_loss: 149.3933 - val_keras_r2: -0.8997\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 110.4635 - keras_r2: -0.5664 - val_loss: 94.8037 - val_keras_r2: -0.1540\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.2037 - keras_r2: -0.0832 - val_loss: 88.1902 - val_keras_r2: -0.0596\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.5853 - keras_r2: -0.0388 - val_loss: 87.2777 - val_keras_r2: -0.0452\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.3073 - keras_r2: -0.0381 - val_loss: 87.1772 - val_keras_r2: -0.0432\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2822 - keras_r2: -0.0298 - val_loss: 87.1574 - val_keras_r2: -0.0428\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2811 - keras_r2: -0.0661 - val_loss: 87.1447 - val_keras_r2: -0.0424\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2780 - keras_r2: -0.0351 - val_loss: 87.1547 - val_keras_r2: -0.0427\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2807 - keras_r2: -0.0523 - val_loss: 87.1405 - val_keras_r2: -0.0423\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2821 - keras_r2: -0.0351 - val_loss: 87.1443 - val_keras_r2: -0.0424\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2786 - keras_r2: -0.0299 - val_loss: 87.1542 - val_keras_r2: -0.0427\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2832 - keras_r2: -0.0414 - val_loss: 87.1602 - val_keras_r2: -0.0428\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2748 - keras_r2: -0.0451 - val_loss: 87.1377 - val_keras_r2: -0.0422\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2847 - keras_r2: -0.0375 - val_loss: 87.1396 - val_keras_r2: -0.0423\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2790 - keras_r2: -0.0900 - val_loss: 87.1333 - val_keras_r2: -0.0420\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2809 - keras_r2: -0.0278 - val_loss: 87.1524 - val_keras_r2: -0.0426\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2799 - keras_r2: -0.0525 - val_loss: 87.1741 - val_keras_r2: -0.0432\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2824 - keras_r2: -0.0541 - val_loss: 87.1447 - val_keras_r2: -0.0424\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2821 - keras_r2: -0.0369 - val_loss: 87.1529 - val_keras_r2: -0.0427\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2814 - keras_r2: -0.0361 - val_loss: 87.1435 - val_keras_r2: -0.0424\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2827 - keras_r2: -0.0403 - val_loss: 87.1439 - val_keras_r2: -0.0424\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2783 - keras_r2: -0.0622 - val_loss: 87.1929 - val_keras_r2: -0.0436\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2837 - keras_r2: -0.0345 - val_loss: 87.1561 - val_keras_r2: -0.0427\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2814 - keras_r2: -0.0501 - val_loss: 87.1602 - val_keras_r2: -0.0428\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2798 - keras_r2: -0.0336 - val_loss: 87.1660 - val_keras_r2: -0.0430\n",
            "Epoch 26: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=22; total time=  14.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 6ms/step - loss: 348.3505 - keras_r2: -3.5757 - val_loss: 81.9040 - val_keras_r2: -0.0241\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 132.8939 - keras_r2: -0.6414 - val_loss: 87.9211 - val_keras_r2: -0.1051\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.0453 - keras_r2: -0.0529 - val_loss: 95.4733 - val_keras_r2: -0.2233\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.1623 - keras_r2: -0.0772 - val_loss: 86.5353 - val_keras_r2: -0.0868\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.4931 - keras_r2: -0.0620 - val_loss: 85.8061 - val_keras_r2: -0.0783\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.4786 - keras_r2: -148463.3750 - val_loss: 85.0122 - val_keras_r2: -0.0711\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.5157 - keras_r2: -0.0676 - val_loss: 87.3295 - val_keras_r2: -0.0961\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.4240 - keras_r2: -0.0533 - val_loss: 102.4191 - val_keras_r2: -0.3195\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.2659 - keras_r2: -0.0695 - val_loss: 85.8020 - val_keras_r2: -0.0783\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.6000 - keras_r2: -0.0688 - val_loss: 91.6042 - val_keras_r2: -0.1697\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.5238 - keras_r2: -0.0723 - val_loss: 92.7127 - val_keras_r2: -0.1848\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=22; total time=   7.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3558.9668 - keras_r2: -36.7565 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.5573 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -24.7687 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.7918 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -25.0368 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -32.6565 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -24.5812 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -25.5293 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.7888 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.2174 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.3413 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=79; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2397.0461 - keras_r2: -32.1355 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -38.7375 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.1823 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.5758 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -25.8292 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.6871 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.9438 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -25.8509 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.6133 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -24.8288 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.9345 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=79; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3398.6719 - keras_r2: -44.0644 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -25.2915 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.0446 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -27.5821 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -26.1776 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -26.0394 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.2725 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -33.1598 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -25.7094 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -26.6375 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -27.2584 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=79; total time=   8.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 9424.4180 - keras_r2: -154.0284 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.4957 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.7996 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -26.5192 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.5195 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4991 - keras_r2: -24.7065 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6505 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.6527 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.3454 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.7447 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.6300 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=79; total time=   8.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2062.8850 - keras_r2: -30.5874 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.3719 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.4024 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.4726 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.1992 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.7214 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.4830 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.5977 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.2294 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -23.0940 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.6914 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=5, n_neurons=79; total time=   8.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1107.9285 - keras_r2: -13.4462 - val_loss: 340.4911 - val_keras_r2: -3.4748\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 189.4131 - keras_r2: -1.4606 - val_loss: 118.9326 - val_keras_r2: -0.4857\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.2959 - keras_r2: -0.3036 - val_loss: 91.3017 - val_keras_r2: -0.1047\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.0913 - keras_r2: -0.0553 - val_loss: 87.6948 - val_keras_r2: -0.0520\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.7595 - keras_r2: -0.0481 - val_loss: 87.2247 - val_keras_r2: -0.0442\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6347 - keras_r2: -0.0401 - val_loss: 87.2095 - val_keras_r2: -0.0439\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6277 - keras_r2: -3.6446 - val_loss: 87.1565 - val_keras_r2: -0.0427\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6180 - keras_r2: -0.0724 - val_loss: 87.1351 - val_keras_r2: -0.0421\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6189 - keras_r2: -0.0321 - val_loss: 87.1350 - val_keras_r2: -0.0421\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6220 - keras_r2: -0.1739 - val_loss: 87.1350 - val_keras_r2: -0.0421\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6200 - keras_r2: -0.0335 - val_loss: 87.1456 - val_keras_r2: -0.0425\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6186 - keras_r2: -0.0395 - val_loss: 87.1539 - val_keras_r2: -0.0427\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 84.6138 - keras_r2: -0.0302 - val_loss: 87.1413 - val_keras_r2: -0.0423\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6184 - keras_r2: -0.0451 - val_loss: 87.1355 - val_keras_r2: -0.0421\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6203 - keras_r2: -0.1157 - val_loss: 87.1365 - val_keras_r2: -0.0422\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6165 - keras_r2: -0.0323 - val_loss: 87.1538 - val_keras_r2: -0.0427\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6211 - keras_r2: -0.0349 - val_loss: 87.1490 - val_keras_r2: -0.0426\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6121 - keras_r2: -0.0468 - val_loss: 87.1798 - val_keras_r2: -0.0433\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6212 - keras_r2: -0.0453 - val_loss: 87.1715 - val_keras_r2: -0.0431\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6208 - keras_r2: -0.0909 - val_loss: 87.1413 - val_keras_r2: -0.0423\n",
            "Epoch 20: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=50; total time=  12.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 884.4378 - keras_r2: -11.0423 - val_loss: 313.4593 - val_keras_r2: -3.1324\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 180.1838 - keras_r2: -1.3661 - val_loss: 113.5207 - val_keras_r2: -0.4251\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 96.1956 - keras_r2: -0.2162 - val_loss: 89.1649 - val_keras_r2: -0.0877\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.7931 - keras_r2: -0.0588 - val_loss: 86.4122 - val_keras_r2: -0.0469\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6498 - keras_r2: -0.1300 - val_loss: 86.1653 - val_keras_r2: -0.0423\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5402 - keras_r2: -0.0286 - val_loss: 86.1540 - val_keras_r2: -0.0419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5339 - keras_r2: -0.0354 - val_loss: 86.1514 - val_keras_r2: -0.0417\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5321 - keras_r2: -0.0634 - val_loss: 86.1511 - val_keras_r2: -0.0417\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5337 - keras_r2: -0.0622 - val_loss: 86.1540 - val_keras_r2: -0.0416\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5292 - keras_r2: -0.0387 - val_loss: 86.1525 - val_keras_r2: -0.0416\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5295 - keras_r2: -0.2925 - val_loss: 86.1527 - val_keras_r2: -0.0416\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5328 - keras_r2: -0.0422 - val_loss: 86.1506 - val_keras_r2: -0.0416\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5269 - keras_r2: -0.0285 - val_loss: 86.1485 - val_keras_r2: -0.0416\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5308 - keras_r2: -0.0457 - val_loss: 86.1522 - val_keras_r2: -0.0415\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5258 - keras_r2: -0.0273 - val_loss: 86.1476 - val_keras_r2: -0.0415\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5269 - keras_r2: -0.0362 - val_loss: 86.1441 - val_keras_r2: -0.0415\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5235 - keras_r2: -0.0404 - val_loss: 86.1442 - val_keras_r2: -0.0414\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5205 - keras_r2: -0.0347 - val_loss: 86.1349 - val_keras_r2: -0.0414\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.5151 - keras_r2: -0.0359 - val_loss: 86.1240 - val_keras_r2: -0.0414\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.4967 - keras_r2: -2158.5205 - val_loss: 86.0928 - val_keras_r2: -0.0409\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.3679 - keras_r2: -0.0317 - val_loss: 85.7143 - val_keras_r2: -0.0353\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.3361 - keras_r2: -0.0894 - val_loss: 84.4683 - val_keras_r2: -0.0090\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.3618 - keras_r2: 0.0649 - val_loss: 75.8700 - val_keras_r2: 0.0956\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2987 - keras_r2: 0.1384 - val_loss: 74.1459 - val_keras_r2: 0.1228\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.9783 - keras_r2: 0.1976 - val_loss: 74.1335 - val_keras_r2: 0.1183\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3048 - keras_r2: 0.2117 - val_loss: 73.3107 - val_keras_r2: 0.1185\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.2772 - keras_r2: 0.2206 - val_loss: 74.8645 - val_keras_r2: 0.1118\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.3438 - keras_r2: 0.2193 - val_loss: 101.9170 - val_keras_r2: -0.2719\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.2894 - keras_r2: 0.1598 - val_loss: 113.8261 - val_keras_r2: -0.3944\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8195 - keras_r2: 0.2476 - val_loss: 71.9836 - val_keras_r2: 0.1416\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.8465 - keras_r2: -0.1881 - val_loss: 89.8678 - val_keras_r2: -0.0810\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5231 - keras_r2: 0.2460 - val_loss: 78.4429 - val_keras_r2: 0.0488\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.9283 - keras_r2: -0.5219 - val_loss: 73.3511 - val_keras_r2: 0.1192\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.8478 - keras_r2: 0.2441 - val_loss: 72.9375 - val_keras_r2: 0.1270\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.1419 - keras_r2: 0.2692 - val_loss: 87.4290 - val_keras_r2: -0.0464\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.7651 - keras_r2: 0.2284 - val_loss: 103.0402 - val_keras_r2: -0.2515\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.6796 - keras_r2: 0.2770 - val_loss: 110.3031 - val_keras_r2: -0.3468\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.5810 - keras_r2: 0.2926 - val_loss: 80.1019 - val_keras_r2: 0.0344\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.6272 - keras_r2: 0.2948 - val_loss: 74.0937 - val_keras_r2: 0.1061\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.1647 - keras_r2: -0.7647 - val_loss: 84.4617 - val_keras_r2: -0.0191\n",
            "Epoch 40: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=50; total time=  41.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 615.2321 - keras_r2: -6.5751 - val_loss: 115.9067 - val_keras_r2: -0.4470\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.2557 - keras_r2: -0.1895 - val_loss: 188.4451 - val_keras_r2: -1.3663\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.5698 - keras_r2: -0.4999 - val_loss: 98.6803 - val_keras_r2: -0.1777\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1200 - keras_r2: -3.9741 - val_loss: 322.7390 - val_keras_r2: -3.2496\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.7505 - keras_r2: 0.0236 - val_loss: 116.5379 - val_keras_r2: -0.4100\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5382 - keras_r2: -0.0732 - val_loss: 175.4411 - val_keras_r2: -1.1856\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8562 - keras_r2: 0.1347 - val_loss: 134.7954 - val_keras_r2: -0.7031\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3971 - keras_r2: 0.1315 - val_loss: 82.6522 - val_keras_r2: 0.0057\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.4583 - keras_r2: 0.1937 - val_loss: 76.4814 - val_keras_r2: 0.0935\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.8573 - keras_r2: 0.2334 - val_loss: 128.8578 - val_keras_r2: -0.5790\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1279 - keras_r2: 0.2356 - val_loss: 92.4821 - val_keras_r2: -0.1041\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.5606 - keras_r2: 0.2183 - val_loss: 84.1448 - val_keras_r2: -0.0015\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.2188 - keras_r2: 0.2297 - val_loss: 74.2052 - val_keras_r2: 0.1224\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.6539 - keras_r2: 0.2658 - val_loss: 91.9729 - val_keras_r2: -0.1077\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.8511 - keras_r2: 0.1902 - val_loss: 82.5269 - val_keras_r2: 0.0174\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.2755 - keras_r2: 0.2756 - val_loss: 97.1472 - val_keras_r2: -0.2017\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.3300 - keras_r2: 0.2633 - val_loss: 173.5285 - val_keras_r2: -1.2427\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.6762 - keras_r2: 0.2894 - val_loss: 96.2764 - val_keras_r2: -0.1934\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.8480 - keras_r2: 0.3257 - val_loss: 80.5025 - val_keras_r2: 0.0454\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.9090 - keras_r2: 0.3151 - val_loss: 76.6258 - val_keras_r2: 0.0890\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.2243 - keras_r2: 0.3039 - val_loss: 92.4311 - val_keras_r2: -0.1365\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.6258 - keras_r2: -0.4773 - val_loss: 131.9866 - val_keras_r2: -0.6753\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.0637 - keras_r2: 0.1340 - val_loss: 96.1922 - val_keras_r2: -0.1739\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=50; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1085.9857 - keras_r2: -15.8625 - val_loss: 349.3594 - val_keras_r2: -3.5940\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 147.7913 - keras_r2: -0.8822 - val_loss: 84.8358 - val_keras_r2: -0.0146\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.7401 - keras_r2: 0.0138 - val_loss: 81.0105 - val_keras_r2: 0.0284\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.8712 - keras_r2: 0.0786 - val_loss: 82.7549 - val_keras_r2: 0.0141\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.5190 - keras_r2: 0.0824 - val_loss: 111.1649 - val_keras_r2: -0.3805\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.0613 - keras_r2: 0.0714 - val_loss: 95.5667 - val_keras_r2: -0.1480\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5229 - keras_r2: 0.1194 - val_loss: 75.4877 - val_keras_r2: 0.1063\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.9231 - keras_r2: 0.0789 - val_loss: 140.1899 - val_keras_r2: -0.7764\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3699 - keras_r2: 0.1384 - val_loss: 75.4370 - val_keras_r2: 0.1094\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.9622 - keras_r2: 0.1350 - val_loss: 96.5051 - val_keras_r2: -0.1581\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.9883 - keras_r2: 0.0747 - val_loss: 78.3140 - val_keras_r2: 0.0612\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.4543 - keras_r2: 0.1864 - val_loss: 77.9300 - val_keras_r2: 0.0722\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.8078 - keras_r2: 0.1777 - val_loss: 74.8170 - val_keras_r2: 0.1166\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.9435 - keras_r2: 0.1984 - val_loss: 75.5281 - val_keras_r2: 0.1068\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.7827 - keras_r2: 0.1847 - val_loss: 81.0885 - val_keras_r2: 0.0261\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5145 - keras_r2: 0.2166 - val_loss: 79.9072 - val_keras_r2: 0.0534\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3788 - keras_r2: 0.1807 - val_loss: 220.9771 - val_keras_r2: -1.8129\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.4785 - keras_r2: 0.1497 - val_loss: 77.3483 - val_keras_r2: 0.0754\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.3620 - keras_r2: 0.2269 - val_loss: 74.9714 - val_keras_r2: 0.1078\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.8879 - keras_r2: 0.1494 - val_loss: 87.6148 - val_keras_r2: -0.0650\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1614 - keras_r2: 0.2203 - val_loss: 74.9259 - val_keras_r2: 0.1113\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.6930 - keras_r2: 0.2546 - val_loss: 75.0623 - val_keras_r2: 0.1115\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.7656 - keras_r2: 0.1981 - val_loss: 78.6472 - val_keras_r2: 0.0612\n",
            "Epoch 23: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=50; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 6ms/step - loss: 444.5576 - keras_r2: -4.8317 - val_loss: 173.6585 - val_keras_r2: -1.2877\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.6951 - keras_r2: -0.1309 - val_loss: 325.8872 - val_keras_r2: -3.2340\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.8412 - keras_r2: -0.0376 - val_loss: 71.1417 - val_keras_r2: 0.1166\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2585 - keras_r2: 0.0917 - val_loss: 104.5549 - val_keras_r2: -0.3177\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.5547 - keras_r2: 0.1357 - val_loss: 73.4585 - val_keras_r2: 0.0758\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8342 - keras_r2: 0.1629 - val_loss: 70.5756 - val_keras_r2: 0.1219\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.7489 - keras_r2: 0.1843 - val_loss: 74.9192 - val_keras_r2: 0.0736\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.7112 - keras_r2: 0.1956 - val_loss: 85.4740 - val_keras_r2: -0.0850\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.8006 - keras_r2: 0.1781 - val_loss: 206.3107 - val_keras_r2: -1.7218\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8740 - keras_r2: 0.1935 - val_loss: 69.4343 - val_keras_r2: 0.1446\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.6744 - keras_r2: 0.1417 - val_loss: 156.4438 - val_keras_r2: -1.0164\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.1753 - keras_r2: 0.2125 - val_loss: 67.6993 - val_keras_r2: 0.1647\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.9899 - keras_r2: 0.2198 - val_loss: 70.3222 - val_keras_r2: 0.1361\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.4937 - keras_r2: 0.2152 - val_loss: 88.1387 - val_keras_r2: -0.0955\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.0774 - keras_r2: 0.1429 - val_loss: 67.6401 - val_keras_r2: 0.1606\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.1723 - keras_r2: 0.0798 - val_loss: 244.2197 - val_keras_r2: -2.1295\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.4908 - keras_r2: 0.2106 - val_loss: 68.1651 - val_keras_r2: 0.1502\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.3830 - keras_r2: 0.2501 - val_loss: 83.0603 - val_keras_r2: -0.0605\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.2620 - keras_r2: 0.2445 - val_loss: 144.1457 - val_keras_r2: -0.8380\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.4327 - keras_r2: 0.2495 - val_loss: 72.2222 - val_keras_r2: 0.0970\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.8898 - keras_r2: 0.2463 - val_loss: 101.6748 - val_keras_r2: -0.3142\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.0526 - keras_r2: 0.2732 - val_loss: 116.5671 - val_keras_r2: -0.4604\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.7682 - keras_r2: 0.2679 - val_loss: 71.1056 - val_keras_r2: 0.1144\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5560 - keras_r2: 0.2583 - val_loss: 71.1067 - val_keras_r2: 0.1192\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.2985 - keras_r2: -4892283.0000 - val_loss: 81.5594 - val_keras_r2: -0.0371\n",
            "Epoch 25: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=50; total time=  15.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1038.3713 - keras_r2: -12.5221 - val_loss: 368.1481 - val_keras_r2: -3.8464\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 200.9718 - keras_r2: -1.6535 - val_loss: 121.7400 - val_keras_r2: -0.5240\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 98.5625 - keras_r2: -0.2344 - val_loss: 91.6986 - val_keras_r2: -0.1103\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.3374 - keras_r2: -0.0647 - val_loss: 87.9207 - val_keras_r2: -0.0555\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.8602 - keras_r2: -0.0888 - val_loss: 87.2271 - val_keras_r2: -0.0442\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6300 - keras_r2: -0.1485 - val_loss: 87.1895 - val_keras_r2: -0.0435\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6242 - keras_r2: -0.0776 - val_loss: 87.1463 - val_keras_r2: -0.0425\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6170 - keras_r2: -0.0497 - val_loss: 87.1348 - val_keras_r2: -0.0421\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6185 - keras_r2: -0.0405 - val_loss: 87.1385 - val_keras_r2: -0.0422\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6191 - keras_r2: -0.0339 - val_loss: 87.1400 - val_keras_r2: -0.0423\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6170 - keras_r2: -0.0278 - val_loss: 87.1374 - val_keras_r2: -0.0422\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6224 - keras_r2: -0.0382 - val_loss: 87.1384 - val_keras_r2: -0.0422\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6157 - keras_r2: -0.0345 - val_loss: 87.1531 - val_keras_r2: -0.0427\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6057 - keras_r2: -0.0376 - val_loss: 87.1256 - val_keras_r2: -0.0422\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.6284 - keras_r2: -0.0149 - val_loss: 84.8496 - val_keras_r2: -0.0136\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.4179 - keras_r2: 0.0248 - val_loss: 81.7616 - val_keras_r2: 0.0280\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.1161 - keras_r2: 0.1176 - val_loss: 79.2288 - val_keras_r2: 0.0595\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.5558 - keras_r2: 0.1731 - val_loss: 76.0026 - val_keras_r2: 0.0973\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.5175 - keras_r2: 0.0103 - val_loss: 77.4783 - val_keras_r2: 0.0723\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5329 - keras_r2: 0.2098 - val_loss: 74.7549 - val_keras_r2: 0.1217\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1286 - keras_r2: 0.2258 - val_loss: 76.3886 - val_keras_r2: 0.0894\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.1857 - keras_r2: 0.2337 - val_loss: 78.3329 - val_keras_r2: 0.0689\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.1121 - keras_r2: 0.2316 - val_loss: 74.0042 - val_keras_r2: 0.1181\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 61.0647 - keras_r2: 0.1896 - val_loss: 72.6757 - val_keras_r2: 0.1462\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.6524 - keras_r2: 0.1996 - val_loss: 80.0373 - val_keras_r2: 0.0350\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.2337 - keras_r2: 0.2588 - val_loss: 75.6250 - val_keras_r2: 0.1017\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.4872 - keras_r2: -2079974.1250 - val_loss: 72.4707 - val_keras_r2: 0.1420\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.3315 - keras_r2: 0.2627 - val_loss: 81.1223 - val_keras_r2: 0.0366\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.0473 - keras_r2: 0.2304 - val_loss: 76.0514 - val_keras_r2: 0.0974\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.3210 - keras_r2: 0.2821 - val_loss: 100.8666 - val_keras_r2: -0.2250\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.9958 - keras_r2: 0.2431 - val_loss: 74.8469 - val_keras_r2: 0.1145\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.4448 - keras_r2: 0.2931 - val_loss: 77.0833 - val_keras_r2: 0.0801\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.9092 - keras_r2: 0.2915 - val_loss: 73.8201 - val_keras_r2: 0.1244\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 56.5194 - keras_r2: 0.3022 - val_loss: 77.2457 - val_keras_r2: 0.0802\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.3733 - keras_r2: 0.3014 - val_loss: 74.3341 - val_keras_r2: 0.1196\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.3197 - keras_r2: 0.3014 - val_loss: 97.1863 - val_keras_r2: -0.1746\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.3836 - keras_r2: 0.3044 - val_loss: 77.2937 - val_keras_r2: 0.0834\n",
            "Epoch 37: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=59; total time=  41.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 177803.8125 - keras_r2: -2079.1208 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.0870 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.3525 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7969 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7028 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.2072 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.9554 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.3507 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -23.9844 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -32.7570 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7155 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=59; total time=   7.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2800.9871 - keras_r2: -48.0609 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -31.8535 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2035.2001 - keras_r2: -68.8947 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -28.3559 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.5800 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.6556 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.2060 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.8064 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 2035.2001 - keras_r2: -26.2484 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.6027 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.9397 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=59; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 288.7975 - keras_r2: -2.7429 - val_loss: 75.3167 - val_keras_r2: 0.1059\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 98.8999 - keras_r2: -0.3594 - val_loss: 88.9477 - val_keras_r2: -0.0635\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.7589 - keras_r2: 0.0528 - val_loss: 164.7286 - val_keras_r2: -1.0412\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.1328 - keras_r2: 0.1371 - val_loss: 80.9748 - val_keras_r2: 0.0158\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.4795 - keras_r2: -2245784.0000 - val_loss: 115.0922 - val_keras_r2: -0.4025\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5434 - keras_r2: 0.2111 - val_loss: 94.2593 - val_keras_r2: -0.1606\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3538 - keras_r2: 0.2108 - val_loss: 105.3642 - val_keras_r2: -0.2736\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.7303 - keras_r2: 0.2117 - val_loss: 113.0827 - val_keras_r2: -0.4201\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.0147 - keras_r2: 0.0931 - val_loss: 82.3101 - val_keras_r2: 0.0103\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.6936 - keras_r2: 0.1579 - val_loss: 75.3768 - val_keras_r2: 0.0946\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.7270 - keras_r2: 0.2452 - val_loss: 74.9441 - val_keras_r2: 0.0972\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.5185 - keras_r2: 0.2646 - val_loss: 93.3979 - val_keras_r2: -0.1153\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.1876 - keras_r2: 0.2476 - val_loss: 74.1531 - val_keras_r2: 0.1111\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.1479 - keras_r2: 0.2450 - val_loss: 95.3284 - val_keras_r2: -0.1580\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.2057 - keras_r2: 0.2688 - val_loss: 72.7583 - val_keras_r2: 0.1298\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.3688 - keras_r2: 0.2776 - val_loss: 107.3718 - val_keras_r2: -0.3061\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.7079 - keras_r2: 0.2301 - val_loss: 113.4162 - val_keras_r2: -0.3951\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.8975 - keras_r2: 0.1894 - val_loss: 278.9519 - val_keras_r2: -2.5512\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.9671 - keras_r2: 0.2053 - val_loss: 80.0803 - val_keras_r2: 0.0365\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.1297 - keras_r2: 0.2643 - val_loss: 104.4259 - val_keras_r2: -0.2637\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 57.4506 - keras_r2: 0.2961 - val_loss: 106.0793 - val_keras_r2: -0.2861\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 59.8820 - keras_r2: -16263441.0000 - val_loss: 153.3102 - val_keras_r2: -0.9709\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.2723 - keras_r2: 0.2795 - val_loss: 83.1885 - val_keras_r2: 0.0092\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.2333 - keras_r2: -110523.8984 - val_loss: 76.3983 - val_keras_r2: 0.0804\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 54.1371 - keras_r2: -0.7282 - val_loss: 85.5944 - val_keras_r2: -0.0552\n",
            "Epoch 25: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=59; total time=  15.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 411.1296 - keras_r2: -4.4262 - val_loss: 80.3458 - val_keras_r2: -0.0046\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 103.6744 - keras_r2: -0.2815 - val_loss: 118.7933 - val_keras_r2: -0.4852\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 11435.6514 - keras_r2: -146.0490 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3075 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.0397 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.1130 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3498 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.2582 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.8350 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3130 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.1009 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........................n_hidden=4, n_neurons=59; total time=  11.1s\n",
            "Epoch 1/100\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 363.8523 - keras_r2: -3.7724 - val_loss: 76.4998 - val_keras_r2: 0.0718\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 74.3949 - keras_r2: 0.1082 - val_loss: 75.5630 - val_keras_r2: 0.0850\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 73.7152 - keras_r2: 0.0974 - val_loss: 75.5193 - val_keras_r2: 0.0921\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 69.8167 - keras_r2: 0.1539 - val_loss: 77.5347 - val_keras_r2: 0.0676\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 67.7868 - keras_r2: 0.1622 - val_loss: 74.1143 - val_keras_r2: 0.1136\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 66.1970 - keras_r2: 0.1948 - val_loss: 72.2798 - val_keras_r2: 0.1265\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 65.3329 - keras_r2: 0.2043 - val_loss: 71.9105 - val_keras_r2: 0.1286\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 63.6966 - keras_r2: 0.2268 - val_loss: 72.7639 - val_keras_r2: 0.1195\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 64.0955 - keras_r2: 0.2187 - val_loss: 71.6642 - val_keras_r2: 0.1383\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 63.0845 - keras_r2: 0.2303 - val_loss: 71.6864 - val_keras_r2: 0.1341\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 63.2242 - keras_r2: 0.2313 - val_loss: 73.7440 - val_keras_r2: 0.1054\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 62.4368 - keras_r2: 0.2446 - val_loss: 75.4024 - val_keras_r2: 0.0797\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 67.5716 - keras_r2: 0.1677 - val_loss: 72.5091 - val_keras_r2: 0.1197\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 63.6358 - keras_r2: 0.2203 - val_loss: 72.1294 - val_keras_r2: 0.1286\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 62.7681 - keras_r2: 0.2321 - val_loss: 73.1992 - val_keras_r2: 0.1068\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 62.2411 - keras_r2: 0.2366 - val_loss: 77.6637 - val_keras_r2: 0.0617\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 62.1406 - keras_r2: 0.2384 - val_loss: 74.5352 - val_keras_r2: 0.0951\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 65.7526 - keras_r2: 0.1810 - val_loss: 72.7556 - val_keras_r2: 0.1240\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 62.6771 - keras_r2: 0.2423 - val_loss: 72.3169 - val_keras_r2: 0.1176\n",
            "Epoch 19: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'n_hidden': 3, 'n_neurons': 22}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_distribs_1 = {\n",
        "    \"n_hidden\": [1, 2, 3, 4, 5],\n",
        "    \"n_neurons\": np.arange(1, 100),\n",
        "}\n",
        "\n",
        "rnd_search_cv_1 = RandomizedSearchCV(keras_class, param_distribs_1, n_iter=30, cv=kFold, verbose=2, scoring=\"r2\")\n",
        "rnd_search_cv_1.fit(X_train_keras, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping_grid_search])\n",
        "rnd_search_cv_1.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyaZPH97yrVT",
        "outputId": "da3f703b-73f9-4864-d2ac-dd15a8d19562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 22)                1474      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 22)                506       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 22)                506       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 23        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,509\n",
            "Trainable params: 2,509\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "history = History()\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(keras.layers.InputLayer(input_shape=X_train_keras.shape[1],))\n",
        "model_1.add(Dense(22,activation=\"relu\"))\n",
        "model_1.add(Dense(22,activation=\"relu\"))\n",
        "model_1.add(Dense(22,activation=\"relu\"))\n",
        "model_1.add(Dense(1,activation=\"relu\"))\n",
        "model_1.summary()\n",
        "\n",
        "model_1.compile(loss=\"mean_squared_error\",optimizer=\"sgd\", metrics=[keras_r2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx88wzEryrVV",
        "outputId": "f5c3e5e2-6115-4c39-da60-e376df1ccb44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.9519 - keras_r2: -2.7243 - val_loss: 0.8250 - val_keras_r2: -0.0124\n",
            "Epoch 2/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7286 - keras_r2: 0.1345 - val_loss: 0.6720 - val_keras_r2: 0.1686\n",
            "Epoch 3/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6948 - keras_r2: 0.1611 - val_loss: 0.6628 - val_keras_r2: 0.1749\n",
            "Epoch 4/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6785 - keras_r2: 0.1827 - val_loss: 0.6480 - val_keras_r2: 0.2007\n",
            "Epoch 5/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.1991 - val_loss: 0.6341 - val_keras_r2: 0.2187\n",
            "Epoch 6/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6600 - keras_r2: 0.2045 - val_loss: 0.6332 - val_keras_r2: 0.2119\n",
            "Epoch 7/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6511 - keras_r2: 0.2167 - val_loss: 0.6447 - val_keras_r2: 0.1929\n",
            "Epoch 8/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6479 - keras_r2: 0.2194 - val_loss: 0.6274 - val_keras_r2: 0.2183\n",
            "Epoch 9/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6434 - keras_r2: 0.2276 - val_loss: 0.6245 - val_keras_r2: 0.2255\n",
            "Epoch 10/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6389 - keras_r2: 0.2250 - val_loss: 0.6308 - val_keras_r2: 0.2173\n",
            "Epoch 11/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6376 - keras_r2: 0.2356 - val_loss: 0.6268 - val_keras_r2: 0.2163\n",
            "Epoch 12/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6305 - keras_r2: 0.2390 - val_loss: 0.6494 - val_keras_r2: 0.1903\n",
            "Epoch 13/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6300 - keras_r2: 0.2351 - val_loss: 0.6287 - val_keras_r2: 0.2099\n",
            "Epoch 14/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6258 - keras_r2: 0.2514 - val_loss: 0.6190 - val_keras_r2: 0.2255\n",
            "Epoch 15/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6255 - keras_r2: 0.2454 - val_loss: 0.6141 - val_keras_r2: 0.2326\n",
            "Epoch 16/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6213 - keras_r2: 0.2545 - val_loss: 0.6393 - val_keras_r2: 0.2001\n",
            "Epoch 17/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6209 - keras_r2: 0.2573 - val_loss: 0.6169 - val_keras_r2: 0.2277\n",
            "Epoch 18/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6198 - keras_r2: 0.2537 - val_loss: 0.6602 - val_keras_r2: 0.1705\n",
            "Epoch 19/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6147 - keras_r2: 0.2615 - val_loss: 0.6213 - val_keras_r2: 0.2211\n",
            "Epoch 20/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6150 - keras_r2: 0.2602 - val_loss: 0.6223 - val_keras_r2: 0.2208\n",
            "Epoch 21/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6133 - keras_r2: 0.2623 - val_loss: 0.6247 - val_keras_r2: 0.2155\n",
            "Epoch 22/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6102 - keras_r2: 0.2673 - val_loss: 0.6306 - val_keras_r2: 0.2010\n",
            "Epoch 23/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6123 - keras_r2: 0.2561 - val_loss: 0.6236 - val_keras_r2: 0.2148\n",
            "Epoch 24/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6083 - keras_r2: 0.2650 - val_loss: 0.6238 - val_keras_r2: 0.2136\n",
            "Epoch 25/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6054 - keras_r2: 0.2725 - val_loss: 0.6269 - val_keras_r2: 0.2079\n",
            "Epoch 25: early stopping\n"
          ]
        }
      ],
      "source": [
        "history_1 = model_1.fit(X_train_keras, y_train, validation_data=(\n",
        "    X_test_keras, y_test), batch_size=32, epochs=100, callbacks=[EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2QzZ1sAyrVV",
        "outputId": "61a89efd-8ec7-44be-c2db-f7b3d02d9992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6269 - keras_r2: 0.2079\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6268920302391052, 0.20787283778190613]"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.evaluate(X_test_keras, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nIXbTf9yrVW",
        "outputId": "c0396fa3-9726-4109-fb0f-f6afabe9848a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'keras_r2', 'val_loss', 'val_keras_r2'])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "5AsAH_2gyrVX",
        "outputId": "2e922279-fc24-41ca-9792-eea9eedd12b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.ylim(ymin=0, ymax=1)\n",
        "\n",
        "plt.plot(history_1.history['loss'], label=\"loss\")\n",
        "plt.plot(history_1.history['val_loss'], label=\"val_loss \")\n",
        "\n",
        "plt.plot(history_1.history['keras_r2'], label=\"r2\")\n",
        "plt.plot(history_1.history['val_keras_r2'], label=\"val_r2\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jako, że parametry tej sieci neuronowej (liczba warstw ukrytych i ilość neuronów na warstwę) były wybrane za pomocą `randomized search`, mimo wielokrotnego losowania i uczenia modelu dla wielu kombinacji wybranych jako najlepsze, model ten jest dosyć słaby.\n",
        "\n",
        "Potencjalnymi czynnikami, które również wpływają na jakość modelu są taka sama ilość neuronów w każdej warstwie ukrytej (co jest wymuszone przez sposób losowego przeszukiwania hiperparametrów) oraz brak poszukiwania odpowiedniej funkcji aktywacji, ew. normalizacji batchy oraz dropoutów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spFODs1CH-Ff"
      },
      "source": [
        "2. Karas Randomized Search CV (liczba warstw + liczba neuronów + funkcja aktywacji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOdQr5OdIIYe",
        "outputId": "1e231c37-faaf-4af5-cf4a-c8d82d2a4b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -34.5009 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.1635 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.6227 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -28.3675 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.7708 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.0529 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.9215 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -26.0360 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -26.9458 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.4371 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.2901 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=4, n_neurons=10; total time=   5.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 211.1478 - keras_r2: -1.5982 - val_loss: 86.1732 - val_keras_r2: -0.0426\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5797 - keras_r2: -0.0404 - val_loss: 86.2076 - val_keras_r2: -0.0435\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4986 - keras_r2: -0.0756 - val_loss: 86.1376 - val_keras_r2: -0.0424\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4400 - keras_r2: -0.0340 - val_loss: 86.2250 - val_keras_r2: -0.0442\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.3947 - keras_r2: -0.0374 - val_loss: 86.0264 - val_keras_r2: -0.0410\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.3296 - keras_r2: -0.0398 - val_loss: 85.8817 - val_keras_r2: -0.0388\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.1748 - keras_r2: -0.0333 - val_loss: 85.7233 - val_keras_r2: -0.0366\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.9894 - keras_r2: -0.0577 - val_loss: 85.5095 - val_keras_r2: -0.0325\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.5223 - keras_r2: -0.0172 - val_loss: 84.9088 - val_keras_r2: -0.0257\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.5087 - keras_r2: -0.0126 - val_loss: 83.8587 - val_keras_r2: -0.0099\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.1828 - keras_r2: 0.0258 - val_loss: 78.7112 - val_keras_r2: 0.0527\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.1106 - keras_r2: 0.1102 - val_loss: 78.3413 - val_keras_r2: 0.0663\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9524 - keras_r2: 0.1523 - val_loss: 73.4493 - val_keras_r2: 0.1276\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.8924 - keras_r2: -1.5902 - val_loss: 74.8423 - val_keras_r2: 0.0996\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5779 - keras_r2: 0.1723 - val_loss: 74.4893 - val_keras_r2: 0.1145\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5556 - keras_r2: 0.1724 - val_loss: 72.6446 - val_keras_r2: 0.1337\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1647 - keras_r2: 0.1842 - val_loss: 72.6686 - val_keras_r2: 0.1353\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9394 - keras_r2: 0.1573 - val_loss: 74.0114 - val_keras_r2: 0.1118\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9292 - keras_r2: 0.1722 - val_loss: 73.2057 - val_keras_r2: 0.1307\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7441 - keras_r2: 0.1316 - val_loss: 73.9273 - val_keras_r2: 0.1154\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.4827 - keras_r2: 0.1868 - val_loss: 74.6665 - val_keras_r2: 0.1141\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3028 - keras_r2: -281669.2188 - val_loss: 72.8078 - val_keras_r2: 0.1352\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0910 - keras_r2: 0.1814 - val_loss: 78.5817 - val_keras_r2: 0.0446\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1397 - keras_r2: 0.0969 - val_loss: 73.5720 - val_keras_r2: 0.1263\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7800 - keras_r2: 0.1941 - val_loss: 72.8099 - val_keras_r2: 0.1312\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.6775 - keras_r2: 0.1886 - val_loss: 73.0047 - val_keras_r2: 0.1280\n",
            "Epoch 26: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=4, n_neurons=10; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 195.0531 - keras_r2: -1.4503 - val_loss: 87.3322 - val_keras_r2: -0.0429\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4823 - keras_r2: -0.0442 - val_loss: 87.0698 - val_keras_r2: -0.0413\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4689 - keras_r2: -0.0986 - val_loss: 87.0192 - val_keras_r2: -0.0401\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4261 - keras_r2: -0.0598 - val_loss: 87.2640 - val_keras_r2: -0.0457\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2798 - keras_r2: -0.0420 - val_loss: 86.8722 - val_keras_r2: -0.0381\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0912 - keras_r2: -0.0776 - val_loss: 86.7788 - val_keras_r2: -0.0382\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.9794 - keras_r2: -0.0301 - val_loss: 86.6354 - val_keras_r2: -0.0369\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.5265 - keras_r2: -0.2070 - val_loss: 85.9916 - val_keras_r2: -0.0270\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.6012 - keras_r2: -171767.4219 - val_loss: 84.6624 - val_keras_r2: -0.0102\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.5486 - keras_r2: -0.0166 - val_loss: 80.1223 - val_keras_r2: 0.0492\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5899 - keras_r2: 0.1226 - val_loss: 74.9761 - val_keras_r2: 0.1127\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.8699 - keras_r2: 0.1800 - val_loss: 73.4899 - val_keras_r2: 0.1334\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.0399 - keras_r2: 0.1738 - val_loss: 73.3141 - val_keras_r2: 0.1376\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7200 - keras_r2: -0.0257 - val_loss: 73.5162 - val_keras_r2: 0.1351\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.6418 - keras_r2: 0.1520 - val_loss: 76.7386 - val_keras_r2: 0.0987\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2376 - keras_r2: 0.1970 - val_loss: 74.1905 - val_keras_r2: 0.1296\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2077 - keras_r2: 0.1954 - val_loss: 75.2475 - val_keras_r2: 0.1084\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9285 - keras_r2: 0.2031 - val_loss: 74.6942 - val_keras_r2: 0.1246\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7008 - keras_r2: 0.1966 - val_loss: 73.6136 - val_keras_r2: 0.1358\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4961 - keras_r2: 0.2043 - val_loss: 74.2802 - val_keras_r2: 0.1289\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1376 - keras_r2: 0.2050 - val_loss: 74.0724 - val_keras_r2: 0.1317\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9942 - keras_r2: 0.1877 - val_loss: 80.9957 - val_keras_r2: 0.0476\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7901 - keras_r2: 0.2149 - val_loss: 75.0975 - val_keras_r2: 0.1111\n",
            "Epoch 23: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=4, n_neurons=10; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 209.1655 - keras_r2: -1.7728 - val_loss: 87.2016 - val_keras_r2: -0.0420\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3708 - keras_r2: -0.0376 - val_loss: 87.4476 - val_keras_r2: -0.0481\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2132 - keras_r2: -0.0538 - val_loss: 87.8348 - val_keras_r2: -0.0543\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3054 - keras_r2: -0.0405 - val_loss: 87.1215 - val_keras_r2: -0.0408\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2635 - keras_r2: -0.0429 - val_loss: 87.0488 - val_keras_r2: -0.0414\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1605 - keras_r2: -0.0346 - val_loss: 86.9697 - val_keras_r2: -0.0398\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1108 - keras_r2: -0.0317 - val_loss: 86.9931 - val_keras_r2: -0.0411\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.9521 - keras_r2: -0.0320 - val_loss: 86.8174 - val_keras_r2: -0.0382\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.8413 - keras_r2: -0.0303 - val_loss: 86.7449 - val_keras_r2: -0.0379\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5794 - keras_r2: -0.0291 - val_loss: 86.3812 - val_keras_r2: -0.0327\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.0753 - keras_r2: -0.2724 - val_loss: 85.9811 - val_keras_r2: -0.0248\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.6783 - keras_r2: -0.2501 - val_loss: 83.9921 - val_keras_r2: -8.9840e-04\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.1747 - keras_r2: 0.0230 - val_loss: 79.4085 - val_keras_r2: 0.0591\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0000 - keras_r2: 0.1230 - val_loss: 76.3830 - val_keras_r2: 0.0953\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0974 - keras_r2: 0.1780 - val_loss: 74.1179 - val_keras_r2: 0.1294\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1451 - keras_r2: 0.1895 - val_loss: 74.1426 - val_keras_r2: 0.1250\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8485 - keras_r2: 0.0992 - val_loss: 74.5555 - val_keras_r2: 0.1234\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2891 - keras_r2: 0.2002 - val_loss: 74.1830 - val_keras_r2: 0.1273\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0231 - keras_r2: -0.4677 - val_loss: 75.6755 - val_keras_r2: 0.1105\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7108 - keras_r2: 0.2045 - val_loss: 74.7665 - val_keras_r2: 0.1141\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3247 - keras_r2: 0.1590 - val_loss: 73.7461 - val_keras_r2: 0.1309\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9089 - keras_r2: 0.2071 - val_loss: 73.9690 - val_keras_r2: 0.1265\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8984 - keras_r2: 0.1987 - val_loss: 76.3652 - val_keras_r2: 0.0890\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7583 - keras_r2: 0.1951 - val_loss: 74.0389 - val_keras_r2: 0.1244\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4573 - keras_r2: 0.2217 - val_loss: 73.8729 - val_keras_r2: 0.1291\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3766 - keras_r2: 0.2173 - val_loss: 73.7712 - val_keras_r2: 0.1287\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8447 - keras_r2: 0.2327 - val_loss: 73.6806 - val_keras_r2: 0.1307\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7652 - keras_r2: -4291179.0000 - val_loss: 73.3174 - val_keras_r2: 0.1362\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6603 - keras_r2: 0.1859 - val_loss: 73.7143 - val_keras_r2: 0.1322\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5212 - keras_r2: 0.1843 - val_loss: 73.7785 - val_keras_r2: 0.1272\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2298 - keras_r2: 0.2336 - val_loss: 73.7333 - val_keras_r2: 0.1286\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1785 - keras_r2: 0.2213 - val_loss: 73.9374 - val_keras_r2: 0.1260\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1095 - keras_r2: 0.1765 - val_loss: 83.8544 - val_keras_r2: 0.0038\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1799 - keras_r2: 0.2082 - val_loss: 74.8564 - val_keras_r2: 0.1113\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7507 - keras_r2: 0.2349 - val_loss: 74.6977 - val_keras_r2: 0.1185\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.4080 - keras_r2: 0.2204 - val_loss: 77.8214 - val_keras_r2: 0.0684\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9995 - keras_r2: 0.2360 - val_loss: 74.3445 - val_keras_r2: 0.1228\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.5815 - keras_r2: 0.2335 - val_loss: 75.1638 - val_keras_r2: 0.1144\n",
            "Epoch 38: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=4, n_neurons=10; total time=  14.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 209.1282 - keras_r2: -1.6061 - val_loss: 83.2319 - val_keras_r2: -0.0308\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2759 - keras_r2: -0.3973 - val_loss: 83.3413 - val_keras_r2: -0.0300\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2663 - keras_r2: -0.0351 - val_loss: 83.7609 - val_keras_r2: -0.0404\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2395 - keras_r2: -0.0382 - val_loss: 83.3689 - val_keras_r2: -0.0340\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1729 - keras_r2: -0.0308 - val_loss: 83.6023 - val_keras_r2: -0.0381\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0933 - keras_r2: -0.0291 - val_loss: 83.2612 - val_keras_r2: -0.0326\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0588 - keras_r2: -0.0321 - val_loss: 83.0744 - val_keras_r2: -0.0297\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.9653 - keras_r2: -0.0387 - val_loss: 83.2015 - val_keras_r2: -0.0325\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6641 - keras_r2: -0.0321 - val_loss: 82.8575 - val_keras_r2: -0.0277\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.3868 - keras_r2: -0.0325 - val_loss: 82.4986 - val_keras_r2: -0.0237\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.5114 - keras_r2: -0.0153 - val_loss: 81.3078 - val_keras_r2: -0.0092\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.5214 - keras_r2: 0.0259 - val_loss: 76.0947 - val_keras_r2: 0.0570\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.4432 - keras_r2: 0.1237 - val_loss: 67.6229 - val_keras_r2: 0.1690\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0460 - keras_r2: 0.1705 - val_loss: 66.9064 - val_keras_r2: 0.1732\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3341 - keras_r2: 0.1802 - val_loss: 66.4060 - val_keras_r2: 0.1806\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7926 - keras_r2: 0.1884 - val_loss: 66.8121 - val_keras_r2: 0.1779\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7778 - keras_r2: 0.1836 - val_loss: 70.0997 - val_keras_r2: 0.1234\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7043 - keras_r2: 0.1895 - val_loss: 68.5076 - val_keras_r2: 0.1449\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3446 - keras_r2: 0.1957 - val_loss: 66.3041 - val_keras_r2: 0.1806\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0860 - keras_r2: 0.2003 - val_loss: 65.8789 - val_keras_r2: 0.1836\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5829 - keras_r2: 0.2047 - val_loss: 66.2749 - val_keras_r2: 0.1810\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.6655 - keras_r2: 0.2006 - val_loss: 67.2512 - val_keras_r2: 0.1710\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.2331 - keras_r2: 0.2097 - val_loss: 65.2993 - val_keras_r2: 0.1914\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0325 - keras_r2: 0.2074 - val_loss: 72.5312 - val_keras_r2: 0.0847\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8564 - keras_r2: 0.1957 - val_loss: 67.3274 - val_keras_r2: 0.1697\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4629 - keras_r2: 0.2179 - val_loss: 65.6417 - val_keras_r2: 0.1843\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2782 - keras_r2: 0.2125 - val_loss: 65.7499 - val_keras_r2: 0.1864\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8945 - keras_r2: 0.2230 - val_loss: 65.4800 - val_keras_r2: 0.1865\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8344 - keras_r2: 0.1949 - val_loss: 66.8669 - val_keras_r2: 0.1740\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5492 - keras_r2: 0.2292 - val_loss: 66.6267 - val_keras_r2: 0.1698\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4514 - keras_r2: 0.2156 - val_loss: 66.1442 - val_keras_r2: 0.1742\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1600 - keras_r2: 0.2258 - val_loss: 65.6972 - val_keras_r2: 0.1840\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7998 - keras_r2: 0.2352 - val_loss: 67.2617 - val_keras_r2: 0.1673\n",
            "Epoch 33: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=4, n_neurons=10; total time=  13.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 10: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=5, n_neurons=74; total time=   5.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1154.2395 - keras_r2: -14.0507 - val_loss: 1075.0681 - val_keras_r2: -13.3248\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=5, n_neurons=74; total time=   5.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 243.5012 - keras_r2: -1.9701 - val_loss: 110.1585 - val_keras_r2: -0.3322\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.7501 - keras_r2: 0.0419 - val_loss: 78.9247 - val_keras_r2: 0.0653\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.5787 - keras_r2: 0.0565 - val_loss: 126.1528 - val_keras_r2: -0.5880\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.8433 - keras_r2: 0.1059 - val_loss: 136.5595 - val_keras_r2: -0.7338\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.6078 - keras_r2: 0.1427 - val_loss: 89.8147 - val_keras_r2: -0.0959\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.2940 - keras_r2: 0.1733 - val_loss: 82.2038 - val_keras_r2: 0.0233\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0837 - keras_r2: 0.1976 - val_loss: 83.5209 - val_keras_r2: 0.0055\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1929 - keras_r2: 0.2079 - val_loss: 220.1247 - val_keras_r2: -1.8096\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2893 - keras_r2: 0.1119 - val_loss: 81.1296 - val_keras_r2: 0.0288\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0351 - keras_r2: 0.2138 - val_loss: 81.6374 - val_keras_r2: 0.0330\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8964 - keras_r2: 0.2013 - val_loss: 78.6323 - val_keras_r2: 0.0649\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2459 - keras_r2: 0.2286 - val_loss: 95.6319 - val_keras_r2: -0.1759\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.7691 - keras_r2: 0.2177 - val_loss: 76.6083 - val_keras_r2: 0.0806\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2902 - keras_r2: 0.2414 - val_loss: 89.9184 - val_keras_r2: -0.1099\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9795 - keras_r2: 0.0447 - val_loss: 94.6177 - val_keras_r2: -0.1336\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9000 - keras_r2: 0.2342 - val_loss: 219.9631 - val_keras_r2: -1.8165\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.4309 - keras_r2: 0.2356 - val_loss: 93.6383 - val_keras_r2: -0.1342\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.2060 - keras_r2: 0.2567 - val_loss: 76.9475 - val_keras_r2: 0.0859\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.2254 - keras_r2: -0.0477 - val_loss: 93.3830 - val_keras_r2: -0.1260\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5493 - keras_r2: 0.2093 - val_loss: 272.6483 - val_keras_r2: -2.5115\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.6185 - keras_r2: 0.2256 - val_loss: 98.6724 - val_keras_r2: -0.1900\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1829 - keras_r2: 0.2287 - val_loss: 72.8987 - val_keras_r2: 0.1304\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.4191 - keras_r2: 0.2399 - val_loss: 81.5003 - val_keras_r2: 0.0141\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.2707 - keras_r2: 0.2575 - val_loss: 83.6028 - val_keras_r2: 0.0040\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.3333 - keras_r2: 0.1792 - val_loss: 82.4152 - val_keras_r2: 0.0141\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.5220 - keras_r2: 0.2773 - val_loss: 94.8454 - val_keras_r2: -0.1696\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.3852 - keras_r2: 0.2839 - val_loss: 83.3071 - val_keras_r2: -0.0099\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.5336 - keras_r2: 0.2918 - val_loss: 100.7252 - val_keras_r2: -0.2246\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.8906 - keras_r2: -0.0436 - val_loss: 129.3372 - val_keras_r2: -0.5931\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.5512 - keras_r2: 0.2689 - val_loss: 74.9461 - val_keras_r2: 0.1155\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.1723 - keras_r2: 0.2917 - val_loss: 75.1583 - val_keras_r2: 0.0945\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.5005 - keras_r2: 0.2928 - val_loss: 96.8649 - val_keras_r2: -0.1902\n",
            "Epoch 32: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=5, n_neurons=74; total time=  14.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 675545.0625 - keras_r2: -10055.4531 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -28.1101 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.7345 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -40.4630 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -34.3618 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.2219 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.9725 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -24.9253 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -181818208.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -26.3961 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -25.5132 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=5, n_neurons=74; total time=   5.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1760.1312 - keras_r2: -22.2016 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -21.9981 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.6782 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -21.9632 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1762.4236 - keras_r2: -22.0770 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.4617 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.3959 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.1458 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.0826 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.7909 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1762.4236 - keras_r2: -22.5625 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=5, n_neurons=74; total time=   5.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 1021.0505 - keras_r2: -14.3476 - val_loss: 982.5496 - val_keras_r2: -11.9068\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 903.2479 - keras_r2: -31.8406 - val_loss: 963.2123 - val_keras_r2: -11.6221\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 828.5345 - keras_r2: -10.0129 - val_loss: 925.9946 - val_keras_r2: -11.1092\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 871.5228 - keras_r2: -10.8749 - val_loss: 893.7094 - val_keras_r2: -10.7548\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 837.0389 - keras_r2: -10.2563 - val_loss: 873.8603 - val_keras_r2: -10.5789\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 902.6446 - keras_r2: -10.9071 - val_loss: 1040.0051 - val_keras_r2: -12.6988\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 959.3862 - keras_r2: -12.0113 - val_loss: 1000.8862 - val_keras_r2: -12.1310\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 910.5248 - keras_r2: -11.3490 - val_loss: 954.8999 - val_keras_r2: -11.4762\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1085.0239 - keras_r2: -13.8207 - val_loss: 1204.9197 - val_keras_r2: -14.7367\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1053.6705 - keras_r2: -13.1784 - val_loss: 1023.9979 - val_keras_r2: -12.2768\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 896.4641 - keras_r2: -11.0280 - val_loss: 850.8491 - val_keras_r2: -10.1691\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 790.3037 - keras_r2: -10.8659 - val_loss: 776.7953 - val_keras_r2: -9.1076\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 733.8758 - keras_r2: -8.7870 - val_loss: 721.7291 - val_keras_r2: -8.4402\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 685.2598 - keras_r2: -8.0772 - val_loss: 653.6375 - val_keras_r2: -7.7770\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 625.3507 - keras_r2: -7.1830 - val_loss: 596.1690 - val_keras_r2: -6.8429\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 704.3474 - keras_r2: -8.2578 - val_loss: 727.9401 - val_keras_r2: -8.6617\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 708.8677 - keras_r2: -8.4727 - val_loss: 648.9075 - val_keras_r2: -7.5751\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 662.1489 - keras_r2: -7.6945 - val_loss: 665.1394 - val_keras_r2: -7.8025\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 660.3469 - keras_r2: -7.8197 - val_loss: 642.3221 - val_keras_r2: -7.5059\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 625.6055 - keras_r2: -8.1267 - val_loss: 674.4521 - val_keras_r2: -7.8312\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 649.2791 - keras_r2: -8.7955 - val_loss: 701.3821 - val_keras_r2: -8.1958\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 668.2830 - keras_r2: -8.7374 - val_loss: 651.8774 - val_keras_r2: -7.5624\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 659.0219 - keras_r2: -7.5849 - val_loss: 655.2854 - val_keras_r2: -7.6364\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 677.3743 - keras_r2: -8.0942 - val_loss: 645.4812 - val_keras_r2: -7.5007\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 689.3391 - keras_r2: -10.7720 - val_loss: 640.7729 - val_keras_r2: -7.4679\n",
            "Epoch 25: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=16; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1001.7383 - keras_r2: -12.3295 - val_loss: 876.7579 - val_keras_r2: -10.6869\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 855.8019 - keras_r2: -10.3592 - val_loss: 821.7437 - val_keras_r2: -10.0495\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 841.1857 - keras_r2: -12.6187 - val_loss: 794.8991 - val_keras_r2: -9.6473\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 827.8195 - keras_r2: -21.7242 - val_loss: 805.5440 - val_keras_r2: -9.8748\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 812.1102 - keras_r2: -10.5418 - val_loss: 849.7703 - val_keras_r2: -10.4081\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 839.4296 - keras_r2: -10.1935 - val_loss: 826.2742 - val_keras_r2: -10.0886\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 835.5612 - keras_r2: -10.2257 - val_loss: 816.4371 - val_keras_r2: -9.9928\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 847.0855 - keras_r2: -15.2773 - val_loss: 890.0624 - val_keras_r2: -10.8798\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 916.5092 - keras_r2: -11.0033 - val_loss: 851.3783 - val_keras_r2: -10.3894\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 866.6131 - keras_r2: -10.7648 - val_loss: 810.4625 - val_keras_r2: -9.8862\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 919.0527 - keras_r2: -11.4926 - val_loss: 885.5646 - val_keras_r2: -10.8367\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 908.4219 - keras_r2: -66.6477 - val_loss: 930.4643 - val_keras_r2: -11.5053\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 917.9512 - keras_r2: -68.9582 - val_loss: 800.3181 - val_keras_r2: -9.7135\n",
            "Epoch 13: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=16; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1051.2843 - keras_r2: -12.6286 - val_loss: 978.8561 - val_keras_r2: -11.9942\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 882.5037 - keras_r2: -10.4569 - val_loss: 937.5402 - val_keras_r2: -11.3653\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 791.1269 - keras_r2: -11.9332 - val_loss: 802.0950 - val_keras_r2: -9.5981\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 760.7043 - keras_r2: -8.7926 - val_loss: 733.7050 - val_keras_r2: -8.6319\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 710.0967 - keras_r2: -8.2339 - val_loss: 761.1662 - val_keras_r2: -9.1420\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 676.5406 - keras_r2: -44.0054 - val_loss: 739.2338 - val_keras_r2: -8.6601\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 692.6561 - keras_r2: -8.4871 - val_loss: 720.2532 - val_keras_r2: -8.5971\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 676.2936 - keras_r2: -12.4971 - val_loss: 672.7437 - val_keras_r2: -7.7884\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 671.5688 - keras_r2: -7.8554 - val_loss: 704.4355 - val_keras_r2: -8.1874\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 643.5282 - keras_r2: -7.3361 - val_loss: 691.2457 - val_keras_r2: -7.9959\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 626.2639 - keras_r2: -7.2207 - val_loss: 662.7958 - val_keras_r2: -7.7357\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 620.9218 - keras_r2: -7.1013 - val_loss: 735.7783 - val_keras_r2: -8.7359\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 698.0463 - keras_r2: -8.1125 - val_loss: 710.4283 - val_keras_r2: -8.3698\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 657.3148 - keras_r2: -8.6395 - val_loss: 699.5339 - val_keras_r2: -8.2545\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 643.6949 - keras_r2: -7.3826 - val_loss: 651.0297 - val_keras_r2: -7.5729\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 627.5435 - keras_r2: -23.7375 - val_loss: 653.6950 - val_keras_r2: -7.6349\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 631.8644 - keras_r2: -7.1760 - val_loss: 646.1592 - val_keras_r2: -7.4931\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 628.5165 - keras_r2: -7.3174 - val_loss: 647.0609 - val_keras_r2: -7.5044\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 625.3770 - keras_r2: -7.4386 - val_loss: 658.4625 - val_keras_r2: -7.6040\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 628.7703 - keras_r2: -7.2031 - val_loss: 649.5491 - val_keras_r2: -7.4774\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 615.3198 - keras_r2: -7.8701 - val_loss: 636.8090 - val_keras_r2: -7.3522\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 623.6086 - keras_r2: -7.1121 - val_loss: 628.4900 - val_keras_r2: -7.2665\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 614.4104 - keras_r2: -6.9408 - val_loss: 639.9116 - val_keras_r2: -7.4447\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 612.1050 - keras_r2: -6.8407 - val_loss: 640.8078 - val_keras_r2: -7.4549\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 613.1843 - keras_r2: -6.9755 - val_loss: 637.8158 - val_keras_r2: -7.4161\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 608.9457 - keras_r2: -6.8043 - val_loss: 633.9162 - val_keras_r2: -7.3595\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 608.4004 - keras_r2: -6.9213 - val_loss: 632.3075 - val_keras_r2: -7.2942\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 607.8596 - keras_r2: -6.8235 - val_loss: 628.7428 - val_keras_r2: -7.2366\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 620.8840 - keras_r2: -7.0036 - val_loss: 645.1926 - val_keras_r2: -7.4749\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 617.9938 - keras_r2: -7.0066 - val_loss: 645.2926 - val_keras_r2: -7.4809\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 613.7032 - keras_r2: -115230840.0000 - val_loss: 640.5718 - val_keras_r2: -7.3991\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 606.5049 - keras_r2: -6.9119 - val_loss: 631.6740 - val_keras_r2: -7.2940\n",
            "Epoch 32: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=16; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 923.1025 - keras_r2: -11.8579 - val_loss: 783.5110 - val_keras_r2: -9.3349\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 733.4879 - keras_r2: -8.6137 - val_loss: 743.7092 - val_keras_r2: -8.8522\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 710.5826 - keras_r2: -8.6255 - val_loss: 754.1752 - val_keras_r2: -9.0146\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 703.9416 - keras_r2: -8.3016 - val_loss: 756.1747 - val_keras_r2: -9.0066\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 749.2855 - keras_r2: -9.9746 - val_loss: 784.1882 - val_keras_r2: -9.3994\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 725.8575 - keras_r2: -8.4658 - val_loss: 746.3462 - val_keras_r2: -8.8961\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 687.4639 - keras_r2: -8.1339 - val_loss: 689.7518 - val_keras_r2: -8.1763\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 658.6239 - keras_r2: -16641628.0000 - val_loss: 666.6708 - val_keras_r2: -7.7682\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 663.9164 - keras_r2: -8.0248 - val_loss: 780.6602 - val_keras_r2: -9.2260\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 708.5899 - keras_r2: -8.6601 - val_loss: 732.4160 - val_keras_r2: -8.6373\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 682.4485 - keras_r2: -7.8648 - val_loss: 730.1186 - val_keras_r2: -8.6354\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 708.1762 - keras_r2: -8.2959 - val_loss: 710.7839 - val_keras_r2: -8.4050\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 682.1061 - keras_r2: -7.8728 - val_loss: 720.2151 - val_keras_r2: -8.4925\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 662.2526 - keras_r2: -8.1683 - val_loss: 707.1443 - val_keras_r2: -8.2498\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 648.7181 - keras_r2: -7.3976 - val_loss: 739.3176 - val_keras_r2: -8.6838\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 698.5555 - keras_r2: -10.5508 - val_loss: 766.8315 - val_keras_r2: -9.0182\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 671.7786 - keras_r2: -7.8373 - val_loss: 669.0667 - val_keras_r2: -7.8232\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 624.1075 - keras_r2: -7.4439 - val_loss: 684.5939 - val_keras_r2: -8.0125\n",
            "Epoch 18: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=16; total time=   8.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 908.8436 - keras_r2: -10.8284 - val_loss: 898.1708 - val_keras_r2: -11.0285\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 899.6583 - keras_r2: -11.0757 - val_loss: 964.1574 - val_keras_r2: -11.8581\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 864.8329 - keras_r2: -10.2099 - val_loss: 906.8822 - val_keras_r2: -11.0787\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 820.3380 - keras_r2: -10.3889 - val_loss: 839.6456 - val_keras_r2: -10.0744\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 779.5751 - keras_r2: -9.2354 - val_loss: 848.5390 - val_keras_r2: -10.2601\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 792.2307 - keras_r2: -9.2993 - val_loss: 858.8296 - val_keras_r2: -10.3963\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 814.3201 - keras_r2: -10.0222 - val_loss: 834.1346 - val_keras_r2: -10.0148\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 735.4556 - keras_r2: -8.7386 - val_loss: 828.9245 - val_keras_r2: -9.9773\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 757.9808 - keras_r2: -9.0667 - val_loss: 798.4958 - val_keras_r2: -9.6377\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 737.6401 - keras_r2: -8.7598 - val_loss: 767.0574 - val_keras_r2: -9.1780\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 731.4919 - keras_r2: -9.0035 - val_loss: 769.8045 - val_keras_r2: -9.2095\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 720.7557 - keras_r2: -8.6036 - val_loss: 756.3807 - val_keras_r2: -9.0916\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 743.2571 - keras_r2: -8.7352 - val_loss: 788.4883 - val_keras_r2: -9.4890\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 744.0180 - keras_r2: -8.6812 - val_loss: 712.7021 - val_keras_r2: -8.4925\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 714.6174 - keras_r2: -9.1724 - val_loss: 669.4647 - val_keras_r2: -7.8346\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 671.9774 - keras_r2: -7.9980 - val_loss: 756.2108 - val_keras_r2: -9.0457\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 730.7986 - keras_r2: -8.6142 - val_loss: 992.1473 - val_keras_r2: -12.1866\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 730.1338 - keras_r2: -8.6110 - val_loss: 725.3793 - val_keras_r2: -8.5552\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 691.4720 - keras_r2: -8.6221 - val_loss: 610.5374 - val_keras_r2: -6.9845\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 609.1899 - keras_r2: -7.6373 - val_loss: 615.1846 - val_keras_r2: -7.1253\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 620.7250 - keras_r2: -7.1775 - val_loss: 681.2318 - val_keras_r2: -8.0283\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 669.5353 - keras_r2: -8.0691 - val_loss: 703.0431 - val_keras_r2: -8.3782\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 627.3450 - keras_r2: -7.2815 - val_loss: 648.3747 - val_keras_r2: -7.7048\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 553.3036 - keras_r2: -6.2005 - val_loss: 567.9833 - val_keras_r2: -6.6208\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 528.3578 - keras_r2: -6.2597 - val_loss: 561.3004 - val_keras_r2: -6.5086\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 503.9418 - keras_r2: -5.6870 - val_loss: 588.5989 - val_keras_r2: -6.9477\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 521.1688 - keras_r2: -5.9971 - val_loss: 553.1032 - val_keras_r2: -6.3767\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 508.8980 - keras_r2: -5.6435 - val_loss: 520.5220 - val_keras_r2: -6.0024\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 514.5518 - keras_r2: -5.7869 - val_loss: 473.2332 - val_keras_r2: -5.2440\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 497.7060 - keras_r2: -5.4591 - val_loss: 540.3408 - val_keras_r2: -6.2011\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 471.3185 - keras_r2: -5.1247 - val_loss: 501.7212 - val_keras_r2: -5.6542\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 478.9809 - keras_r2: -5.4035 - val_loss: 532.6044 - val_keras_r2: -6.1315\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 435.6646 - keras_r2: -5.6002 - val_loss: 446.3584 - val_keras_r2: -4.8405\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 492.0556 - keras_r2: -5.4179 - val_loss: 575.2709 - val_keras_r2: -6.7192\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 538.5369 - keras_r2: -6.2863 - val_loss: 496.1308 - val_keras_r2: -5.6603\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 453.5472 - keras_r2: -5.5920 - val_loss: 471.8043 - val_keras_r2: -5.2462\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 445.6303 - keras_r2: -4.8240 - val_loss: 513.7400 - val_keras_r2: -5.8670\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 471.7470 - keras_r2: -5.2198 - val_loss: 519.7793 - val_keras_r2: -5.9959\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 498.1366 - keras_r2: -5.7027 - val_loss: 513.9775 - val_keras_r2: -5.8908\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 503.4846 - keras_r2: -5.6615 - val_loss: 506.4722 - val_keras_r2: -5.7631\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 497.1344 - keras_r2: -5.6565 - val_loss: 501.1721 - val_keras_r2: -5.6443\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 425.3588 - keras_r2: -4.6176 - val_loss: 456.7130 - val_keras_r2: -5.0246\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 451.9788 - keras_r2: -4.7905 - val_loss: 488.0249 - val_keras_r2: -5.4157\n",
            "Epoch 43: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=16; total time=  18.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.4834 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.8963 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -28.3456 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -30.4129 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.3685 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.7331 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.8421 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -25.4083 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -71.6615 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -24.8193 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4823 - keras_r2: -27.7831 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=5, n_neurons=17; total time=   5.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 169.2832 - keras_r2: -1.3964 - val_loss: 86.4229 - val_keras_r2: -0.0436\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.7080 - keras_r2: -0.0341 - val_loss: 86.1530 - val_keras_r2: -0.0420\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6337 - keras_r2: -0.0371 - val_loss: 86.3081 - val_keras_r2: -0.0425\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.7221 - keras_r2: -0.0351 - val_loss: 86.2668 - val_keras_r2: -0.0421\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6272 - keras_r2: -0.0391 - val_loss: 86.5864 - val_keras_r2: -0.0497\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5468 - keras_r2: -0.0314 - val_loss: 86.2063 - val_keras_r2: -0.0433\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5979 - keras_r2: -0.0363 - val_loss: 86.2359 - val_keras_r2: -0.0418\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6193 - keras_r2: -0.0339 - val_loss: 86.1408 - val_keras_r2: -0.0419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5636 - keras_r2: -0.1288 - val_loss: 86.1320 - val_keras_r2: -0.0412\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6660 - keras_r2: -0.0472 - val_loss: 86.2462 - val_keras_r2: -0.0441\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5853 - keras_r2: -0.0333 - val_loss: 86.1943 - val_keras_r2: -0.0432\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6460 - keras_r2: -0.0422 - val_loss: 87.8866 - val_keras_r2: -0.0605\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6369 - keras_r2: -0.0363 - val_loss: 86.1774 - val_keras_r2: -0.0430\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5682 - keras_r2: -0.0329 - val_loss: 87.5382 - val_keras_r2: -0.0642\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6649 - keras_r2: -0.0359 - val_loss: 86.1234 - val_keras_r2: -0.0420\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5797 - keras_r2: -0.0354 - val_loss: 89.7010 - val_keras_r2: -0.0955\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6803 - keras_r2: -0.0449 - val_loss: 86.0506 - val_keras_r2: -0.0406\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5843 - keras_r2: -0.1788 - val_loss: 87.7144 - val_keras_r2: -0.0584\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.5650 - keras_r2: -0.0350 - val_loss: 85.9843 - val_keras_r2: -0.0396\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4774 - keras_r2: -0.0384 - val_loss: 85.9443 - val_keras_r2: -0.0386\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.3725 - keras_r2: -13520479.0000 - val_loss: 86.9986 - val_keras_r2: -0.0496\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.2247 - keras_r2: -0.2949 - val_loss: 85.7075 - val_keras_r2: -0.0355\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.9898 - keras_r2: -0.0309 - val_loss: 85.5566 - val_keras_r2: -0.0326\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.3257 - keras_r2: -0.0222 - val_loss: 84.8146 - val_keras_r2: -0.0257\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.5933 - keras_r2: -0.0024 - val_loss: 82.7916 - val_keras_r2: -7.3299e-04\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.7475 - keras_r2: 0.0665 - val_loss: 77.2019 - val_keras_r2: 0.0718\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.3579 - keras_r2: 0.1433 - val_loss: 81.3155 - val_keras_r2: 0.0106\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.3267 - keras_r2: -2496534.7500 - val_loss: 74.4171 - val_keras_r2: 0.1167\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0333 - keras_r2: 0.1661 - val_loss: 78.7198 - val_keras_r2: 0.0460\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6706 - keras_r2: -0.3835 - val_loss: 77.3321 - val_keras_r2: 0.0811\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7735 - keras_r2: 0.1024 - val_loss: 73.1637 - val_keras_r2: 0.1286\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3939 - keras_r2: 0.1568 - val_loss: 73.1308 - val_keras_r2: 0.1312\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2347 - keras_r2: 0.1816 - val_loss: 72.8756 - val_keras_r2: 0.1349\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1414 - keras_r2: 0.1660 - val_loss: 72.7903 - val_keras_r2: 0.1352\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1938 - keras_r2: 0.1665 - val_loss: 72.9966 - val_keras_r2: 0.1336\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8011 - keras_r2: 0.1837 - val_loss: 76.2256 - val_keras_r2: 0.0960\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5631 - keras_r2: 0.1832 - val_loss: 73.5933 - val_keras_r2: 0.1172\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3837 - keras_r2: 0.1786 - val_loss: 75.0538 - val_keras_r2: 0.1105\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1815 - keras_r2: 0.1794 - val_loss: 72.7860 - val_keras_r2: 0.1352\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9656 - keras_r2: 0.1921 - val_loss: 72.9757 - val_keras_r2: 0.1303\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7330 - keras_r2: 0.0971 - val_loss: 82.4799 - val_keras_r2: 0.0165\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5800 - keras_r2: 0.1770 - val_loss: 83.1391 - val_keras_r2: 0.0089\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.2724 - keras_r2: 0.2032 - val_loss: 77.7650 - val_keras_r2: 0.0561\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8129 - keras_r2: -2.0072 - val_loss: 87.1615 - val_keras_r2: -0.0770\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6939 - keras_r2: 0.0460 - val_loss: 78.3894 - val_keras_r2: 0.0682\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5029 - keras_r2: 0.1889 - val_loss: 92.7003 - val_keras_r2: -0.1168\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.0298 - keras_r2: 0.2193 - val_loss: 72.7021 - val_keras_r2: 0.1360\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6274 - keras_r2: 0.2232 - val_loss: 72.5743 - val_keras_r2: 0.1365\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2738 - keras_r2: 0.2244 - val_loss: 73.3091 - val_keras_r2: 0.1291\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7249 - keras_r2: 0.2343 - val_loss: 77.7318 - val_keras_r2: 0.0748\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.8166 - keras_r2: -0.4305 - val_loss: 93.1688 - val_keras_r2: -0.1597\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.4777 - keras_r2: 0.2178 - val_loss: 72.9194 - val_keras_r2: 0.1369\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9733 - keras_r2: 0.2398 - val_loss: 80.4667 - val_keras_r2: 0.0407\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9195 - keras_r2: -0.0398 - val_loss: 83.5231 - val_keras_r2: 9.7041e-04\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9093 - keras_r2: 0.2381 - val_loss: 75.4453 - val_keras_r2: 0.0975\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5274 - keras_r2: 0.2402 - val_loss: 79.7073 - val_keras_r2: 0.0499\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.0380 - keras_r2: 0.2529 - val_loss: 87.1766 - val_keras_r2: -0.0478\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.0611 - keras_r2: 0.2379 - val_loss: 73.2193 - val_keras_r2: 0.1237\n",
            "Epoch 58: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=5, n_neurons=17; total time=  41.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 186.7926 - keras_r2: -1.2807 - val_loss: 87.5051 - val_keras_r2: -0.0490\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6513 - keras_r2: -0.0499 - val_loss: 87.3920 - val_keras_r2: -0.0435\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6037 - keras_r2: -0.0393 - val_loss: 87.4996 - val_keras_r2: -0.0446\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5778 - keras_r2: -0.0533 - val_loss: 87.2778 - val_keras_r2: -0.0452\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6802 - keras_r2: -0.0387 - val_loss: 87.4012 - val_keras_r2: -0.0436\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6848 - keras_r2: -0.1374 - val_loss: 87.6418 - val_keras_r2: -0.0461\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6897 - keras_r2: -0.0496 - val_loss: 87.8269 - val_keras_r2: -0.0541\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.7093 - keras_r2: -0.0445 - val_loss: 87.1248 - val_keras_r2: -0.0421\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5075 - keras_r2: -0.0329 - val_loss: 89.2410 - val_keras_r2: -0.0752\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6773 - keras_r2: -0.0482 - val_loss: 87.4824 - val_keras_r2: -0.0487\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6080 - keras_r2: -0.1117 - val_loss: 87.8775 - val_keras_r2: -0.0549\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6582 - keras_r2: -0.0383 - val_loss: 87.3531 - val_keras_r2: -0.0466\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5867 - keras_r2: -0.0436 - val_loss: 87.8321 - val_keras_r2: -0.0481\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6500 - keras_r2: -0.0439 - val_loss: 88.5559 - val_keras_r2: -0.0565\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6696 - keras_r2: -0.0410 - val_loss: 87.1706 - val_keras_r2: -0.0434\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4424 - keras_r2: -0.0343 - val_loss: 87.5965 - val_keras_r2: -0.0455\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5392 - keras_r2: -0.0486 - val_loss: 87.2283 - val_keras_r2: -0.0446\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.6281 - keras_r2: -0.0415 - val_loss: 87.1066 - val_keras_r2: -0.0408\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5371 - keras_r2: -0.0322 - val_loss: 87.1822 - val_keras_r2: -0.0438\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5136 - keras_r2: -0.5416 - val_loss: 87.5371 - val_keras_r2: -0.0447\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4801 - keras_r2: -0.0305 - val_loss: 87.4753 - val_keras_r2: -0.0489\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5296 - keras_r2: -0.0501 - val_loss: 86.9941 - val_keras_r2: -0.0398\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3994 - keras_r2: -0.0417 - val_loss: 87.1799 - val_keras_r2: -0.0442\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3983 - keras_r2: -0.0394 - val_loss: 87.5754 - val_keras_r2: -0.0449\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3442 - keras_r2: -0.0342 - val_loss: 87.2487 - val_keras_r2: -0.0458\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2494 - keras_r2: -0.0339 - val_loss: 86.6979 - val_keras_r2: -0.0362\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0072 - keras_r2: -0.0294 - val_loss: 86.5745 - val_keras_r2: -0.0333\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4748 - keras_r2: -0.0172 - val_loss: 86.0776 - val_keras_r2: -0.0297\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.2178 - keras_r2: -0.0110 - val_loss: 88.4274 - val_keras_r2: -0.0524\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.8932 - keras_r2: 0.0598 - val_loss: 78.0575 - val_keras_r2: 0.0715\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1652 - keras_r2: 0.1674 - val_loss: 74.2487 - val_keras_r2: 0.1227\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5749 - keras_r2: -16088409.0000 - val_loss: 85.1576 - val_keras_r2: -0.0074\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2604 - keras_r2: 0.1849 - val_loss: 74.2027 - val_keras_r2: 0.1210\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.8723 - keras_r2: 0.1883 - val_loss: 87.0521 - val_keras_r2: -0.0327\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8352 - keras_r2: 0.1853 - val_loss: 77.1049 - val_keras_r2: 0.0785\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.4397 - keras_r2: 0.1947 - val_loss: 75.4323 - val_keras_r2: 0.1142\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3969 - keras_r2: 0.1175 - val_loss: 89.5047 - val_keras_r2: -0.0619\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2526 - keras_r2: 0.1977 - val_loss: 77.4271 - val_keras_r2: 0.0899\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8752 - keras_r2: 0.1982 - val_loss: 73.6278 - val_keras_r2: 0.1329\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4664 - keras_r2: 0.1944 - val_loss: 75.3890 - val_keras_r2: 0.1158\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3350 - keras_r2: 0.1861 - val_loss: 73.5669 - val_keras_r2: 0.1358\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.2813 - keras_r2: 0.1853 - val_loss: 87.8647 - val_keras_r2: -0.0423\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.2511 - keras_r2: 0.1428 - val_loss: 92.1347 - val_keras_r2: -0.0967\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0656 - keras_r2: 0.2129 - val_loss: 76.8912 - val_keras_r2: 0.0955\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4565 - keras_r2: 0.2180 - val_loss: 83.0960 - val_keras_r2: 0.0179\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5170 - keras_r2: 0.1891 - val_loss: 91.8276 - val_keras_r2: -0.0945\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.1021 - keras_r2: 0.1975 - val_loss: 113.9987 - val_keras_r2: -0.4341\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.1293 - keras_r2: -0.2532 - val_loss: 74.8376 - val_keras_r2: 0.1103\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7748 - keras_r2: 0.2156 - val_loss: 74.4388 - val_keras_r2: 0.1138\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1051 - keras_r2: 0.0482 - val_loss: 85.6946 - val_keras_r2: -0.0146\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0447 - keras_r2: 0.2293 - val_loss: 78.1902 - val_keras_r2: 0.0798\n",
            "Epoch 51: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=5, n_neurons=17; total time=  22.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 166.1053 - keras_r2: -1.0594 - val_loss: 87.1904 - val_keras_r2: -0.0417\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.5065 - keras_r2: -0.0393 - val_loss: 87.5832 - val_keras_r2: -0.0503\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.3733 - keras_r2: -0.0391 - val_loss: 87.3966 - val_keras_r2: -0.0473\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4374 - keras_r2: -0.0473 - val_loss: 87.2502 - val_keras_r2: -0.0448\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3590 - keras_r2: -0.0552 - val_loss: 87.4408 - val_keras_r2: -0.0439\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3379 - keras_r2: -0.6158 - val_loss: 88.2557 - val_keras_r2: -0.0607\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3991 - keras_r2: -0.0347 - val_loss: 87.1106 - val_keras_r2: -0.0423\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3250 - keras_r2: -0.0340 - val_loss: 87.1861 - val_keras_r2: -0.0438\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3909 - keras_r2: -0.1055 - val_loss: 90.8095 - val_keras_r2: -0.0840\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4232 - keras_r2: -0.0377 - val_loss: 87.0437 - val_keras_r2: -0.0409\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3544 - keras_r2: -0.0352 - val_loss: 87.0239 - val_keras_r2: -0.0403\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2815 - keras_r2: -0.0320 - val_loss: 87.0204 - val_keras_r2: -0.0410\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2355 - keras_r2: -0.2007 - val_loss: 88.5870 - val_keras_r2: -0.0659\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1278 - keras_r2: -0.0294 - val_loss: 86.9395 - val_keras_r2: -0.0390\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1323 - keras_r2: -0.0366 - val_loss: 86.9370 - val_keras_r2: -0.0403\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1928 - keras_r2: -0.0415 - val_loss: 87.2965 - val_keras_r2: -0.0467\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.8927 - keras_r2: -0.0329 - val_loss: 86.8273 - val_keras_r2: -0.0365\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.8190 - keras_r2: -0.0557 - val_loss: 87.4261 - val_keras_r2: -0.0496\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4839 - keras_r2: -0.0270 - val_loss: 86.1641 - val_keras_r2: -0.0312\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.4583 - keras_r2: -0.0092 - val_loss: 84.7922 - val_keras_r2: -0.0133\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.4235 - keras_r2: 0.0255 - val_loss: 80.4663 - val_keras_r2: 0.0439\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.0795 - keras_r2: 0.1128 - val_loss: 75.5778 - val_keras_r2: 0.1060\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4192 - keras_r2: 0.1621 - val_loss: 80.1049 - val_keras_r2: 0.0374\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6758 - keras_r2: 0.1784 - val_loss: 73.8425 - val_keras_r2: 0.1300\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2530 - keras_r2: 0.1894 - val_loss: 74.1502 - val_keras_r2: 0.1274\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9394 - keras_r2: 0.1905 - val_loss: 73.9790 - val_keras_r2: 0.1285\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7269 - keras_r2: 0.1866 - val_loss: 74.3488 - val_keras_r2: 0.1241\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3441 - keras_r2: 0.1937 - val_loss: 74.7831 - val_keras_r2: 0.1202\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.4425 - keras_r2: 0.1539 - val_loss: 82.1289 - val_keras_r2: 0.0093\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0986 - keras_r2: -746351.9375 - val_loss: 74.3252 - val_keras_r2: 0.1250\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8492 - keras_r2: -3466931.2500 - val_loss: 75.5065 - val_keras_r2: 0.1139\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.6114 - keras_r2: 0.2136 - val_loss: 75.3939 - val_keras_r2: 0.1059\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.3327 - keras_r2: 0.2022 - val_loss: 73.3690 - val_keras_r2: 0.1338\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0810 - keras_r2: 0.2109 - val_loss: 75.4595 - val_keras_r2: 0.1051\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7600 - keras_r2: -3312490.2500 - val_loss: 75.5914 - val_keras_r2: 0.1133\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3954 - keras_r2: 0.1635 - val_loss: 75.4578 - val_keras_r2: 0.1053\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.2218 - keras_r2: 0.2140 - val_loss: 84.8191 - val_keras_r2: -0.0305\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2717 - keras_r2: -0.1192 - val_loss: 113.7346 - val_keras_r2: -0.4294\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.0457 - keras_r2: 0.0038 - val_loss: 77.2287 - val_keras_r2: 0.0913\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5055 - keras_r2: 0.2326 - val_loss: 76.5809 - val_keras_r2: 0.0876\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4621 - keras_r2: 0.1758 - val_loss: 84.4204 - val_keras_r2: 0.0032\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1363 - keras_r2: 0.2226 - val_loss: 75.5517 - val_keras_r2: 0.1032\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9105 - keras_r2: 0.2325 - val_loss: 74.5983 - val_keras_r2: 0.1193\n",
            "Epoch 43: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=5, n_neurons=17; total time=  19.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 160.0238 - keras_r2: -1.0596 - val_loss: 83.8267 - val_keras_r2: -0.0349\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4755 - keras_r2: -0.0402 - val_loss: 84.4663 - val_keras_r2: -0.0512\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3360 - keras_r2: -0.0341 - val_loss: 84.6321 - val_keras_r2: -0.0537\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3050 - keras_r2: -0.0354 - val_loss: 83.2006 - val_keras_r2: -0.0298\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.4225 - keras_r2: -0.0468 - val_loss: 83.2403 - val_keras_r2: -0.0295\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3951 - keras_r2: -0.0394 - val_loss: 83.1925 - val_keras_r2: -0.0296\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2668 - keras_r2: -0.0510 - val_loss: 89.7045 - val_keras_r2: -0.1268\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3715 - keras_r2: -0.0346 - val_loss: 83.1852 - val_keras_r2: -0.0294\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3003 - keras_r2: -0.0377 - val_loss: 85.0946 - val_keras_r2: -0.0606\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2822 - keras_r2: -0.0347 - val_loss: 84.8468 - val_keras_r2: -0.0570\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2205 - keras_r2: -0.0383 - val_loss: 84.6712 - val_keras_r2: -0.0444\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3385 - keras_r2: -0.0675 - val_loss: 83.6408 - val_keras_r2: -0.0328\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3923 - keras_r2: -0.0551 - val_loss: 83.2861 - val_keras_r2: -0.0325\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.3554 - keras_r2: -0.0408 - val_loss: 83.1362 - val_keras_r2: -0.0293\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2789 - keras_r2: -0.0323 - val_loss: 83.1571 - val_keras_r2: -0.0284\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2714 - keras_r2: -0.0492 - val_loss: 83.2972 - val_keras_r2: -0.0329\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2132 - keras_r2: -0.0815 - val_loss: 83.4673 - val_keras_r2: -0.0308\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.2146 - keras_r2: -0.0342 - val_loss: 83.0480 - val_keras_r2: -0.0282\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.1681 - keras_r2: -0.0346 - val_loss: 87.9539 - val_keras_r2: -0.1022\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0863 - keras_r2: -0.1045 - val_loss: 84.3409 - val_keras_r2: -0.0499\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 85.0421 - keras_r2: -0.0588 - val_loss: 83.2726 - val_keras_r2: -0.0336\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.8194 - keras_r2: -0.0958 - val_loss: 83.3120 - val_keras_r2: -0.0283\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.6918 - keras_r2: -0.1044 - val_loss: 89.9729 - val_keras_r2: -0.1315\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4656 - keras_r2: -0.0297 - val_loss: 82.5194 - val_keras_r2: -0.0246\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.3690 - keras_r2: -0.0146 - val_loss: 81.7775 - val_keras_r2: -0.0165\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.8284 - keras_r2: 0.0100 - val_loss: 82.1512 - val_keras_r2: -0.0277\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.5010 - keras_r2: 0.1021 - val_loss: 70.0665 - val_keras_r2: 0.1348\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.6056 - keras_r2: 0.1737 - val_loss: 66.9747 - val_keras_r2: 0.1752\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.4037 - keras_r2: 0.1743 - val_loss: 67.4015 - val_keras_r2: 0.1661\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2315 - keras_r2: 0.1763 - val_loss: 69.9845 - val_keras_r2: 0.1275\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9134 - keras_r2: 0.1780 - val_loss: 67.0118 - val_keras_r2: 0.1700\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7033 - keras_r2: 0.1821 - val_loss: 66.2801 - val_keras_r2: 0.1808\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.6060 - keras_r2: 0.1271 - val_loss: 67.6241 - val_keras_r2: 0.1673\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2952 - keras_r2: 0.1962 - val_loss: 67.2325 - val_keras_r2: 0.1674\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.4096 - keras_r2: 0.1943 - val_loss: 66.4500 - val_keras_r2: 0.1795\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2242 - keras_r2: 0.1987 - val_loss: 66.7004 - val_keras_r2: 0.1729\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7576 - keras_r2: 0.2006 - val_loss: 66.1454 - val_keras_r2: 0.1839\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5384 - keras_r2: 0.2049 - val_loss: 67.4732 - val_keras_r2: 0.1610\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5463 - keras_r2: 0.1897 - val_loss: 68.1467 - val_keras_r2: 0.1609\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.2571 - keras_r2: 0.1873 - val_loss: 66.4242 - val_keras_r2: 0.1765\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9868 - keras_r2: 0.2070 - val_loss: 95.1847 - val_keras_r2: -0.2248\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.2209 - keras_r2: 0.1516 - val_loss: 66.0323 - val_keras_r2: 0.1848\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4612 - keras_r2: 0.1986 - val_loss: 72.3672 - val_keras_r2: 0.1085\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3012 - keras_r2: 0.2196 - val_loss: 66.2797 - val_keras_r2: 0.1780\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2662 - keras_r2: 0.2189 - val_loss: 66.7340 - val_keras_r2: 0.1781\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.8811 - keras_r2: 0.2211 - val_loss: 65.8089 - val_keras_r2: 0.1878\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7548 - keras_r2: -0.3604 - val_loss: 66.1377 - val_keras_r2: 0.1839\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5072 - keras_r2: 0.2216 - val_loss: 66.6196 - val_keras_r2: 0.1804\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.3087 - keras_r2: 0.2353 - val_loss: 68.2474 - val_keras_r2: 0.1591\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0136 - keras_r2: 0.2171 - val_loss: 113.4516 - val_keras_r2: -0.4728\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4810 - keras_r2: 0.2248 - val_loss: 66.3928 - val_keras_r2: 0.1773\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.9071 - keras_r2: 0.2288 - val_loss: 67.9822 - val_keras_r2: 0.1487\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.2314 - keras_r2: 0.2382 - val_loss: 65.4395 - val_keras_r2: 0.1928\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0076 - keras_r2: 0.2405 - val_loss: 66.2584 - val_keras_r2: 0.1746\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.7807 - keras_r2: 0.2406 - val_loss: 75.6852 - val_keras_r2: 0.0400\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.4023 - keras_r2: 0.2503 - val_loss: 75.8847 - val_keras_r2: 0.0382\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.1507 - keras_r2: 0.2582 - val_loss: 64.9844 - val_keras_r2: 0.1955\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.0851 - keras_r2: 0.2425 - val_loss: 70.6255 - val_keras_r2: 0.1278\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.6969 - keras_r2: 0.2568 - val_loss: 65.5653 - val_keras_r2: 0.1886\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.3480 - keras_r2: 0.2662 - val_loss: 66.1984 - val_keras_r2: 0.1719\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.0282 - keras_r2: 0.2382 - val_loss: 80.6104 - val_keras_r2: -0.0300\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.9360 - keras_r2: 0.2239 - val_loss: 65.0907 - val_keras_r2: 0.1933\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.3449 - keras_r2: 0.2756 - val_loss: 70.8389 - val_keras_r2: 0.1053\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.1467 - keras_r2: 0.2770 - val_loss: 64.9346 - val_keras_r2: 0.1949\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.8744 - keras_r2: 0.2793 - val_loss: 66.4956 - val_keras_r2: 0.1782\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.4533 - keras_r2: 0.2894 - val_loss: 72.7010 - val_keras_r2: 0.0785\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.4772 - keras_r2: 0.2623 - val_loss: 65.7743 - val_keras_r2: 0.1847\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.1336 - keras_r2: 0.2924 - val_loss: 65.2580 - val_keras_r2: 0.1880\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.0605 - keras_r2: 0.2892 - val_loss: 71.9694 - val_keras_r2: 0.0907\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.6498 - keras_r2: 0.2972 - val_loss: 66.6702 - val_keras_r2: 0.1742\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.4428 - keras_r2: 0.2225 - val_loss: 73.0424 - val_keras_r2: 0.0961\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.5422 - keras_r2: 0.2894 - val_loss: 66.7342 - val_keras_r2: 0.1747\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.9865 - keras_r2: 0.3089 - val_loss: 65.8837 - val_keras_r2: 0.1800\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.5422 - keras_r2: 0.3056 - val_loss: 66.6022 - val_keras_r2: 0.1778\n",
            "Epoch 74: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=5, n_neurons=17; total time=  32.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 948.2199 - keras_r2: -11.5580 - val_loss: 96.5923 - val_keras_r2: -0.1392\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.4679 - keras_r2: -0.0419 - val_loss: 94.9852 - val_keras_r2: -0.1273\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 83.1186 - keras_r2: -0.0208 - val_loss: 82.9394 - val_keras_r2: 2.5678e-04\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.6871 - keras_r2: -0.0217 - val_loss: 90.4532 - val_keras_r2: -0.0733\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.5957 - keras_r2: 0.0024 - val_loss: 83.7097 - val_keras_r2: 0.0022\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.8129 - keras_r2: 0.0073 - val_loss: 82.3016 - val_keras_r2: 0.0162\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.7662 - keras_r2: 0.0195 - val_loss: 84.0216 - val_keras_r2: -0.0013\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.6999 - keras_r2: 0.0276 - val_loss: 81.4620 - val_keras_r2: 0.0265\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.5227 - keras_r2: 0.0099 - val_loss: 82.7323 - val_keras_r2: -0.0028\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.6000 - keras_r2: -0.2072 - val_loss: 85.1126 - val_keras_r2: -0.0140\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.4573 - keras_r2: 0.0285 - val_loss: 82.5387 - val_keras_r2: 0.0171\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.3074 - keras_r2: 0.0412 - val_loss: 79.8105 - val_keras_r2: 0.0466\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.9319 - keras_r2: 0.0584 - val_loss: 80.1842 - val_keras_r2: 0.0346\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.5676 - keras_r2: 0.0605 - val_loss: 79.7446 - val_keras_r2: 0.0483\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.8960 - keras_r2: 0.0699 - val_loss: 80.0851 - val_keras_r2: 0.0457\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.5724 - keras_r2: 0.0512 - val_loss: 82.4018 - val_keras_r2: 0.0173\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.5490 - keras_r2: 0.0655 - val_loss: 80.5573 - val_keras_r2: 0.0411\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.0355 - keras_r2: 0.0666 - val_loss: 82.1978 - val_keras_r2: 0.0221\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.8789 - keras_r2: -1275744.5000 - val_loss: 79.2204 - val_keras_r2: 0.0542\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.7712 - keras_r2: 0.0281 - val_loss: 77.6387 - val_keras_r2: 0.0721\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.4972 - keras_r2: 0.0858 - val_loss: 79.2183 - val_keras_r2: 0.0603\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.6121 - keras_r2: 0.0579 - val_loss: 140.3530 - val_keras_r2: -0.7266\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.7815 - keras_r2: 0.0874 - val_loss: 86.0277 - val_keras_r2: -0.0401\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.5046 - keras_r2: -23952678.0000 - val_loss: 79.2033 - val_keras_r2: 0.0534\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.4315 - keras_r2: 0.0880 - val_loss: 84.5826 - val_keras_r2: -0.0056\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.8261 - keras_r2: 0.1026 - val_loss: 77.3332 - val_keras_r2: 0.0799\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.5397 - keras_r2: 0.0627 - val_loss: 81.7920 - val_keras_r2: 0.0107\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.0683 - keras_r2: 0.0706 - val_loss: 79.4341 - val_keras_r2: 0.0482\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.3596 - keras_r2: 0.0918 - val_loss: 78.3008 - val_keras_r2: 0.0654\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.1985 - keras_r2: 0.1034 - val_loss: 80.9405 - val_keras_r2: 0.0263\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.1269 - keras_r2: 0.0570 - val_loss: 78.0238 - val_keras_r2: 0.0687\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.3338 - keras_r2: 0.0572 - val_loss: 79.6142 - val_keras_r2: 0.0507\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.5488 - keras_r2: -1.2203 - val_loss: 81.7439 - val_keras_r2: 0.0279\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.3652 - keras_r2: -0.1072 - val_loss: 84.0552 - val_keras_r2: -0.0116\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.8164 - keras_r2: 0.0899 - val_loss: 78.8559 - val_keras_r2: 0.0548\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.3542 - keras_r2: 0.1000 - val_loss: 78.2796 - val_keras_r2: 0.0694\n",
            "Epoch 36: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=4, n_neurons=23; total time=  16.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 309.3384 - keras_r2: -3.0395 - val_loss: 87.5360 - val_keras_r2: -0.0662\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.5384 - keras_r2: 0.0375 - val_loss: 76.8763 - val_keras_r2: 0.0802\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.9066 - keras_r2: -0.1559 - val_loss: 81.4068 - val_keras_r2: 0.0163\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.4133 - keras_r2: 0.0805 - val_loss: 78.4791 - val_keras_r2: 0.0592\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5879 - keras_r2: -6.3756 - val_loss: 91.7360 - val_keras_r2: -0.1064\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.5362 - keras_r2: 0.1084 - val_loss: 82.5120 - val_keras_r2: -0.0023\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0478 - keras_r2: 0.1066 - val_loss: 78.5744 - val_keras_r2: 0.0585\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2946 - keras_r2: 0.0458 - val_loss: 75.8958 - val_keras_r2: 0.0943\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.3061 - keras_r2: 0.1046 - val_loss: 75.1234 - val_keras_r2: 0.0998\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.8116 - keras_r2: 0.1272 - val_loss: 74.0287 - val_keras_r2: 0.1143\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2900 - keras_r2: 0.1331 - val_loss: 75.5476 - val_keras_r2: 0.0963\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.3022 - keras_r2: 0.1405 - val_loss: 80.6865 - val_keras_r2: 0.0252\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.4700 - keras_r2: 0.1454 - val_loss: 76.7137 - val_keras_r2: 0.0874\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4171 - keras_r2: -0.1956 - val_loss: 75.5496 - val_keras_r2: 0.1011\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.3988 - keras_r2: 0.1635 - val_loss: 84.1001 - val_keras_r2: -0.0072\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.8801 - keras_r2: 0.1332 - val_loss: 88.3637 - val_keras_r2: -0.0629\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0328 - keras_r2: 0.1551 - val_loss: 74.0444 - val_keras_r2: 0.1172\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.4672 - keras_r2: 0.1658 - val_loss: 74.7425 - val_keras_r2: 0.1109\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8108 - keras_r2: 0.0611 - val_loss: 73.7085 - val_keras_r2: 0.1219\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5110 - keras_r2: 0.0420 - val_loss: 78.3600 - val_keras_r2: 0.0652\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0422 - keras_r2: 0.1932 - val_loss: 73.9569 - val_keras_r2: 0.1165\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.6193 - keras_r2: 0.1871 - val_loss: 75.6085 - val_keras_r2: 0.0901\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4473 - keras_r2: -0.4811 - val_loss: 72.3156 - val_keras_r2: 0.1372\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4246 - keras_r2: 0.1928 - val_loss: 71.9933 - val_keras_r2: 0.1408\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.7054 - keras_r2: -0.0014 - val_loss: 81.3687 - val_keras_r2: 0.0058\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3071 - keras_r2: 0.1880 - val_loss: 79.6212 - val_keras_r2: 0.0556\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.4012 - keras_r2: 0.2115 - val_loss: 72.6343 - val_keras_r2: 0.1341\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.1586 - keras_r2: -4.7477 - val_loss: 94.0841 - val_keras_r2: -0.1680\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.6346 - keras_r2: 0.1741 - val_loss: 85.3997 - val_keras_r2: -0.0292\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0460 - keras_r2: 0.2017 - val_loss: 74.0107 - val_keras_r2: 0.1088\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6898 - keras_r2: 0.2256 - val_loss: 75.7616 - val_keras_r2: 0.0895\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2581 - keras_r2: 0.2289 - val_loss: 75.4630 - val_keras_r2: 0.0958\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.4233 - keras_r2: 0.1972 - val_loss: 83.4292 - val_keras_r2: 0.0020\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5200 - keras_r2: -0.6862 - val_loss: 76.0725 - val_keras_r2: 0.0944\n",
            "Epoch 34: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=4, n_neurons=23; total time=  15.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 287.7478 - keras_r2: -2.7555 - val_loss: 509.0197 - val_keras_r2: -5.6772\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 103.4921 - keras_r2: -0.6573 - val_loss: 145.4503 - val_keras_r2: -0.7933\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 93.5020 - keras_r2: -0.1682 - val_loss: 183.8567 - val_keras_r2: -1.3687\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.3851 - keras_r2: -0.1281 - val_loss: 125.6609 - val_keras_r2: -0.5344\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.1964 - keras_r2: -0.0972 - val_loss: 92.2603 - val_keras_r2: -0.1253\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 86.6399 - keras_r2: -0.1197 - val_loss: 97.9214 - val_keras_r2: -0.2027\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.5598 - keras_r2: -0.0099 - val_loss: 113.1740 - val_keras_r2: -0.3758\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.2745 - keras_r2: -0.0211 - val_loss: 137.0994 - val_keras_r2: -0.7062\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.5574 - keras_r2: -0.3131 - val_loss: 86.7352 - val_keras_r2: -0.0385\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.9958 - keras_r2: 0.0726 - val_loss: 93.8046 - val_keras_r2: -0.1164\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.6859 - keras_r2: 0.1217 - val_loss: 134.0218 - val_keras_r2: -0.6374\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.9145 - keras_r2: 0.1018 - val_loss: 79.8238 - val_keras_r2: 0.0449\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.1533 - keras_r2: 0.1299 - val_loss: 84.0581 - val_keras_r2: -0.0200\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2527 - keras_r2: 0.1508 - val_loss: 87.3024 - val_keras_r2: -0.0544\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2335 - keras_r2: 0.1390 - val_loss: 79.8002 - val_keras_r2: 0.0413\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4448 - keras_r2: 0.0976 - val_loss: 80.1922 - val_keras_r2: 0.0413\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.7977 - keras_r2: -0.2404 - val_loss: 79.4169 - val_keras_r2: 0.0451\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.7596 - keras_r2: 0.1490 - val_loss: 84.4196 - val_keras_r2: -0.0062\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.0884 - keras_r2: 0.0463 - val_loss: 91.7321 - val_keras_r2: -0.1198\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.3886 - keras_r2: 0.1386 - val_loss: 75.3577 - val_keras_r2: 0.0981\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.6956 - keras_r2: 0.1453 - val_loss: 112.2124 - val_keras_r2: -0.3953\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.4205 - keras_r2: 0.1109 - val_loss: 78.0174 - val_keras_r2: 0.0678\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.3741 - keras_r2: 0.1408 - val_loss: 76.2497 - val_keras_r2: 0.0935\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2934 - keras_r2: 0.1318 - val_loss: 76.4043 - val_keras_r2: 0.0891\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.9898 - keras_r2: 0.1418 - val_loss: 76.2895 - val_keras_r2: 0.0927\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4796 - keras_r2: 0.1211 - val_loss: 79.4428 - val_keras_r2: 0.0467\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.6962 - keras_r2: 0.1610 - val_loss: 76.0083 - val_keras_r2: 0.0897\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.5298 - keras_r2: 0.1682 - val_loss: 75.4059 - val_keras_r2: 0.1005\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.7804 - keras_r2: 0.1689 - val_loss: 75.4705 - val_keras_r2: 0.0918\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.5163 - keras_r2: 0.1437 - val_loss: 78.4015 - val_keras_r2: 0.0528\n",
            "Epoch 30: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=4, n_neurons=23; total time=  14.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 6ms/step - loss: 316.0764 - keras_r2: -3.0007 - val_loss: 94.4964 - val_keras_r2: -0.1380\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.7755 - keras_r2: -0.0102 - val_loss: 82.2066 - val_keras_r2: 0.0179\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.9349 - keras_r2: -1153556.5000 - val_loss: 82.4930 - val_keras_r2: 0.0113\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5717 - keras_r2: 0.0876 - val_loss: 85.2122 - val_keras_r2: -0.0191\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1604 - keras_r2: 0.1624 - val_loss: 76.2471 - val_keras_r2: 0.0965\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2889 - keras_r2: 0.1345 - val_loss: 88.1386 - val_keras_r2: -0.0523\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.7072 - keras_r2: -0.0264 - val_loss: 95.2339 - val_keras_r2: -0.1746\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0854 - keras_r2: 0.2020 - val_loss: 80.9854 - val_keras_r2: 0.0413\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6528 - keras_r2: 0.2152 - val_loss: 84.7109 - val_keras_r2: -0.0042\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.4632 - keras_r2: 0.2232 - val_loss: 84.9292 - val_keras_r2: -0.0173\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.1394 - keras_r2: -0.2214 - val_loss: 80.2312 - val_keras_r2: 0.0552\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.3924 - keras_r2: 0.2161 - val_loss: 76.8431 - val_keras_r2: 0.0912\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2072 - keras_r2: 0.2259 - val_loss: 80.0404 - val_keras_r2: 0.0510\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.0530 - keras_r2: 0.2189 - val_loss: 100.1176 - val_keras_r2: -0.2361\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.5941 - keras_r2: 0.2379 - val_loss: 80.6061 - val_keras_r2: 0.0381\n",
            "Epoch 15: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=4, n_neurons=23; total time=   7.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 205.3560 - keras_r2: -1.6342 - val_loss: 76.1377 - val_keras_r2: 0.0554\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.0237 - keras_r2: 0.1420 - val_loss: 75.7076 - val_keras_r2: 0.0581\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0919 - keras_r2: 0.1701 - val_loss: 70.8054 - val_keras_r2: 0.1196\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2566 - keras_r2: 0.1858 - val_loss: 86.1894 - val_keras_r2: -0.0756\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.2117 - keras_r2: 0.2083 - val_loss: 65.9003 - val_keras_r2: 0.1817\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4614 - keras_r2: 0.2180 - val_loss: 68.7682 - val_keras_r2: 0.1478\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9505 - keras_r2: 0.2158 - val_loss: 65.5405 - val_keras_r2: 0.1909\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9194 - keras_r2: 0.2334 - val_loss: 64.7751 - val_keras_r2: 0.1998\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.5765 - keras_r2: 0.2423 - val_loss: 67.8960 - val_keras_r2: 0.1675\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.9748 - keras_r2: 0.2385 - val_loss: 65.2096 - val_keras_r2: 0.1923\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5966 - keras_r2: 0.2119 - val_loss: 103.8335 - val_keras_r2: -0.3340\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.3509 - keras_r2: 0.2430 - val_loss: 66.3096 - val_keras_r2: 0.1859\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.6357 - keras_r2: 0.2497 - val_loss: 106.8491 - val_keras_r2: -0.3714\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.8346 - keras_r2: 0.2545 - val_loss: 109.1931 - val_keras_r2: -0.4040\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0530 - keras_r2: 0.1924 - val_loss: 67.2867 - val_keras_r2: 0.1607\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.5745 - keras_r2: 0.2209 - val_loss: 73.9838 - val_keras_r2: 0.0946\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1142 - keras_r2: 0.2433 - val_loss: 68.2929 - val_keras_r2: 0.1422\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.9639 - keras_r2: 0.2556 - val_loss: 67.1988 - val_keras_r2: 0.1729\n",
            "Epoch 18: early stopping\n",
            "[CV] END ...........activation=elu, n_hidden=4, n_neurons=23; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1186.0916 - keras_r2: -14.8034 - val_loss: 76.2505 - val_keras_r2: 0.1029\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7294 - keras_r2: 0.1214 - val_loss: 83.2716 - val_keras_r2: -2.9881e-05\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3710 - keras_r2: 0.1756 - val_loss: 75.3746 - val_keras_r2: 0.1119\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2847 - keras_r2: 0.1876 - val_loss: 75.8201 - val_keras_r2: 0.1074\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2368 - keras_r2: 0.1895 - val_loss: 75.5525 - val_keras_r2: 0.1072\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0287 - keras_r2: 0.1839 - val_loss: 75.9151 - val_keras_r2: 0.1106\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5838 - keras_r2: 0.2060 - val_loss: 74.7726 - val_keras_r2: 0.1182\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1404 - keras_r2: 0.1873 - val_loss: 74.3805 - val_keras_r2: 0.1237\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8289 - keras_r2: 0.2113 - val_loss: 74.8681 - val_keras_r2: 0.1183\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4708 - keras_r2: 0.2142 - val_loss: 75.1500 - val_keras_r2: 0.1164\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.0233 - keras_r2: 0.1998 - val_loss: 75.2450 - val_keras_r2: 0.1140\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9236 - keras_r2: 0.2207 - val_loss: 73.9305 - val_keras_r2: 0.1226\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6040 - keras_r2: 0.2129 - val_loss: 73.8504 - val_keras_r2: 0.1284\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9884 - keras_r2: 0.1995 - val_loss: 72.4105 - val_keras_r2: 0.1415\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9129 - keras_r2: 0.2268 - val_loss: 73.4734 - val_keras_r2: 0.1324\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.4274 - keras_r2: 0.2264 - val_loss: 73.0936 - val_keras_r2: 0.1384\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0576 - keras_r2: -0.0157 - val_loss: 78.1839 - val_keras_r2: 0.0631\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.8759 - keras_r2: 0.0966 - val_loss: 75.3140 - val_keras_r2: 0.1103\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.6129 - keras_r2: 0.2446 - val_loss: 73.8145 - val_keras_r2: 0.1286\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.2250 - keras_r2: 0.2483 - val_loss: 73.3159 - val_keras_r2: 0.1287\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.8896 - keras_r2: 0.2404 - val_loss: 73.5281 - val_keras_r2: 0.1245\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.6311 - keras_r2: 0.2362 - val_loss: 74.1940 - val_keras_r2: 0.1209\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.3643 - keras_r2: 0.2577 - val_loss: 72.8789 - val_keras_r2: 0.1390\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.0568 - keras_r2: 0.2595 - val_loss: 73.5548 - val_keras_r2: 0.1314\n",
            "Epoch 24: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=1, n_neurons=67; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 142.5184 - keras_r2: -0.8061 - val_loss: 74.1268 - val_keras_r2: 0.1235\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.0978 - keras_r2: 0.1501 - val_loss: 74.6523 - val_keras_r2: 0.1036\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6754 - keras_r2: 0.1544 - val_loss: 74.3820 - val_keras_r2: 0.1136\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3777 - keras_r2: 0.1693 - val_loss: 74.1413 - val_keras_r2: 0.1198\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8115 - keras_r2: 0.1786 - val_loss: 73.9765 - val_keras_r2: 0.1170\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5724 - keras_r2: 0.1922 - val_loss: 73.3071 - val_keras_r2: 0.1273\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2565 - keras_r2: 0.1842 - val_loss: 73.1188 - val_keras_r2: 0.1260\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9798 - keras_r2: 0.1885 - val_loss: 72.8757 - val_keras_r2: 0.1291\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8138 - keras_r2: 0.1231 - val_loss: 76.5732 - val_keras_r2: 0.0667\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3418 - keras_r2: 0.1848 - val_loss: 73.1689 - val_keras_r2: 0.1252\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8347 - keras_r2: -5722428.5000 - val_loss: 72.5671 - val_keras_r2: 0.1368\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0832 - keras_r2: 0.1959 - val_loss: 71.8523 - val_keras_r2: 0.1434\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4809 - keras_r2: -0.5101 - val_loss: 74.1231 - val_keras_r2: 0.1119\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.0601 - keras_r2: 0.1864 - val_loss: 74.8317 - val_keras_r2: 0.1072\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9299 - keras_r2: 0.2259 - val_loss: 72.4845 - val_keras_r2: 0.1344\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5331 - keras_r2: 0.2337 - val_loss: 72.6395 - val_keras_r2: 0.1311\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.3253 - keras_r2: 0.2158 - val_loss: 71.9998 - val_keras_r2: 0.1385\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.9873 - keras_r2: 0.1905 - val_loss: 72.5768 - val_keras_r2: 0.1344\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.6250 - keras_r2: 0.2226 - val_loss: 72.9932 - val_keras_r2: 0.1210\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1736 - keras_r2: 0.2283 - val_loss: 72.2134 - val_keras_r2: 0.1348\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.0322 - keras_r2: -2512602.2500 - val_loss: 71.4352 - val_keras_r2: 0.1466\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.4921 - keras_r2: 0.2490 - val_loss: 71.6466 - val_keras_r2: 0.1467\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.2970 - keras_r2: 0.2461 - val_loss: 72.3644 - val_keras_r2: 0.1356\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.9833 - keras_r2: 0.2126 - val_loss: 72.0874 - val_keras_r2: 0.1376\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.7072 - keras_r2: 0.2589 - val_loss: 71.7766 - val_keras_r2: 0.1446\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.3508 - keras_r2: 0.2626 - val_loss: 72.3946 - val_keras_r2: 0.1334\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.3539 - keras_r2: 0.2537 - val_loss: 72.4750 - val_keras_r2: 0.1373\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.8644 - keras_r2: 0.2560 - val_loss: 71.5622 - val_keras_r2: 0.1432\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.6591 - keras_r2: 0.2701 - val_loss: 71.4637 - val_keras_r2: 0.1445\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.2666 - keras_r2: 0.2691 - val_loss: 72.3414 - val_keras_r2: 0.1366\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 59.0672 - keras_r2: 0.2807 - val_loss: 71.0072 - val_keras_r2: 0.1512\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.8777 - keras_r2: 0.2798 - val_loss: 71.1780 - val_keras_r2: 0.1489\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.6333 - keras_r2: 0.2121 - val_loss: 72.2850 - val_keras_r2: 0.1377\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.3866 - keras_r2: 0.2876 - val_loss: 72.0663 - val_keras_r2: 0.1402\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.1153 - keras_r2: -1003814.0000 - val_loss: 72.2097 - val_keras_r2: 0.1323\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.8471 - keras_r2: 0.2831 - val_loss: 75.7040 - val_keras_r2: 0.0816\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.2145 - keras_r2: 0.2878 - val_loss: 70.9676 - val_keras_r2: 0.1490\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.4972 - keras_r2: 0.0337 - val_loss: 72.0947 - val_keras_r2: 0.1414\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.3084 - keras_r2: 0.2965 - val_loss: 71.0998 - val_keras_r2: 0.1521\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.0517 - keras_r2: 0.2975 - val_loss: 71.0164 - val_keras_r2: 0.1509\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.7695 - keras_r2: 0.3024 - val_loss: 72.2519 - val_keras_r2: 0.1323\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.6908 - keras_r2: 0.3135 - val_loss: 71.5831 - val_keras_r2: 0.1478\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.5176 - keras_r2: -1.1950 - val_loss: 71.7618 - val_keras_r2: 0.1420\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.3229 - keras_r2: 0.2887 - val_loss: 71.2806 - val_keras_r2: 0.1482\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.0539 - keras_r2: 0.3092 - val_loss: 71.2168 - val_keras_r2: 0.1480\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.8825 - keras_r2: -1919482.0000 - val_loss: 70.7924 - val_keras_r2: 0.1532\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.7243 - keras_r2: 0.3226 - val_loss: 71.4985 - val_keras_r2: 0.1426\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.5664 - keras_r2: 0.3205 - val_loss: 70.9594 - val_keras_r2: 0.1520\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.3637 - keras_r2: 0.3095 - val_loss: 72.4746 - val_keras_r2: 0.1250\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.2945 - keras_r2: 0.3238 - val_loss: 71.1019 - val_keras_r2: 0.1509\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.9438 - keras_r2: 0.2305 - val_loss: 71.4525 - val_keras_r2: 0.1469\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.8468 - keras_r2: 0.2746 - val_loss: 73.9099 - val_keras_r2: 0.1185\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.7400 - keras_r2: 0.3305 - val_loss: 71.3969 - val_keras_r2: 0.1451\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.5819 - keras_r2: 0.3239 - val_loss: 71.1047 - val_keras_r2: 0.1514\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.4247 - keras_r2: 0.3143 - val_loss: 71.3553 - val_keras_r2: 0.1480\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.2181 - keras_r2: 0.3357 - val_loss: 71.1968 - val_keras_r2: 0.1495\n",
            "Epoch 56: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=1, n_neurons=67; total time=  24.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 179.4748 - keras_r2: -1.1583 - val_loss: 74.6379 - val_keras_r2: 0.1198\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2204 - keras_r2: 0.1867 - val_loss: 75.2231 - val_keras_r2: 0.1081\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9311 - keras_r2: 0.1685 - val_loss: 77.5445 - val_keras_r2: 0.0865\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8487 - keras_r2: 0.1822 - val_loss: 73.8883 - val_keras_r2: 0.1304\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2781 - keras_r2: 0.1901 - val_loss: 74.6717 - val_keras_r2: 0.1218\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1026 - keras_r2: 0.1962 - val_loss: 74.1175 - val_keras_r2: 0.1282\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.6982 - keras_r2: 0.1920 - val_loss: 75.4216 - val_keras_r2: 0.1114\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3892 - keras_r2: 0.1497 - val_loss: 74.6272 - val_keras_r2: 0.1224\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9448 - keras_r2: 0.2054 - val_loss: 73.7609 - val_keras_r2: 0.1338\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6551 - keras_r2: 0.1469 - val_loss: 73.5434 - val_keras_r2: 0.1357\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3858 - keras_r2: 0.2124 - val_loss: 73.8815 - val_keras_r2: 0.1289\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9804 - keras_r2: 0.2266 - val_loss: 72.9277 - val_keras_r2: 0.1411\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6360 - keras_r2: 0.2232 - val_loss: 74.1990 - val_keras_r2: 0.1299\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2371 - keras_r2: 0.2337 - val_loss: 75.6052 - val_keras_r2: 0.1116\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1360 - keras_r2: -12257344.0000 - val_loss: 74.3238 - val_keras_r2: 0.1296\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.6911 - keras_r2: -0.0856 - val_loss: 73.7066 - val_keras_r2: 0.1346\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.3194 - keras_r2: 0.2352 - val_loss: 74.1323 - val_keras_r2: 0.1273\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1352 - keras_r2: 0.2503 - val_loss: 73.9798 - val_keras_r2: 0.1298\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.8347 - keras_r2: -0.5902 - val_loss: 73.1784 - val_keras_r2: 0.1404\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.4115 - keras_r2: 0.2552 - val_loss: 72.7098 - val_keras_r2: 0.1440\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.0602 - keras_r2: 0.2578 - val_loss: 73.7196 - val_keras_r2: 0.1344\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.8954 - keras_r2: 0.2502 - val_loss: 72.5527 - val_keras_r2: 0.1443\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.5900 - keras_r2: 0.2676 - val_loss: 72.5055 - val_keras_r2: 0.1495\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.1111 - keras_r2: 0.2095 - val_loss: 73.3964 - val_keras_r2: 0.1368\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.8731 - keras_r2: 0.2856 - val_loss: 72.6723 - val_keras_r2: 0.1444\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.6910 - keras_r2: 0.2596 - val_loss: 72.3909 - val_keras_r2: 0.1486\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.4150 - keras_r2: 0.2793 - val_loss: 73.5277 - val_keras_r2: 0.1358\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.1102 - keras_r2: 0.2870 - val_loss: 74.8619 - val_keras_r2: 0.1204\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.8758 - keras_r2: 0.2834 - val_loss: 72.4383 - val_keras_r2: 0.1482\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.6296 - keras_r2: 0.2642 - val_loss: 72.8158 - val_keras_r2: 0.1444\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.4872 - keras_r2: 0.2814 - val_loss: 74.0344 - val_keras_r2: 0.1283\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.2921 - keras_r2: 0.2937 - val_loss: 73.5200 - val_keras_r2: 0.1367\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.9720 - keras_r2: 0.2956 - val_loss: 72.8024 - val_keras_r2: 0.1445\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.6493 - keras_r2: 0.3078 - val_loss: 72.2565 - val_keras_r2: 0.1467\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.4785 - keras_r2: 0.3048 - val_loss: 72.2651 - val_keras_r2: 0.1497\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.1587 - keras_r2: 0.3027 - val_loss: 72.2723 - val_keras_r2: 0.1470\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.0456 - keras_r2: 0.2723 - val_loss: 74.4313 - val_keras_r2: 0.1285\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.8314 - keras_r2: 0.0873 - val_loss: 72.4130 - val_keras_r2: 0.1425\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.7466 - keras_r2: 0.3127 - val_loss: 73.0893 - val_keras_r2: 0.1362\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.4015 - keras_r2: 0.3077 - val_loss: 72.9981 - val_keras_r2: 0.1401\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.2144 - keras_r2: 0.3183 - val_loss: 73.8025 - val_keras_r2: 0.1237\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.9535 - keras_r2: 0.3301 - val_loss: 72.3579 - val_keras_r2: 0.1493\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.7609 - keras_r2: 0.3161 - val_loss: 72.5997 - val_keras_r2: 0.1496\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.6145 - keras_r2: 0.3108 - val_loss: 74.4742 - val_keras_r2: 0.1171\n",
            "Epoch 44: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=1, n_neurons=67; total time=  19.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 174.7780 - keras_r2: -1.0782 - val_loss: 74.7307 - val_keras_r2: 0.1218\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2150 - keras_r2: 0.1747 - val_loss: 75.0444 - val_keras_r2: 0.1137\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7195 - keras_r2: 0.1642 - val_loss: 75.0969 - val_keras_r2: 0.1106\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5453 - keras_r2: 0.1857 - val_loss: 79.9476 - val_keras_r2: 0.0525\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7799 - keras_r2: 0.1792 - val_loss: 76.5670 - val_keras_r2: 0.1035\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0739 - keras_r2: 0.1862 - val_loss: 75.4504 - val_keras_r2: 0.1168\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4743 - keras_r2: 0.1830 - val_loss: 99.4977 - val_keras_r2: -0.2403\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6247 - keras_r2: 0.1643 - val_loss: 75.7703 - val_keras_r2: 0.1005\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8517 - keras_r2: 0.1989 - val_loss: 73.8720 - val_keras_r2: 0.1259\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4272 - keras_r2: 0.2099 - val_loss: 73.8312 - val_keras_r2: 0.1253\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.1688 - keras_r2: 0.2085 - val_loss: 74.4367 - val_keras_r2: 0.1234\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.6852 - keras_r2: -145640.5625 - val_loss: 74.6428 - val_keras_r2: 0.1207\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.4381 - keras_r2: 0.2276 - val_loss: 73.5320 - val_keras_r2: 0.1332\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0866 - keras_r2: 0.1827 - val_loss: 73.6216 - val_keras_r2: 0.1260\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.8159 - keras_r2: 0.2449 - val_loss: 74.5935 - val_keras_r2: 0.1243\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.3566 - keras_r2: 0.2460 - val_loss: 74.2487 - val_keras_r2: 0.1252\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.1139 - keras_r2: 0.2423 - val_loss: 73.3417 - val_keras_r2: 0.1354\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.6731 - keras_r2: 0.2513 - val_loss: 74.2229 - val_keras_r2: 0.1258\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.5494 - keras_r2: 0.2390 - val_loss: 74.0411 - val_keras_r2: 0.1292\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.3338 - keras_r2: -2.0545 - val_loss: 77.2642 - val_keras_r2: 0.0939\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.1263 - keras_r2: 0.2114 - val_loss: 74.6012 - val_keras_r2: 0.1223\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.7450 - keras_r2: 0.2502 - val_loss: 73.4299 - val_keras_r2: 0.1331\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.4507 - keras_r2: 0.2610 - val_loss: 73.8699 - val_keras_r2: 0.1302\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.1168 - keras_r2: 0.2457 - val_loss: 75.7701 - val_keras_r2: 0.1076\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.9222 - keras_r2: 0.2760 - val_loss: 73.1276 - val_keras_r2: 0.1392\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.4808 - keras_r2: 0.2821 - val_loss: 73.0165 - val_keras_r2: 0.1358\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.2421 - keras_r2: 0.2743 - val_loss: 72.5965 - val_keras_r2: 0.1447\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.0210 - keras_r2: -0.0376 - val_loss: 76.0601 - val_keras_r2: 0.1023\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.0073 - keras_r2: -3.6727 - val_loss: 75.7744 - val_keras_r2: 0.1133\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.6338 - keras_r2: 0.2518 - val_loss: 73.1886 - val_keras_r2: 0.1395\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.2062 - keras_r2: 0.2943 - val_loss: 72.7221 - val_keras_r2: 0.1403\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.1295 - keras_r2: 0.0992 - val_loss: 73.2808 - val_keras_r2: 0.1377\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.8435 - keras_r2: 0.2838 - val_loss: 73.4906 - val_keras_r2: 0.1345\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.6891 - keras_r2: 0.2992 - val_loss: 73.4598 - val_keras_r2: 0.1368\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.4328 - keras_r2: 0.3043 - val_loss: 74.0490 - val_keras_r2: 0.1303\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.1067 - keras_r2: 0.3008 - val_loss: 72.8954 - val_keras_r2: 0.1370\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.0412 - keras_r2: 0.3066 - val_loss: 72.5507 - val_keras_r2: 0.1419\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 56.7463 - keras_r2: 0.2944 - val_loss: 73.1055 - val_keras_r2: 0.1294\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.5777 - keras_r2: 0.3091 - val_loss: 73.0916 - val_keras_r2: 0.1381\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.4740 - keras_r2: 0.2012 - val_loss: 72.8671 - val_keras_r2: 0.1414\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.1007 - keras_r2: 0.3304 - val_loss: 72.6338 - val_keras_r2: 0.1412\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.0736 - keras_r2: 0.3223 - val_loss: 73.0053 - val_keras_r2: 0.1362\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.8793 - keras_r2: 0.3199 - val_loss: 72.5792 - val_keras_r2: 0.1438\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.5336 - keras_r2: 0.3221 - val_loss: 72.5052 - val_keras_r2: 0.1432\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.4869 - keras_r2: 0.3056 - val_loss: 74.3231 - val_keras_r2: 0.1242\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.3757 - keras_r2: 0.1896 - val_loss: 72.4321 - val_keras_r2: 0.1428\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.1073 - keras_r2: 0.3262 - val_loss: 72.0312 - val_keras_r2: 0.1474\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.0472 - keras_r2: 0.3270 - val_loss: 72.5716 - val_keras_r2: 0.1423\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.8770 - keras_r2: 0.3159 - val_loss: 73.0345 - val_keras_r2: 0.1399\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.6112 - keras_r2: 0.3102 - val_loss: 72.1430 - val_keras_r2: 0.1453\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.5282 - keras_r2: 0.3363 - val_loss: 73.1068 - val_keras_r2: 0.1365\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.4087 - keras_r2: 0.3260 - val_loss: 72.6032 - val_keras_r2: 0.1391\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.2508 - keras_r2: 0.3276 - val_loss: 72.5611 - val_keras_r2: 0.1416\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.1117 - keras_r2: 0.3510 - val_loss: 72.3524 - val_keras_r2: 0.1440\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.9635 - keras_r2: 0.1733 - val_loss: 73.5932 - val_keras_r2: 0.1298\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 53.7825 - keras_r2: 0.3389 - val_loss: 73.0124 - val_keras_r2: 0.1376\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.6311 - keras_r2: 0.3333 - val_loss: 72.6800 - val_keras_r2: 0.1411\n",
            "Epoch 57: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=1, n_neurons=67; total time=  41.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 114.2218 - keras_r2: -0.4606 - val_loss: 66.7827 - val_keras_r2: 0.1718\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.4204 - keras_r2: 0.1826 - val_loss: 69.8945 - val_keras_r2: 0.1247\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.3262 - keras_r2: 0.1876 - val_loss: 66.9250 - val_keras_r2: 0.1681\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.6412 - keras_r2: 0.1905 - val_loss: 67.3941 - val_keras_r2: 0.1589\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.6734 - keras_r2: 0.1683 - val_loss: 66.5124 - val_keras_r2: 0.1748\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3491 - keras_r2: 0.1884 - val_loss: 67.0805 - val_keras_r2: 0.1644\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9327 - keras_r2: 0.1038 - val_loss: 65.7255 - val_keras_r2: 0.1835\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.7634 - keras_r2: 0.1940 - val_loss: 67.8980 - val_keras_r2: 0.1495\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.5658 - keras_r2: 0.1376 - val_loss: 65.8150 - val_keras_r2: 0.1819\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1028 - keras_r2: 0.2117 - val_loss: 65.7312 - val_keras_r2: 0.1816\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7324 - keras_r2: 0.1841 - val_loss: 66.6627 - val_keras_r2: 0.1678\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3077 - keras_r2: 0.2160 - val_loss: 65.1230 - val_keras_r2: 0.1926\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.1564 - keras_r2: 0.1072 - val_loss: 65.2811 - val_keras_r2: 0.1877\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.7561 - keras_r2: 0.2150 - val_loss: 65.8231 - val_keras_r2: 0.1819\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.3372 - keras_r2: 0.2103 - val_loss: 64.8513 - val_keras_r2: 0.1913\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.0657 - keras_r2: 0.1849 - val_loss: 65.9587 - val_keras_r2: 0.1821\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.7293 - keras_r2: 0.2388 - val_loss: 65.3082 - val_keras_r2: 0.1855\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.5063 - keras_r2: 0.2478 - val_loss: 65.1267 - val_keras_r2: 0.1897\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.8525 - keras_r2: 0.2317 - val_loss: 65.5574 - val_keras_r2: 0.1867\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.9510 - keras_r2: 0.2311 - val_loss: 66.2272 - val_keras_r2: 0.1783\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.3804 - keras_r2: 0.2394 - val_loss: 65.5210 - val_keras_r2: 0.1881\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 61.1397 - keras_r2: 0.2467 - val_loss: 66.0675 - val_keras_r2: 0.1750\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.9887 - keras_r2: 0.2523 - val_loss: 64.2006 - val_keras_r2: 0.2036\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.5268 - keras_r2: 0.2477 - val_loss: 65.2689 - val_keras_r2: 0.1899\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.1749 - keras_r2: 0.2419 - val_loss: 75.9065 - val_keras_r2: 0.0449\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 60.6969 - keras_r2: 0.2398 - val_loss: 64.2726 - val_keras_r2: 0.2043\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.6956 - keras_r2: 0.2320 - val_loss: 63.8545 - val_keras_r2: 0.2069\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 59.4642 - keras_r2: 0.2749 - val_loss: 64.7586 - val_keras_r2: 0.1978\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.1823 - keras_r2: 0.2799 - val_loss: 66.0379 - val_keras_r2: 0.1739\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.9750 - keras_r2: 0.2850 - val_loss: 64.5672 - val_keras_r2: 0.1972\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.6825 - keras_r2: 0.2865 - val_loss: 64.0893 - val_keras_r2: 0.2031\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.3287 - keras_r2: 0.2924 - val_loss: 64.0830 - val_keras_r2: 0.2031\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.1810 - keras_r2: 0.2970 - val_loss: 63.7670 - val_keras_r2: 0.2081\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 58.0025 - keras_r2: 0.2953 - val_loss: 64.1850 - val_keras_r2: 0.2001\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.6621 - keras_r2: 0.2902 - val_loss: 64.1152 - val_keras_r2: 0.2037\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.5039 - keras_r2: 0.2948 - val_loss: 64.2443 - val_keras_r2: 0.2015\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.3559 - keras_r2: 0.3011 - val_loss: 63.7993 - val_keras_r2: 0.2075\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 57.1060 - keras_r2: 0.2841 - val_loss: 63.6618 - val_keras_r2: 0.2091\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.7823 - keras_r2: 0.3045 - val_loss: 63.5425 - val_keras_r2: 0.2092\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.7027 - keras_r2: 0.3109 - val_loss: 63.8029 - val_keras_r2: 0.2086\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.5457 - keras_r2: 0.3137 - val_loss: 63.3367 - val_keras_r2: 0.2133\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.3507 - keras_r2: 0.2398 - val_loss: 63.9069 - val_keras_r2: 0.2072\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 56.1695 - keras_r2: 0.3194 - val_loss: 63.4955 - val_keras_r2: 0.2113\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.9553 - keras_r2: 0.3152 - val_loss: 64.8116 - val_keras_r2: 0.1909\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.8493 - keras_r2: 0.3246 - val_loss: 63.3269 - val_keras_r2: 0.2144\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.6253 - keras_r2: 0.3269 - val_loss: 63.7344 - val_keras_r2: 0.2067\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.4505 - keras_r2: 0.3228 - val_loss: 63.5812 - val_keras_r2: 0.2082\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.1122 - keras_r2: 0.3296 - val_loss: 63.6326 - val_keras_r2: 0.2101\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.1153 - keras_r2: 0.3331 - val_loss: 64.2205 - val_keras_r2: 0.2010\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 55.0034 - keras_r2: 0.3322 - val_loss: 63.4361 - val_keras_r2: 0.2117\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.7187 - keras_r2: 0.3373 - val_loss: 63.2310 - val_keras_r2: 0.2128\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.6491 - keras_r2: 0.3434 - val_loss: 63.2435 - val_keras_r2: 0.2151\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.5104 - keras_r2: 0.3345 - val_loss: 64.4394 - val_keras_r2: 0.1982\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.4147 - keras_r2: 0.3401 - val_loss: 64.0640 - val_keras_r2: 0.2038\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.2344 - keras_r2: 0.3260 - val_loss: 63.7463 - val_keras_r2: 0.2126\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 54.0561 - keras_r2: 0.3369 - val_loss: 63.4520 - val_keras_r2: 0.2125\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.9313 - keras_r2: 0.3462 - val_loss: 63.6245 - val_keras_r2: 0.2096\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.8044 - keras_r2: 0.3447 - val_loss: 63.1255 - val_keras_r2: 0.2171\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.6448 - keras_r2: 0.3164 - val_loss: 63.5263 - val_keras_r2: 0.2090\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.5123 - keras_r2: 0.3493 - val_loss: 64.0648 - val_keras_r2: 0.2009\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.4203 - keras_r2: 0.3507 - val_loss: 64.0333 - val_keras_r2: 0.2029\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.3335 - keras_r2: 0.3483 - val_loss: 63.6872 - val_keras_r2: 0.2077\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 53.1299 - keras_r2: 0.3524 - val_loss: 63.5880 - val_keras_r2: 0.2106\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 52.9819 - keras_r2: 0.3475 - val_loss: 63.1521 - val_keras_r2: 0.2171\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 52.8684 - keras_r2: 0.3503 - val_loss: 63.9535 - val_keras_r2: 0.2069\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 52.8351 - keras_r2: 0.3550 - val_loss: 63.6729 - val_keras_r2: 0.2057\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 52.6623 - keras_r2: 0.3149 - val_loss: 63.9881 - val_keras_r2: 0.2067\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 52.4682 - keras_r2: 0.3669 - val_loss: 63.0560 - val_keras_r2: 0.2167\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 52.4104 - keras_r2: 0.3622 - val_loss: 63.4213 - val_keras_r2: 0.2125\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 52.2701 - keras_r2: 0.3578 - val_loss: 63.4573 - val_keras_r2: 0.2090\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 52.1476 - keras_r2: 0.3360 - val_loss: 63.5742 - val_keras_r2: 0.2078\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 51.9339 - keras_r2: 0.3701 - val_loss: 63.3628 - val_keras_r2: 0.2126\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 51.9512 - keras_r2: 0.3617 - val_loss: 64.0728 - val_keras_r2: 0.2004\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 51.8466 - keras_r2: 0.3628 - val_loss: 63.9147 - val_keras_r2: 0.2024\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 51.6942 - keras_r2: 0.3713 - val_loss: 63.6666 - val_keras_r2: 0.2090\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 51.6834 - keras_r2: 0.3731 - val_loss: 63.4618 - val_keras_r2: 0.2107\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 51.5060 - keras_r2: 0.3510 - val_loss: 63.2407 - val_keras_r2: 0.2127\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 51.4045 - keras_r2: 0.3744 - val_loss: 63.2170 - val_keras_r2: 0.2132\n",
            "Epoch 78: early stopping\n",
            "[CV] END .......activation=sigmoid, n_hidden=1, n_neurons=67; total time=  41.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1049.1304 - keras_r2: -13.0783 - val_loss: 1016.3597 - val_keras_r2: -12.4524\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 951.7498 - keras_r2: -12.1244 - val_loss: 854.8667 - val_keras_r2: -10.3200\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 829.1223 - keras_r2: -10.0638 - val_loss: 821.4258 - val_keras_r2: -9.9105\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 806.6666 - keras_r2: -9.5072 - val_loss: 745.5826 - val_keras_r2: -8.9222\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 687.5536 - keras_r2: -8.0147 - val_loss: 625.2472 - val_keras_r2: -7.2227\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 601.0412 - keras_r2: -6.9436 - val_loss: 790.3025 - val_keras_r2: -9.4704\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 572.7904 - keras_r2: -6.5378 - val_loss: 592.5433 - val_keras_r2: -6.8166\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 590.9049 - keras_r2: -6.7466 - val_loss: 593.4534 - val_keras_r2: -6.8123\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 560.5098 - keras_r2: -6.2589 - val_loss: 885.4528 - val_keras_r2: -10.7043\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 690.1997 - keras_r2: -700755.3750 - val_loss: 585.1488 - val_keras_r2: -6.7045\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 542.5959 - keras_r2: -6.1843 - val_loss: 591.8020 - val_keras_r2: -6.8051\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 539.5598 - keras_r2: -1704984.1250 - val_loss: 547.8259 - val_keras_r2: -6.1694\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 472.8435 - keras_r2: -5.4003 - val_loss: 535.4203 - val_keras_r2: -6.0557\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 431.8408 - keras_r2: -4.5932 - val_loss: 475.5927 - val_keras_r2: -5.1439\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 415.0395 - keras_r2: -4.4356 - val_loss: 443.4219 - val_keras_r2: -4.7653\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 384.5224 - keras_r2: -4.0200 - val_loss: 449.9384 - val_keras_r2: -4.8856\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 394.1001 - keras_r2: -4.0457 - val_loss: 469.4087 - val_keras_r2: -5.1599\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 388.8157 - keras_r2: -4.2563 - val_loss: 453.6219 - val_keras_r2: -4.9062\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 380.2155 - keras_r2: -191022720.0000 - val_loss: 423.6698 - val_keras_r2: -4.5525\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 360.3445 - keras_r2: -3.6189 - val_loss: 388.4670 - val_keras_r2: -4.0103\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 333.0145 - keras_r2: -3.3297 - val_loss: 352.8965 - val_keras_r2: -3.5394\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 312.5090 - keras_r2: -3.0687 - val_loss: 362.6084 - val_keras_r2: -3.7400\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 306.6358 - keras_r2: -1376470.1250 - val_loss: 337.5151 - val_keras_r2: -3.3853\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 316.3844 - keras_r2: -3.1681 - val_loss: 345.2039 - val_keras_r2: -3.4859\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 314.7369 - keras_r2: -3.0846 - val_loss: 332.6440 - val_keras_r2: -3.3383\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 293.8989 - keras_r2: -2.8236 - val_loss: 360.7650 - val_keras_r2: -3.6261\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 306.4616 - keras_r2: -3.0594 - val_loss: 332.5188 - val_keras_r2: -3.2638\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 275.7055 - keras_r2: -2.5756 - val_loss: 293.2405 - val_keras_r2: -2.7600\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 267.2523 - keras_r2: -2.5430 - val_loss: 328.9223 - val_keras_r2: -3.2737\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 239.6292 - keras_r2: -3.8047 - val_loss: 243.0977 - val_keras_r2: -2.0732\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 221.0477 - keras_r2: -1.8525 - val_loss: 239.7140 - val_keras_r2: -2.0689\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 228.8712 - keras_r2: -1.9446 - val_loss: 244.6363 - val_keras_r2: -2.1787\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 223.7447 - keras_r2: -1.8391 - val_loss: 239.9587 - val_keras_r2: -2.0692\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 208.0611 - keras_r2: -9.6712 - val_loss: 249.6777 - val_keras_r2: -2.1950\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 214.3544 - keras_r2: -2.2547 - val_loss: 219.4162 - val_keras_r2: -1.7844\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 197.4613 - keras_r2: -1.5346 - val_loss: 216.8410 - val_keras_r2: -1.7986\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 190.1760 - keras_r2: -2.8695 - val_loss: 213.9184 - val_keras_r2: -1.7547\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 161.0740 - keras_r2: -1.2234 - val_loss: 165.2723 - val_keras_r2: -1.0832\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 136.8882 - keras_r2: -0.8423 - val_loss: 150.3580 - val_keras_r2: -0.8567\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 124.4830 - keras_r2: -0.5678 - val_loss: 135.7721 - val_keras_r2: -0.7108\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 121.9062 - keras_r2: -0.7918 - val_loss: 156.8092 - val_keras_r2: -1.0497\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 130.6621 - keras_r2: -0.6475 - val_loss: 161.0352 - val_keras_r2: -1.0850\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 112.6605 - keras_r2: -0.3947 - val_loss: 128.8912 - val_keras_r2: -0.6283\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 104.1304 - keras_r2: -0.3074 - val_loss: 126.2166 - val_keras_r2: -0.5751\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.6378 - keras_r2: -0.5096 - val_loss: 139.3014 - val_keras_r2: -0.7512\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.9600 - keras_r2: -0.1700 - val_loss: 135.5830 - val_keras_r2: -0.6950\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 98.5203 - keras_r2: -0.2565 - val_loss: 125.4237 - val_keras_r2: -0.6019\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.7748 - keras_r2: -0.2250 - val_loss: 128.0638 - val_keras_r2: -0.5605\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.1902 - keras_r2: -0.1996 - val_loss: 134.6270 - val_keras_r2: -0.6665\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.2732 - keras_r2: -0.1269 - val_loss: 119.1218 - val_keras_r2: -0.4630\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.0599 - keras_r2: -1.1498 - val_loss: 124.0802 - val_keras_r2: -0.5208\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.3863 - keras_r2: -0.1339 - val_loss: 114.5121 - val_keras_r2: -0.4630\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.2283 - keras_r2: -0.1585 - val_loss: 112.7945 - val_keras_r2: -0.4200\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.9249 - keras_r2: -0.1450 - val_loss: 125.5805 - val_keras_r2: -0.5452\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 93.5348 - keras_r2: -0.1694 - val_loss: 122.0017 - val_keras_r2: -0.5060\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.5894 - keras_r2: -0.1503 - val_loss: 125.2861 - val_keras_r2: -0.5667\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.8880 - keras_r2: -0.0687 - val_loss: 128.5970 - val_keras_r2: -0.5855\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.1735 - keras_r2: -0.1260 - val_loss: 108.0261 - val_keras_r2: -0.3324\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.9050 - keras_r2: -0.1268 - val_loss: 110.4408 - val_keras_r2: -0.4263\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.4505 - keras_r2: -0.1003 - val_loss: 122.9145 - val_keras_r2: -0.5961\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.7031 - keras_r2: -0.0716 - val_loss: 103.0368 - val_keras_r2: -0.2636\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.9028 - keras_r2: 0.0209 - val_loss: 107.4187 - val_keras_r2: -0.3423\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.9761 - keras_r2: -0.8635 - val_loss: 106.9129 - val_keras_r2: -0.3362\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.2950 - keras_r2: -0.1692 - val_loss: 143.1954 - val_keras_r2: -0.7834\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 109.1113 - keras_r2: -0.3717 - val_loss: 124.3489 - val_keras_r2: -0.5797\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 107.0707 - keras_r2: -0.3626 - val_loss: 122.7048 - val_keras_r2: -0.5615\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.4923 - keras_r2: -0.6393 - val_loss: 125.7577 - val_keras_r2: -0.5980\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.3990 - keras_r2: -0.6063 - val_loss: 127.2547 - val_keras_r2: -0.6028\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 104.2751 - keras_r2: -0.3692 - val_loss: 129.3565 - val_keras_r2: -0.6163\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.5502 - keras_r2: -0.2123 - val_loss: 120.3042 - val_keras_r2: -0.4877\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.6428 - keras_r2: -0.1250 - val_loss: 112.7398 - val_keras_r2: -0.3964\n",
            "Epoch 71: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=51; total time=  41.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 931.4944 - keras_r2: -11.2601 - val_loss: 916.6408 - val_keras_r2: -11.1115\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 849.6313 - keras_r2: -10.2241 - val_loss: 925.3029 - val_keras_r2: -11.2227\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 821.0449 - keras_r2: -9.7500 - val_loss: 837.8716 - val_keras_r2: -10.0129\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 770.4469 - keras_r2: -9.1949 - val_loss: 835.7272 - val_keras_r2: -9.9856\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 729.8082 - keras_r2: -44.0396 - val_loss: 795.1690 - val_keras_r2: -9.4671\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 723.6993 - keras_r2: -10.5100 - val_loss: 755.8945 - val_keras_r2: -8.8954\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 680.5071 - keras_r2: -144286320.0000 - val_loss: 749.2971 - val_keras_r2: -8.8310\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 687.5002 - keras_r2: -8.0316 - val_loss: 732.4694 - val_keras_r2: -8.5778\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 659.6107 - keras_r2: -7.7184 - val_loss: 718.1985 - val_keras_r2: -8.3960\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 672.9549 - keras_r2: -33.9834 - val_loss: 728.3724 - val_keras_r2: -8.5484\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 654.9746 - keras_r2: -9.0314 - val_loss: 702.7975 - val_keras_r2: -8.2241\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 630.4343 - keras_r2: -7.5539 - val_loss: 682.0766 - val_keras_r2: -7.9161\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 624.0403 - keras_r2: -7.4099 - val_loss: 673.3710 - val_keras_r2: -7.7655\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 614.6046 - keras_r2: -7.0367 - val_loss: 706.2149 - val_keras_r2: -8.2389\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 615.1826 - keras_r2: -8.2309 - val_loss: 666.8935 - val_keras_r2: -7.7483\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 604.0640 - keras_r2: -6.9186 - val_loss: 653.6586 - val_keras_r2: -7.5550\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 599.2084 - keras_r2: -6.7990 - val_loss: 691.9792 - val_keras_r2: -8.0597\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 606.1066 - keras_r2: -7.0306 - val_loss: 661.5243 - val_keras_r2: -7.6468\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 600.6190 - keras_r2: -6.8493 - val_loss: 661.8855 - val_keras_r2: -7.6450\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 603.9911 - keras_r2: -7.1436 - val_loss: 661.4884 - val_keras_r2: -7.7089\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 607.7866 - keras_r2: -7.0699 - val_loss: 680.4163 - val_keras_r2: -7.8927\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 610.2055 - keras_r2: -11.4325 - val_loss: 661.0525 - val_keras_r2: -7.6830\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 588.9364 - keras_r2: -6.6861 - val_loss: 645.7581 - val_keras_r2: -7.4973\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 573.4885 - keras_r2: -6.6424 - val_loss: 617.9761 - val_keras_r2: -7.1118\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 560.4124 - keras_r2: -6.3823 - val_loss: 615.7112 - val_keras_r2: -7.0911\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 561.0745 - keras_r2: -7.3667 - val_loss: 621.1898 - val_keras_r2: -7.1602\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 563.1657 - keras_r2: -6.4733 - val_loss: 633.2170 - val_keras_r2: -7.3095\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 558.4371 - keras_r2: -6.4624 - val_loss: 606.4294 - val_keras_r2: -6.9416\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 552.4289 - keras_r2: -6.7527 - val_loss: 614.9932 - val_keras_r2: -7.0415\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 570.5555 - keras_r2: -7.1370 - val_loss: 636.8667 - val_keras_r2: -7.3523\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 573.4479 - keras_r2: -6.4867 - val_loss: 631.0930 - val_keras_r2: -7.2842\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 565.6598 - keras_r2: -6.5176 - val_loss: 620.1160 - val_keras_r2: -7.1211\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 563.8387 - keras_r2: -5296078.0000 - val_loss: 628.6141 - val_keras_r2: -7.2253\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 551.8139 - keras_r2: -10.6522 - val_loss: 611.2838 - val_keras_r2: -6.9985\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 547.1655 - keras_r2: -7.1457 - val_loss: 607.3771 - val_keras_r2: -6.9416\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 544.0641 - keras_r2: -7.0187 - val_loss: 602.4401 - val_keras_r2: -6.8868\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 542.9216 - keras_r2: -6.3060 - val_loss: 609.2796 - val_keras_r2: -6.9749\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 541.2584 - keras_r2: -6.1642 - val_loss: 628.9297 - val_keras_r2: -7.2793\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 545.0644 - keras_r2: -6.1626 - val_loss: 607.9625 - val_keras_r2: -6.9752\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 544.4684 - keras_r2: -23672800.0000 - val_loss: 631.3780 - val_keras_r2: -7.3327\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 541.5479 - keras_r2: -6.0392 - val_loss: 607.8885 - val_keras_r2: -6.9848\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 536.7637 - keras_r2: -6.7412 - val_loss: 606.6099 - val_keras_r2: -6.9651\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 533.6850 - keras_r2: -6.9101 - val_loss: 614.6437 - val_keras_r2: -7.0820\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 534.0654 - keras_r2: -6.0849 - val_loss: 605.9071 - val_keras_r2: -6.9557\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 532.3516 - keras_r2: -6.4034 - val_loss: 601.8444 - val_keras_r2: -6.9066\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 533.6469 - keras_r2: -6.0075 - val_loss: 616.5666 - val_keras_r2: -7.0933\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 529.6528 - keras_r2: -6.7197 - val_loss: 612.2631 - val_keras_r2: -7.0440\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 529.2567 - keras_r2: -6.1079 - val_loss: 609.7784 - val_keras_r2: -7.0076\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 507.8890 - keras_r2: -6.0266 - val_loss: 555.1718 - val_keras_r2: -6.2626\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 427.6422 - keras_r2: -4.6951 - val_loss: 404.4803 - val_keras_r2: -4.1993\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 246.6796 - keras_r2: -2.2805 - val_loss: 229.7515 - val_keras_r2: -1.9779\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 180.5514 - keras_r2: -1.3153 - val_loss: 192.1543 - val_keras_r2: -1.4048\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 145.4582 - keras_r2: -0.9251 - val_loss: 492.4140 - val_keras_r2: -5.4103\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 144.2715 - keras_r2: -0.8371 - val_loss: 149.3237 - val_keras_r2: -0.8547\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 122.5883 - keras_r2: -0.5433 - val_loss: 163.7550 - val_keras_r2: -1.0645\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 115.7358 - keras_r2: -0.4434 - val_loss: 145.2454 - val_keras_r2: -0.8246\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 120.4730 - keras_r2: -0.6062 - val_loss: 155.3527 - val_keras_r2: -1.0205\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 115.1847 - keras_r2: -0.3987 - val_loss: 135.6729 - val_keras_r2: -0.7009\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 109.2303 - keras_r2: -0.3814 - val_loss: 152.6655 - val_keras_r2: -0.9271\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 106.2442 - keras_r2: -0.3472 - val_loss: 153.4660 - val_keras_r2: -0.9708\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 115.6151 - keras_r2: -0.5385 - val_loss: 181.9124 - val_keras_r2: -1.2961\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 102.5694 - keras_r2: -0.4119 - val_loss: 220.9223 - val_keras_r2: -1.8583\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 105.2782 - keras_r2: -2973138.5000 - val_loss: 137.5900 - val_keras_r2: -0.7804\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.5471 - keras_r2: -1591746.7500 - val_loss: 124.7160 - val_keras_r2: -0.6292\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 100.1709 - keras_r2: -0.2629 - val_loss: 121.5832 - val_keras_r2: -0.5502\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.4157 - keras_r2: -0.1502 - val_loss: 114.0958 - val_keras_r2: -0.4243\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.7270 - keras_r2: -2.9642 - val_loss: 133.2590 - val_keras_r2: -0.6924\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 100.5430 - keras_r2: -0.2592 - val_loss: 117.6288 - val_keras_r2: -0.5586\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 94.8448 - keras_r2: -0.2079 - val_loss: 122.6684 - val_keras_r2: -0.5769\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.7352 - keras_r2: -0.1180 - val_loss: 122.0102 - val_keras_r2: -0.6076\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.8079 - keras_r2: -0.1401 - val_loss: 112.2768 - val_keras_r2: -0.4337\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 101.6663 - keras_r2: -0.2712 - val_loss: 116.2366 - val_keras_r2: -0.4682\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.5718 - keras_r2: -0.1310 - val_loss: 123.2669 - val_keras_r2: -0.5900\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.3673 - keras_r2: -0.1172 - val_loss: 111.0446 - val_keras_r2: -0.3701\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.5445 - keras_r2: -0.1361 - val_loss: 129.6602 - val_keras_r2: -0.6226\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.6940 - keras_r2: -0.2216 - val_loss: 116.0910 - val_keras_r2: -0.4795\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 93.1845 - keras_r2: -0.1692 - val_loss: 119.2380 - val_keras_r2: -0.4808\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.3765 - keras_r2: -0.1452 - val_loss: 105.5781 - val_keras_r2: -0.2915\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.4168 - keras_r2: -0.0719 - val_loss: 111.5946 - val_keras_r2: -0.3609\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 82.2461 - keras_r2: -0.0618 - val_loss: 126.4604 - val_keras_r2: -0.5934\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.3807 - keras_r2: 0.0177 - val_loss: 115.8578 - val_keras_r2: -0.4459\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.2602 - keras_r2: 0.0399 - val_loss: 110.8406 - val_keras_r2: -0.3552\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.0057 - keras_r2: 0.0621 - val_loss: 119.9115 - val_keras_r2: -0.4836\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.5536 - keras_r2: -1.5082 - val_loss: 116.2383 - val_keras_r2: -0.4276\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.6144 - keras_r2: 0.0174 - val_loss: 104.7381 - val_keras_r2: -0.2723\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.2556 - keras_r2: -0.0159 - val_loss: 109.6109 - val_keras_r2: -0.3670\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.8051 - keras_r2: -1196089.0000 - val_loss: 109.6934 - val_keras_r2: -0.3605\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.9213 - keras_r2: 0.0241 - val_loss: 107.1269 - val_keras_r2: -0.3033\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.6478 - keras_r2: 0.0249 - val_loss: 110.3871 - val_keras_r2: -0.3566\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.6155 - keras_r2: 0.0773 - val_loss: 112.4970 - val_keras_r2: -0.3913\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.1500 - keras_r2: 0.0710 - val_loss: 117.9166 - val_keras_r2: -0.4730\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.9087 - keras_r2: -0.0295 - val_loss: 124.5272 - val_keras_r2: -0.5475\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.6945 - keras_r2: 0.0260 - val_loss: 116.9056 - val_keras_r2: -0.4544\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6110 - keras_r2: 0.0662 - val_loss: 121.6559 - val_keras_r2: -0.5296\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.8931 - keras_r2: 0.0655 - val_loss: 118.3513 - val_keras_r2: -0.4743\n",
            "Epoch 95: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=51; total time= 1.4min\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 984.3137 - keras_r2: -12.0192 - val_loss: 856.4614 - val_keras_r2: -10.3064\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 881.6729 - keras_r2: -220000000.0000 - val_loss: 842.0369 - val_keras_r2: -10.2548\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 816.4662 - keras_r2: -9.7484 - val_loss: 779.0792 - val_keras_r2: -9.2976\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 723.3300 - keras_r2: -105347664.0000 - val_loss: 690.0287 - val_keras_r2: -8.0744\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 720.5696 - keras_r2: -8.4311 - val_loss: 721.9338 - val_keras_r2: -8.4280\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 684.4860 - keras_r2: -8.0302 - val_loss: 671.4123 - val_keras_r2: -7.8073\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 676.6712 - keras_r2: -8.6262 - val_loss: 702.8787 - val_keras_r2: -8.2749\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 639.1226 - keras_r2: -7.2340 - val_loss: 620.5644 - val_keras_r2: -7.1238\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 628.6226 - keras_r2: -22.7585 - val_loss: 706.8677 - val_keras_r2: -8.3700\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 597.8060 - keras_r2: -10.2990 - val_loss: 571.4387 - val_keras_r2: -6.5802\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 536.7858 - keras_r2: -5.9856 - val_loss: 620.4368 - val_keras_r2: -7.2117\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 518.6664 - keras_r2: -5.9338 - val_loss: 606.8666 - val_keras_r2: -7.0786\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 497.7691 - keras_r2: -5.3455 - val_loss: 521.8448 - val_keras_r2: -5.8918\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 454.8544 - keras_r2: -5.1657 - val_loss: 874.9255 - val_keras_r2: -10.5502\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 458.6089 - keras_r2: -4.9826 - val_loss: 459.5667 - val_keras_r2: -5.0189\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 437.2157 - keras_r2: -142754512.0000 - val_loss: 482.0493 - val_keras_r2: -5.2778\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 423.7218 - keras_r2: -4.5445 - val_loss: 449.9012 - val_keras_r2: -4.9763\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 400.6349 - keras_r2: -4.1304 - val_loss: 430.8529 - val_keras_r2: -4.6666\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 396.7043 - keras_r2: -4.0610 - val_loss: 412.1831 - val_keras_r2: -4.4281\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 388.5300 - keras_r2: -3.9342 - val_loss: 425.5421 - val_keras_r2: -4.5979\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 384.9850 - keras_r2: -4.0184 - val_loss: 408.1288 - val_keras_r2: -4.3550\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 359.5186 - keras_r2: -36.1958 - val_loss: 410.9283 - val_keras_r2: -4.3707\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 305.8527 - keras_r2: -2.9018 - val_loss: 355.2281 - val_keras_r2: -3.6256\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 272.5313 - keras_r2: -2.4748 - val_loss: 302.7633 - val_keras_r2: -2.8814\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 250.1633 - keras_r2: -2.2734 - val_loss: 260.2214 - val_keras_r2: -2.3432\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 215.5553 - keras_r2: -1.7734 - val_loss: 249.7609 - val_keras_r2: -2.2469\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 203.2317 - keras_r2: -1.5782 - val_loss: 250.3101 - val_keras_r2: -2.2127\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 194.5856 - keras_r2: -1.4872 - val_loss: 239.2184 - val_keras_r2: -2.0795\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 191.0774 - keras_r2: -1.4276 - val_loss: 232.0920 - val_keras_r2: -1.9373\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 187.7804 - keras_r2: -1.3975 - val_loss: 223.1222 - val_keras_r2: -1.8570\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 158.8920 - keras_r2: -0.9888 - val_loss: 175.5413 - val_keras_r2: -1.2499\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 130.6419 - keras_r2: -0.6292 - val_loss: 137.8343 - val_keras_r2: -0.7045\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 118.1620 - keras_r2: -0.5385 - val_loss: 163.2307 - val_keras_r2: -1.0443\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 112.6736 - keras_r2: -0.4042 - val_loss: 123.1887 - val_keras_r2: -0.4950\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.7101 - keras_r2: -0.1455 - val_loss: 110.5255 - val_keras_r2: -0.3071\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 101.0023 - keras_r2: -0.2651 - val_loss: 131.0409 - val_keras_r2: -0.6169\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.6613 - keras_r2: -0.2042 - val_loss: 133.1507 - val_keras_r2: -0.7214\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.1428 - keras_r2: -0.1772 - val_loss: 100.3018 - val_keras_r2: -0.2277\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.5466 - keras_r2: -0.0394 - val_loss: 103.8441 - val_keras_r2: -0.2812\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 82.7135 - keras_r2: -0.0715 - val_loss: 140.0660 - val_keras_r2: -0.8125\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.0439 - keras_r2: -0.0026 - val_loss: 110.7156 - val_keras_r2: -0.3926\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.4689 - keras_r2: 0.0206 - val_loss: 106.3328 - val_keras_r2: -0.3207\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.3052 - keras_r2: -0.0027 - val_loss: 109.7636 - val_keras_r2: -0.3615\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.5467 - keras_r2: 0.0702 - val_loss: 84.8979 - val_keras_r2: -0.0035\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.7521 - keras_r2: -0.0659 - val_loss: 94.6187 - val_keras_r2: -0.1321\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5482 - keras_r2: 0.0974 - val_loss: 84.8806 - val_keras_r2: -0.0140\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5123 - keras_r2: 0.1195 - val_loss: 89.2250 - val_keras_r2: -0.1055\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.2640 - keras_r2: 0.1540 - val_loss: 88.0950 - val_keras_r2: -0.0905\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.7345 - keras_r2: 0.1872 - val_loss: 87.2973 - val_keras_r2: -0.0785\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.9469 - keras_r2: 0.2131 - val_loss: 87.6506 - val_keras_r2: -0.0895\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.3825 - keras_r2: 0.2223 - val_loss: 92.8871 - val_keras_r2: -0.1756\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.7029 - keras_r2: 0.1493 - val_loss: 85.9063 - val_keras_r2: -0.0556\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7517 - keras_r2: 0.2468 - val_loss: 93.0378 - val_keras_r2: -0.1606\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.3119 - keras_r2: 0.2159 - val_loss: 123.2074 - val_keras_r2: -0.5715\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.6400 - keras_r2: 0.1925 - val_loss: 90.9920 - val_keras_r2: -0.1192\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.8991 - keras_r2: 0.2539 - val_loss: 89.5587 - val_keras_r2: -0.0966\n",
            "Epoch 56: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=51; total time=  28.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 817.6141 - keras_r2: -9.4927 - val_loss: 687.1914 - val_keras_r2: -8.0183\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 630.2148 - keras_r2: -7.3293 - val_loss: 652.3949 - val_keras_r2: -7.5992\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 593.0170 - keras_r2: -6.7117 - val_loss: 637.8663 - val_keras_r2: -7.3975\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 586.4100 - keras_r2: -10.2896 - val_loss: 634.3839 - val_keras_r2: -7.3519\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 583.4329 - keras_r2: -6.5842 - val_loss: 634.0666 - val_keras_r2: -7.3543\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 582.7277 - keras_r2: -6.6568 - val_loss: 635.2276 - val_keras_r2: -7.3674\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 582.0115 - keras_r2: -6.5114 - val_loss: 632.6874 - val_keras_r2: -7.3310\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 581.2896 - keras_r2: -6.7024 - val_loss: 633.5182 - val_keras_r2: -7.3449\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 580.1402 - keras_r2: -6.8251 - val_loss: 631.6902 - val_keras_r2: -7.3215\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 580.1545 - keras_r2: -6.4894 - val_loss: 632.7921 - val_keras_r2: -7.3354\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 579.6196 - keras_r2: -6.5425 - val_loss: 639.4524 - val_keras_r2: -7.4211\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 579.4600 - keras_r2: -6.6395 - val_loss: 642.2682 - val_keras_r2: -7.4578\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 579.3165 - keras_r2: -6.6218 - val_loss: 633.9778 - val_keras_r2: -7.3545\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 578.5978 - keras_r2: -6.4961 - val_loss: 639.4124 - val_keras_r2: -7.4205\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 577.7242 - keras_r2: -6.6638 - val_loss: 632.1166 - val_keras_r2: -7.3357\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 577.6061 - keras_r2: -6.8211 - val_loss: 630.9489 - val_keras_r2: -7.3143\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 577.1859 - keras_r2: -6.8290 - val_loss: 631.6546 - val_keras_r2: -7.3291\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 576.6412 - keras_r2: -6.4484 - val_loss: 633.2843 - val_keras_r2: -7.3456\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 576.4739 - keras_r2: -7.1086 - val_loss: 629.9459 - val_keras_r2: -7.3017\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 575.8817 - keras_r2: -6.5738 - val_loss: 680.0746 - val_keras_r2: -7.9923\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 576.3116 - keras_r2: -6.5427 - val_loss: 631.7709 - val_keras_r2: -7.3262\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 575.4295 - keras_r2: -6.3461 - val_loss: 655.1382 - val_keras_r2: -7.6584\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 575.1143 - keras_r2: -6.4657 - val_loss: 649.0206 - val_keras_r2: -7.5764\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 575.1792 - keras_r2: -6.4893 - val_loss: 634.0931 - val_keras_r2: -7.3646\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 574.0538 - keras_r2: -11.1962 - val_loss: 633.0508 - val_keras_r2: -7.3514\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 573.8829 - keras_r2: -6.6441 - val_loss: 629.8721 - val_keras_r2: -7.3084\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 573.2083 - keras_r2: -7.5046 - val_loss: 631.4902 - val_keras_r2: -7.3270\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 573.0976 - keras_r2: -6.3823 - val_loss: 632.3160 - val_keras_r2: -7.3310\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 572.9028 - keras_r2: -7.1565 - val_loss: 635.2358 - val_keras_r2: -7.3707\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 572.5628 - keras_r2: -6.5245 - val_loss: 635.9764 - val_keras_r2: -7.3829\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 572.2568 - keras_r2: -6.8350 - val_loss: 634.3084 - val_keras_r2: -7.3644\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 571.7166 - keras_r2: -6.5275 - val_loss: 656.1451 - val_keras_r2: -7.6682\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 572.2265 - keras_r2: -6.5024 - val_loss: 679.3607 - val_keras_r2: -7.9324\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 572.4841 - keras_r2: -6.4599 - val_loss: 644.2186 - val_keras_r2: -7.4807\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 571.2566 - keras_r2: -6.5757 - val_loss: 632.8045 - val_keras_r2: -7.3407\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 570.7744 - keras_r2: -6.4783 - val_loss: 633.6444 - val_keras_r2: -7.3492\n",
            "Epoch 36: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=51; total time=  19.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 722.8336 - keras_r2: -8.4838 - val_loss: 721.3182 - val_keras_r2: -8.5485\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 610.1516 - keras_r2: -7.1295 - val_loss: 657.7213 - val_keras_r2: -7.6139\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 616.5204 - keras_r2: -6.9181 - val_loss: 671.8242 - val_keras_r2: -7.7091\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 558.8595 - keras_r2: -6.2562 - val_loss: 570.3477 - val_keras_r2: -6.4069\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 522.3012 - keras_r2: -6.0123 - val_loss: 538.4634 - val_keras_r2: -5.9978\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 492.0190 - keras_r2: -5.3876 - val_loss: 519.1967 - val_keras_r2: -5.7501\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 482.7510 - keras_r2: -5.3368 - val_loss: 510.7175 - val_keras_r2: -5.6238\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 484.6231 - keras_r2: -5.2510 - val_loss: 508.1149 - val_keras_r2: -5.5992\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 479.2421 - keras_r2: -5.2188 - val_loss: 525.3692 - val_keras_r2: -5.8100\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 477.7885 - keras_r2: -5.2217 - val_loss: 509.7750 - val_keras_r2: -5.6174\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 476.3661 - keras_r2: -5.1846 - val_loss: 505.8911 - val_keras_r2: -5.5635\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 475.6219 - keras_r2: -5.0821 - val_loss: 516.4904 - val_keras_r2: -5.7299\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 474.7191 - keras_r2: -5.1694 - val_loss: 510.3228 - val_keras_r2: -5.6230\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 473.7943 - keras_r2: -5.3551 - val_loss: 507.7502 - val_keras_r2: -5.5907\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 473.0060 - keras_r2: -4.9764 - val_loss: 507.9933 - val_keras_r2: -5.6070\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 472.4859 - keras_r2: -5.6075 - val_loss: 503.9267 - val_keras_r2: -5.5442\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 472.1896 - keras_r2: -5.1205 - val_loss: 507.0637 - val_keras_r2: -5.5763\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 471.7295 - keras_r2: -5.3145 - val_loss: 516.5155 - val_keras_r2: -5.7292\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 470.9740 - keras_r2: -5.3019 - val_loss: 504.2735 - val_keras_r2: -5.5484\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 470.1616 - keras_r2: -5.1502 - val_loss: 513.8578 - val_keras_r2: -5.6952\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 470.3461 - keras_r2: -5.2681 - val_loss: 518.8997 - val_keras_r2: -5.7637\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 469.6954 - keras_r2: -5.1896 - val_loss: 520.9502 - val_keras_r2: -5.7970\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 469.1647 - keras_r2: -5.1942 - val_loss: 514.1282 - val_keras_r2: -5.6748\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 468.3661 - keras_r2: -5.0976 - val_loss: 520.4097 - val_keras_r2: -5.7913\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 468.7276 - keras_r2: -5.1606 - val_loss: 520.8867 - val_keras_r2: -5.7622\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 468.5855 - keras_r2: -5.3241 - val_loss: 503.3445 - val_keras_r2: -5.5355\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 467.7184 - keras_r2: -5.0305 - val_loss: 504.3610 - val_keras_r2: -5.5540\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 467.5641 - keras_r2: -5.5167 - val_loss: 507.2918 - val_keras_r2: -5.5875\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 466.9262 - keras_r2: -5.0255 - val_loss: 507.3137 - val_keras_r2: -5.5991\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 466.4782 - keras_r2: -5.1865 - val_loss: 505.7275 - val_keras_r2: -5.5767\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 466.1651 - keras_r2: -4.9213 - val_loss: 513.5090 - val_keras_r2: -5.6561\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 465.9796 - keras_r2: -5.0764 - val_loss: 508.8042 - val_keras_r2: -5.6271\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 465.0312 - keras_r2: -5.0619 - val_loss: 512.8268 - val_keras_r2: -5.6814\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 465.6347 - keras_r2: -5.1966 - val_loss: 503.7629 - val_keras_r2: -5.5473\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 464.6065 - keras_r2: -5.0937 - val_loss: 514.0626 - val_keras_r2: -5.7012\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 464.8370 - keras_r2: -5.2957 - val_loss: 511.6747 - val_keras_r2: -5.6691\n",
            "Epoch 36: early stopping\n",
            "[CV] END ..........activation=tanh, n_hidden=4, n_neurons=51; total time=  19.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2312.3062 - keras_r2: -28.7485 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -24.8680 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.2243 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.4140 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.7769 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.8781 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -24.8406 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1933.4823 - keras_r2: -92.1473 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -25.9922 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -30.5006 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4823 - keras_r2: -29.7470 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ..........activation=relu, n_hidden=5, n_neurons=73; total time=   7.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4773.2744 - keras_r2: -54.0371 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -147272752.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.7274 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8548 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8102 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.3669 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.9031 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.5623 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.1114 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -272840928.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.0814 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ..........activation=relu, n_hidden=5, n_neurons=73; total time=   7.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 13696328704.0000 - keras_r2: -277546752.0000 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.8865 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.1065 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.8662 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -26.1860 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -27.2817 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -38.2421 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.6221 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -33.0757 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -25.1854 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2035.2001 - keras_r2: -29.2436 - val_loss: 2033.9514 - val_keras_r2: -26.1419\n",
            "Epoch 11: early stopping\n",
            "[CV] END ..........activation=relu, n_hidden=5, n_neurons=73; total time=   7.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 4494768128.0000 - keras_r2: -34769436.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.2982 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.2697 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.8806 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -27.2066 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -25.1559 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.9968 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -26.2068 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -31.5080 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.5618 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1933.4991 - keras_r2: -24.4430 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END ..........activation=relu, n_hidden=5, n_neurons=73; total time=   7.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 3005.8105 - keras_r2: -47.6180 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3143 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -23.2038 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6218 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.3947 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.7370 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6552 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.0776 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -23.3373 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1762.4236 - keras_r2: -22.4451 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1762.4236 - keras_r2: -22.6835 - val_loss: 1801.3505 - val_keras_r2: -23.0911\n",
            "Epoch 11: early stopping\n",
            "[CV] END ..........activation=relu, n_hidden=5, n_neurons=73; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 377.2447 - keras_r2: -3.7620 - val_loss: 157.6060 - val_keras_r2: -1.0146\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 293.3306 - keras_r2: -2.9113 - val_loss: 189.2477 - val_keras_r2: -1.4656\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 103.2660 - keras_r2: -0.3014 - val_loss: 100.5776 - val_keras_r2: -0.2431\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 92.1363 - keras_r2: -0.2027 - val_loss: 107.2193 - val_keras_r2: -0.3123\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.9476 - keras_r2: -0.1064 - val_loss: 93.2102 - val_keras_r2: -0.1408\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4108 - keras_r2: -0.0773 - val_loss: 94.2695 - val_keras_r2: -0.1434\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.0633 - keras_r2: -0.2410 - val_loss: 96.5835 - val_keras_r2: -0.1855\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.2316 - keras_r2: -0.5908 - val_loss: 106.3161 - val_keras_r2: -0.2883\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.6561 - keras_r2: -0.0020 - val_loss: 84.0557 - val_keras_r2: -0.0187\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.1839 - keras_r2: 0.0120 - val_loss: 85.5336 - val_keras_r2: -0.0272\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.6692 - keras_r2: 0.0297 - val_loss: 86.0453 - val_keras_r2: -0.0366\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.2071 - keras_r2: 0.0166 - val_loss: 86.4378 - val_keras_r2: -0.0499\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.3184 - keras_r2: -0.3225 - val_loss: 85.9545 - val_keras_r2: -0.0404\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.3201 - keras_r2: -0.0510 - val_loss: 81.0007 - val_keras_r2: 0.0299\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.4678 - keras_r2: 0.0049 - val_loss: 92.8008 - val_keras_r2: -0.1179\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.9506 - keras_r2: 0.0463 - val_loss: 81.3344 - val_keras_r2: 0.0165\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.0679 - keras_r2: 0.0850 - val_loss: 82.7639 - val_keras_r2: -0.0064\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.1082 - keras_r2: -0.1633 - val_loss: 89.6071 - val_keras_r2: -0.0865\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.5241 - keras_r2: 0.0914 - val_loss: 79.1972 - val_keras_r2: 0.0458\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.0599 - keras_r2: -0.3924 - val_loss: 85.8456 - val_keras_r2: -0.0404\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.8018 - keras_r2: 0.0804 - val_loss: 84.9726 - val_keras_r2: -0.0309\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.2802 - keras_r2: 0.0603 - val_loss: 92.3302 - val_keras_r2: -0.1389\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.5762 - keras_r2: 0.0984 - val_loss: 108.7347 - val_keras_r2: -0.3593\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.4293 - keras_r2: 0.1044 - val_loss: 80.1812 - val_keras_r2: 0.0294\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.3349 - keras_r2: -728506.1875 - val_loss: 77.3097 - val_keras_r2: 0.0736\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.4671 - keras_r2: -0.2151 - val_loss: 77.4119 - val_keras_r2: 0.0696\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.1703 - keras_r2: 0.1052 - val_loss: 77.4257 - val_keras_r2: 0.0676\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.3679 - keras_r2: 0.1177 - val_loss: 86.6733 - val_keras_r2: -0.0608\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.4582 - keras_r2: 0.1312 - val_loss: 83.2685 - val_keras_r2: -5.7666e-04\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.0319 - keras_r2: 0.1098 - val_loss: 92.0536 - val_keras_r2: -0.1318\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.9640 - keras_r2: 0.1327 - val_loss: 78.8796 - val_keras_r2: 0.0477\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.7130 - keras_r2: 0.1424 - val_loss: 77.9623 - val_keras_r2: 0.0630\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.2598 - keras_r2: 0.1529 - val_loss: 77.5153 - val_keras_r2: 0.0723\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1614 - keras_r2: 0.1486 - val_loss: 76.4500 - val_keras_r2: 0.0841\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.7318 - keras_r2: 0.1399 - val_loss: 91.6378 - val_keras_r2: -0.1252\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0955 - keras_r2: 0.1366 - val_loss: 76.3227 - val_keras_r2: 0.0853\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.3796 - keras_r2: 0.1509 - val_loss: 75.4818 - val_keras_r2: 0.0986\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.4138 - keras_r2: 0.1304 - val_loss: 76.6815 - val_keras_r2: 0.0846\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.2300 - keras_r2: 0.1552 - val_loss: 76.5432 - val_keras_r2: 0.0891\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0483 - keras_r2: -1.2469 - val_loss: 91.4023 - val_keras_r2: -0.1274\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.9491 - keras_r2: 0.1649 - val_loss: 76.5116 - val_keras_r2: 0.0802\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.8194 - keras_r2: 0.0573 - val_loss: 76.8631 - val_keras_r2: 0.0789\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6947 - keras_r2: 0.1609 - val_loss: 77.9266 - val_keras_r2: 0.0724\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.4795 - keras_r2: 0.1655 - val_loss: 75.5737 - val_keras_r2: 0.0999\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.4106 - keras_r2: 0.1559 - val_loss: 78.0859 - val_keras_r2: 0.0610\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.3043 - keras_r2: 0.1642 - val_loss: 78.9827 - val_keras_r2: 0.0542\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.1196 - keras_r2: 0.1582 - val_loss: 74.9943 - val_keras_r2: 0.1069\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.9648 - keras_r2: 0.1557 - val_loss: 76.7992 - val_keras_r2: 0.0787\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.9130 - keras_r2: 0.1823 - val_loss: 75.8086 - val_keras_r2: 0.0925\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.5635 - keras_r2: 0.1809 - val_loss: 84.1343 - val_keras_r2: -0.0126\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.5548 - keras_r2: 0.1778 - val_loss: 83.3190 - val_keras_r2: -0.0055\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.5233 - keras_r2: 0.1901 - val_loss: 78.3848 - val_keras_r2: 0.0659\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.4608 - keras_r2: 0.1804 - val_loss: 75.8497 - val_keras_r2: 0.0937\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.3811 - keras_r2: 0.1648 - val_loss: 75.4592 - val_keras_r2: 0.0961\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2173 - keras_r2: 0.1157 - val_loss: 76.2316 - val_keras_r2: 0.0870\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.3076 - keras_r2: -0.1504 - val_loss: 95.4835 - val_keras_r2: -0.1827\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.1391 - keras_r2: 0.1829 - val_loss: 76.9707 - val_keras_r2: 0.0784\n",
            "Epoch 57: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=1, n_neurons=4; total time=  27.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -23.8212 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -53.9363 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.4016 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.2294 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -82.0303 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.1151 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.9229 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.0293 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.5634 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.3295 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1862.7312 - keras_r2: -24.1530 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=1, n_neurons=4; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 293.4533 - keras_r2: -2.6510 - val_loss: 127.3220 - val_keras_r2: -0.5536\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 367.1538 - keras_r2: -3.5609 - val_loss: 699.4363 - val_keras_r2: -8.3000\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 443.4477 - keras_r2: -4.8104 - val_loss: 437.6144 - val_keras_r2: -4.7357\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 437.0915 - keras_r2: -4.7323 - val_loss: 447.3134 - val_keras_r2: -4.8661\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 434.3120 - keras_r2: -4.6651 - val_loss: 439.0095 - val_keras_r2: -4.7388\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 432.1576 - keras_r2: -4.8793 - val_loss: 499.1461 - val_keras_r2: -5.5261\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 432.6223 - keras_r2: -4.6713 - val_loss: 458.4960 - val_keras_r2: -5.0025\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 431.9124 - keras_r2: -4.6668 - val_loss: 434.7663 - val_keras_r2: -4.6891\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 429.6569 - keras_r2: -30.1930 - val_loss: 428.2897 - val_keras_r2: -4.5998\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 428.7250 - keras_r2: -4.5142 - val_loss: 446.6500 - val_keras_r2: -4.8472\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 429.0163 - keras_r2: -4.4857 - val_loss: 431.6661 - val_keras_r2: -4.6490\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=1, n_neurons=4; total time=  10.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 348.4216 - keras_r2: -3.4979 - val_loss: 163.6172 - val_keras_r2: -1.0467\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 599.4105 - keras_r2: -7.0150 - val_loss: 498.8256 - val_keras_r2: -5.5446\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 483.5410 - keras_r2: -5.4684 - val_loss: 444.8624 - val_keras_r2: -4.8073\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 474.0023 - keras_r2: -5.8016 - val_loss: 433.2152 - val_keras_r2: -4.6585\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 475.5735 - keras_r2: -5.1484 - val_loss: 438.8549 - val_keras_r2: -4.7476\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 466.9256 - keras_r2: -5.0952 - val_loss: 499.3621 - val_keras_r2: -5.5448\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 473.8910 - keras_r2: -5.1492 - val_loss: 428.6044 - val_keras_r2: -4.6014\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 462.4690 - keras_r2: -4.9418 - val_loss: 425.1790 - val_keras_r2: -4.5584\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 460.6934 - keras_r2: -5.1730 - val_loss: 435.9057 - val_keras_r2: -4.6983\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 460.3724 - keras_r2: -4.9944 - val_loss: 430.8482 - val_keras_r2: -4.6364\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 459.8481 - keras_r2: -4.9766 - val_loss: 442.9810 - val_keras_r2: -4.8098\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=1, n_neurons=4; total time=   6.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 569.1470 - keras_r2: -14.3426 - val_loss: 1112.2412 - val_keras_r2: -13.8170\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 804.2054 - keras_r2: -9.7156 - val_loss: 753.9336 - val_keras_r2: -9.0571\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 702.2149 - keras_r2: -8.1791 - val_loss: 748.6694 - val_keras_r2: -8.9900\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 701.5480 - keras_r2: -8.1147 - val_loss: 776.1016 - val_keras_r2: -9.3438\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 701.3975 - keras_r2: -8.2518 - val_loss: 748.4697 - val_keras_r2: -8.9858\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 700.6211 - keras_r2: -8.2603 - val_loss: 743.8347 - val_keras_r2: -8.9249\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 700.3838 - keras_r2: -8.2836 - val_loss: 753.6422 - val_keras_r2: -9.0693\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 700.3879 - keras_r2: -8.2439 - val_loss: 748.3028 - val_keras_r2: -8.9830\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 699.4170 - keras_r2: -8.5761 - val_loss: 744.3235 - val_keras_r2: -8.9322\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 699.3104 - keras_r2: -8.1298 - val_loss: 755.2952 - val_keras_r2: -9.0643\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 698.8820 - keras_r2: -8.1755 - val_loss: 746.5090 - val_keras_r2: -8.9627\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 698.3079 - keras_r2: -8.0464 - val_loss: 744.9939 - val_keras_r2: -8.9434\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 698.1124 - keras_r2: -8.1324 - val_loss: 758.7427 - val_keras_r2: -9.1098\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 698.3727 - keras_r2: -8.2106 - val_loss: 744.3708 - val_keras_r2: -8.9268\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 697.4907 - keras_r2: -8.2593 - val_loss: 745.7163 - val_keras_r2: -8.9578\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 697.3494 - keras_r2: -8.1367 - val_loss: 753.9764 - val_keras_r2: -9.0547\n",
            "Epoch 16: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=1, n_neurons=4; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 914.7211 - keras_r2: -10.8415 - val_loss: 338.4309 - val_keras_r2: -3.4471\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 187.9118 - keras_r2: -8121376.0000 - val_loss: 117.6699 - val_keras_r2: -0.4685\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 96.8418 - keras_r2: -0.2525 - val_loss: 90.7690 - val_keras_r2: -0.0971\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.9340 - keras_r2: -0.1728 - val_loss: 87.6247 - val_keras_r2: -0.0509\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.7515 - keras_r2: -0.0507 - val_loss: 87.2076 - val_keras_r2: -0.0439\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6297 - keras_r2: -0.1248 - val_loss: 87.1598 - val_keras_r2: -0.0428\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6244 - keras_r2: -0.1856 - val_loss: 87.1478 - val_keras_r2: -0.0425\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6194 - keras_r2: -0.0333 - val_loss: 87.1507 - val_keras_r2: -0.0426\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6188 - keras_r2: -0.0392 - val_loss: 87.1452 - val_keras_r2: -0.0425\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6183 - keras_r2: -0.0312 - val_loss: 87.1390 - val_keras_r2: -0.0423\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6208 - keras_r2: -0.0401 - val_loss: 87.1451 - val_keras_r2: -0.0425\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6169 - keras_r2: -0.0327 - val_loss: 87.1419 - val_keras_r2: -0.0424\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6187 - keras_r2: -0.0355 - val_loss: 87.1414 - val_keras_r2: -0.0423\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6161 - keras_r2: -0.0694 - val_loss: 87.1432 - val_keras_r2: -0.0424\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6179 - keras_r2: -0.2357 - val_loss: 87.1372 - val_keras_r2: -0.0422\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6189 - keras_r2: -0.0281 - val_loss: 87.1420 - val_keras_r2: -0.0424\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6176 - keras_r2: -0.0381 - val_loss: 87.1385 - val_keras_r2: -0.0423\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6166 - keras_r2: -2770805.2500 - val_loss: 87.1325 - val_keras_r2: -0.0420\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6221 - keras_r2: -0.0342 - val_loss: 87.1462 - val_keras_r2: -0.0425\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6176 - keras_r2: -0.4887 - val_loss: 87.1645 - val_keras_r2: -0.0430\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6229 - keras_r2: -0.2187 - val_loss: 87.1684 - val_keras_r2: -0.0430\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6203 - keras_r2: -7.8656 - val_loss: 87.1374 - val_keras_r2: -0.0422\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6190 - keras_r2: -0.3102 - val_loss: 87.1904 - val_keras_r2: -0.0435\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6246 - keras_r2: -0.0432 - val_loss: 87.1500 - val_keras_r2: -0.0426\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6165 - keras_r2: -0.1088 - val_loss: 87.1720 - val_keras_r2: -0.0431\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6237 - keras_r2: -0.7173 - val_loss: 87.1686 - val_keras_r2: -0.0430\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6210 - keras_r2: -0.0420 - val_loss: 87.1414 - val_keras_r2: -0.0423\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6231 - keras_r2: -0.0556 - val_loss: 87.1484 - val_keras_r2: -0.0426\n",
            "Epoch 28: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=5, n_neurons=5; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1862.7312 - keras_r2: -210113648.0000 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -32.3350 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.8219 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.0729 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.3123 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.2767 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1862.7312 - keras_r2: -93.3635 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 1862.7312 - keras_r2: -24.3879 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -24.3548 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -23.7109 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1862.7312 - keras_r2: -26.6670 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 11: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=5, n_neurons=5; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 961.9199 - keras_r2: -11.8976 - val_loss: 328.8835 - val_keras_r2: -3.3188\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 187.2336 - keras_r2: -1.4486 - val_loss: 116.5158 - val_keras_r2: -0.4528\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 97.8741 - keras_r2: -0.2383 - val_loss: 90.6279 - val_keras_r2: -0.0951\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.9784 - keras_r2: -0.0652 - val_loss: 87.5443 - val_keras_r2: -0.0496\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.6732 - keras_r2: -0.0455 - val_loss: 87.1961 - val_keras_r2: -0.0436\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.5092 - keras_r2: -0.7325 - val_loss: 87.1439 - val_keras_r2: -0.0424\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4835 - keras_r2: -0.0332 - val_loss: 87.1331 - val_keras_r2: -0.0420\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4780 - keras_r2: -0.0354 - val_loss: 87.1329 - val_keras_r2: -0.0419\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4708 - keras_r2: -0.0393 - val_loss: 87.1349 - val_keras_r2: -0.0417\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4765 - keras_r2: -0.0427 - val_loss: 87.1413 - val_keras_r2: -0.0417\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4769 - keras_r2: -0.0403 - val_loss: 87.1327 - val_keras_r2: -0.0419\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4779 - keras_r2: -0.1195 - val_loss: 87.1352 - val_keras_r2: -0.0417\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4775 - keras_r2: -0.0427 - val_loss: 87.1327 - val_keras_r2: -0.0419\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4754 - keras_r2: -0.0316 - val_loss: 87.1336 - val_keras_r2: -0.0418\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4720 - keras_r2: -0.1094 - val_loss: 87.1352 - val_keras_r2: -0.0417\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4778 - keras_r2: -0.0897 - val_loss: 87.1328 - val_keras_r2: -0.0419\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4755 - keras_r2: -0.0753 - val_loss: 87.1327 - val_keras_r2: -0.0419\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4779 - keras_r2: -0.0358 - val_loss: 87.1333 - val_keras_r2: -0.0418\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4737 - keras_r2: -0.4710 - val_loss: 87.1391 - val_keras_r2: -0.0417\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4753 - keras_r2: -0.0386 - val_loss: 87.1329 - val_keras_r2: -0.0419\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4803 - keras_r2: -0.2148 - val_loss: 87.1371 - val_keras_r2: -0.0417\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4763 - keras_r2: -0.0351 - val_loss: 87.1369 - val_keras_r2: -0.0417\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4749 - keras_r2: -157338.5938 - val_loss: 87.1349 - val_keras_r2: -0.0417\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4770 - keras_r2: -0.0486 - val_loss: 87.1418 - val_keras_r2: -0.0417\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4815 - keras_r2: -0.0683 - val_loss: 87.1421 - val_keras_r2: -0.0417\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4786 - keras_r2: -0.0815 - val_loss: 87.1344 - val_keras_r2: -0.0420\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.4790 - keras_r2: -0.0376 - val_loss: 87.1330 - val_keras_r2: -0.0419\n",
            "Epoch 27: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=5, n_neurons=5; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 1285.4858 - keras_r2: -15.5262 - val_loss: 390.8976 - val_keras_r2: -4.1519\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 210.6634 - keras_r2: -1.7140 - val_loss: 124.2379 - val_keras_r2: -0.5580\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 100.2253 - keras_r2: -0.2834 - val_loss: 91.6947 - val_keras_r2: -0.1103\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.9507 - keras_r2: -0.0738 - val_loss: 87.7438 - val_keras_r2: -0.0528\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4581 - keras_r2: -0.0631 - val_loss: 87.3082 - val_keras_r2: -0.0457\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.3106 - keras_r2: -0.0391 - val_loss: 87.1682 - val_keras_r2: -0.0430\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2834 - keras_r2: -0.0419 - val_loss: 87.1494 - val_keras_r2: -0.0426\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2800 - keras_r2: -0.0353 - val_loss: 87.1400 - val_keras_r2: -0.0423\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2815 - keras_r2: -0.0472 - val_loss: 87.1767 - val_keras_r2: -0.0432\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2817 - keras_r2: -0.0320 - val_loss: 87.1482 - val_keras_r2: -0.0425\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2827 - keras_r2: -0.0389 - val_loss: 87.1536 - val_keras_r2: -0.0427\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2813 - keras_r2: -0.0340 - val_loss: 87.1478 - val_keras_r2: -0.0425\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2830 - keras_r2: -0.1380 - val_loss: 87.1402 - val_keras_r2: -0.0423\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2785 - keras_r2: -0.0429 - val_loss: 87.1755 - val_keras_r2: -0.0432\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2817 - keras_r2: -0.9989 - val_loss: 87.1447 - val_keras_r2: -0.0424\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2839 - keras_r2: -0.0456 - val_loss: 87.1538 - val_keras_r2: -0.0427\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2815 - keras_r2: -0.0355 - val_loss: 87.1465 - val_keras_r2: -0.0425\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2817 - keras_r2: -0.0354 - val_loss: 87.1525 - val_keras_r2: -0.0426\n",
            "Epoch 18: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=5, n_neurons=5; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 893.2779 - keras_r2: -12.2346 - val_loss: 309.3742 - val_keras_r2: -3.1044\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 174.1285 - keras_r2: -1.2007 - val_loss: 113.9485 - val_keras_r2: -0.4620\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.8788 - keras_r2: -0.1819 - val_loss: 88.0857 - val_keras_r2: -0.1038\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.4197 - keras_r2: -0.0606 - val_loss: 84.3780 - val_keras_r2: -0.0498\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.3585 - keras_r2: -0.0825 - val_loss: 83.6712 - val_keras_r2: -0.0388\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2219 - keras_r2: -0.0526 - val_loss: 83.5455 - val_keras_r2: -0.0367\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2144 - keras_r2: -0.0381 - val_loss: 83.5291 - val_keras_r2: -0.0364\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2113 - keras_r2: -0.0315 - val_loss: 83.4864 - val_keras_r2: -0.0357\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2088 - keras_r2: -0.0767 - val_loss: 83.6228 - val_keras_r2: -0.0380\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2115 - keras_r2: -0.0369 - val_loss: 83.4728 - val_keras_r2: -0.0355\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2091 - keras_r2: -0.0381 - val_loss: 83.5429 - val_keras_r2: -0.0367\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2122 - keras_r2: -0.0354 - val_loss: 83.4843 - val_keras_r2: -0.0357\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2089 - keras_r2: -0.0361 - val_loss: 83.4647 - val_keras_r2: -0.0353\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2141 - keras_r2: -0.0429 - val_loss: 83.4351 - val_keras_r2: -0.0348\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2112 - keras_r2: -0.0366 - val_loss: 83.4534 - val_keras_r2: -0.0351\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2103 - keras_r2: -0.0362 - val_loss: 83.4226 - val_keras_r2: -0.0346\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2132 - keras_r2: -0.0459 - val_loss: 83.4180 - val_keras_r2: -0.0345\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2122 - keras_r2: -0.0349 - val_loss: 83.4588 - val_keras_r2: -0.0352\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2120 - keras_r2: -0.0497 - val_loss: 83.3922 - val_keras_r2: -0.0340\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2141 - keras_r2: -0.0373 - val_loss: 83.4007 - val_keras_r2: -0.0342\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2128 - keras_r2: -0.0346 - val_loss: 83.4274 - val_keras_r2: -0.0347\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2077 - keras_r2: -0.0403 - val_loss: 83.5293 - val_keras_r2: -0.0364\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2131 - keras_r2: -0.0398 - val_loss: 83.4561 - val_keras_r2: -0.0352\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2178 - keras_r2: -0.0474 - val_loss: 83.4572 - val_keras_r2: -0.0352\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2113 - keras_r2: -0.0484 - val_loss: 83.4909 - val_keras_r2: -0.0358\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2100 - keras_r2: -0.0332 - val_loss: 83.4737 - val_keras_r2: -0.0355\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.2151 - keras_r2: -0.0381 - val_loss: 83.4923 - val_keras_r2: -0.0358\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2111 - keras_r2: -0.0325 - val_loss: 83.4886 - val_keras_r2: -0.0357\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.2113 - keras_r2: -0.0416 - val_loss: 83.4804 - val_keras_r2: -0.0356\n",
            "Epoch 29: early stopping\n",
            "[CV] END ...........activation=relu, n_hidden=5, n_neurons=5; total time=  21.1s\n",
            "Epoch 1/100\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 249.6633 - keras_r2: -2.2123 - val_loss: 87.6633 - val_keras_r2: -0.0746\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 86.5537 - keras_r2: -0.0513 - val_loss: 86.1094 - val_keras_r2: -0.0515\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 86.1485 - keras_r2: -0.0475 - val_loss: 86.0797 - val_keras_r2: -0.0486\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.7596 - keras_r2: -0.0379 - val_loss: 86.1978 - val_keras_r2: -0.0528\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.4790 - keras_r2: -0.0341 - val_loss: 86.0428 - val_keras_r2: -0.0500\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5940 - keras_r2: -0.0320 - val_loss: 86.1908 - val_keras_r2: -0.0482\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5559 - keras_r2: -0.0380 - val_loss: 86.7233 - val_keras_r2: -0.0614\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5164 - keras_r2: -0.0288 - val_loss: 86.4901 - val_keras_r2: -0.0576\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5877 - keras_r2: -0.0402 - val_loss: 86.7590 - val_keras_r2: -0.0619\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5989 - keras_r2: -0.0354 - val_loss: 86.0126 - val_keras_r2: -0.0494\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.4825 - keras_r2: -0.0369 - val_loss: 85.8980 - val_keras_r2: -0.0463\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5108 - keras_r2: -0.0345 - val_loss: 85.9550 - val_keras_r2: -0.0482\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5148 - keras_r2: -0.0408 - val_loss: 86.9374 - val_keras_r2: -0.0647\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5040 - keras_r2: -0.0325 - val_loss: 86.3196 - val_keras_r2: -0.0548\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.6578 - keras_r2: -0.0423 - val_loss: 85.9210 - val_keras_r2: -0.0474\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5099 - keras_r2: -0.0360 - val_loss: 86.2283 - val_keras_r2: -0.0533\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5282 - keras_r2: -0.0341 - val_loss: 86.1866 - val_keras_r2: -0.0526\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5932 - keras_r2: -0.0352 - val_loss: 86.3800 - val_keras_r2: -0.0558\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5842 - keras_r2: -0.0378 - val_loss: 86.4307 - val_keras_r2: -0.0506\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.5363 - keras_r2: -0.0365 - val_loss: 85.9082 - val_keras_r2: -0.0471\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 85.6302 - keras_r2: -0.0440 - val_loss: 86.2025 - val_keras_r2: -0.0529\n",
            "Epoch 21: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'activation': 'elu', 'n_hidden': 4, 'n_neurons': 23}"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_distribs_2 = {\n",
        "    \"n_hidden\": [1, 2, 3, 4, 5],\n",
        "    \"n_neurons\": np.arange(1, 100),\n",
        "    \"activation\": [\"relu\", \"elu\", \"sigmoid\", \"tanh\"],\n",
        "}\n",
        "\n",
        "rnd_search_cv_2 = RandomizedSearchCV(keras_class, param_distribs_2, n_iter=10, cv=kFold, verbose=2, scoring=\"r2\")\n",
        "rnd_search_cv_2.fit(X_train_keras, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping_grid_search])\n",
        "rnd_search_cv_2.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9EYLpf3bPjP",
        "outputId": "e0778d50-2e79-492d-980a-01863c806f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 23)                1541      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 23)                552       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 23)                552       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 23)                552       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,221\n",
            "Trainable params: 3,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "history_2 = History()\n",
        "\n",
        "model_2 = Sequential()\n",
        "model_2.add(keras.layers.InputLayer(input_shape=X_train_keras.shape[1],))\n",
        "model_2.add(Dense(23, activation=\"elu\"))\n",
        "model_2.add(Dense(23, activation=\"elu\"))\n",
        "model_2.add(Dense(23, activation=\"elu\"))\n",
        "model_2.add(Dense(23, activation=\"elu\"))\n",
        "model_2.add(Dense(1,activation=\"relu\"))\n",
        "model_2.summary()\n",
        "\n",
        "model_2.compile(loss=\"mean_squared_error\",optimizer=\"sgd\", metrics=[keras_r2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_8clWk5bgCp",
        "outputId": "511b60a7-ecec-426d-e329-edee444d9aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 1.4817 - keras_r2: -0.7015 - val_loss: 0.7808 - val_keras_r2: 0.0239\n",
            "Epoch 2/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7185 - keras_r2: 0.1299 - val_loss: 0.6704 - val_keras_r2: 0.1763\n",
            "Epoch 3/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6993 - keras_r2: 0.1591 - val_loss: 0.6617 - val_keras_r2: 0.1839\n",
            "Epoch 4/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6946 - keras_r2: 0.1638 - val_loss: 0.6606 - val_keras_r2: 0.1853\n",
            "Epoch 5/100\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6857 - keras_r2: 0.1774 - val_loss: 0.6734 - val_keras_r2: 0.1703\n",
            "Epoch 6/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6807 - keras_r2: 0.1803 - val_loss: 0.6540 - val_keras_r2: 0.1837\n",
            "Epoch 7/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6766 - keras_r2: 0.1811 - val_loss: 0.6396 - val_keras_r2: 0.2111\n",
            "Epoch 8/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6714 - keras_r2: 0.1976 - val_loss: 0.6409 - val_keras_r2: 0.2112\n",
            "Epoch 9/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.2014 - val_loss: 0.6729 - val_keras_r2: 0.1660\n",
            "Epoch 10/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.2040 - val_loss: 0.6194 - val_keras_r2: 0.2305\n",
            "Epoch 11/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6592 - keras_r2: 0.2074 - val_loss: 0.6285 - val_keras_r2: 0.2137\n",
            "Epoch 12/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6566 - keras_r2: 0.2092 - val_loss: 0.6112 - val_keras_r2: 0.2416\n",
            "Epoch 13/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6533 - keras_r2: 0.2141 - val_loss: 0.6115 - val_keras_r2: 0.2405\n",
            "Epoch 14/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6519 - keras_r2: 0.2193 - val_loss: 0.7164 - val_keras_r2: 0.0797\n",
            "Epoch 15/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6454 - keras_r2: 0.2285 - val_loss: 0.6265 - val_keras_r2: 0.2203\n",
            "Epoch 16/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6452 - keras_r2: 0.2351 - val_loss: 0.6136 - val_keras_r2: 0.2366\n",
            "Epoch 17/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6443 - keras_r2: 0.2238 - val_loss: 0.6190 - val_keras_r2: 0.2331\n",
            "Epoch 18/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6417 - keras_r2: 0.2327 - val_loss: 0.6502 - val_keras_r2: 0.1944\n",
            "Epoch 19/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6380 - keras_r2: 0.2296 - val_loss: 0.7852 - val_keras_r2: -0.0278\n",
            "Epoch 20/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6401 - keras_r2: 0.2353 - val_loss: 0.6633 - val_keras_r2: 0.1739\n",
            "Epoch 21/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6401 - keras_r2: 0.2279 - val_loss: 0.6445 - val_keras_r2: 0.2009\n",
            "Epoch 22/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6353 - keras_r2: 0.2331 - val_loss: 0.6053 - val_keras_r2: 0.2441\n",
            "Epoch 23/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6338 - keras_r2: 0.2407 - val_loss: 0.6083 - val_keras_r2: 0.2415\n",
            "Epoch 24/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6333 - keras_r2: 0.2425 - val_loss: 0.6188 - val_keras_r2: 0.2206\n",
            "Epoch 25/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6312 - keras_r2: 0.2429 - val_loss: 0.6297 - val_keras_r2: 0.2178\n",
            "Epoch 26/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6306 - keras_r2: 0.2425 - val_loss: 0.6140 - val_keras_r2: 0.2358\n",
            "Epoch 27/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6267 - keras_r2: 0.2512 - val_loss: 0.6140 - val_keras_r2: 0.2344\n",
            "Epoch 28/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6249 - keras_r2: 0.2463 - val_loss: 0.6188 - val_keras_r2: 0.2226\n",
            "Epoch 29/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6257 - keras_r2: 0.2466 - val_loss: 0.6044 - val_keras_r2: 0.2453\n",
            "Epoch 30/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6236 - keras_r2: 0.2441 - val_loss: 0.6298 - val_keras_r2: 0.2212\n",
            "Epoch 31/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6228 - keras_r2: 0.2498 - val_loss: 0.6155 - val_keras_r2: 0.2270\n",
            "Epoch 32/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6233 - keras_r2: 0.2520 - val_loss: 0.6404 - val_keras_r2: 0.1823\n",
            "Epoch 33/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6186 - keras_r2: 0.2618 - val_loss: 0.6241 - val_keras_r2: 0.2226\n",
            "Epoch 34/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6194 - keras_r2: 0.2535 - val_loss: 0.6262 - val_keras_r2: 0.2199\n",
            "Epoch 35/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6213 - keras_r2: 0.2487 - val_loss: 0.6104 - val_keras_r2: 0.2376\n",
            "Epoch 36/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6173 - keras_r2: 0.2554 - val_loss: 0.5981 - val_keras_r2: 0.2496\n",
            "Epoch 37/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6150 - keras_r2: 0.2640 - val_loss: 0.6179 - val_keras_r2: 0.2257\n",
            "Epoch 38/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6126 - keras_r2: 0.2631 - val_loss: 0.6125 - val_keras_r2: 0.2373\n",
            "Epoch 39/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6125 - keras_r2: 0.2539 - val_loss: 0.6465 - val_keras_r2: 0.1912\n",
            "Epoch 40/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6094 - keras_r2: 0.2679 - val_loss: 0.6139 - val_keras_r2: 0.2331\n",
            "Epoch 41/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6091 - keras_r2: 0.2627 - val_loss: 0.6214 - val_keras_r2: 0.2255\n",
            "Epoch 42/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6073 - keras_r2: 0.2704 - val_loss: 0.6115 - val_keras_r2: 0.2359\n",
            "Epoch 43/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6072 - keras_r2: 0.2685 - val_loss: 0.6103 - val_keras_r2: 0.2352\n",
            "Epoch 44/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6061 - keras_r2: 0.2715 - val_loss: 0.6359 - val_keras_r2: 0.1857\n",
            "Epoch 45/100\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.6053 - keras_r2: 0.2709 - val_loss: 0.6145 - val_keras_r2: 0.2311\n",
            "Epoch 46/100\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6024 - keras_r2: 0.2754 - val_loss: 0.6117 - val_keras_r2: 0.2351\n",
            "Epoch 46: early stopping\n"
          ]
        }
      ],
      "source": [
        "history_2 = model_2.fit(X_train_keras, y_train, validation_data=(\n",
        "    X_test_keras, y_test), batch_size=32, epochs=100, callbacks=[EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cRqL-7zb1qg",
        "outputId": "b45138af-1b6d-4071-c3e8-f54cd644fb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6117 - keras_r2: 0.2351\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6116870045661926, 0.2351062148809433]"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.evaluate(X_test_keras, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "biR6ACZhb7zm",
        "outputId": "e15b791d-f6d7-4a3f-ef15-4564c72b3cb7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.ylim(ymin=0, ymax=1)\n",
        "\n",
        "plt.plot(history_2.history['loss'], label=\"loss\")\n",
        "plt.plot(history_2.history['val_loss'], label=\"val_loss \")\n",
        "\n",
        "plt.plot(history_2.history['keras_r2'], label=\"r2\")\n",
        "plt.plot(history_2.history['val_keras_r2'], label=\"val_r2\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podobnie jak w poprzednim modelu parametry zostały dobrane za pomocą `randomized search`, a więc nie ma mimo wielokrotnego przeszukiwania gwarancji, że są one optymalne.\n",
        "\n",
        "Jako, że w odróżnieniu od modelu poprzedniego dla tego modelu testowane są również różne funkcje aktywacji, model jest nieco lepszy, ale nie daje to (przynajmniej dla hiperparametrów wybranych w `randomized search`) zbyt dużego wpływu na ostateczny wynik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT-vsncVk56I"
      },
      "source": [
        "3. Karas Randomized Search CV (liczba warstw + liczba neuronów + funkcja aktywacji + normalizacja + dropout)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-oS5X8Rk4vn",
        "outputId": "c0c12ed4-474a-4ccc-a4bd-606e60c5c114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 3s 6ms/step - loss: 237.2287 - keras_r2: -4.2866 - val_loss: 76.7985 - val_keras_r2: 0.0996\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 125.2039 - keras_r2: -0.6041 - val_loss: 79.5292 - val_keras_r2: 0.0684\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 113.9511 - keras_r2: -0.6522 - val_loss: 74.5797 - val_keras_r2: 0.1288\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 109.3372 - keras_r2: -0.4478 - val_loss: 74.7149 - val_keras_r2: 0.1252\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 104.2877 - keras_r2: -0.4131 - val_loss: 81.2418 - val_keras_r2: 0.0253\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 97.8899 - keras_r2: -0.2290 - val_loss: 77.3570 - val_keras_r2: 0.0796\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 93.9588 - keras_r2: -0.1966 - val_loss: 73.6557 - val_keras_r2: 0.1356\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 96.7085 - keras_r2: -0.2079 - val_loss: 74.7514 - val_keras_r2: 0.1247\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 5ms/step - loss: 94.0393 - keras_r2: -0.1697 - val_loss: 75.6925 - val_keras_r2: 0.1118\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 91.4101 - keras_r2: -0.1481 - val_loss: 74.0304 - val_keras_r2: 0.1291\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 91.5340 - keras_r2: -0.3135 - val_loss: 86.9569 - val_keras_r2: -0.0574\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 88.8654 - keras_r2: -0.2936 - val_loss: 79.6008 - val_keras_r2: 0.0466\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.9593 - keras_r2: -0.5970 - val_loss: 74.0498 - val_keras_r2: 0.1309\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 87.7312 - keras_r2: -0.1180 - val_loss: 122.9988 - val_keras_r2: -0.5486\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 87.2280 - keras_r2: -0.0961 - val_loss: 73.7687 - val_keras_r2: 0.1341\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 84.7117 - keras_r2: -0.1426 - val_loss: 73.2247 - val_keras_r2: 0.1394\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.4815 - keras_r2: -0.0674 - val_loss: 73.7416 - val_keras_r2: 0.1279\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.7043 - keras_r2: -0.0999 - val_loss: 74.0940 - val_keras_r2: 0.1316\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 82.3981 - keras_r2: -0.0249 - val_loss: 73.5876 - val_keras_r2: 0.1332\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.2237 - keras_r2: -0.0702 - val_loss: 75.7956 - val_keras_r2: 0.0986\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.7658 - keras_r2: -6338382.0000 - val_loss: 74.1538 - val_keras_r2: 0.1311\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.5885 - keras_r2: 0.0103 - val_loss: 73.4317 - val_keras_r2: 0.1363\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.9556 - keras_r2: -6.3703 - val_loss: 94.7547 - val_keras_r2: -0.1665\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.5943 - keras_r2: 0.0358 - val_loss: 74.5460 - val_keras_r2: 0.1147\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.0256 - keras_r2: 0.0189 - val_loss: 75.0789 - val_keras_r2: 0.1088\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.4444 - keras_r2: 0.0521 - val_loss: 74.3725 - val_keras_r2: 0.1184\n",
            "Epoch 26: early stopping\n",
            "[CV] END activation=elu, batch_normalization=True, dropout=0.2, n_hidden=2, n_neurons=9; total time=  22.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 29s 159ms/step - loss: 261.8828 - keras_r2: -2.4373 - val_loss: 75.8817 - val_keras_r2: 0.0903\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 121.3680 - keras_r2: -4.0944 - val_loss: 78.2560 - val_keras_r2: 0.0704\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 109.1432 - keras_r2: -2228463.2500 - val_loss: 72.0396 - val_keras_r2: 0.1468\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 103.0483 - keras_r2: -0.4874 - val_loss: 85.7185 - val_keras_r2: -0.0484\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 99.3580 - keras_r2: -0.2381 - val_loss: 74.1579 - val_keras_r2: 0.1128\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 98.1788 - keras_r2: -0.2246 - val_loss: 72.5848 - val_keras_r2: 0.1384\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 95.0197 - keras_r2: -0.2413 - val_loss: 73.0332 - val_keras_r2: 0.1292\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 93.9951 - keras_r2: -0.9161 - val_loss: 74.1359 - val_keras_r2: 0.1222\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 94.0540 - keras_r2: -0.2588 - val_loss: 73.2117 - val_keras_r2: 0.1278\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.7761 - keras_r2: -0.2379 - val_loss: 72.5660 - val_keras_r2: 0.1374\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.2100 - keras_r2: -3589789.0000 - val_loss: 72.4302 - val_keras_r2: 0.1405\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.5454 - keras_r2: -0.6275 - val_loss: 73.0317 - val_keras_r2: 0.1315\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.4377 - keras_r2: -0.1236 - val_loss: 73.2345 - val_keras_r2: 0.1274\n",
            "Epoch 13: early stopping\n",
            "[CV] END activation=elu, batch_normalization=True, dropout=0.2, n_hidden=2, n_neurons=9; total time=  34.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 256.6244 - keras_r2: -2.6709 - val_loss: 87.6664 - val_keras_r2: -0.0618\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 122.1719 - keras_r2: -0.5612 - val_loss: 89.8579 - val_keras_r2: -0.0947\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 112.5216 - keras_r2: -0.5704 - val_loss: 130.7336 - val_keras_r2: -0.6568\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 108.4134 - keras_r2: -0.5140 - val_loss: 82.7343 - val_keras_r2: 0.0026\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 102.7976 - keras_r2: -16658175.0000 - val_loss: 82.0238 - val_keras_r2: 0.0354\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 100.3410 - keras_r2: -0.2413 - val_loss: 76.9460 - val_keras_r2: 0.0850\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 100.7035 - keras_r2: -0.4891 - val_loss: 73.9954 - val_keras_r2: 0.1277\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 99.5998 - keras_r2: -14120087.0000 - val_loss: 80.7098 - val_keras_r2: 0.0513\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 96.0692 - keras_r2: -0.2082 - val_loss: 73.9854 - val_keras_r2: 0.1333\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 94.1408 - keras_r2: -0.1889 - val_loss: 97.5562 - val_keras_r2: -0.2026\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 90.3150 - keras_r2: -0.5711 - val_loss: 73.6814 - val_keras_r2: 0.1354\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.5495 - keras_r2: -0.2663 - val_loss: 74.0156 - val_keras_r2: 0.1278\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.7176 - keras_r2: -0.0997 - val_loss: 73.1674 - val_keras_r2: 0.1391\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 86.6325 - keras_r2: -0.8763 - val_loss: 76.6580 - val_keras_r2: 0.0873\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.1335 - keras_r2: -0.0893 - val_loss: 75.0808 - val_keras_r2: 0.1102\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 86.7399 - keras_r2: -0.0959 - val_loss: 82.8156 - val_keras_r2: 0.0255\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.7947 - keras_r2: -0.0633 - val_loss: 75.6015 - val_keras_r2: 0.1019\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.6410 - keras_r2: -0.1607 - val_loss: 73.3199 - val_keras_r2: 0.1398\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.1129 - keras_r2: -0.1179 - val_loss: 74.7142 - val_keras_r2: 0.1165\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.8981 - keras_r2: -0.0176 - val_loss: 75.6027 - val_keras_r2: 0.1123\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.9270 - keras_r2: -0.0227 - val_loss: 74.5593 - val_keras_r2: 0.1172\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.3913 - keras_r2: -9.0843e-04 - val_loss: 76.3105 - val_keras_r2: 0.0917\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.6802 - keras_r2: -4.1493e-04 - val_loss: 74.7954 - val_keras_r2: 0.1136\n",
            "Epoch 23: early stopping\n",
            "[CV] END activation=elu, batch_normalization=True, dropout=0.2, n_hidden=2, n_neurons=9; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 286.3000 - keras_r2: -2.6437 - val_loss: 83.8657 - val_keras_r2: -0.0150\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 124.2250 - keras_r2: -0.7270 - val_loss: 73.3151 - val_keras_r2: 0.1382\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 108.2929 - keras_r2: -0.3680 - val_loss: 73.1866 - val_keras_r2: 0.1407\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 104.0948 - keras_r2: -0.3087 - val_loss: 76.9077 - val_keras_r2: 0.0812\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 102.7866 - keras_r2: -0.2945 - val_loss: 81.3430 - val_keras_r2: 0.0212\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 97.6994 - keras_r2: -0.2323 - val_loss: 73.6206 - val_keras_r2: 0.1361\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 95.9934 - keras_r2: -0.1948 - val_loss: 73.8267 - val_keras_r2: 0.1261\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 94.4145 - keras_r2: -729393.5000 - val_loss: 74.1656 - val_keras_r2: 0.1219\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.9304 - keras_r2: -0.1674 - val_loss: 84.5349 - val_keras_r2: -0.0267\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.2553 - keras_r2: -0.1226 - val_loss: 74.9293 - val_keras_r2: 0.1109\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.4792 - keras_r2: -0.1149 - val_loss: 78.3176 - val_keras_r2: 0.0621\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 89.8201 - keras_r2: -0.1563 - val_loss: 75.1144 - val_keras_r2: 0.1082\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 86.2523 - keras_r2: -0.0763 - val_loss: 73.7428 - val_keras_r2: 0.1280\n",
            "Epoch 13: early stopping\n",
            "[CV] END activation=elu, batch_normalization=True, dropout=0.2, n_hidden=2, n_neurons=9; total time=  11.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 211.9986 - keras_r2: -1.9753 - val_loss: 73.5818 - val_keras_r2: 0.0838\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 110.9878 - keras_r2: -0.4160 - val_loss: 81.9708 - val_keras_r2: -0.0386\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 107.9607 - keras_r2: -0.3709 - val_loss: 68.0450 - val_keras_r2: 0.1610\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 103.7698 - keras_r2: -0.3131 - val_loss: 68.7427 - val_keras_r2: 0.1471\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 102.5647 - keras_r2: -0.3129 - val_loss: 73.4441 - val_keras_r2: 0.0768\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 99.2038 - keras_r2: -0.2494 - val_loss: 70.2221 - val_keras_r2: 0.1311\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 96.1884 - keras_r2: -0.1953 - val_loss: 66.6410 - val_keras_r2: 0.1711\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 95.0530 - keras_r2: -0.1858 - val_loss: 69.8836 - val_keras_r2: 0.1263\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 92.1436 - keras_r2: -0.1644 - val_loss: 67.2414 - val_keras_r2: 0.1700\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 91.2099 - keras_r2: -0.1353 - val_loss: 73.8977 - val_keras_r2: 0.0693\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 90.0824 - keras_r2: -0.1273 - val_loss: 69.0601 - val_keras_r2: 0.1402\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 88.1251 - keras_r2: -0.1690 - val_loss: 86.5470 - val_keras_r2: -0.1028\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 87.3650 - keras_r2: -0.0864 - val_loss: 66.8433 - val_keras_r2: 0.1738\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.4619 - keras_r2: -0.0916 - val_loss: 67.1278 - val_keras_r2: 0.1724\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.4146 - keras_r2: -0.0460 - val_loss: 87.3928 - val_keras_r2: -0.1133\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 84.9194 - keras_r2: -0.0477 - val_loss: 70.5170 - val_keras_r2: 0.1162\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.8086 - keras_r2: -0.0129 - val_loss: 68.8190 - val_keras_r2: 0.1411\n",
            "Epoch 17: early stopping\n",
            "[CV] END activation=elu, batch_normalization=True, dropout=0.2, n_hidden=2, n_neurons=9; total time=  11.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 181.2970 - keras_r2: -1.2017 - val_loss: 93.6582 - val_keras_r2: -0.1461\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.9038 - keras_r2: 0.0781 - val_loss: 74.2612 - val_keras_r2: 0.1175\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.0076 - keras_r2: 0.1143 - val_loss: 74.7219 - val_keras_r2: 0.1147\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.2995 - keras_r2: 0.1211 - val_loss: 75.3222 - val_keras_r2: 0.1152\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.5244 - keras_r2: 0.1071 - val_loss: 92.8555 - val_keras_r2: -0.1061\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.5684 - keras_r2: 0.0760 - val_loss: 83.5159 - val_keras_r2: 0.0145\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.4007 - keras_r2: 0.1308 - val_loss: 77.9383 - val_keras_r2: 0.0655\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1744 - keras_r2: 0.1445 - val_loss: 72.8315 - val_keras_r2: 0.1410\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4251 - keras_r2: 0.1246 - val_loss: 81.2158 - val_keras_r2: 0.0418\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.2825 - keras_r2: 0.1610 - val_loss: 73.9598 - val_keras_r2: 0.1309\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5359 - keras_r2: 0.1315 - val_loss: 93.9258 - val_keras_r2: -0.1592\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.9215 - keras_r2: 0.1665 - val_loss: 479.4702 - val_keras_r2: -5.3219\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.8820 - keras_r2: 0.0851 - val_loss: 91.2286 - val_keras_r2: -0.1126\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0201 - keras_r2: 0.1496 - val_loss: 73.4529 - val_keras_r2: 0.1325\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4248 - keras_r2: 0.1424 - val_loss: 250.3740 - val_keras_r2: -2.2524\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0101 - keras_r2: 0.1243 - val_loss: 72.3508 - val_keras_r2: 0.1472\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.2290 - keras_r2: -127322.4922 - val_loss: 73.4789 - val_keras_r2: 0.1353\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.4437 - keras_r2: 0.1196 - val_loss: 90.2032 - val_keras_r2: -0.0773\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.4861 - keras_r2: 0.1716 - val_loss: 137.7703 - val_keras_r2: -0.7664\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.9202 - keras_r2: 0.1349 - val_loss: 74.3435 - val_keras_r2: 0.1105\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9117 - keras_r2: 0.1698 - val_loss: 87.8114 - val_keras_r2: -0.0817\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2188 - keras_r2: 0.1852 - val_loss: 114.5891 - val_keras_r2: -0.4550\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.6505 - keras_r2: 0.1732 - val_loss: 94.2038 - val_keras_r2: -0.1313\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3066 - keras_r2: 0.1785 - val_loss: 74.8029 - val_keras_r2: 0.1154\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.3859 - keras_r2: 0.1723 - val_loss: 88.9373 - val_keras_r2: -0.0986\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.2867 - keras_r2: -0.8284 - val_loss: 90.4203 - val_keras_r2: -0.1176\n",
            "Epoch 26: early stopping\n",
            "[CV] END activation=elu, batch_normalization=False, dropout=0.1, n_hidden=4, n_neurons=67; total time=  12.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 2510.1040 - keras_r2: -33.3130 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 3855.0811 - keras_r2: -49.6439 - val_loss: 1861.5024 - val_keras_r2: -23.9317\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: nan - keras_r2: nan - val_loss: nan - val_keras_r2: nan\n",
            "Epoch 11: early stopping\n",
            "[CV] END activation=elu, batch_normalization=False, dropout=0.1, n_hidden=4, n_neurons=67; total time=  11.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 286.5804 - keras_r2: -2.8632 - val_loss: 94.8066 - val_keras_r2: -0.1539\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.5544 - keras_r2: -0.1209 - val_loss: 95.1116 - val_keras_r2: -0.1380\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.2310 - keras_r2: -0.0909 - val_loss: 87.5634 - val_keras_r2: -0.0450\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.6742 - keras_r2: -0.7949 - val_loss: 113.3607 - val_keras_r2: -0.3754\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 89.6128 - keras_r2: -0.1272 - val_loss: 86.0952 - val_keras_r2: -0.0323\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.6642 - keras_r2: -0.0484 - val_loss: 85.3818 - val_keras_r2: -0.0191\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.9300 - keras_r2: -0.0218 - val_loss: 80.1885 - val_keras_r2: 0.0503\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.6655 - keras_r2: -0.0282 - val_loss: 124.2735 - val_keras_r2: -0.5274\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.5352 - keras_r2: -0.0069 - val_loss: 78.8528 - val_keras_r2: 0.0596\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.7783 - keras_r2: -3.1576 - val_loss: 105.0781 - val_keras_r2: -0.2666\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.5257 - keras_r2: 0.0461 - val_loss: 77.7116 - val_keras_r2: 0.0827\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.1201 - keras_r2: 0.0951 - val_loss: 78.2159 - val_keras_r2: 0.0780\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.3425 - keras_r2: 0.0431 - val_loss: 424.5260 - val_keras_r2: -4.6329\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.2887 - keras_r2: -0.1531 - val_loss: 87.4538 - val_keras_r2: -0.0433\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.1955 - keras_r2: 0.0935 - val_loss: 76.3711 - val_keras_r2: 0.0992\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.1561 - keras_r2: 0.0809 - val_loss: 77.6433 - val_keras_r2: 0.0822\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.5500 - keras_r2: 0.0906 - val_loss: 75.5884 - val_keras_r2: 0.1059\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.8682 - keras_r2: 0.0586 - val_loss: 74.0397 - val_keras_r2: 0.1259\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.7521 - keras_r2: 0.0969 - val_loss: 79.5839 - val_keras_r2: 0.0566\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.7334 - keras_r2: -0.7669 - val_loss: 93.5759 - val_keras_r2: -0.1202\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.8171 - keras_r2: 0.1411 - val_loss: 74.3589 - val_keras_r2: 0.1220\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.7106 - keras_r2: 0.1210 - val_loss: 129.6317 - val_keras_r2: -0.6613\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.8192 - keras_r2: 0.1267 - val_loss: 76.2267 - val_keras_r2: 0.1015\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.5579 - keras_r2: 0.1029 - val_loss: 85.6500 - val_keras_r2: -0.0171\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.3318 - keras_r2: 0.1214 - val_loss: 82.6377 - val_keras_r2: 6.1395e-04\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.7022 - keras_r2: -4959024.0000 - val_loss: 84.1347 - val_keras_r2: -0.0210\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.8824 - keras_r2: 0.1307 - val_loss: 82.0179 - val_keras_r2: 0.0305\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6384 - keras_r2: 0.1441 - val_loss: 85.5083 - val_keras_r2: -0.0179\n",
            "Epoch 28: early stopping\n",
            "[CV] END activation=elu, batch_normalization=False, dropout=0.1, n_hidden=4, n_neurons=67; total time=  21.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 2058.3157 - keras_r2: -26.5170 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -31.8598 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -26.2730 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.3784 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -26.4320 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.7079 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.4257 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -40.1377 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.7517 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 1933.4991 - keras_r2: -240454560.0000 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 1933.4991 - keras_r2: -24.7020 - val_loss: 1946.7059 - val_keras_r2: -24.9757\n",
            "Epoch 11: early stopping\n",
            "[CV] END activation=elu, batch_normalization=False, dropout=0.1, n_hidden=4, n_neurons=67; total time=  11.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 170.4833 - keras_r2: -1.2175 - val_loss: 477.5028 - val_keras_r2: -5.3770\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.6446 - keras_r2: -0.0070 - val_loss: 83.0165 - val_keras_r2: -0.0548\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.7971 - keras_r2: 0.0400 - val_loss: 80.9597 - val_keras_r2: 0.0025\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.2678 - keras_r2: 0.0933 - val_loss: 66.8583 - val_keras_r2: 0.1760\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.7272 - keras_r2: 0.1172 - val_loss: 67.9375 - val_keras_r2: 0.1637\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.6109 - keras_r2: 0.1188 - val_loss: 73.4349 - val_keras_r2: 0.0988\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.2781 - keras_r2: 0.1139 - val_loss: 80.1015 - val_keras_r2: -0.0254\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.4399 - keras_r2: 0.1377 - val_loss: 69.5268 - val_keras_r2: 0.1285\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6307 - keras_r2: 0.1293 - val_loss: 76.8259 - val_keras_r2: 0.0318\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.8536 - keras_r2: 0.1518 - val_loss: 65.8750 - val_keras_r2: 0.1882\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0601 - keras_r2: 0.1446 - val_loss: 71.8032 - val_keras_r2: 0.1118\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.5737 - keras_r2: 0.0788 - val_loss: 76.2183 - val_keras_r2: 0.0637\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.7679 - keras_r2: 0.1538 - val_loss: 71.4309 - val_keras_r2: 0.0935\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.9019 - keras_r2: 0.1422 - val_loss: 78.0725 - val_keras_r2: 0.0370\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.0521 - keras_r2: 0.1674 - val_loss: 66.2203 - val_keras_r2: 0.1859\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.2095 - keras_r2: 0.1779 - val_loss: 79.4429 - val_keras_r2: -0.0117\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.7710 - keras_r2: 0.1850 - val_loss: 66.0023 - val_keras_r2: 0.1790\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.7279 - keras_r2: 0.1750 - val_loss: 70.9044 - val_keras_r2: 0.1226\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.5098 - keras_r2: 0.1742 - val_loss: 68.4370 - val_keras_r2: 0.1568\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.2850 - keras_r2: 0.1878 - val_loss: 76.1097 - val_keras_r2: 0.0642\n",
            "Epoch 20: early stopping\n",
            "[CV] END activation=elu, batch_normalization=False, dropout=0.1, n_hidden=4, n_neurons=67; total time=  11.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 5ms/step - loss: 145.1539 - keras_r2: -0.9642 - val_loss: 128.6171 - val_keras_r2: -0.5894\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.8906 - keras_r2: -0.9459 - val_loss: 362.6477 - val_keras_r2: -3.7050\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.2981 - keras_r2: -0.0117 - val_loss: 347.3784 - val_keras_r2: -3.5473\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8984 - keras_r2: 0.0900 - val_loss: 80.3492 - val_keras_r2: 0.0511\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.6219 - keras_r2: 0.1394 - val_loss: 78.9338 - val_keras_r2: 0.0522\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5849 - keras_r2: 0.0929 - val_loss: 77.0958 - val_keras_r2: 0.0744\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.4405 - keras_r2: -0.1039 - val_loss: 74.8185 - val_keras_r2: 0.1104\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1062 - keras_r2: 0.1029 - val_loss: 72.4652 - val_keras_r2: 0.1439\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.7413 - keras_r2: 0.1681 - val_loss: 101.5202 - val_keras_r2: -0.2637\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.9254 - keras_r2: 0.1685 - val_loss: 94.8704 - val_keras_r2: -0.1513\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 66.1229 - keras_r2: 0.1438 - val_loss: 82.6717 - val_keras_r2: 0.0226\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.3262 - keras_r2: 0.1749 - val_loss: 91.0390 - val_keras_r2: -0.1001\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8098 - keras_r2: 0.1830 - val_loss: 2054.8679 - val_keras_r2: -25.4751\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.1414 - keras_r2: -0.1719 - val_loss: 90.3745 - val_keras_r2: -0.0743\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.6113 - keras_r2: 0.1786 - val_loss: 74.8377 - val_keras_r2: 0.1010\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 66.0981 - keras_r2: 0.1938 - val_loss: 74.5040 - val_keras_r2: 0.1157\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.1019 - keras_r2: 0.1484 - val_loss: 99.3664 - val_keras_r2: -0.2186\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.7790 - keras_r2: 0.2055 - val_loss: 92.2791 - val_keras_r2: -0.1145\n",
            "Epoch 18: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=94; total time=  12.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 157.7924 - keras_r2: -1.0901 - val_loss: 153.9489 - val_keras_r2: -0.9203\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.9085 - keras_r2: -0.0228 - val_loss: 2951.6472 - val_keras_r2: -39.6529\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.0953 - keras_r2: -0.0143 - val_loss: 185.9734 - val_keras_r2: -1.3519\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.7832 - keras_r2: 0.0787 - val_loss: 154.0479 - val_keras_r2: -0.9835\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5838 - keras_r2: -0.0137 - val_loss: 77.3610 - val_keras_r2: 0.0601\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.8455 - keras_r2: 0.0902 - val_loss: 4845.9126 - val_keras_r2: -65.7444\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6575 - keras_r2: 0.1291 - val_loss: 77.3107 - val_keras_r2: 0.0785\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.6239 - keras_r2: 0.1466 - val_loss: 75.0425 - val_keras_r2: 0.1033\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5875 - keras_r2: 0.1274 - val_loss: 90.1665 - val_keras_r2: -0.0765\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0822 - keras_r2: -0.7199 - val_loss: 80.9750 - val_keras_r2: 0.0246\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.2236 - keras_r2: 0.1656 - val_loss: 75.9205 - val_keras_r2: 0.0738\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.6120 - keras_r2: 0.0017 - val_loss: 99.6680 - val_keras_r2: -0.2192\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.0878 - keras_r2: 0.0472 - val_loss: 98.5172 - val_keras_r2: -0.2376\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.0649 - keras_r2: 0.1620 - val_loss: 75.8767 - val_keras_r2: 0.1008\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.7159 - keras_r2: 0.2022 - val_loss: 82.7699 - val_keras_r2: -0.0328\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.7292 - keras_r2: 0.1897 - val_loss: 74.6978 - val_keras_r2: 0.0937\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.5108 - keras_r2: 0.1763 - val_loss: 122.2269 - val_keras_r2: -0.5547\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.0490 - keras_r2: 0.1936 - val_loss: 71.2479 - val_keras_r2: 0.1416\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 64.2966 - keras_r2: 0.1963 - val_loss: 92.3383 - val_keras_r2: -0.1163\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.4465 - keras_r2: 0.1033 - val_loss: 96.8251 - val_keras_r2: -0.1809\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3505 - keras_r2: -1.2209 - val_loss: 82.8297 - val_keras_r2: -0.0049\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8139 - keras_r2: 0.1739 - val_loss: 96.1857 - val_keras_r2: -0.2084\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.0208 - keras_r2: -1292812.2500 - val_loss: 72.1228 - val_keras_r2: 0.1260\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.1123 - keras_r2: 0.1944 - val_loss: 84.4191 - val_keras_r2: -0.0171\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.8590 - keras_r2: 0.1525 - val_loss: 75.5474 - val_keras_r2: 0.0821\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.6385 - keras_r2: 0.1891 - val_loss: 72.5297 - val_keras_r2: 0.1332\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5851 - keras_r2: 0.2070 - val_loss: 79.6334 - val_keras_r2: 0.0323\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5913 - keras_r2: 0.1154 - val_loss: 74.5820 - val_keras_r2: 0.1024\n",
            "Epoch 28: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=94; total time=  18.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 146.4795 - keras_r2: -4177106.2500 - val_loss: 197.6352 - val_keras_r2: -1.3772\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.0280 - keras_r2: 0.0095 - val_loss: 95.2725 - val_keras_r2: -0.1780\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.9263 - keras_r2: 0.0476 - val_loss: 759.7259 - val_keras_r2: -8.5340\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2013 - keras_r2: 0.0846 - val_loss: 80.0306 - val_keras_r2: 0.0481\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8292 - keras_r2: 0.0759 - val_loss: 78.2048 - val_keras_r2: 0.0679\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.4620 - keras_r2: 0.1265 - val_loss: 74.6453 - val_keras_r2: 0.1204\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.5548 - keras_r2: 0.1176 - val_loss: 77.9835 - val_keras_r2: 0.0841\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.3396 - keras_r2: 0.0661 - val_loss: 93.4449 - val_keras_r2: -0.1032\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8748 - keras_r2: 0.1577 - val_loss: 76.3166 - val_keras_r2: 0.0977\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.8849 - keras_r2: -0.2328 - val_loss: 86.3034 - val_keras_r2: -0.0236\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.2343 - keras_r2: 0.1237 - val_loss: 1346.5298 - val_keras_r2: -16.7358\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7461 - keras_r2: 0.1319 - val_loss: 87.8060 - val_keras_r2: -0.0675\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8383 - keras_r2: 0.0899 - val_loss: 87.8233 - val_keras_r2: -0.0439\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 68.3045 - keras_r2: 0.1550 - val_loss: 93.9807 - val_keras_r2: -0.1244\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.9197 - keras_r2: 0.0449 - val_loss: 465.3492 - val_keras_r2: -4.9005\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 67.8807 - keras_r2: 0.1429 - val_loss: 75.5743 - val_keras_r2: 0.1103\n",
            "Epoch 16: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=94; total time=  11.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 140.6482 - keras_r2: -0.8540 - val_loss: 399.1010 - val_keras_r2: -3.9085\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.8401 - keras_r2: 0.0077 - val_loss: 79.6915 - val_keras_r2: 0.0559\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.8705 - keras_r2: 0.0899 - val_loss: 98.7058 - val_keras_r2: -0.1877\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.6937 - keras_r2: 0.1079 - val_loss: 302.3935 - val_keras_r2: -3.0632\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2432 - keras_r2: 0.1158 - val_loss: 235.3053 - val_keras_r2: -1.9789\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.9393 - keras_r2: 0.1114 - val_loss: 80.9189 - val_keras_r2: 0.0293\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.2935 - keras_r2: 0.1342 - val_loss: 106.6258 - val_keras_r2: -0.3204\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6280 - keras_r2: -0.1116 - val_loss: 141.1116 - val_keras_r2: -0.7288\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 68.1810 - keras_r2: 0.1638 - val_loss: 103.9175 - val_keras_r2: -0.2475\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1773 - keras_r2: 0.1750 - val_loss: 85.8059 - val_keras_r2: -0.0251\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1773 - keras_r2: 0.1603 - val_loss: 81.4140 - val_keras_r2: 0.0408\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 66.4988 - keras_r2: 0.1688 - val_loss: 78.5245 - val_keras_r2: 0.0635\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.6629 - keras_r2: 0.2011 - val_loss: 124.1017 - val_keras_r2: -0.5258\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.3788 - keras_r2: -633172.5625 - val_loss: 74.3847 - val_keras_r2: 0.1155\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.2583 - keras_r2: -0.1239 - val_loss: 77.8556 - val_keras_r2: 0.0742\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.1882 - keras_r2: 0.1870 - val_loss: 86.8309 - val_keras_r2: -0.0517\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 65.3421 - keras_r2: 0.1912 - val_loss: 76.8656 - val_keras_r2: 0.0934\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.9296 - keras_r2: 0.0963 - val_loss: 708.9269 - val_keras_r2: -8.1415\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.9803 - keras_r2: 0.2060 - val_loss: 79.3290 - val_keras_r2: 0.0641\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.8126 - keras_r2: 0.2153 - val_loss: 75.9370 - val_keras_r2: 0.1008\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3316 - keras_r2: 0.2049 - val_loss: 76.8336 - val_keras_r2: 0.0900\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 62.8257 - keras_r2: 0.2150 - val_loss: 77.3036 - val_keras_r2: 0.0948\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.0961 - keras_r2: -16916510.0000 - val_loss: 74.4522 - val_keras_r2: 0.1155\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.3085 - keras_r2: 0.2319 - val_loss: 87.5203 - val_keras_r2: -0.0708\n",
            "Epoch 24: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=94; total time=  16.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 134.6135 - keras_r2: -0.6769 - val_loss: 100.0216 - val_keras_r2: -0.2593\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.4727 - keras_r2: 0.0431 - val_loss: 77.3654 - val_keras_r2: 0.0367\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4067 - keras_r2: 0.0872 - val_loss: 71.1085 - val_keras_r2: 0.1205\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2050 - keras_r2: 0.1110 - val_loss: 85.8441 - val_keras_r2: -0.0898\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0699 - keras_r2: 0.1380 - val_loss: 113.8560 - val_keras_r2: -0.4237\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.4697 - keras_r2: 0.1427 - val_loss: 64.9543 - val_keras_r2: 0.1851\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8624 - keras_r2: 0.1466 - val_loss: 73.7205 - val_keras_r2: 0.0656\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 67.0475 - keras_r2: 0.1695 - val_loss: 80.7000 - val_keras_r2: -0.0150\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 67.2049 - keras_r2: 0.1669 - val_loss: 80.1701 - val_keras_r2: 0.0086\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.6024 - keras_r2: 0.1803 - val_loss: 69.9525 - val_keras_r2: 0.1242\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.6872 - keras_r2: 0.1855 - val_loss: 64.8026 - val_keras_r2: 0.2005\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.7969 - keras_r2: 0.1274 - val_loss: 90.7582 - val_keras_r2: -0.1591\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 63.8520 - keras_r2: 0.2196 - val_loss: 67.4476 - val_keras_r2: 0.1586\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 64.6915 - keras_r2: 0.1909 - val_loss: 75.7180 - val_keras_r2: 0.0580\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 63.5475 - keras_r2: 0.2130 - val_loss: 75.3163 - val_keras_r2: 0.0429\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.9681 - keras_r2: 0.2138 - val_loss: 65.8526 - val_keras_r2: 0.1826\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 62.5003 - keras_r2: 0.2308 - val_loss: 73.7056 - val_keras_r2: 0.0648\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 62.8970 - keras_r2: 0.2249 - val_loss: 65.4335 - val_keras_r2: 0.1835\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8595 - keras_r2: 0.2479 - val_loss: 75.3789 - val_keras_r2: 0.0380\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.1540 - keras_r2: 0.2280 - val_loss: 77.4001 - val_keras_r2: 0.0102\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 62.3677 - keras_r2: 0.2290 - val_loss: 66.4104 - val_keras_r2: 0.1740\n",
            "Epoch 21: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=94; total time=  14.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 187.2888 - keras_r2: -1.4102 - val_loss: 95.4685 - val_keras_r2: -0.0956\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.8243 - keras_r2: 0.0393 - val_loss: 85.7667 - val_keras_r2: 0.0061\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.5463 - keras_r2: 0.0505 - val_loss: 89.5417 - val_keras_r2: -0.0342\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.9701 - keras_r2: 0.0331 - val_loss: 89.7664 - val_keras_r2: -0.0480\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.4100 - keras_r2: 0.0836 - val_loss: 81.8888 - val_keras_r2: 0.0529\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.4626 - keras_r2: -0.0584 - val_loss: 79.1730 - val_keras_r2: 0.0766\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.0963 - keras_r2: 0.1178 - val_loss: 81.6466 - val_keras_r2: 0.0414\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.0063 - keras_r2: 0.1152 - val_loss: 86.0048 - val_keras_r2: -0.0264\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.3244 - keras_r2: 0.1303 - val_loss: 91.3069 - val_keras_r2: -0.0929\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.6368 - keras_r2: 0.1519 - val_loss: 78.9258 - val_keras_r2: 0.0822\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.1376 - keras_r2: 0.1143 - val_loss: 86.8207 - val_keras_r2: -0.0461\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.4292 - keras_r2: 0.1667 - val_loss: 79.4054 - val_keras_r2: 0.0739\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7033 - keras_r2: 0.1631 - val_loss: 78.7874 - val_keras_r2: 0.0677\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.8742 - keras_r2: -0.0659 - val_loss: 95.7950 - val_keras_r2: -0.1725\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9204 - keras_r2: 0.1593 - val_loss: 80.7468 - val_keras_r2: 0.0539\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9122 - keras_r2: 0.1550 - val_loss: 84.9865 - val_keras_r2: -0.0217\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7357 - keras_r2: 0.1526 - val_loss: 81.4391 - val_keras_r2: 0.0247\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6526 - keras_r2: 0.1470 - val_loss: 82.3850 - val_keras_r2: 0.0338\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.0535 - keras_r2: 0.1518 - val_loss: 130.0547 - val_keras_r2: -0.8223\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.4153 - keras_r2: 0.0999 - val_loss: 77.8176 - val_keras_r2: 0.0766\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8624 - keras_r2: 0.1723 - val_loss: 87.6975 - val_keras_r2: -0.0589\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8937 - keras_r2: 0.1310 - val_loss: 118.2818 - val_keras_r2: -0.4937\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.6769 - keras_r2: 0.1934 - val_loss: 84.0476 - val_keras_r2: -8.8893e-04\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.1902 - keras_r2: 0.1484 - val_loss: 75.6734 - val_keras_r2: 0.1103\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.7367 - keras_r2: 0.1705 - val_loss: 76.6124 - val_keras_r2: 0.1053\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.2550 - keras_r2: 0.0190 - val_loss: 88.5223 - val_keras_r2: -0.0792\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.8892 - keras_r2: 0.1376 - val_loss: 75.2632 - val_keras_r2: 0.1170\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2041 - keras_r2: 0.1478 - val_loss: 75.0009 - val_keras_r2: 0.1156\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5214 - keras_r2: -0.5023 - val_loss: 94.3773 - val_keras_r2: -0.1580\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0713 - keras_r2: 0.1605 - val_loss: 88.1651 - val_keras_r2: -0.0435\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0753 - keras_r2: -0.1893 - val_loss: 80.1943 - val_keras_r2: 0.0518\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3117 - keras_r2: 0.1748 - val_loss: 77.0158 - val_keras_r2: 0.0814\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1838 - keras_r2: 0.1978 - val_loss: 81.0023 - val_keras_r2: 0.0263\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1679 - keras_r2: 0.1681 - val_loss: 79.9166 - val_keras_r2: 0.0625\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.9397 - keras_r2: 0.1997 - val_loss: 83.1162 - val_keras_r2: -0.0093\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9229 - keras_r2: 0.1934 - val_loss: 74.0873 - val_keras_r2: 0.1281\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.4468 - keras_r2: 0.1944 - val_loss: 85.2165 - val_keras_r2: -0.0052\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8772 - keras_r2: 0.1533 - val_loss: 76.1969 - val_keras_r2: 0.1043\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4831 - keras_r2: 0.1975 - val_loss: 73.7375 - val_keras_r2: 0.1317\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0351 - keras_r2: 0.0698 - val_loss: 107.3559 - val_keras_r2: -0.3409\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6499 - keras_r2: 0.1866 - val_loss: 77.4495 - val_keras_r2: 0.0908\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5419 - keras_r2: 0.1803 - val_loss: 99.2403 - val_keras_r2: -0.2318\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1206 - keras_r2: 0.1447 - val_loss: 73.9711 - val_keras_r2: 0.1276\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9068 - keras_r2: -16636447.0000 - val_loss: 90.7334 - val_keras_r2: -0.1078\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.3761 - keras_r2: 0.1646 - val_loss: 96.2179 - val_keras_r2: -0.1852\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7028 - keras_r2: 0.2028 - val_loss: 75.2191 - val_keras_r2: 0.1050\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.8532 - keras_r2: 0.1872 - val_loss: 74.3215 - val_keras_r2: 0.1199\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9721 - keras_r2: 0.0392 - val_loss: 92.4374 - val_keras_r2: -0.1324\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.3907 - keras_r2: 0.1816 - val_loss: 76.9843 - val_keras_r2: 0.0926\n",
            "Epoch 49: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=1, n_neurons=44; total time=  41.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 178.0505 - keras_r2: -1.3300 - val_loss: 111.0002 - val_keras_r2: -0.3884\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.4785 - keras_r2: 6.7472e-05 - val_loss: 123.8040 - val_keras_r2: -0.5674\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9705 - keras_r2: 0.0444 - val_loss: 75.8487 - val_keras_r2: 0.1016\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.8253 - keras_r2: 0.0527 - val_loss: 91.9754 - val_keras_r2: -0.1328\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.7553 - keras_r2: 0.0386 - val_loss: 94.4643 - val_keras_r2: -0.1302\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.5626 - keras_r2: 0.0706 - val_loss: 80.9865 - val_keras_r2: 0.0460\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.4821 - keras_r2: -0.0984 - val_loss: 83.2453 - val_keras_r2: 0.0231\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.3443 - keras_r2: 0.1007 - val_loss: 88.6001 - val_keras_r2: -0.0850\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6554 - keras_r2: 0.1285 - val_loss: 86.3652 - val_keras_r2: -0.0602\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4952 - keras_r2: 0.1401 - val_loss: 76.3585 - val_keras_r2: 0.0922\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.1722 - keras_r2: 0.0753 - val_loss: 90.2092 - val_keras_r2: -0.0696\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.0283 - keras_r2: 0.1434 - val_loss: 81.4543 - val_keras_r2: 0.0387\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.4942 - keras_r2: 0.1214 - val_loss: 80.9481 - val_keras_r2: 0.0183\n",
            "Epoch 13: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=1, n_neurons=44; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 184.3469 - keras_r2: -1.4720 - val_loss: 113.6265 - val_keras_r2: -0.3329\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.7244 - keras_r2: -0.0932 - val_loss: 97.4914 - val_keras_r2: -0.1985\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.5681 - keras_r2: 0.0585 - val_loss: 79.6003 - val_keras_r2: 0.0748\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4216 - keras_r2: 0.0315 - val_loss: 79.4166 - val_keras_r2: 0.0718\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.6851 - keras_r2: 0.0793 - val_loss: 76.2424 - val_keras_r2: 0.1126\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.9930 - keras_r2: 0.0928 - val_loss: 77.0554 - val_keras_r2: 0.1015\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.7693 - keras_r2: 0.1269 - val_loss: 74.6680 - val_keras_r2: 0.1282\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.0023 - keras_r2: 0.1218 - val_loss: 82.0880 - val_keras_r2: 0.0466\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9330 - keras_r2: 0.1200 - val_loss: 74.9989 - val_keras_r2: 0.1265\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7287 - keras_r2: 0.1392 - val_loss: 79.4110 - val_keras_r2: 0.0734\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.2384 - keras_r2: 0.1217 - val_loss: 96.2513 - val_keras_r2: -0.1734\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.5004 - keras_r2: -0.0120 - val_loss: 95.9476 - val_keras_r2: -0.1809\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5700 - keras_r2: 0.1299 - val_loss: 102.2412 - val_keras_r2: -0.2569\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.1292 - keras_r2: 0.0999 - val_loss: 75.3450 - val_keras_r2: 0.1233\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9640 - keras_r2: 0.1514 - val_loss: 78.5282 - val_keras_r2: 0.0690\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4985 - keras_r2: -3831049.7500 - val_loss: 77.2997 - val_keras_r2: 0.1017\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.3887 - keras_r2: 0.1697 - val_loss: 76.4772 - val_keras_r2: 0.1129\n",
            "Epoch 17: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=1, n_neurons=44; total time=  11.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 168.0315 - keras_r2: -1.3910 - val_loss: 106.8777 - val_keras_r2: -0.3018\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.8079 - keras_r2: -5416952.5000 - val_loss: 104.2658 - val_keras_r2: -0.2844\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.8516 - keras_r2: 0.0711 - val_loss: 90.8609 - val_keras_r2: -0.0892\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.5674 - keras_r2: 0.0718 - val_loss: 96.5915 - val_keras_r2: -0.1607\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.1914 - keras_r2: 0.0793 - val_loss: 109.9164 - val_keras_r2: -0.3477\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.9058 - keras_r2: -0.0359 - val_loss: 84.5647 - val_keras_r2: 0.0232\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.1946 - keras_r2: 0.1009 - val_loss: 80.8841 - val_keras_r2: 0.0640\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.2461 - keras_r2: 0.1111 - val_loss: 87.0005 - val_keras_r2: -0.0253\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.8997 - keras_r2: 0.1307 - val_loss: 79.8062 - val_keras_r2: 0.0737\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4050 - keras_r2: 0.1386 - val_loss: 125.5162 - val_keras_r2: -0.4765\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4179 - keras_r2: 0.1021 - val_loss: 91.1164 - val_keras_r2: -0.0971\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.0642 - keras_r2: 0.0447 - val_loss: 83.3704 - val_keras_r2: 0.0390\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.9032 - keras_r2: 0.1594 - val_loss: 82.4207 - val_keras_r2: 0.0413\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4987 - keras_r2: 0.1440 - val_loss: 82.8071 - val_keras_r2: 0.0324\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1437 - keras_r2: 0.1425 - val_loss: 91.2677 - val_keras_r2: -0.0654\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.0299 - keras_r2: -513102.0312 - val_loss: 80.8885 - val_keras_r2: 0.0649\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3057 - keras_r2: -0.0730 - val_loss: 92.5297 - val_keras_r2: -0.0780\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.8057 - keras_r2: 0.1653 - val_loss: 81.9906 - val_keras_r2: 0.0451\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.7669 - keras_r2: 0.1507 - val_loss: 83.0696 - val_keras_r2: 0.0344\n",
            "Epoch 19: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=1, n_neurons=44; total time=   9.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 165.0015 - keras_r2: -1.1586 - val_loss: 118.8674 - val_keras_r2: -0.3994\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.8316 - keras_r2: 0.0364 - val_loss: 88.4304 - val_keras_r2: -0.0425\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.7880 - keras_r2: 0.0820 - val_loss: 88.6256 - val_keras_r2: -0.0887\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.0751 - keras_r2: 0.0875 - val_loss: 97.7094 - val_keras_r2: -0.2317\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.3950 - keras_r2: 0.1081 - val_loss: 77.1167 - val_keras_r2: 0.0557\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.0999 - keras_r2: 0.1187 - val_loss: 74.0256 - val_keras_r2: 0.1004\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.4254 - keras_r2: 0.1440 - val_loss: 71.4260 - val_keras_r2: 0.1330\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5860 - keras_r2: 0.1347 - val_loss: 73.2802 - val_keras_r2: 0.1071\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6104 - keras_r2: -0.1259 - val_loss: 75.5575 - val_keras_r2: 0.0863\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.8460 - keras_r2: 0.1556 - val_loss: 71.2842 - val_keras_r2: 0.1334\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.2700 - keras_r2: 0.1530 - val_loss: 72.7841 - val_keras_r2: 0.1009\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.6997 - keras_r2: 0.1460 - val_loss: 72.7848 - val_keras_r2: 0.1158\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7957 - keras_r2: 0.1660 - val_loss: 69.2217 - val_keras_r2: 0.1496\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.6571 - keras_r2: 0.1552 - val_loss: 73.2199 - val_keras_r2: 0.0937\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.9352 - keras_r2: 0.1522 - val_loss: 68.6719 - val_keras_r2: 0.1626\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.6567 - keras_r2: 0.1758 - val_loss: 100.4304 - val_keras_r2: -0.2870\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8195 - keras_r2: 0.1121 - val_loss: 83.0420 - val_keras_r2: -0.0136\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.7459 - keras_r2: 0.1804 - val_loss: 70.5845 - val_keras_r2: 0.1370\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.8725 - keras_r2: 0.1730 - val_loss: 71.0414 - val_keras_r2: 0.1226\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.4863 - keras_r2: 0.1808 - val_loss: 68.7055 - val_keras_r2: 0.1519\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.5027 - keras_r2: 0.1712 - val_loss: 74.7842 - val_keras_r2: 0.0646\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.1038 - keras_r2: 0.1685 - val_loss: 73.3628 - val_keras_r2: 0.1051\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.4073 - keras_r2: 0.1618 - val_loss: 74.5940 - val_keras_r2: 0.0700\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3913 - keras_r2: 0.1564 - val_loss: 68.5787 - val_keras_r2: 0.1614\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.6004 - keras_r2: 0.1704 - val_loss: 69.6575 - val_keras_r2: 0.1403\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.6150 - keras_r2: 0.1796 - val_loss: 68.1327 - val_keras_r2: 0.1641\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9084 - keras_r2: 0.1970 - val_loss: 69.9173 - val_keras_r2: 0.1319\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.5901 - keras_r2: 0.1908 - val_loss: 70.8824 - val_keras_r2: 0.1207\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.2286 - keras_r2: 0.1817 - val_loss: 79.7391 - val_keras_r2: -0.0051\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.2888 - keras_r2: 0.1535 - val_loss: 66.7152 - val_keras_r2: 0.1823\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.5526 - keras_r2: 0.2107 - val_loss: 69.3301 - val_keras_r2: 0.1527\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.3304 - keras_r2: 0.1374 - val_loss: 86.4750 - val_keras_r2: -0.1009\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.9508 - keras_r2: -16285283.0000 - val_loss: 68.5850 - val_keras_r2: 0.1613\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9703 - keras_r2: 0.1982 - val_loss: 73.4690 - val_keras_r2: 0.0819\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1006 - keras_r2: 0.2021 - val_loss: 69.0972 - val_keras_r2: 0.1406\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.7418 - keras_r2: 0.2084 - val_loss: 68.1333 - val_keras_r2: 0.1544\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.9434 - keras_r2: 0.2098 - val_loss: 69.5459 - val_keras_r2: 0.1395\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.9631 - keras_r2: 0.2053 - val_loss: 67.3455 - val_keras_r2: 0.1721\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.2482 - keras_r2: 0.2107 - val_loss: 67.5654 - val_keras_r2: 0.1713\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.7339 - keras_r2: 0.2271 - val_loss: 68.2022 - val_keras_r2: 0.1573\n",
            "Epoch 40: early stopping\n",
            "[CV] END activation=relu, batch_normalization=True, dropout=0.1, n_hidden=1, n_neurons=44; total time=  18.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 295.3728 - keras_r2: -3.4739 - val_loss: 77.8758 - val_keras_r2: 0.0655\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.9148 - keras_r2: -0.0378 - val_loss: 80.6793 - val_keras_r2: 0.0286\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.4816 - keras_r2: -0.0261 - val_loss: 74.1713 - val_keras_r2: 0.1247\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.8595 - keras_r2: 0.0138 - val_loss: 75.2704 - val_keras_r2: 0.1140\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.4327 - keras_r2: 0.0326 - val_loss: 73.2631 - val_keras_r2: 0.1401\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.8803 - keras_r2: 0.0502 - val_loss: 73.9783 - val_keras_r2: 0.1315\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.4934 - keras_r2: -0.0613 - val_loss: 89.3613 - val_keras_r2: -0.0925\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.8309 - keras_r2: 0.0088 - val_loss: 74.9260 - val_keras_r2: 0.1218\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2084 - keras_r2: 0.0498 - val_loss: 94.9308 - val_keras_r2: -0.1345\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.3340 - keras_r2: 0.0670 - val_loss: 77.0212 - val_keras_r2: 0.0940\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8140 - keras_r2: 0.0546 - val_loss: 79.5047 - val_keras_r2: 0.0430\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9542 - keras_r2: 0.0915 - val_loss: 73.0703 - val_keras_r2: 0.1360\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4603 - keras_r2: 0.0748 - val_loss: 72.1393 - val_keras_r2: 0.1508\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.7090 - keras_r2: -0.0083 - val_loss: 71.3598 - val_keras_r2: 0.1590\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8259 - keras_r2: 0.1021 - val_loss: 73.6815 - val_keras_r2: 0.1372\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1394 - keras_r2: 0.0724 - val_loss: 72.6705 - val_keras_r2: 0.1421\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6251 - keras_r2: -0.0429 - val_loss: 83.5737 - val_keras_r2: 0.0125\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0204 - keras_r2: 0.1244 - val_loss: 72.3597 - val_keras_r2: 0.1495\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.6519 - keras_r2: 0.1195 - val_loss: 76.7891 - val_keras_r2: 0.0807\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.9966 - keras_r2: 0.1122 - val_loss: 71.5893 - val_keras_r2: 0.1609\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2003 - keras_r2: 0.0844 - val_loss: 71.4380 - val_keras_r2: 0.1609\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9431 - keras_r2: -0.0657 - val_loss: 74.5231 - val_keras_r2: 0.1114\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5500 - keras_r2: 0.1554 - val_loss: 71.3952 - val_keras_r2: 0.1613\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7202 - keras_r2: 0.1225 - val_loss: 71.0685 - val_keras_r2: 0.1619\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7387 - keras_r2: 0.1195 - val_loss: 73.0305 - val_keras_r2: 0.1328\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.1201 - keras_r2: 0.1420 - val_loss: 70.9052 - val_keras_r2: 0.1677\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.8857 - keras_r2: 0.1011 - val_loss: 77.6611 - val_keras_r2: 0.0649\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.2286 - keras_r2: -0.3501 - val_loss: 73.1935 - val_keras_r2: 0.1307\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2262 - keras_r2: 0.1018 - val_loss: 72.2803 - val_keras_r2: 0.1443\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.9460 - keras_r2: 0.1317 - val_loss: 82.4264 - val_keras_r2: 0.0016\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.7542 - keras_r2: 0.0761 - val_loss: 71.8361 - val_keras_r2: 0.1576\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.1459 - keras_r2: 0.1423 - val_loss: 72.5022 - val_keras_r2: 0.1500\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.2592 - keras_r2: -0.0715 - val_loss: 73.3271 - val_keras_r2: 0.1385\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.9769 - keras_r2: 0.1774 - val_loss: 74.2167 - val_keras_r2: 0.1181\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.2683 - keras_r2: -0.7421 - val_loss: 71.4375 - val_keras_r2: 0.1535\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6719 - keras_r2: 0.1316 - val_loss: 74.7514 - val_keras_r2: 0.1211\n",
            "Epoch 36: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=89; total time=  20.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 310.1219 - keras_r2: -3.2178 - val_loss: 77.8022 - val_keras_r2: 0.0539\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.8982 - keras_r2: -0.0458 - val_loss: 73.8730 - val_keras_r2: 0.1201\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.8458 - keras_r2: -0.0222 - val_loss: 71.6029 - val_keras_r2: 0.1469\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.0699 - keras_r2: 0.0016 - val_loss: 74.3203 - val_keras_r2: 0.1164\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.4306 - keras_r2: 0.0335 - val_loss: 71.9292 - val_keras_r2: 0.1420\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.1419 - keras_r2: -0.0822 - val_loss: 77.1450 - val_keras_r2: 0.0817\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 75.3745 - keras_r2: 0.0607 - val_loss: 74.7979 - val_keras_r2: 0.1126\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.9331 - keras_r2: 0.0296 - val_loss: 72.6086 - val_keras_r2: 0.1308\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.7302 - keras_r2: 0.0696 - val_loss: 72.2770 - val_keras_r2: 0.1344\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.5089 - keras_r2: 0.0626 - val_loss: 72.0779 - val_keras_r2: 0.1447\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.0543 - keras_r2: -0.0651 - val_loss: 73.7917 - val_keras_r2: 0.1239\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4731 - keras_r2: 0.0797 - val_loss: 71.4273 - val_keras_r2: 0.1471\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5631 - keras_r2: 0.0834 - val_loss: 71.4795 - val_keras_r2: 0.1505\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2478 - keras_r2: 0.0625 - val_loss: 72.2788 - val_keras_r2: 0.1320\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.7775 - keras_r2: 0.0586 - val_loss: 77.9323 - val_keras_r2: 0.0511\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8345 - keras_r2: 0.1012 - val_loss: 71.6723 - val_keras_r2: 0.1488\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5759 - keras_r2: 0.0918 - val_loss: 74.4359 - val_keras_r2: 0.1013\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5315 - keras_r2: 0.0844 - val_loss: 74.6016 - val_keras_r2: 0.1142\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.7083 - keras_r2: -0.2792 - val_loss: 82.2762 - val_keras_r2: -0.0074\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2129 - keras_r2: 0.0999 - val_loss: 71.0031 - val_keras_r2: 0.1558\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2321 - keras_r2: -2.6854 - val_loss: 84.6152 - val_keras_r2: -0.0144\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.3833 - keras_r2: 0.0681 - val_loss: 71.2732 - val_keras_r2: 0.1527\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.9701 - keras_r2: 0.0943 - val_loss: 71.6398 - val_keras_r2: 0.1483\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.0253 - keras_r2: 0.0801 - val_loss: 74.0887 - val_keras_r2: 0.1205\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6349 - keras_r2: 0.1259 - val_loss: 72.0045 - val_keras_r2: 0.1377\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5681 - keras_r2: 0.1036 - val_loss: 92.9450 - val_keras_r2: -0.1588\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3133 - keras_r2: 0.0879 - val_loss: 72.2185 - val_keras_r2: 0.1335\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2067 - keras_r2: -18734286.0000 - val_loss: 87.0269 - val_keras_r2: -0.0779\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2097 - keras_r2: 0.1075 - val_loss: 83.1860 - val_keras_r2: 0.0027\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.1146 - keras_r2: 0.1306 - val_loss: 110.4934 - val_keras_r2: -0.3943\n",
            "Epoch 30: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=89; total time=  21.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 387.5256 - keras_r2: -7.3785 - val_loss: 76.6420 - val_keras_r2: 0.1018\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.6098 - keras_r2: -0.0401 - val_loss: 75.3741 - val_keras_r2: 0.1084\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.3832 - keras_r2: -0.0235 - val_loss: 74.5840 - val_keras_r2: 0.1157\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.0046 - keras_r2: 0.0164 - val_loss: 73.1605 - val_keras_r2: 0.1423\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.9867 - keras_r2: 0.0375 - val_loss: 73.5250 - val_keras_r2: 0.1370\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.2952 - keras_r2: -2.7883 - val_loss: 84.9703 - val_keras_r2: -0.0298\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.2415 - keras_r2: 0.0261 - val_loss: 82.4227 - val_keras_r2: 0.0295\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.5481 - keras_r2: 0.0695 - val_loss: 73.6529 - val_keras_r2: 0.1316\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.1900 - keras_r2: 0.0628 - val_loss: 74.9895 - val_keras_r2: 0.1211\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.0427 - keras_r2: 0.0789 - val_loss: 73.0182 - val_keras_r2: 0.1447\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.9774 - keras_r2: 0.0770 - val_loss: 76.2883 - val_keras_r2: 0.1037\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.1710 - keras_r2: 0.0704 - val_loss: 73.2149 - val_keras_r2: 0.1360\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.8095 - keras_r2: -0.1855 - val_loss: 80.2099 - val_keras_r2: 0.0543\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6508 - keras_r2: 0.0755 - val_loss: 79.0817 - val_keras_r2: 0.0523\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.7642 - keras_r2: -0.3729 - val_loss: 77.9594 - val_keras_r2: 0.0851\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0626 - keras_r2: -0.2712 - val_loss: 74.0777 - val_keras_r2: 0.1260\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5638 - keras_r2: 0.1103 - val_loss: 76.2392 - val_keras_r2: 0.0883\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.8218 - keras_r2: -0.0745 - val_loss: 78.9084 - val_keras_r2: 0.0719\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8669 - keras_r2: 0.0945 - val_loss: 73.5254 - val_keras_r2: 0.1368\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.1917 - keras_r2: 0.0646 - val_loss: 79.9698 - val_keras_r2: 0.0359\n",
            "Epoch 20: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=89; total time=  21.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 309.4503 - keras_r2: -3.0622 - val_loss: 76.6874 - val_keras_r2: 0.0906\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.3761 - keras_r2: -0.1670 - val_loss: 83.8867 - val_keras_r2: 0.0081\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.7237 - keras_r2: -8603939.0000 - val_loss: 80.6283 - val_keras_r2: 0.0492\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.4022 - keras_r2: 0.0386 - val_loss: 76.9209 - val_keras_r2: 0.0838\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.3210 - keras_r2: 0.0552 - val_loss: 73.6728 - val_keras_r2: 0.1339\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.2044 - keras_r2: 0.0624 - val_loss: 73.9656 - val_keras_r2: 0.1287\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.8153 - keras_r2: -0.8120 - val_loss: 74.3516 - val_keras_r2: 0.1280\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.7019 - keras_r2: -0.0700 - val_loss: 78.8048 - val_keras_r2: 0.0713\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.3476 - keras_r2: 0.0549 - val_loss: 75.3237 - val_keras_r2: 0.1149\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.1966 - keras_r2: -0.4978 - val_loss: 73.2269 - val_keras_r2: 0.1400\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6936 - keras_r2: 0.0879 - val_loss: 74.6619 - val_keras_r2: 0.1117\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.7296 - keras_r2: 0.0818 - val_loss: 72.9991 - val_keras_r2: 0.1427\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.7755 - keras_r2: 0.0928 - val_loss: 82.8193 - val_keras_r2: -8.0215e-04\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.6723 - keras_r2: 0.0923 - val_loss: 73.6250 - val_keras_r2: 0.1314\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9170 - keras_r2: -2925375.7500 - val_loss: 72.8321 - val_keras_r2: 0.1429\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0894 - keras_r2: 0.0604 - val_loss: 72.5354 - val_keras_r2: 0.1455\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.3515 - keras_r2: 0.1120 - val_loss: 73.0447 - val_keras_r2: 0.1383\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1707 - keras_r2: 0.1072 - val_loss: 72.5630 - val_keras_r2: 0.1453\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.1283 - keras_r2: 0.1264 - val_loss: 82.5228 - val_keras_r2: 0.0012\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3372 - keras_r2: 0.0813 - val_loss: 82.8856 - val_keras_r2: 0.0228\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0188 - keras_r2: 0.1147 - val_loss: 76.0064 - val_keras_r2: 0.0914\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.4394 - keras_r2: 0.0641 - val_loss: 79.9265 - val_keras_r2: 0.0601\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.4361 - keras_r2: 0.0845 - val_loss: 73.0615 - val_keras_r2: 0.1436\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.1230 - keras_r2: 0.0274 - val_loss: 76.7883 - val_keras_r2: 0.0961\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5020 - keras_r2: 0.1287 - val_loss: 72.1411 - val_keras_r2: 0.1513\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3976 - keras_r2: 0.1140 - val_loss: 77.0163 - val_keras_r2: 0.0774\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1703 - keras_r2: 0.0938 - val_loss: 71.8618 - val_keras_r2: 0.1546\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.1776 - keras_r2: -0.0988 - val_loss: 77.3551 - val_keras_r2: 0.0869\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9754 - keras_r2: 0.1363 - val_loss: 77.1509 - val_keras_r2: 0.0919\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8595 - keras_r2: 0.1368 - val_loss: 72.4991 - val_keras_r2: 0.1466\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.3881 - keras_r2: 0.1171 - val_loss: 73.2423 - val_keras_r2: 0.1341\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0143 - keras_r2: 0.1350 - val_loss: 74.4487 - val_keras_r2: 0.1282\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0435 - keras_r2: 0.1329 - val_loss: 97.2024 - val_keras_r2: -0.2052\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.3678 - keras_r2: 0.0948 - val_loss: 82.4633 - val_keras_r2: 0.0269\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9777 - keras_r2: 0.1374 - val_loss: 76.7951 - val_keras_r2: 0.0786\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5374 - keras_r2: 0.0634 - val_loss: 85.4707 - val_keras_r2: -0.0097\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.7358 - keras_r2: -0.1391 - val_loss: 71.7411 - val_keras_r2: 0.1532\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8958 - keras_r2: 0.0648 - val_loss: 78.9494 - val_keras_r2: 0.0727\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1796 - keras_r2: 0.1720 - val_loss: 73.8049 - val_keras_r2: 0.1229\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.9797 - keras_r2: -1.0997 - val_loss: 92.0592 - val_keras_r2: -0.0957\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0932 - keras_r2: 0.1137 - val_loss: 78.5535 - val_keras_r2: 0.0762\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.9073 - keras_r2: 0.1215 - val_loss: 73.2818 - val_keras_r2: 0.1321\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.1844 - keras_r2: 0.1416 - val_loss: 74.8247 - val_keras_r2: 0.1216\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.5952 - keras_r2: -4.7632 - val_loss: 90.0155 - val_keras_r2: -0.1047\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8003 - keras_r2: 0.1536 - val_loss: 75.7046 - val_keras_r2: 0.1120\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.0015 - keras_r2: 0.1139 - val_loss: 74.8372 - val_keras_r2: 0.1090\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.2916 - keras_r2: 0.1599 - val_loss: 72.6164 - val_keras_r2: 0.1458\n",
            "Epoch 47: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=89; total time=  27.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 283.9142 - keras_r2: -2.4586 - val_loss: 68.0883 - val_keras_r2: 0.1555\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.8750 - keras_r2: -0.0179 - val_loss: 67.3068 - val_keras_r2: 0.1627\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.1473 - keras_r2: 0.0251 - val_loss: 70.9755 - val_keras_r2: 0.1056\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.7368 - keras_r2: 0.0233 - val_loss: 66.9430 - val_keras_r2: 0.1709\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.8782 - keras_r2: 0.0656 - val_loss: 66.1105 - val_keras_r2: 0.1837\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 77.8054 - keras_r2: 0.0378 - val_loss: 66.4570 - val_keras_r2: 0.1802\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.8557 - keras_r2: 0.0776 - val_loss: 66.3549 - val_keras_r2: 0.1753\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5079 - keras_r2: 0.0827 - val_loss: 81.7653 - val_keras_r2: -0.0388\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2654 - keras_r2: 0.0284 - val_loss: 65.4504 - val_keras_r2: 0.1923\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.6176 - keras_r2: 0.0798 - val_loss: 67.2375 - val_keras_r2: 0.1720\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8490 - keras_r2: 0.0409 - val_loss: 74.6854 - val_keras_r2: 0.0622\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.0274 - keras_r2: 0.0304 - val_loss: 68.1937 - val_keras_r2: 0.1517\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5830 - keras_r2: 0.0871 - val_loss: 65.9409 - val_keras_r2: 0.1856\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1979 - keras_r2: 0.0755 - val_loss: 65.2415 - val_keras_r2: 0.1947\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.9096 - keras_r2: 0.1073 - val_loss: 66.8569 - val_keras_r2: 0.1761\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0798 - keras_r2: 0.0949 - val_loss: 67.1847 - val_keras_r2: 0.1606\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.8513 - keras_r2: 0.1296 - val_loss: 65.5860 - val_keras_r2: 0.1872\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5391 - keras_r2: 0.0758 - val_loss: 66.0411 - val_keras_r2: 0.1800\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2376 - keras_r2: 0.1318 - val_loss: 65.8289 - val_keras_r2: 0.1821\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6026 - keras_r2: 0.0336 - val_loss: 73.4287 - val_keras_r2: 0.0732\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0604 - keras_r2: 0.1217 - val_loss: 65.4132 - val_keras_r2: 0.1885\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5527 - keras_r2: 0.1391 - val_loss: 64.7579 - val_keras_r2: 0.1967\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.9431 - keras_r2: 0.1327 - val_loss: 63.8942 - val_keras_r2: 0.2056\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2661 - keras_r2: 0.1338 - val_loss: 64.2829 - val_keras_r2: 0.2000\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.8051 - keras_r2: 0.1730 - val_loss: 72.3825 - val_keras_r2: 0.0862\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8167 - keras_r2: 0.0808 - val_loss: 86.8607 - val_keras_r2: -0.1123\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3395 - keras_r2: 0.1327 - val_loss: 66.7244 - val_keras_r2: 0.1750\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8400 - keras_r2: 0.1420 - val_loss: 66.1983 - val_keras_r2: 0.1743\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.0744 - keras_r2: 0.1547 - val_loss: 64.6945 - val_keras_r2: 0.2012\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.9089 - keras_r2: 0.1613 - val_loss: 67.1757 - val_keras_r2: 0.1657\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.7944 - keras_r2: 0.1444 - val_loss: 73.3076 - val_keras_r2: 0.0701\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.8487 - keras_r2: 0.1616 - val_loss: 66.9516 - val_keras_r2: 0.1711\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.2745 - keras_r2: 0.1695 - val_loss: 69.3396 - val_keras_r2: 0.1401\n",
            "Epoch 33: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=89; total time=  20.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 261.8580 - keras_r2: -2.5270 - val_loss: 76.9630 - val_keras_r2: 0.0883\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 103.8289 - keras_r2: -0.3255 - val_loss: 77.8001 - val_keras_r2: 0.0751\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 100.7645 - keras_r2: -0.6426 - val_loss: 74.0528 - val_keras_r2: 0.1307\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 100.2662 - keras_r2: -0.2990 - val_loss: 73.8442 - val_keras_r2: 0.1325\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.8296 - keras_r2: -0.3735 - val_loss: 76.7367 - val_keras_r2: 0.0874\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 98.4993 - keras_r2: -1.7007 - val_loss: 74.4834 - val_keras_r2: 0.1217\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.0178 - keras_r2: -0.1810 - val_loss: 74.0278 - val_keras_r2: 0.1267\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 93.6761 - keras_r2: -0.2465 - val_loss: 73.6122 - val_keras_r2: 0.1377\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.3410 - keras_r2: -0.6388 - val_loss: 73.8946 - val_keras_r2: 0.1311\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 92.2998 - keras_r2: -0.1567 - val_loss: 74.0712 - val_keras_r2: 0.1315\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.6725 - keras_r2: -0.1334 - val_loss: 74.2970 - val_keras_r2: 0.1234\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.8559 - keras_r2: -2186718.7500 - val_loss: 73.7565 - val_keras_r2: 0.1318\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 88.5665 - keras_r2: -0.1133 - val_loss: 74.1626 - val_keras_r2: 0.1256\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.8328 - keras_r2: -0.1036 - val_loss: 74.9233 - val_keras_r2: 0.1133\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.0535 - keras_r2: -0.0574 - val_loss: 74.0866 - val_keras_r2: 0.1256\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.8096 - keras_r2: -0.1277 - val_loss: 73.2238 - val_keras_r2: 0.1393\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.1905 - keras_r2: -0.0449 - val_loss: 73.1991 - val_keras_r2: 0.1396\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.2708 - keras_r2: -0.0102 - val_loss: 73.9731 - val_keras_r2: 0.1263\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.6419 - keras_r2: -0.0462 - val_loss: 74.0878 - val_keras_r2: 0.1250\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.7447 - keras_r2: -0.1750 - val_loss: 73.0963 - val_keras_r2: 0.1409\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.7447 - keras_r2: 0.0060 - val_loss: 73.1836 - val_keras_r2: 0.1380\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.3985 - keras_r2: -0.0627 - val_loss: 73.3891 - val_keras_r2: 0.1340\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.7670 - keras_r2: -0.0464 - val_loss: 73.2714 - val_keras_r2: 0.1393\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.3376 - keras_r2: -0.0043 - val_loss: 75.1292 - val_keras_r2: 0.1081\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.1905 - keras_r2: -1.7018 - val_loss: 73.0717 - val_keras_r2: 0.1398\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.9521 - keras_r2: 0.0419 - val_loss: 73.5276 - val_keras_r2: 0.1320\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.0447 - keras_r2: -1.8669 - val_loss: 73.3251 - val_keras_r2: 0.1348\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.7641 - keras_r2: 0.0374 - val_loss: 73.2088 - val_keras_r2: 0.1365\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.3156 - keras_r2: -0.0832 - val_loss: 72.9128 - val_keras_r2: 0.1436\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.1683 - keras_r2: 0.0612 - val_loss: 74.5212 - val_keras_r2: 0.1176\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.8271 - keras_r2: 0.0728 - val_loss: 74.4663 - val_keras_r2: 0.1171\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.6901 - keras_r2: 0.0678 - val_loss: 72.9647 - val_keras_r2: 0.1405\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.7068 - keras_r2: 0.0686 - val_loss: 73.4588 - val_keras_r2: 0.1333\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.3013 - keras_r2: 0.0842 - val_loss: 72.9790 - val_keras_r2: 0.1416\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9196 - keras_r2: -0.0912 - val_loss: 73.1010 - val_keras_r2: 0.1424\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.0917 - keras_r2: 0.0519 - val_loss: 73.0606 - val_keras_r2: 0.1402\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9604 - keras_r2: -0.0575 - val_loss: 74.2687 - val_keras_r2: 0.1205\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.3933 - keras_r2: -1.2861 - val_loss: 73.4323 - val_keras_r2: 0.1394\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.3399 - keras_r2: 0.0557 - val_loss: 73.3094 - val_keras_r2: 0.1355\n",
            "Epoch 39: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=18; total time=  21.6s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 241.6384 - keras_r2: -2.0793 - val_loss: 77.7492 - val_keras_r2: 0.0698\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 106.7682 - keras_r2: -0.3355 - val_loss: 73.5802 - val_keras_r2: 0.1207\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 102.9678 - keras_r2: -0.3200 - val_loss: 73.5792 - val_keras_r2: 0.1203\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 100.2480 - keras_r2: -0.3168 - val_loss: 72.6860 - val_keras_r2: 0.1358\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 97.1993 - keras_r2: -0.2187 - val_loss: 72.9093 - val_keras_r2: 0.1298\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.5861 - keras_r2: -7153132.5000 - val_loss: 73.5880 - val_keras_r2: 0.1208\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 92.8307 - keras_r2: -0.1882 - val_loss: 72.6747 - val_keras_r2: 0.1372\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 91.7721 - keras_r2: -0.1360 - val_loss: 72.8139 - val_keras_r2: 0.1336\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 94.2438 - keras_r2: -0.1985 - val_loss: 72.6465 - val_keras_r2: 0.1359\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 91.6884 - keras_r2: -0.3877 - val_loss: 74.0480 - val_keras_r2: 0.1137\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.2167 - keras_r2: -0.1272 - val_loss: 72.9426 - val_keras_r2: 0.1295\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.7702 - keras_r2: -0.1337 - val_loss: 72.4681 - val_keras_r2: 0.1372\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.1422 - keras_r2: -0.0746 - val_loss: 73.1147 - val_keras_r2: 0.1271\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.8488 - keras_r2: -0.1066 - val_loss: 73.4980 - val_keras_r2: 0.1214\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.0570 - keras_r2: -0.0759 - val_loss: 72.6833 - val_keras_r2: 0.1335\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6170 - keras_r2: -0.0554 - val_loss: 73.5233 - val_keras_r2: 0.1203\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.2181 - keras_r2: -0.0406 - val_loss: 72.6397 - val_keras_r2: 0.1333\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4272 - keras_r2: -0.0678 - val_loss: 72.5202 - val_keras_r2: 0.1368\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.1513 - keras_r2: -0.0980 - val_loss: 72.2107 - val_keras_r2: 0.1406\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.7453 - keras_r2: -0.0626 - val_loss: 74.0077 - val_keras_r2: 0.1132\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.2885 - keras_r2: -0.1460 - val_loss: 72.2292 - val_keras_r2: 0.1404\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.5756 - keras_r2: -0.0341 - val_loss: 72.1228 - val_keras_r2: 0.1425\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.0757 - keras_r2: 0.0031 - val_loss: 72.3019 - val_keras_r2: 0.1400\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.1649 - keras_r2: 0.0307 - val_loss: 72.2028 - val_keras_r2: 0.1411\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.7630 - keras_r2: -0.2957 - val_loss: 73.1336 - val_keras_r2: 0.1257\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.7018 - keras_r2: -0.0425 - val_loss: 72.2842 - val_keras_r2: 0.1421\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.8518 - keras_r2: 0.0152 - val_loss: 73.3367 - val_keras_r2: 0.1235\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.3635 - keras_r2: 0.0456 - val_loss: 73.0352 - val_keras_r2: 0.1279\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.5189 - keras_r2: 0.0306 - val_loss: 72.2881 - val_keras_r2: 0.1436\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.2689 - keras_r2: -0.0046 - val_loss: 72.0916 - val_keras_r2: 0.1438\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.7060 - keras_r2: 0.0745 - val_loss: 72.2031 - val_keras_r2: 0.1414\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.1059 - keras_r2: -0.0158 - val_loss: 73.2258 - val_keras_r2: 0.1234\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.2281 - keras_r2: 0.0688 - val_loss: 71.9918 - val_keras_r2: 0.1449\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.8922 - keras_r2: 0.0650 - val_loss: 72.1562 - val_keras_r2: 0.1432\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.8720 - keras_r2: 0.0843 - val_loss: 72.5018 - val_keras_r2: 0.1361\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.4428 - keras_r2: 0.0677 - val_loss: 73.1820 - val_keras_r2: 0.1245\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.3699 - keras_r2: 0.0978 - val_loss: 72.0624 - val_keras_r2: 0.1417\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.0762 - keras_r2: 0.0744 - val_loss: 72.0340 - val_keras_r2: 0.1428\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4163 - keras_r2: 0.0603 - val_loss: 72.6647 - val_keras_r2: 0.1360\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.5145 - keras_r2: 0.0807 - val_loss: 72.0416 - val_keras_r2: 0.1428\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2442 - keras_r2: 0.1050 - val_loss: 72.2368 - val_keras_r2: 0.1406\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.8604 - keras_r2: -0.4813 - val_loss: 72.3582 - val_keras_r2: 0.1416\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9550 - keras_r2: 0.1059 - val_loss: 72.1308 - val_keras_r2: 0.1415\n",
            "Epoch 43: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=18; total time=  42.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 262.1942 - keras_r2: -2.4322 - val_loss: 76.9281 - val_keras_r2: 0.0974\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 106.3022 - keras_r2: -0.3281 - val_loss: 73.5724 - val_keras_r2: 0.1369\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 105.6606 - keras_r2: -0.3721 - val_loss: 76.5878 - val_keras_r2: 0.1018\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 101.1425 - keras_r2: -0.2806 - val_loss: 73.3914 - val_keras_r2: 0.1366\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 98.6297 - keras_r2: -0.2350 - val_loss: 74.3239 - val_keras_r2: 0.1228\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 94.1856 - keras_r2: -0.1964 - val_loss: 73.5146 - val_keras_r2: 0.1372\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.9015 - keras_r2: -0.2005 - val_loss: 73.9141 - val_keras_r2: 0.1283\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 93.9814 - keras_r2: -0.1866 - val_loss: 73.6408 - val_keras_r2: 0.1346\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 93.3640 - keras_r2: -0.1826 - val_loss: 73.4404 - val_keras_r2: 0.1350\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 92.7509 - keras_r2: -0.1483 - val_loss: 73.8377 - val_keras_r2: 0.1277\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 91.2956 - keras_r2: -0.3351 - val_loss: 73.5424 - val_keras_r2: 0.1333\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.9726 - keras_r2: -0.2731 - val_loss: 73.4780 - val_keras_r2: 0.1353\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.7927 - keras_r2: -0.1524 - val_loss: 73.6734 - val_keras_r2: 0.1345\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.9915 - keras_r2: -0.2126 - val_loss: 73.5395 - val_keras_r2: 0.1365\n",
            "Epoch 14: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=18; total time=  11.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 238.8975 - keras_r2: -2.0984 - val_loss: 76.3772 - val_keras_r2: 0.1001\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 105.9054 - keras_r2: -0.3131 - val_loss: 73.7465 - val_keras_r2: 0.1331\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 102.8544 - keras_r2: -0.2901 - val_loss: 73.7614 - val_keras_r2: 0.1351\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 101.6073 - keras_r2: -6589150.5000 - val_loss: 73.8249 - val_keras_r2: 0.1304\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 97.4081 - keras_r2: -0.2516 - val_loss: 74.9326 - val_keras_r2: 0.1119\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 96.0214 - keras_r2: -0.2978 - val_loss: 74.1276 - val_keras_r2: 0.1300\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 93.4537 - keras_r2: -0.4755 - val_loss: 73.9804 - val_keras_r2: 0.1332\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 93.9690 - keras_r2: -0.1933 - val_loss: 75.8677 - val_keras_r2: 0.0980\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 93.2920 - keras_r2: -0.1597 - val_loss: 73.8131 - val_keras_r2: 0.1304\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.0645 - keras_r2: -0.2598 - val_loss: 74.5606 - val_keras_r2: 0.1195\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.8844 - keras_r2: -0.3700 - val_loss: 73.5291 - val_keras_r2: 0.1374\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.7368 - keras_r2: -0.3247 - val_loss: 74.4768 - val_keras_r2: 0.1208\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.8151 - keras_r2: -0.0846 - val_loss: 74.2986 - val_keras_r2: 0.1246\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.0191 - keras_r2: -0.0684 - val_loss: 74.2499 - val_keras_r2: 0.1245\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.5081 - keras_r2: -0.3206 - val_loss: 73.9833 - val_keras_r2: 0.1274\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.9634 - keras_r2: -0.0625 - val_loss: 73.3460 - val_keras_r2: 0.1376\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.8281 - keras_r2: -0.1952 - val_loss: 74.3033 - val_keras_r2: 0.1219\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.0051 - keras_r2: -0.0224 - val_loss: 74.0868 - val_keras_r2: 0.1250\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 82.0815 - keras_r2: -0.0160 - val_loss: 74.1571 - val_keras_r2: 0.1244\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.1940 - keras_r2: -0.0096 - val_loss: 73.4770 - val_keras_r2: 0.1346\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.7156 - keras_r2: -0.0451 - val_loss: 75.5863 - val_keras_r2: 0.1029\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.3267 - keras_r2: -0.0404 - val_loss: 74.8887 - val_keras_r2: 0.1140\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.5674 - keras_r2: 0.0411 - val_loss: 73.6690 - val_keras_r2: 0.1329\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.5266 - keras_r2: -0.0037 - val_loss: 74.5945 - val_keras_r2: 0.1205\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.9542 - keras_r2: 0.0072 - val_loss: 75.7726 - val_keras_r2: 0.0995\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.9025 - keras_r2: 0.0291 - val_loss: 73.2712 - val_keras_r2: 0.1389\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.4803 - keras_r2: 0.0649 - val_loss: 73.3056 - val_keras_r2: 0.1373\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.4357 - keras_r2: 0.0286 - val_loss: 73.2787 - val_keras_r2: 0.1398\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.9860 - keras_r2: -0.4248 - val_loss: 73.2161 - val_keras_r2: 0.1397\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.3157 - keras_r2: -0.0128 - val_loss: 75.6249 - val_keras_r2: 0.1006\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.1971 - keras_r2: -0.1288 - val_loss: 74.2333 - val_keras_r2: 0.1300\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.2964 - keras_r2: -0.0046 - val_loss: 73.6476 - val_keras_r2: 0.1306\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6440 - keras_r2: 0.0854 - val_loss: 73.6397 - val_keras_r2: 0.1308\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.1650 - keras_r2: 0.0749 - val_loss: 73.2952 - val_keras_r2: 0.1357\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.8385 - keras_r2: -1973002.8750 - val_loss: 73.8168 - val_keras_r2: 0.1272\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.3226 - keras_r2: -2.7269 - val_loss: 73.0115 - val_keras_r2: 0.1408\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.3345 - keras_r2: -9608070.0000 - val_loss: 73.1303 - val_keras_r2: 0.1395\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.6974 - keras_r2: 0.0830 - val_loss: 73.0473 - val_keras_r2: 0.1397\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.2341 - keras_r2: 0.0891 - val_loss: 72.8545 - val_keras_r2: 0.1430\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5202 - keras_r2: 0.1023 - val_loss: 73.7477 - val_keras_r2: 0.1273\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5333 - keras_r2: 0.1095 - val_loss: 73.6294 - val_keras_r2: 0.1296\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5264 - keras_r2: -0.5310 - val_loss: 73.6736 - val_keras_r2: 0.1276\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.3322 - keras_r2: -0.9492 - val_loss: 72.8438 - val_keras_r2: 0.1412\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1693 - keras_r2: 0.1014 - val_loss: 72.8799 - val_keras_r2: 0.1385\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2037 - keras_r2: -0.4630 - val_loss: 73.0451 - val_keras_r2: 0.1360\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.8557 - keras_r2: -0.3297 - val_loss: 73.4571 - val_keras_r2: 0.1302\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3051 - keras_r2: 0.1317 - val_loss: 73.0125 - val_keras_r2: 0.1371\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.6507 - keras_r2: 0.0151 - val_loss: 73.2836 - val_keras_r2: 0.1335\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3260 - keras_r2: 0.1217 - val_loss: 72.7233 - val_keras_r2: 0.1436\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.5492 - keras_r2: 0.1336 - val_loss: 73.0229 - val_keras_r2: 0.1386\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2818 - keras_r2: 0.1086 - val_loss: 73.2478 - val_keras_r2: 0.1336\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0422 - keras_r2: -0.4741 - val_loss: 73.2493 - val_keras_r2: 0.1342\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.4147 - keras_r2: -0.3444 - val_loss: 73.3185 - val_keras_r2: 0.1345\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.8791 - keras_r2: 0.1492 - val_loss: 72.8569 - val_keras_r2: 0.1417\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9091 - keras_r2: 0.1153 - val_loss: 73.1939 - val_keras_r2: 0.1352\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3767 - keras_r2: 0.1074 - val_loss: 72.8772 - val_keras_r2: 0.1417\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9796 - keras_r2: 0.0864 - val_loss: 72.6159 - val_keras_r2: 0.1443\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.1236 - keras_r2: 0.1608 - val_loss: 72.7612 - val_keras_r2: 0.1414\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.3431 - keras_r2: 0.0953 - val_loss: 73.2730 - val_keras_r2: 0.1331\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5255 - keras_r2: -0.0870 - val_loss: 74.6346 - val_keras_r2: 0.1126\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0508 - keras_r2: 0.1554 - val_loss: 72.6082 - val_keras_r2: 0.1447\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.3180 - keras_r2: -0.0151 - val_loss: 72.7107 - val_keras_r2: 0.1425\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.2754 - keras_r2: 0.1215 - val_loss: 72.7721 - val_keras_r2: 0.1422\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5167 - keras_r2: 0.1069 - val_loss: 72.7841 - val_keras_r2: 0.1418\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6198 - keras_r2: -301114.7812 - val_loss: 72.6221 - val_keras_r2: 0.1444\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5789 - keras_r2: 0.1642 - val_loss: 72.7820 - val_keras_r2: 0.1413\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.9568 - keras_r2: 0.1031 - val_loss: 73.1327 - val_keras_r2: 0.1352\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5382 - keras_r2: 0.1705 - val_loss: 72.8880 - val_keras_r2: 0.1417\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.7043 - keras_r2: -1.0692 - val_loss: 72.9968 - val_keras_r2: 0.1373\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.8813 - keras_r2: 0.1554 - val_loss: 72.7027 - val_keras_r2: 0.1436\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.7079 - keras_r2: -0.0699 - val_loss: 72.6249 - val_keras_r2: 0.1426\n",
            "Epoch 71: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=18; total time=  38.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 233.7531 - keras_r2: -2.1623 - val_loss: 70.8057 - val_keras_r2: 0.1278\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 102.5215 - keras_r2: -0.2787 - val_loss: 66.8763 - val_keras_r2: 0.1751\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 99.9668 - keras_r2: -0.2492 - val_loss: 67.7491 - val_keras_r2: 0.1572\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 95.9167 - keras_r2: -0.2245 - val_loss: 66.0130 - val_keras_r2: 0.1855\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 95.2639 - keras_r2: -0.1804 - val_loss: 67.1722 - val_keras_r2: 0.1642\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 92.6506 - keras_r2: -0.1415 - val_loss: 67.0274 - val_keras_r2: 0.1664\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 92.6116 - keras_r2: -0.2373 - val_loss: 66.2206 - val_keras_r2: 0.1817\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.9279 - keras_r2: -0.1481 - val_loss: 66.3363 - val_keras_r2: 0.1792\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 90.7430 - keras_r2: -0.1264 - val_loss: 68.0847 - val_keras_r2: 0.1532\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.6061 - keras_r2: -0.0863 - val_loss: 67.4656 - val_keras_r2: 0.1649\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.6858 - keras_r2: -0.1014 - val_loss: 67.3373 - val_keras_r2: 0.1638\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 86.5617 - keras_r2: -0.1046 - val_loss: 70.3619 - val_keras_r2: 0.1187\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.1649 - keras_r2: -0.0771 - val_loss: 67.3090 - val_keras_r2: 0.1600\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.4588 - keras_r2: -0.0577 - val_loss: 65.7896 - val_keras_r2: 0.1851\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.0948 - keras_r2: -0.0826 - val_loss: 65.8442 - val_keras_r2: 0.1851\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.7301 - keras_r2: -0.0605 - val_loss: 65.7855 - val_keras_r2: 0.1859\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 83.3550 - keras_r2: -0.0287 - val_loss: 66.8170 - val_keras_r2: 0.1691\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.7328 - keras_r2: -0.0191 - val_loss: 66.1326 - val_keras_r2: 0.1811\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.1125 - keras_r2: -0.0150 - val_loss: 68.1669 - val_keras_r2: 0.1507\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.9271 - keras_r2: -0.0073 - val_loss: 65.9956 - val_keras_r2: 0.1834\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.7621 - keras_r2: 0.0180 - val_loss: 66.1365 - val_keras_r2: 0.1802\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.7666 - keras_r2: 0.0026 - val_loss: 67.6108 - val_keras_r2: 0.1584\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.7934 - keras_r2: 0.0353 - val_loss: 66.4780 - val_keras_r2: 0.1742\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.6729 - keras_r2: 0.0029 - val_loss: 66.7174 - val_keras_r2: 0.1716\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.1045 - keras_r2: 0.0429 - val_loss: 65.7884 - val_keras_r2: 0.1870\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.4108 - keras_r2: -0.0408 - val_loss: 65.5397 - val_keras_r2: 0.1902\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.4852 - keras_r2: 0.0482 - val_loss: 65.8730 - val_keras_r2: 0.1837\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.9379 - keras_r2: 0.0666 - val_loss: 65.9923 - val_keras_r2: 0.1807\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.6535 - keras_r2: 0.0723 - val_loss: 65.8145 - val_keras_r2: 0.1843\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.1180 - keras_r2: 0.0437 - val_loss: 65.4612 - val_keras_r2: 0.1903\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.4813 - keras_r2: 0.0610 - val_loss: 66.9636 - val_keras_r2: 0.1681\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.4294 - keras_r2: 0.0723 - val_loss: 65.8119 - val_keras_r2: 0.1848\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4948 - keras_r2: 0.0841 - val_loss: 66.0952 - val_keras_r2: 0.1796\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.5277 - keras_r2: 0.0749 - val_loss: 65.2511 - val_keras_r2: 0.1928\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.3682 - keras_r2: 0.0745 - val_loss: 66.8148 - val_keras_r2: 0.1693\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0008 - keras_r2: 0.0889 - val_loss: 67.1534 - val_keras_r2: 0.1643\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.7457 - keras_r2: 0.0912 - val_loss: 65.5786 - val_keras_r2: 0.1869\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0593 - keras_r2: 0.1239 - val_loss: 65.4351 - val_keras_r2: 0.1889\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.7229 - keras_r2: 0.1152 - val_loss: 65.2072 - val_keras_r2: 0.1930\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.4218 - keras_r2: 0.1336 - val_loss: 66.3794 - val_keras_r2: 0.1742\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1037 - keras_r2: 0.1073 - val_loss: 65.8748 - val_keras_r2: 0.1818\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.7819 - keras_r2: 0.1310 - val_loss: 65.9583 - val_keras_r2: 0.1807\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.8874 - keras_r2: 0.1297 - val_loss: 65.5659 - val_keras_r2: 0.1864\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.3315 - keras_r2: 0.1244 - val_loss: 64.9859 - val_keras_r2: 0.1956\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0242 - keras_r2: 0.1196 - val_loss: 64.9476 - val_keras_r2: 0.1959\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.1348 - keras_r2: 0.1378 - val_loss: 65.8299 - val_keras_r2: 0.1820\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5609 - keras_r2: 0.1300 - val_loss: 65.2300 - val_keras_r2: 0.1904\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7399 - keras_r2: 0.1413 - val_loss: 64.6498 - val_keras_r2: 0.2005\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.7920 - keras_r2: -1.3035 - val_loss: 64.5402 - val_keras_r2: 0.2011\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.4797 - keras_r2: 0.1501 - val_loss: 64.4685 - val_keras_r2: 0.2032\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.1808 - keras_r2: 0.1342 - val_loss: 65.0120 - val_keras_r2: 0.1938\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0844 - keras_r2: 0.1305 - val_loss: 65.2162 - val_keras_r2: 0.1912\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.6625 - keras_r2: 0.1438 - val_loss: 65.0909 - val_keras_r2: 0.1930\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.6831 - keras_r2: 0.1431 - val_loss: 64.7142 - val_keras_r2: 0.2000\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5020 - keras_r2: 0.1557 - val_loss: 64.8033 - val_keras_r2: 0.1981\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.0419 - keras_r2: 0.1655 - val_loss: 64.5082 - val_keras_r2: 0.2021\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.6014 - keras_r2: 0.1426 - val_loss: 66.3067 - val_keras_r2: 0.1758\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.2236 - keras_r2: 0.1477 - val_loss: 64.6935 - val_keras_r2: 0.1997\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.0734 - keras_r2: 0.1688 - val_loss: 64.6270 - val_keras_r2: 0.2013\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.7420 - keras_r2: 0.1610 - val_loss: 64.6869 - val_keras_r2: 0.2003\n",
            "Epoch 60: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=True, dropout=0.3, n_hidden=2, n_neurons=18; total time=  42.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 137.2720 - keras_r2: -0.9802 - val_loss: 73.4257 - val_keras_r2: 0.1293\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 82.1862 - keras_r2: -0.0283 - val_loss: 74.0560 - val_keras_r2: 0.1242\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.9040 - keras_r2: -0.1456 - val_loss: 77.6673 - val_keras_r2: 0.0886\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.2152 - keras_r2: -0.0105 - val_loss: 74.5860 - val_keras_r2: 0.1239\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.5631 - keras_r2: 0.0142 - val_loss: 75.2794 - val_keras_r2: 0.1089\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.9418 - keras_r2: -0.0161 - val_loss: 74.7388 - val_keras_r2: 0.1179\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.4826 - keras_r2: 0.0457 - val_loss: 73.9407 - val_keras_r2: 0.1314\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.4925 - keras_r2: 0.0238 - val_loss: 75.2471 - val_keras_r2: 0.1081\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.4325 - keras_r2: 0.0204 - val_loss: 74.3642 - val_keras_r2: 0.1229\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.6075 - keras_r2: 0.0479 - val_loss: 74.2385 - val_keras_r2: 0.1210\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.2480 - keras_r2: 0.0465 - val_loss: 73.8694 - val_keras_r2: 0.1267\n",
            "Epoch 11: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=60; total time=  10.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 145.6839 - keras_r2: -0.8580 - val_loss: 73.6045 - val_keras_r2: 0.1244\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.8387 - keras_r2: -0.0258 - val_loss: 72.5644 - val_keras_r2: 0.1329\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.2585 - keras_r2: 0.0053 - val_loss: 72.3920 - val_keras_r2: 0.1312\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.0847 - keras_r2: 0.0129 - val_loss: 73.6044 - val_keras_r2: 0.1166\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.5811 - keras_r2: 0.0120 - val_loss: 76.8054 - val_keras_r2: 0.0703\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.5134 - keras_r2: 0.0288 - val_loss: 73.5259 - val_keras_r2: 0.1237\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.4726 - keras_r2: -0.0105 - val_loss: 73.4953 - val_keras_r2: 0.1227\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.7467 - keras_r2: 0.0418 - val_loss: 73.9906 - val_keras_r2: 0.1199\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.5163 - keras_r2: -0.8715 - val_loss: 72.7700 - val_keras_r2: 0.1341\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.3712 - keras_r2: 0.0416 - val_loss: 72.7957 - val_keras_r2: 0.1351\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.8499 - keras_r2: 0.0382 - val_loss: 72.0288 - val_keras_r2: 0.1405\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.6366 - keras_r2: -0.0532 - val_loss: 76.5772 - val_keras_r2: 0.0901\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.0777 - keras_r2: 0.0643 - val_loss: 71.8761 - val_keras_r2: 0.1422\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.5130 - keras_r2: -0.0815 - val_loss: 73.1397 - val_keras_r2: 0.1299\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.6085 - keras_r2: 0.0572 - val_loss: 72.6357 - val_keras_r2: 0.1343\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.1345 - keras_r2: 0.0750 - val_loss: 73.5303 - val_keras_r2: 0.1252\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.4155 - keras_r2: 0.0564 - val_loss: 80.4658 - val_keras_r2: 0.0194\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.2697 - keras_r2: -0.0293 - val_loss: 73.5610 - val_keras_r2: 0.1249\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.5965 - keras_r2: 0.0643 - val_loss: 72.8994 - val_keras_r2: 0.1324\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.8853 - keras_r2: 0.0702 - val_loss: 74.3267 - val_keras_r2: 0.1111\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.9359 - keras_r2: 0.0700 - val_loss: 72.9733 - val_keras_r2: 0.1317\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.7126 - keras_r2: 0.0937 - val_loss: 72.1539 - val_keras_r2: 0.1360\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4521 - keras_r2: -0.0185 - val_loss: 73.5895 - val_keras_r2: 0.1246\n",
            "Epoch 23: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=60; total time=  21.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 138.4766 - keras_r2: -0.7235 - val_loss: 75.6092 - val_keras_r2: 0.1086\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.9985 - keras_r2: 0.0027 - val_loss: 78.5025 - val_keras_r2: 0.0807\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.7330 - keras_r2: 0.0116 - val_loss: 75.0284 - val_keras_r2: 0.1128\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.4763 - keras_r2: -0.0527 - val_loss: 75.7900 - val_keras_r2: 0.1071\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.1707 - keras_r2: -0.0014 - val_loss: 74.7032 - val_keras_r2: 0.1193\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.5599 - keras_r2: -0.0419 - val_loss: 75.1923 - val_keras_r2: 0.1149\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.4967 - keras_r2: -0.5234 - val_loss: 76.9346 - val_keras_r2: 0.0872\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.1691 - keras_r2: 0.0443 - val_loss: 74.2750 - val_keras_r2: 0.1245\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.3232 - keras_r2: 0.0145 - val_loss: 73.3104 - val_keras_r2: 0.1394\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.2016 - keras_r2: 0.0406 - val_loss: 75.2883 - val_keras_r2: 0.1125\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.1682 - keras_r2: 0.0437 - val_loss: 74.4827 - val_keras_r2: 0.1231\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9251 - keras_r2: 0.0591 - val_loss: 73.4495 - val_keras_r2: 0.1379\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.4941 - keras_r2: 0.0472 - val_loss: 82.5135 - val_keras_r2: 0.0094\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.4788 - keras_r2: 0.0478 - val_loss: 73.4979 - val_keras_r2: 0.1332\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.4260 - keras_r2: 0.0594 - val_loss: 74.3453 - val_keras_r2: 0.1243\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.7375 - keras_r2: 0.0907 - val_loss: 73.8667 - val_keras_r2: 0.1320\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.0931 - keras_r2: 0.0783 - val_loss: 73.9020 - val_keras_r2: 0.1319\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.1107 - keras_r2: 0.0737 - val_loss: 73.1853 - val_keras_r2: 0.1413\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.3527 - keras_r2: 0.0449 - val_loss: 76.4527 - val_keras_r2: 0.0907\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.6697 - keras_r2: 0.0904 - val_loss: 73.5543 - val_keras_r2: 0.1344\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.8799 - keras_r2: 0.0272 - val_loss: 73.9629 - val_keras_r2: 0.1277\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.5727 - keras_r2: 0.0926 - val_loss: 73.6049 - val_keras_r2: 0.1300\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.7625 - keras_r2: 0.0925 - val_loss: 74.5742 - val_keras_r2: 0.1177\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.2432 - keras_r2: 0.0672 - val_loss: 73.9460 - val_keras_r2: 0.1275\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.5094 - keras_r2: 0.1045 - val_loss: 73.3708 - val_keras_r2: 0.1334\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.1830 - keras_r2: 0.0239 - val_loss: 73.4129 - val_keras_r2: 0.1367\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.9071 - keras_r2: 0.0793 - val_loss: 72.9167 - val_keras_r2: 0.1445\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.9398 - keras_r2: 0.1042 - val_loss: 73.4261 - val_keras_r2: 0.1360\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.7187 - keras_r2: -1.0367 - val_loss: 75.0736 - val_keras_r2: 0.1205\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.7160 - keras_r2: 0.0810 - val_loss: 72.9657 - val_keras_r2: 0.1421\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.6470 - keras_r2: 0.1234 - val_loss: 73.4861 - val_keras_r2: 0.1353\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.3213 - keras_r2: 0.1231 - val_loss: 72.8897 - val_keras_r2: 0.1421\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.1612 - keras_r2: 0.1258 - val_loss: 72.4335 - val_keras_r2: 0.1504\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.2502 - keras_r2: 0.1269 - val_loss: 72.8313 - val_keras_r2: 0.1424\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.2274 - keras_r2: 0.1014 - val_loss: 76.2871 - val_keras_r2: 0.0904\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6948 - keras_r2: 0.1409 - val_loss: 72.9163 - val_keras_r2: 0.1423\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6243 - keras_r2: 0.1230 - val_loss: 73.2894 - val_keras_r2: 0.1387\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.8378 - keras_r2: 0.1303 - val_loss: 72.7714 - val_keras_r2: 0.1455\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.8576 - keras_r2: 0.1565 - val_loss: 73.4930 - val_keras_r2: 0.1298\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6814 - keras_r2: 0.1384 - val_loss: 72.5741 - val_keras_r2: 0.1474\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.2924 - keras_r2: 0.1496 - val_loss: 73.6537 - val_keras_r2: 0.1308\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.8179 - keras_r2: 0.1388 - val_loss: 72.9993 - val_keras_r2: 0.1384\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.5770 - keras_r2: 0.1379 - val_loss: 73.3966 - val_keras_r2: 0.1394\n",
            "Epoch 43: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=60; total time=  19.7s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 143.7437 - keras_r2: -0.8096 - val_loss: 75.4686 - val_keras_r2: 0.1091\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 80.2758 - keras_r2: 0.0084 - val_loss: 75.8468 - val_keras_r2: 0.1048\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.5746 - keras_r2: 0.0312 - val_loss: 81.1837 - val_keras_r2: 0.0341\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.0535 - keras_r2: -0.0831 - val_loss: 76.0481 - val_keras_r2: 0.1034\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.3258 - keras_r2: 0.0058 - val_loss: 77.5077 - val_keras_r2: 0.0752\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.6699 - keras_r2: 0.0274 - val_loss: 76.9683 - val_keras_r2: 0.0804\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.6635 - keras_r2: 0.0339 - val_loss: 74.9656 - val_keras_r2: 0.1095\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9952 - keras_r2: 0.0531 - val_loss: 74.5071 - val_keras_r2: 0.1179\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.2989 - keras_r2: 0.0621 - val_loss: 74.6777 - val_keras_r2: 0.1232\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 78.4221 - keras_r2: -0.0012 - val_loss: 75.0486 - val_keras_r2: 0.1142\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.9202 - keras_r2: 0.0499 - val_loss: 76.6620 - val_keras_r2: 0.0871\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.2813 - keras_r2: 0.0393 - val_loss: 73.6744 - val_keras_r2: 0.1313\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.4368 - keras_r2: 0.0753 - val_loss: 77.7199 - val_keras_r2: 0.0837\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.2900 - keras_r2: 0.0704 - val_loss: 75.4540 - val_keras_r2: 0.0972\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.3529 - keras_r2: -1.3004 - val_loss: 74.3155 - val_keras_r2: 0.1187\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.3991 - keras_r2: 0.0029 - val_loss: 74.5879 - val_keras_r2: 0.1132\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.2900 - keras_r2: 0.0607 - val_loss: 77.4818 - val_keras_r2: 0.0808\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.8150 - keras_r2: 0.0832 - val_loss: 73.8538 - val_keras_r2: 0.1307\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.1540 - keras_r2: 0.0972 - val_loss: 74.1605 - val_keras_r2: 0.1240\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.7309 - keras_r2: -1.8315 - val_loss: 76.5257 - val_keras_r2: 0.0930\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.3052 - keras_r2: 0.0974 - val_loss: 73.4297 - val_keras_r2: 0.1334\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.5222 - keras_r2: 0.0759 - val_loss: 74.3553 - val_keras_r2: 0.1198\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.4041 - keras_r2: 0.0112 - val_loss: 78.9604 - val_keras_r2: 0.0544\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2588 - keras_r2: 0.1109 - val_loss: 73.4676 - val_keras_r2: 0.1313\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.1667 - keras_r2: 0.1071 - val_loss: 75.4310 - val_keras_r2: 0.1028\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.7653 - keras_r2: 0.1106 - val_loss: 73.5197 - val_keras_r2: 0.1295\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.8567 - keras_r2: -0.0474 - val_loss: 73.4342 - val_keras_r2: 0.1294\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.8946 - keras_r2: -0.1952 - val_loss: 72.9637 - val_keras_r2: 0.1361\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.1739 - keras_r2: 0.1117 - val_loss: 74.0870 - val_keras_r2: 0.1273\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0049 - keras_r2: -15306486.0000 - val_loss: 74.4507 - val_keras_r2: 0.1218\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.4835 - keras_r2: 0.1259 - val_loss: 74.9932 - val_keras_r2: 0.1076\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.9629 - keras_r2: -1.3306 - val_loss: 73.8208 - val_keras_r2: 0.1293\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.6608 - keras_r2: -0.3950 - val_loss: 73.5392 - val_keras_r2: 0.1316\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.7076 - keras_r2: 5.0233e-04 - val_loss: 74.3822 - val_keras_r2: 0.1151\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4370 - keras_r2: 0.1511 - val_loss: 73.7832 - val_keras_r2: 0.1312\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.0328 - keras_r2: 0.1050 - val_loss: 74.3970 - val_keras_r2: 0.1227\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.5118 - keras_r2: -0.8112 - val_loss: 73.1147 - val_keras_r2: 0.1338\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.1791 - keras_r2: 0.1315 - val_loss: 74.1665 - val_keras_r2: 0.1262\n",
            "Epoch 38: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=60; total time=  21.0s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 137.0896 - keras_r2: -0.7021 - val_loss: 70.6522 - val_keras_r2: 0.1097\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.0812 - keras_r2: -0.0070 - val_loss: 67.4278 - val_keras_r2: 0.1656\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.5265 - keras_r2: -0.1903 - val_loss: 67.3659 - val_keras_r2: 0.1658\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 77.9905 - keras_r2: 0.0477 - val_loss: 66.5874 - val_keras_r2: 0.1746\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.7825 - keras_r2: 0.0292 - val_loss: 67.2248 - val_keras_r2: 0.1629\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.9218 - keras_r2: 0.0423 - val_loss: 68.8263 - val_keras_r2: 0.1373\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.4571 - keras_r2: 0.0562 - val_loss: 66.3023 - val_keras_r2: 0.1776\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.7434 - keras_r2: 0.0714 - val_loss: 66.2417 - val_keras_r2: 0.1755\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.2961 - keras_r2: 0.0657 - val_loss: 66.3294 - val_keras_r2: 0.1764\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.0524 - keras_r2: 0.0621 - val_loss: 66.7091 - val_keras_r2: 0.1688\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 76.2555 - keras_r2: 0.0453 - val_loss: 66.9846 - val_keras_r2: 0.1666\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.2060 - keras_r2: 0.0747 - val_loss: 66.3992 - val_keras_r2: 0.1738\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.1018 - keras_r2: 0.0872 - val_loss: 66.8043 - val_keras_r2: 0.1657\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.6930 - keras_r2: 0.0846 - val_loss: 65.5214 - val_keras_r2: 0.1864\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.0607 - keras_r2: 0.0922 - val_loss: 66.1801 - val_keras_r2: 0.1769\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.4204 - keras_r2: 0.0804 - val_loss: 66.3873 - val_keras_r2: 0.1755\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.0225 - keras_r2: 0.1059 - val_loss: 66.8270 - val_keras_r2: 0.1693\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 74.4864 - keras_r2: 0.0539 - val_loss: 66.8411 - val_keras_r2: 0.1685\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.2377 - keras_r2: 0.1016 - val_loss: 65.4846 - val_keras_r2: 0.1864\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.3724 - keras_r2: 0.0860 - val_loss: 66.0740 - val_keras_r2: 0.1786\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.3320 - keras_r2: 0.0991 - val_loss: 65.9738 - val_keras_r2: 0.1777\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.8380 - keras_r2: 0.1104 - val_loss: 65.3076 - val_keras_r2: 0.1875\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.9715 - keras_r2: 0.1362 - val_loss: 65.0806 - val_keras_r2: 0.1920\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2876 - keras_r2: 0.1147 - val_loss: 65.4703 - val_keras_r2: 0.1863\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.7785 - keras_r2: 0.1184 - val_loss: 65.9315 - val_keras_r2: 0.1774\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0007 - keras_r2: 0.1200 - val_loss: 65.1192 - val_keras_r2: 0.1889\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.9722 - keras_r2: 0.1210 - val_loss: 65.0771 - val_keras_r2: 0.1905\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.8801 - keras_r2: 0.1169 - val_loss: 64.8535 - val_keras_r2: 0.1936\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.7086 - keras_r2: 0.1296 - val_loss: 69.1386 - val_keras_r2: 0.1354\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.9082 - keras_r2: 0.0580 - val_loss: 64.9604 - val_keras_r2: 0.1963\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 71.3988 - keras_r2: 0.1094 - val_loss: 64.7784 - val_keras_r2: 0.1956\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.5682 - keras_r2: 0.1472 - val_loss: 64.2309 - val_keras_r2: 0.2025\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.8891 - keras_r2: 0.1315 - val_loss: 65.2999 - val_keras_r2: 0.1861\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.5881 - keras_r2: 0.1180 - val_loss: 64.5669 - val_keras_r2: 0.2015\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.7036 - keras_r2: 0.1445 - val_loss: 64.5178 - val_keras_r2: 0.2013\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.0932 - keras_r2: 0.1607 - val_loss: 65.0054 - val_keras_r2: 0.1911\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6874 - keras_r2: 0.1418 - val_loss: 64.1702 - val_keras_r2: 0.2020\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 70.1324 - keras_r2: 0.1338 - val_loss: 64.4002 - val_keras_r2: 0.1998\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.2671 - keras_r2: 0.1339 - val_loss: 64.1892 - val_keras_r2: 0.2026\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.2142 - keras_r2: 0.1628 - val_loss: 64.3463 - val_keras_r2: 0.1994\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5564 - keras_r2: 0.1633 - val_loss: 64.0467 - val_keras_r2: 0.2064\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.4904 - keras_r2: -0.0571 - val_loss: 65.3894 - val_keras_r2: 0.1848\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.7465 - keras_r2: 0.1640 - val_loss: 64.1195 - val_keras_r2: 0.2055\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.5767 - keras_r2: 0.1527 - val_loss: 70.6628 - val_keras_r2: 0.1092\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.1033 - keras_r2: 0.1558 - val_loss: 63.6252 - val_keras_r2: 0.2125\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.7141 - keras_r2: 0.1619 - val_loss: 63.9137 - val_keras_r2: 0.2075\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.3292 - keras_r2: 0.1725 - val_loss: 63.9189 - val_keras_r2: 0.2093\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.6808 - keras_r2: 0.1713 - val_loss: 64.3774 - val_keras_r2: 0.1998\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.8849 - keras_r2: 0.1844 - val_loss: 64.6413 - val_keras_r2: 0.1952\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.2767 - keras_r2: 0.1499 - val_loss: 65.6896 - val_keras_r2: 0.1781\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.3423 - keras_r2: 0.1797 - val_loss: 63.6808 - val_keras_r2: 0.2093\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.0785 - keras_r2: 0.1935 - val_loss: 63.9567 - val_keras_r2: 0.2062\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.1476 - keras_r2: 0.1812 - val_loss: 63.7566 - val_keras_r2: 0.2080\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 66.0500 - keras_r2: 0.1803 - val_loss: 64.5674 - val_keras_r2: 0.1949\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.6442 - keras_r2: 0.1796 - val_loss: 63.3927 - val_keras_r2: 0.2149\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 67.0207 - keras_r2: 0.1808 - val_loss: 63.4837 - val_keras_r2: 0.2124\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.5501 - keras_r2: 0.1924 - val_loss: 63.9143 - val_keras_r2: 0.2076\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.4739 - keras_r2: 0.1937 - val_loss: 65.0015 - val_keras_r2: 0.1897\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.8510 - keras_r2: 0.1833 - val_loss: 67.1372 - val_keras_r2: 0.1599\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0740 - keras_r2: 0.1994 - val_loss: 63.7540 - val_keras_r2: 0.2091\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.0556 - keras_r2: 0.0551 - val_loss: 63.7516 - val_keras_r2: 0.2114\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0692 - keras_r2: 0.1978 - val_loss: 63.3879 - val_keras_r2: 0.2143\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.9270 - keras_r2: 0.2120 - val_loss: 63.8095 - val_keras_r2: 0.2068\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.6401 - keras_r2: 0.2024 - val_loss: 67.0394 - val_keras_r2: 0.1588\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.1702 - keras_r2: 0.2035 - val_loss: 63.0720 - val_keras_r2: 0.2166\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.0485 - keras_r2: 0.2078 - val_loss: 63.4234 - val_keras_r2: 0.2141\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.0887 - keras_r2: 0.2058 - val_loss: 63.1641 - val_keras_r2: 0.2163\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.8753 - keras_r2: 0.2104 - val_loss: 63.1785 - val_keras_r2: 0.2178\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.0316 - keras_r2: 0.1984 - val_loss: 63.2256 - val_keras_r2: 0.2168\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.3867 - keras_r2: 0.2074 - val_loss: 63.4771 - val_keras_r2: 0.2117\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6678 - keras_r2: 0.1885 - val_loss: 63.4160 - val_keras_r2: 0.2118\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 64.6285 - keras_r2: 0.2109 - val_loss: 63.5747 - val_keras_r2: 0.2092\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9598 - keras_r2: 0.2125 - val_loss: 63.7515 - val_keras_r2: 0.2070\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.5390 - keras_r2: 0.2057 - val_loss: 63.1126 - val_keras_r2: 0.2195\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.3712 - keras_r2: 0.2219 - val_loss: 63.0520 - val_keras_r2: 0.2205\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.1966 - keras_r2: 0.2098 - val_loss: 64.3301 - val_keras_r2: 0.1972\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.2988 - keras_r2: 0.2126 - val_loss: 62.8297 - val_keras_r2: 0.2227\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9533 - keras_r2: 0.2147 - val_loss: 62.9919 - val_keras_r2: 0.2179\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.5068 - keras_r2: 0.2252 - val_loss: 64.6749 - val_keras_r2: 0.2000\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.2311 - keras_r2: 0.2135 - val_loss: 63.7142 - val_keras_r2: 0.2069\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 62.8914 - keras_r2: 0.2349 - val_loss: 62.8847 - val_keras_r2: 0.2213\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.0861 - keras_r2: 0.2213 - val_loss: 62.9856 - val_keras_r2: 0.2196\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.3708 - keras_r2: 0.2144 - val_loss: 63.8402 - val_keras_r2: 0.2052\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.4551 - keras_r2: 0.2207 - val_loss: 63.3865 - val_keras_r2: 0.2113\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.5807 - keras_r2: 0.1344 - val_loss: 63.9862 - val_keras_r2: 0.2030\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 63.2176 - keras_r2: 0.2283 - val_loss: 63.1735 - val_keras_r2: 0.2152\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.9453 - keras_r2: 0.2398 - val_loss: 62.9622 - val_keras_r2: 0.2197\n",
            "Epoch 87: early stopping\n",
            "[CV] END activation=sigmoid, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=60; total time=  41.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 172.3347 - keras_r2: -1.2285 - val_loss: 75.0469 - val_keras_r2: 0.1170\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9852 - keras_r2: 0.0857 - val_loss: 73.2972 - val_keras_r2: 0.1364\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.2430 - keras_r2: 0.1352 - val_loss: 74.4450 - val_keras_r2: 0.1211\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.3256 - keras_r2: 0.1312 - val_loss: 74.5519 - val_keras_r2: 0.1172\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5693 - keras_r2: 0.1451 - val_loss: 82.1244 - val_keras_r2: 0.0087\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.6391 - keras_r2: 0.1582 - val_loss: 73.3124 - val_keras_r2: 0.1335\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.5087 - keras_r2: 0.1892 - val_loss: 75.7437 - val_keras_r2: 0.0987\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.0250 - keras_r2: 0.1818 - val_loss: 117.9211 - val_keras_r2: -0.4810\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8310 - keras_r2: 0.1943 - val_loss: 75.6039 - val_keras_r2: 0.1108\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.7258 - keras_r2: 0.1898 - val_loss: 83.5215 - val_keras_r2: 0.0077\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1209 - keras_r2: 0.2173 - val_loss: 88.7473 - val_keras_r2: -0.0827\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.0957 - keras_r2: 0.2157 - val_loss: 141.0625 - val_keras_r2: -0.8136\n",
            "Epoch 12: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.1, n_hidden=2, n_neurons=91; total time=  10.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 175.3705 - keras_r2: -1.4046 - val_loss: 85.8469 - val_keras_r2: -0.0282\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.2128 - keras_r2: 0.0242 - val_loss: 82.0353 - val_keras_r2: 0.0205\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.5383 - keras_r2: 0.0584 - val_loss: 81.6035 - val_keras_r2: 0.0198\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.6864 - keras_r2: 0.0837 - val_loss: 120.2980 - val_keras_r2: -0.5171\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2022 - keras_r2: 0.0307 - val_loss: 74.2666 - val_keras_r2: 0.1180\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.6602 - keras_r2: 0.1476 - val_loss: 87.8197 - val_keras_r2: -0.0628\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.1669 - keras_r2: 0.0969 - val_loss: 82.7555 - val_keras_r2: 0.0055\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.2543 - keras_r2: 0.1081 - val_loss: 76.4779 - val_keras_r2: 0.0710\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.5731 - keras_r2: 0.0929 - val_loss: 75.5199 - val_keras_r2: 0.0990\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.3388 - keras_r2: 0.1735 - val_loss: 77.2185 - val_keras_r2: 0.0772\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.6163 - keras_r2: 0.1897 - val_loss: 106.5332 - val_keras_r2: -0.3390\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.4089 - keras_r2: 0.1820 - val_loss: 73.7535 - val_keras_r2: 0.1156\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.5217 - keras_r2: -0.0982 - val_loss: 77.1396 - val_keras_r2: 0.0745\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.1528 - keras_r2: 0.2031 - val_loss: 112.1944 - val_keras_r2: -0.3842\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.7171 - keras_r2: 0.2163 - val_loss: 77.9241 - val_keras_r2: 0.0460\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 61.9581 - keras_r2: 0.0480 - val_loss: 80.3271 - val_keras_r2: 0.0304\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.9985 - keras_r2: 0.2222 - val_loss: 95.5764 - val_keras_r2: -0.1549\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.3531 - keras_r2: 0.2460 - val_loss: 76.1923 - val_keras_r2: 0.0824\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7327 - keras_r2: 0.2470 - val_loss: 78.1927 - val_keras_r2: 0.0418\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 60.2701 - keras_r2: 0.2482 - val_loss: 73.5293 - val_keras_r2: 0.1052\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 58.2048 - keras_r2: 0.2646 - val_loss: 93.1548 - val_keras_r2: -0.1417\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 59.0796 - keras_r2: 0.2695 - val_loss: 79.6789 - val_keras_r2: 0.0353\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.6865 - keras_r2: 0.2673 - val_loss: 72.2774 - val_keras_r2: 0.1189\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 57.6837 - keras_r2: -0.5162 - val_loss: 73.4013 - val_keras_r2: 0.1130\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.3615 - keras_r2: 0.2941 - val_loss: 74.4006 - val_keras_r2: 0.0907\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 56.8232 - keras_r2: 0.2858 - val_loss: 73.0670 - val_keras_r2: 0.1105\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.1530 - keras_r2: 0.3006 - val_loss: 73.8335 - val_keras_r2: 0.1094\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 55.0801 - keras_r2: 0.3216 - val_loss: 78.0076 - val_keras_r2: 0.0548\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.7364 - keras_r2: 0.3001 - val_loss: 76.5231 - val_keras_r2: 0.0704\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 54.7275 - keras_r2: 0.2887 - val_loss: 74.9954 - val_keras_r2: 0.0967\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.1029 - keras_r2: 0.3204 - val_loss: 88.2670 - val_keras_r2: -0.0725\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 53.7002 - keras_r2: -0.6916 - val_loss: 110.5805 - val_keras_r2: -0.4220\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.3164 - keras_r2: 0.3076 - val_loss: 73.4276 - val_keras_r2: 0.1063\n",
            "Epoch 33: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.1, n_hidden=2, n_neurons=91; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 184.5463 - keras_r2: -1.1727 - val_loss: 84.9503 - val_keras_r2: -0.0038\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.4196 - keras_r2: 0.0495 - val_loss: 74.8218 - val_keras_r2: 0.1213\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.7812 - keras_r2: 0.1056 - val_loss: 83.5590 - val_keras_r2: 0.0150\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7463 - keras_r2: 0.1469 - val_loss: 74.0562 - val_keras_r2: 0.1232\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.0136 - keras_r2: 0.1186 - val_loss: 75.5332 - val_keras_r2: 0.1142\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.9351 - keras_r2: 0.0562 - val_loss: 87.3109 - val_keras_r2: -0.0366\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.0637 - keras_r2: 0.1601 - val_loss: 81.6971 - val_keras_r2: 0.0395\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.9512 - keras_r2: 0.1730 - val_loss: 75.5509 - val_keras_r2: 0.0962\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.2506 - keras_r2: -11383562.0000 - val_loss: 110.7080 - val_keras_r2: -0.3838\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.8722 - keras_r2: 0.1868 - val_loss: 74.6882 - val_keras_r2: 0.1183\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.4513 - keras_r2: 0.1555 - val_loss: 75.6556 - val_keras_r2: 0.1006\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.2993 - keras_r2: 0.1511 - val_loss: 81.7417 - val_keras_r2: 0.0347\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.3838 - keras_r2: 0.2115 - val_loss: 75.0726 - val_keras_r2: 0.1096\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.8158 - keras_r2: 0.2058 - val_loss: 75.9578 - val_keras_r2: 0.1037\n",
            "Epoch 14: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.1, n_hidden=2, n_neurons=91; total time=   7.9s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 172.4880 - keras_r2: -1.2619 - val_loss: 93.4759 - val_keras_r2: -0.1384\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.8140 - keras_r2: -0.0950 - val_loss: 86.8331 - val_keras_r2: -0.0473\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 82.2293 - keras_r2: -0.0409 - val_loss: 86.6962 - val_keras_r2: -0.0579\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.4480 - keras_r2: 0.0093 - val_loss: 91.6075 - val_keras_r2: -0.1076\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.4085 - keras_r2: 0.0218 - val_loss: 94.6622 - val_keras_r2: -0.1471\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.5212 - keras_r2: 0.0397 - val_loss: 94.6387 - val_keras_r2: -0.1644\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.1399 - keras_r2: 0.0567 - val_loss: 86.3297 - val_keras_r2: -0.0401\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.6320 - keras_r2: 0.0609 - val_loss: 102.5167 - val_keras_r2: -0.2472\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.5375 - keras_r2: 0.0673 - val_loss: 86.8639 - val_keras_r2: -0.0523\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.1924 - keras_r2: 0.0823 - val_loss: 84.3520 - val_keras_r2: -0.0242\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.2421 - keras_r2: 0.0806 - val_loss: 87.4634 - val_keras_r2: -0.0688\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.6517 - keras_r2: 0.1123 - val_loss: 80.5436 - val_keras_r2: 0.0437\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.9814 - keras_r2: 0.1743 - val_loss: 77.4137 - val_keras_r2: 0.0915\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.6158 - keras_r2: 0.1920 - val_loss: 89.0830 - val_keras_r2: -0.0781\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 63.9564 - keras_r2: 0.2117 - val_loss: 77.8423 - val_keras_r2: 0.0806\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.9387 - keras_r2: 0.1835 - val_loss: 102.3645 - val_keras_r2: -0.2250\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.5073 - keras_r2: 0.1424 - val_loss: 78.2899 - val_keras_r2: 0.0738\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8713 - keras_r2: 0.2396 - val_loss: 77.7639 - val_keras_r2: 0.0807\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.1934 - keras_r2: 0.2283 - val_loss: 138.6373 - val_keras_r2: -0.7790\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 62.0323 - keras_r2: 0.2358 - val_loss: 90.4913 - val_keras_r2: -0.0767\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7352 - keras_r2: 0.2501 - val_loss: 85.6588 - val_keras_r2: -0.0090\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.8591 - keras_r2: 0.1881 - val_loss: 79.2572 - val_keras_r2: 0.0644\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.0305 - keras_r2: 0.2352 - val_loss: 90.2805 - val_keras_r2: -0.0721\n",
            "Epoch 23: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.1, n_hidden=2, n_neurons=91; total time=  21.1s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 155.5247 - keras_r2: -0.8508 - val_loss: 70.9270 - val_keras_r2: 0.1110\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.1272 - keras_r2: 0.0852 - val_loss: 70.1759 - val_keras_r2: 0.1272\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5749 - keras_r2: -0.0315 - val_loss: 68.7437 - val_keras_r2: 0.1454\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.7158 - keras_r2: 0.1273 - val_loss: 118.6451 - val_keras_r2: -0.5483\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.3269 - keras_r2: 0.1423 - val_loss: 85.3338 - val_keras_r2: -0.0612\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.8849 - keras_r2: 0.1602 - val_loss: 96.7364 - val_keras_r2: -0.2511\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.7291 - keras_r2: 0.1666 - val_loss: 73.3610 - val_keras_r2: 0.0762\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.1615 - keras_r2: 0.1940 - val_loss: 79.5266 - val_keras_r2: 0.0090\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.2066 - keras_r2: 0.1770 - val_loss: 71.7563 - val_keras_r2: 0.1097\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.1355 - keras_r2: 0.1745 - val_loss: 84.1021 - val_keras_r2: -0.0458\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 63.9140 - keras_r2: 0.2012 - val_loss: 75.3060 - val_keras_r2: 0.0673\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 64.0751 - keras_r2: 0.2173 - val_loss: 71.0063 - val_keras_r2: 0.1028\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 62.5090 - keras_r2: 0.2350 - val_loss: 65.5295 - val_keras_r2: 0.1802\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.9580 - keras_r2: 0.2416 - val_loss: 70.4363 - val_keras_r2: 0.1180\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 61.8772 - keras_r2: 0.2324 - val_loss: 72.2814 - val_keras_r2: 0.1018\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7429 - keras_r2: 0.2483 - val_loss: 74.7279 - val_keras_r2: 0.0746\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.6478 - keras_r2: 0.2397 - val_loss: 83.9033 - val_keras_r2: -0.0610\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 60.7525 - keras_r2: 0.2300 - val_loss: 64.8083 - val_keras_r2: 0.1955\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.4110 - keras_r2: 0.2777 - val_loss: 67.6933 - val_keras_r2: 0.1596\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.9186 - keras_r2: 0.2843 - val_loss: 70.2570 - val_keras_r2: 0.1191\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 58.1613 - keras_r2: 0.2779 - val_loss: 69.3909 - val_keras_r2: 0.1428\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 57.2718 - keras_r2: 0.2843 - val_loss: 81.2192 - val_keras_r2: -0.0120\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 56.8621 - keras_r2: 0.2900 - val_loss: 67.9561 - val_keras_r2: 0.1474\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.9161 - keras_r2: 0.3046 - val_loss: 70.6925 - val_keras_r2: 0.1208\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 55.7092 - keras_r2: 0.3093 - val_loss: 65.9550 - val_keras_r2: 0.1802\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 54.7195 - keras_r2: 0.3249 - val_loss: 68.3163 - val_keras_r2: 0.1441\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 54.1569 - keras_r2: 0.3289 - val_loss: 65.8855 - val_keras_r2: 0.1754\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 53.8571 - keras_r2: 0.2963 - val_loss: 73.5423 - val_keras_r2: 0.0860\n",
            "Epoch 28: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.1, n_hidden=2, n_neurons=91; total time=  15.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 286.0656 - keras_r2: -2.6011 - val_loss: 75.6306 - val_keras_r2: 0.1120\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 78.4398 - keras_r2: 0.0103 - val_loss: 74.2223 - val_keras_r2: 0.1269\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.1025 - keras_r2: 0.0406 - val_loss: 73.9969 - val_keras_r2: 0.1290\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.9238 - keras_r2: 0.0562 - val_loss: 74.7279 - val_keras_r2: 0.1158\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.8355 - keras_r2: -0.2195 - val_loss: 82.9378 - val_keras_r2: 2.6977e-04\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.3147 - keras_r2: 0.0745 - val_loss: 73.5161 - val_keras_r2: 0.1334\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.9877 - keras_r2: 0.0879 - val_loss: 75.5963 - val_keras_r2: 0.1033\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9328 - keras_r2: 0.0475 - val_loss: 74.8250 - val_keras_r2: 0.1206\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.2679 - keras_r2: 0.0820 - val_loss: 72.7634 - val_keras_r2: 0.1395\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.7468 - keras_r2: -0.1114 - val_loss: 74.4889 - val_keras_r2: 0.1262\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1331 - keras_r2: 0.0936 - val_loss: 73.1211 - val_keras_r2: 0.1342\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1145 - keras_r2: -0.1182 - val_loss: 73.0009 - val_keras_r2: 0.1431\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.0793 - keras_r2: -4.4306e-04 - val_loss: 74.7132 - val_keras_r2: 0.1159\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.4063 - keras_r2: 0.0905 - val_loss: 71.5603 - val_keras_r2: 0.1557\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.8616 - keras_r2: -0.2723 - val_loss: 73.6618 - val_keras_r2: 0.1342\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2944 - keras_r2: -1410213.1250 - val_loss: 73.1168 - val_keras_r2: 0.1335\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.2857 - keras_r2: 0.1020 - val_loss: 71.1091 - val_keras_r2: 0.1626\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0303 - keras_r2: 0.1218 - val_loss: 71.3998 - val_keras_r2: 0.1594\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.4857 - keras_r2: 0.1063 - val_loss: 71.4385 - val_keras_r2: 0.1571\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3325 - keras_r2: 0.1309 - val_loss: 71.8129 - val_keras_r2: 0.1544\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.4158 - keras_r2: 0.0855 - val_loss: 71.3605 - val_keras_r2: 0.1586\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.2230 - keras_r2: 0.1258 - val_loss: 72.6159 - val_keras_r2: 0.1427\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.4659 - keras_r2: 0.1341 - val_loss: 71.8663 - val_keras_r2: 0.1509\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5120 - keras_r2: -4611436.5000 - val_loss: 72.2376 - val_keras_r2: 0.1501\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2032 - keras_r2: 0.1255 - val_loss: 71.9140 - val_keras_r2: 0.1521\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.5007 - keras_r2: -1.7391 - val_loss: 71.7572 - val_keras_r2: 0.1550\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.2857 - keras_r2: -0.0171 - val_loss: 73.6433 - val_keras_r2: 0.1340\n",
            "Epoch 27: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=22; total time=  22.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 257.5824 - keras_r2: -2.5505 - val_loss: 73.7050 - val_keras_r2: 0.1155\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.5048 - keras_r2: -0.0513 - val_loss: 73.0881 - val_keras_r2: 0.1297\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.8922 - keras_r2: 0.0153 - val_loss: 74.1076 - val_keras_r2: 0.1164\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 78.7419 - keras_r2: 0.0380 - val_loss: 72.8107 - val_keras_r2: 0.1305\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.9171 - keras_r2: 0.0279 - val_loss: 73.8418 - val_keras_r2: 0.1223\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.6867 - keras_r2: -0.0396 - val_loss: 72.4806 - val_keras_r2: 0.1377\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 76.4071 - keras_r2: -1563441.6250 - val_loss: 73.7244 - val_keras_r2: 0.1224\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.2646 - keras_r2: 0.0586 - val_loss: 72.1212 - val_keras_r2: 0.1416\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.6958 - keras_r2: -0.0716 - val_loss: 72.0490 - val_keras_r2: 0.1413\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.4963 - keras_r2: 0.0649 - val_loss: 73.5283 - val_keras_r2: 0.1267\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 75.8163 - keras_r2: 0.0550 - val_loss: 75.4099 - val_keras_r2: 0.0899\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.8535 - keras_r2: 0.0436 - val_loss: 80.6797 - val_keras_r2: 0.0117\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.3355 - keras_r2: 0.0207 - val_loss: 74.8221 - val_keras_r2: 0.0976\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.3282 - keras_r2: -0.3774 - val_loss: 73.6132 - val_keras_r2: 0.1244\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.3994 - keras_r2: 0.0874 - val_loss: 71.3408 - val_keras_r2: 0.1473\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.1514 - keras_r2: -0.2254 - val_loss: 71.9094 - val_keras_r2: 0.1404\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.6867 - keras_r2: 0.0951 - val_loss: 71.1274 - val_keras_r2: 0.1502\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.2253 - keras_r2: 0.0699 - val_loss: 72.4239 - val_keras_r2: 0.1350\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.3738 - keras_r2: 0.0301 - val_loss: 70.7756 - val_keras_r2: 0.1535\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.7053 - keras_r2: 0.1129 - val_loss: 71.2448 - val_keras_r2: 0.1485\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.8888 - keras_r2: 0.1195 - val_loss: 70.9950 - val_keras_r2: 0.1531\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.0013 - keras_r2: 0.1143 - val_loss: 73.3277 - val_keras_r2: 0.1213\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.9111 - keras_r2: 0.0850 - val_loss: 76.5225 - val_keras_r2: 0.0663\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.8273 - keras_r2: -1.4714 - val_loss: 72.3399 - val_keras_r2: 0.1343\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3745 - keras_r2: 0.1189 - val_loss: 70.9686 - val_keras_r2: 0.1466\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.7891 - keras_r2: 0.1289 - val_loss: 71.7392 - val_keras_r2: 0.1431\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.4445 - keras_r2: -3189704.0000 - val_loss: 71.6282 - val_keras_r2: 0.1433\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.4027 - keras_r2: 0.1514 - val_loss: 71.4754 - val_keras_r2: 0.1454\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.1494 - keras_r2: 0.1642 - val_loss: 72.9534 - val_keras_r2: 0.1161\n",
            "Epoch 29: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=22; total time=  19.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 5ms/step - loss: 284.9157 - keras_r2: -2.8186 - val_loss: 77.4415 - val_keras_r2: 0.0729\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 79.1099 - keras_r2: 0.0375 - val_loss: 74.3256 - val_keras_r2: 0.1229\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 78.0597 - keras_r2: -0.0409 - val_loss: 76.0094 - val_keras_r2: 0.0934\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 77.2537 - keras_r2: 0.0275 - val_loss: 75.1368 - val_keras_r2: 0.1081\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 78.4356 - keras_r2: 0.0247 - val_loss: 74.0119 - val_keras_r2: 0.1275\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 77.4774 - keras_r2: 0.0337 - val_loss: 75.2254 - val_keras_r2: 0.1156\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 76.2705 - keras_r2: -29785938.0000 - val_loss: 74.1323 - val_keras_r2: 0.1261\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 75.0612 - keras_r2: 0.0869 - val_loss: 73.3299 - val_keras_r2: 0.1326\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 76.3965 - keras_r2: 0.0504 - val_loss: 74.9997 - val_keras_r2: 0.1085\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4760 - keras_r2: 0.0862 - val_loss: 80.0039 - val_keras_r2: 0.0376\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 74.2661 - keras_r2: 0.0932 - val_loss: 74.8759 - val_keras_r2: 0.1211\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 75.0900 - keras_r2: 0.0797 - val_loss: 74.5051 - val_keras_r2: 0.1142\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.9074 - keras_r2: 0.0627 - val_loss: 75.3408 - val_keras_r2: 0.1040\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 74.3852 - keras_r2: 0.0338 - val_loss: 74.3867 - val_keras_r2: 0.1260\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.5404 - keras_r2: 0.1053 - val_loss: 73.6202 - val_keras_r2: 0.1341\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.6114 - keras_r2: 0.0615 - val_loss: 72.7908 - val_keras_r2: 0.1437\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5000 - keras_r2: 0.1316 - val_loss: 72.9733 - val_keras_r2: 0.1373\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1711 - keras_r2: 0.1182 - val_loss: 72.7703 - val_keras_r2: 0.1416\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.9499 - keras_r2: 0.0368 - val_loss: 73.4986 - val_keras_r2: 0.1371\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.9540 - keras_r2: 0.0987 - val_loss: 74.1444 - val_keras_r2: 0.1287\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.9712 - keras_r2: 0.1093 - val_loss: 75.9167 - val_keras_r2: 0.0918\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.0238 - keras_r2: -0.2386 - val_loss: 75.8476 - val_keras_r2: 0.0930\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.0339 - keras_r2: 0.1193 - val_loss: 74.2957 - val_keras_r2: 0.1273\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3821 - keras_r2: -0.1100 - val_loss: 75.7333 - val_keras_r2: 0.1121\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.2208 - keras_r2: 0.1149 - val_loss: 71.6073 - val_keras_r2: 0.1558\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.5044 - keras_r2: 0.1193 - val_loss: 72.5440 - val_keras_r2: 0.1445\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.5383 - keras_r2: 0.1189 - val_loss: 74.4366 - val_keras_r2: 0.1253\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.5680 - keras_r2: 0.1425 - val_loss: 74.7178 - val_keras_r2: 0.1077\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.1366 - keras_r2: 0.1257 - val_loss: 71.8505 - val_keras_r2: 0.1516\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9274 - keras_r2: 0.1393 - val_loss: 72.0011 - val_keras_r2: 0.1513\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.1183 - keras_r2: 0.1362 - val_loss: 73.1156 - val_keras_r2: 0.1380\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.9733 - keras_r2: 0.1333 - val_loss: 71.9279 - val_keras_r2: 0.1543\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.6600 - keras_r2: 0.1132 - val_loss: 72.1618 - val_keras_r2: 0.1524\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.1785 - keras_r2: 0.1548 - val_loss: 71.7130 - val_keras_r2: 0.1535\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.4605 - keras_r2: -0.1321 - val_loss: 72.8521 - val_keras_r2: 0.1355\n",
            "Epoch 35: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=22; total time=  42.4s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 277.5128 - keras_r2: -2.7181 - val_loss: 75.7500 - val_keras_r2: 0.1075\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 80.3120 - keras_r2: 0.0250 - val_loss: 74.2152 - val_keras_r2: 0.1218\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.9675 - keras_r2: 0.0430 - val_loss: 74.9266 - val_keras_r2: 0.1115\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 77.5605 - keras_r2: 0.0265 - val_loss: 75.1471 - val_keras_r2: 0.1080\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.4668 - keras_r2: -0.0144 - val_loss: 74.2752 - val_keras_r2: 0.1207\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.4268 - keras_r2: 0.0441 - val_loss: 76.8118 - val_keras_r2: 0.0825\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.6814 - keras_r2: 0.0576 - val_loss: 73.4553 - val_keras_r2: 0.1349\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.4638 - keras_r2: 0.0697 - val_loss: 73.9476 - val_keras_r2: 0.1285\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.4003 - keras_r2: 0.0921 - val_loss: 73.6855 - val_keras_r2: 0.1339\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5257 - keras_r2: 0.0711 - val_loss: 73.9211 - val_keras_r2: 0.1295\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.0784 - keras_r2: 0.0886 - val_loss: 75.3646 - val_keras_r2: 0.1051\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.6739 - keras_r2: 0.0673 - val_loss: 89.9677 - val_keras_r2: -0.1060\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.5670 - keras_r2: 0.1091 - val_loss: 73.9063 - val_keras_r2: 0.1240\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.5470 - keras_r2: -1.3462 - val_loss: 81.7372 - val_keras_r2: 0.0134\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.1176 - keras_r2: 0.1070 - val_loss: 75.4231 - val_keras_r2: 0.1051\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.3417 - keras_r2: -0.0074 - val_loss: 77.1935 - val_keras_r2: 0.0914\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.9846 - keras_r2: 0.0245 - val_loss: 74.7274 - val_keras_r2: 0.1090\n",
            "Epoch 17: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=22; total time=  21.8s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 2s 4ms/step - loss: 260.9636 - keras_r2: -2.4282 - val_loss: 69.8818 - val_keras_r2: 0.1316\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 76.9039 - keras_r2: 0.0504 - val_loss: 66.8322 - val_keras_r2: 0.1756\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 76.9709 - keras_r2: 0.0422 - val_loss: 67.4729 - val_keras_r2: 0.1643\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.8693 - keras_r2: 0.0342 - val_loss: 69.9303 - val_keras_r2: 0.1306\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 74.8891 - keras_r2: 0.0584 - val_loss: 67.0405 - val_keras_r2: 0.1746\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5237 - keras_r2: 0.0919 - val_loss: 66.1517 - val_keras_r2: 0.1827\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.1518 - keras_r2: 0.0730 - val_loss: 66.1708 - val_keras_r2: 0.1805\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.9637 - keras_r2: 0.0932 - val_loss: 68.5049 - val_keras_r2: 0.1517\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.7371 - keras_r2: 0.0739 - val_loss: 66.2917 - val_keras_r2: 0.1800\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.3814 - keras_r2: 0.0609 - val_loss: 65.9285 - val_keras_r2: 0.1862\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 73.3992 - keras_r2: 0.0108 - val_loss: 69.6922 - val_keras_r2: 0.1278\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.7279 - keras_r2: 0.1123 - val_loss: 67.7017 - val_keras_r2: 0.1571\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.4203 - keras_r2: 0.1170 - val_loss: 65.9744 - val_keras_r2: 0.1790\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.9250 - keras_r2: 0.1040 - val_loss: 66.3208 - val_keras_r2: 0.1744\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 72.2220 - keras_r2: 0.0743 - val_loss: 67.0517 - val_keras_r2: 0.1747\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.5856 - keras_r2: -0.1300 - val_loss: 64.9452 - val_keras_r2: 0.1915\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.2418 - keras_r2: 0.1288 - val_loss: 66.4528 - val_keras_r2: 0.1711\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.5776 - keras_r2: 0.1382 - val_loss: 64.8071 - val_keras_r2: 0.2031\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2250 - keras_r2: 0.1164 - val_loss: 66.9445 - val_keras_r2: 0.1645\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.4423 - keras_r2: -0.6523 - val_loss: 64.5156 - val_keras_r2: 0.2049\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.5910 - keras_r2: 0.1337 - val_loss: 65.2978 - val_keras_r2: 0.1885\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 71.1751 - keras_r2: 0.1291 - val_loss: 64.3676 - val_keras_r2: 0.2019\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.7462 - keras_r2: 0.1518 - val_loss: 67.1117 - val_keras_r2: 0.1613\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.4751 - keras_r2: 0.1529 - val_loss: 64.4626 - val_keras_r2: 0.2038\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 70.9261 - keras_r2: 0.1200 - val_loss: 63.3738 - val_keras_r2: 0.2187\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.1902 - keras_r2: 0.0279 - val_loss: 64.8997 - val_keras_r2: 0.1968\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.3113 - keras_r2: 0.1223 - val_loss: 64.5851 - val_keras_r2: 0.1990\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 68.5229 - keras_r2: 0.1285 - val_loss: 65.0481 - val_keras_r2: 0.2006\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.1264 - keras_r2: 0.0642 - val_loss: 64.1035 - val_keras_r2: 0.2084\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 68.7539 - keras_r2: 0.1551 - val_loss: 66.1294 - val_keras_r2: 0.1749\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.0833 - keras_r2: 0.1360 - val_loss: 65.1046 - val_keras_r2: 0.1915\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.5495 - keras_r2: 0.1788 - val_loss: 64.7725 - val_keras_r2: 0.1942\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 69.4610 - keras_r2: 0.1464 - val_loss: 65.1190 - val_keras_r2: 0.1861\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 67.7408 - keras_r2: 0.1605 - val_loss: 64.5541 - val_keras_r2: 0.2000\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 66.9909 - keras_r2: 0.1492 - val_loss: 65.6284 - val_keras_r2: 0.1794\n",
            "Epoch 35: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=True, dropout=0.1, n_hidden=3, n_neurons=22; total time=  42.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 250.7698 - keras_r2: -2.0535 - val_loss: 97.3306 - val_keras_r2: -0.1695\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 96.7857 - keras_r2: -0.2266 - val_loss: 88.8856 - val_keras_r2: -0.0596\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 89.5836 - keras_r2: -0.1194 - val_loss: 114.2517 - val_keras_r2: -0.3819\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 85.0217 - keras_r2: -0.0687 - val_loss: 76.6323 - val_keras_r2: 0.0877\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 82.2547 - keras_r2: -0.0310 - val_loss: 75.8641 - val_keras_r2: 0.1097\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 79.8864 - keras_r2: -0.2487 - val_loss: 76.7663 - val_keras_r2: 0.0804\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.6722 - keras_r2: -0.2419 - val_loss: 77.4353 - val_keras_r2: 0.0810\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.5597 - keras_r2: -0.0331 - val_loss: 73.7149 - val_keras_r2: 0.1297\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 76.4506 - keras_r2: 0.0470 - val_loss: 77.3580 - val_keras_r2: 0.0757\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.5651 - keras_r2: 0.0358 - val_loss: 77.3735 - val_keras_r2: 0.0878\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.5289 - keras_r2: 0.0182 - val_loss: 76.0702 - val_keras_r2: 0.0924\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.0741 - keras_r2: 0.0092 - val_loss: 82.7379 - val_keras_r2: 0.0134\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.2607 - keras_r2: 0.0112 - val_loss: 75.7713 - val_keras_r2: 0.0972\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.3265 - keras_r2: 0.0737 - val_loss: 73.8274 - val_keras_r2: 0.1197\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.0973 - keras_r2: 0.0904 - val_loss: 75.9982 - val_keras_r2: 0.0940\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.4038 - keras_r2: 0.0665 - val_loss: 76.6582 - val_keras_r2: 0.0913\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.2623 - keras_r2: 0.0944 - val_loss: 73.3541 - val_keras_r2: 0.1288\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.0364 - keras_r2: 0.1031 - val_loss: 73.9352 - val_keras_r2: 0.1220\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.8042 - keras_r2: 0.1118 - val_loss: 73.6360 - val_keras_r2: 0.1276\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.2579 - keras_r2: 0.0752 - val_loss: 75.0169 - val_keras_r2: 0.1104\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.5266 - keras_r2: 0.1067 - val_loss: 75.6738 - val_keras_r2: 0.1012\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.2956 - keras_r2: 0.1390 - val_loss: 71.7014 - val_keras_r2: 0.1479\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.7105 - keras_r2: 0.1401 - val_loss: 75.9346 - val_keras_r2: 0.0970\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.1191 - keras_r2: -0.8463 - val_loss: 73.5565 - val_keras_r2: 0.1207\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.3454 - keras_r2: 0.1354 - val_loss: 73.6973 - val_keras_r2: 0.1225\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.4008 - keras_r2: -0.6208 - val_loss: 76.2268 - val_keras_r2: 0.0878\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.6028 - keras_r2: 0.1689 - val_loss: 72.9034 - val_keras_r2: 0.1313\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.8329 - keras_r2: 0.1380 - val_loss: 73.1168 - val_keras_r2: 0.1320\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.2186 - keras_r2: 0.1706 - val_loss: 74.8296 - val_keras_r2: 0.1089\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.5935 - keras_r2: 0.1804 - val_loss: 72.8026 - val_keras_r2: 0.1366\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.7873 - keras_r2: 0.1708 - val_loss: 76.1121 - val_keras_r2: 0.0862\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.0487 - keras_r2: -0.0243 - val_loss: 75.2329 - val_keras_r2: 0.1019\n",
            "Epoch 32: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=75; total time=  16.3s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 4ms/step - loss: 246.6913 - keras_r2: -2.0759 - val_loss: 81.1159 - val_keras_r2: 0.0244\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 92.3276 - keras_r2: -0.1890 - val_loss: 84.8724 - val_keras_r2: -0.0112\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 88.1832 - keras_r2: -0.1232 - val_loss: 142.7403 - val_keras_r2: -0.8202\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 87.4007 - keras_r2: -0.0809 - val_loss: 85.0466 - val_keras_r2: -0.0354\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 82.1072 - keras_r2: -0.0215 - val_loss: 81.5177 - val_keras_r2: 0.0148\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.2957 - keras_r2: -0.1185 - val_loss: 75.2933 - val_keras_r2: 0.0967\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.5068 - keras_r2: -0.0107 - val_loss: 77.7272 - val_keras_r2: 0.0748\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 77.3308 - keras_r2: -0.0299 - val_loss: 77.8455 - val_keras_r2: 0.0492\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.8331 - keras_r2: 0.0239 - val_loss: 74.1612 - val_keras_r2: 0.1136\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.9837 - keras_r2: 0.0411 - val_loss: 79.4856 - val_keras_r2: 0.0470\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.5904 - keras_r2: 0.0531 - val_loss: 75.7203 - val_keras_r2: 0.0912\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.0562 - keras_r2: 0.0459 - val_loss: 77.0361 - val_keras_r2: 0.0721\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.5775 - keras_r2: 0.0146 - val_loss: 77.4432 - val_keras_r2: 0.0572\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.9303 - keras_r2: 0.0576 - val_loss: 78.2283 - val_keras_r2: 0.0579\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 73.0608 - keras_r2: 0.0903 - val_loss: 72.0752 - val_keras_r2: 0.1327\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 72.0366 - keras_r2: 0.1078 - val_loss: 74.6867 - val_keras_r2: 0.0973\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.0579 - keras_r2: 0.0833 - val_loss: 73.2795 - val_keras_r2: 0.1197\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.9185 - keras_r2: -0.4953 - val_loss: 77.9324 - val_keras_r2: 0.0563\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.8874 - keras_r2: 0.1111 - val_loss: 74.7271 - val_keras_r2: 0.0965\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.1907 - keras_r2: 0.0760 - val_loss: 73.5699 - val_keras_r2: 0.1142\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.5747 - keras_r2: -0.0041 - val_loss: 73.5770 - val_keras_r2: 0.1174\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9623 - keras_r2: 0.1119 - val_loss: 72.9526 - val_keras_r2: 0.1246\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0868 - keras_r2: -0.6432 - val_loss: 73.6566 - val_keras_r2: 0.1186\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 70.0044 - keras_r2: 0.1357 - val_loss: 73.2055 - val_keras_r2: 0.1207\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.1856 - keras_r2: 0.1448 - val_loss: 73.5198 - val_keras_r2: 0.1125\n",
            "Epoch 25: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=75; total time=  13.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 242.5067 - keras_r2: -2.1833 - val_loss: 89.8044 - val_keras_r2: -0.0843\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.9994 - keras_r2: -0.1320 - val_loss: 86.4080 - val_keras_r2: -0.0363\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 87.1732 - keras_r2: -0.3236 - val_loss: 92.3807 - val_keras_r2: -0.1230\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 84.6334 - keras_r2: -0.0397 - val_loss: 76.4478 - val_keras_r2: 0.0940\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.7751 - keras_r2: -0.1445 - val_loss: 124.8088 - val_keras_r2: -0.5970\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 81.7152 - keras_r2: -0.0191 - val_loss: 77.7999 - val_keras_r2: 0.0698\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 80.6644 - keras_r2: 0.0017 - val_loss: 75.2533 - val_keras_r2: 0.1076\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.6417 - keras_r2: 0.0104 - val_loss: 75.1898 - val_keras_r2: 0.1057\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 78.9423 - keras_r2: 0.0237 - val_loss: 79.4071 - val_keras_r2: 0.0516\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.6573 - keras_r2: -1.2209 - val_loss: 90.4576 - val_keras_r2: -0.0836\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.6769 - keras_r2: 0.0337 - val_loss: 75.5193 - val_keras_r2: 0.1087\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.1102 - keras_r2: 0.0086 - val_loss: 81.6954 - val_keras_r2: 0.0297\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.5907 - keras_r2: 0.0470 - val_loss: 78.4593 - val_keras_r2: 0.0611\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 73.5833 - keras_r2: 0.0850 - val_loss: 76.4025 - val_keras_r2: 0.0971\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 75.4109 - keras_r2: 0.0550 - val_loss: 74.4663 - val_keras_r2: 0.1219\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.4734 - keras_r2: 0.0657 - val_loss: 75.2597 - val_keras_r2: 0.1063\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.7868 - keras_r2: 0.0914 - val_loss: 75.2334 - val_keras_r2: 0.1116\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.7474 - keras_r2: 0.1211 - val_loss: 74.6574 - val_keras_r2: 0.1129\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.0861 - keras_r2: 0.0772 - val_loss: 96.0249 - val_keras_r2: -0.1781\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 72.9991 - keras_r2: 0.0611 - val_loss: 76.2007 - val_keras_r2: 0.0916\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.6820 - keras_r2: 0.0946 - val_loss: 77.3392 - val_keras_r2: 0.0840\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.8958 - keras_r2: 0.1097 - val_loss: 72.7497 - val_keras_r2: 0.1378\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.9498 - keras_r2: 0.1149 - val_loss: 109.2422 - val_keras_r2: -0.3584\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.5836 - keras_r2: 0.1104 - val_loss: 74.0717 - val_keras_r2: 0.1242\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 69.6999 - keras_r2: 0.1137 - val_loss: 75.6133 - val_keras_r2: 0.1026\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.7572 - keras_r2: -6714977.5000 - val_loss: 75.5454 - val_keras_r2: 0.1068\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.2920 - keras_r2: 0.1459 - val_loss: 73.6047 - val_keras_r2: 0.1253\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.9953 - keras_r2: 0.1221 - val_loss: 73.2347 - val_keras_r2: 0.1254\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 68.6125 - keras_r2: -2717790.5000 - val_loss: 74.8993 - val_keras_r2: 0.1108\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.8402 - keras_r2: 0.1790 - val_loss: 74.9757 - val_keras_r2: 0.1074\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.9793 - keras_r2: 0.1276 - val_loss: 73.3933 - val_keras_r2: 0.1300\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.4238 - keras_r2: 0.1810 - val_loss: 72.5495 - val_keras_r2: 0.1352\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.5841 - keras_r2: 0.1487 - val_loss: 76.4487 - val_keras_r2: 0.0909\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.1833 - keras_r2: 0.0872 - val_loss: 74.0322 - val_keras_r2: 0.1235\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 65.6342 - keras_r2: 0.1706 - val_loss: 77.9856 - val_keras_r2: 0.0603\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.3274 - keras_r2: 0.1568 - val_loss: 78.9877 - val_keras_r2: 0.0414\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.8766 - keras_r2: 0.1751 - val_loss: 75.1824 - val_keras_r2: 0.0955\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 66.6340 - keras_r2: 0.1526 - val_loss: 74.0396 - val_keras_r2: 0.1160\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 66.3334 - keras_r2: 0.1845 - val_loss: 79.1786 - val_keras_r2: 0.0438\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 65.9489 - keras_r2: -0.1502 - val_loss: 75.2755 - val_keras_r2: 0.1005\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 64.8576 - keras_r2: -0.0196 - val_loss: 75.8235 - val_keras_r2: 0.0981\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 0s 2ms/step - loss: 65.1825 - keras_r2: 0.2037 - val_loss: 74.1805 - val_keras_r2: 0.1155\n",
            "Epoch 42: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=75; total time=  41.5s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 254.6925 - keras_r2: -2.2647 - val_loss: 95.5138 - val_keras_r2: -0.1508\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 100.2522 - keras_r2: -0.4524 - val_loss: 84.9802 - val_keras_r2: 0.0047\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 91.0975 - keras_r2: -0.1355 - val_loss: 96.7989 - val_keras_r2: -0.1686\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 85.5434 - keras_r2: -0.0796 - val_loss: 77.7611 - val_keras_r2: 0.0794\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 83.2767 - keras_r2: -0.0395 - val_loss: 77.6724 - val_keras_r2: 0.0802\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 81.8816 - keras_r2: -0.2278 - val_loss: 109.9392 - val_keras_r2: -0.3534\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.7754 - keras_r2: -0.1167 - val_loss: 77.6265 - val_keras_r2: 0.0750\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 78.5011 - keras_r2: 0.0147 - val_loss: 77.3561 - val_keras_r2: 0.0838\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.7919 - keras_r2: -0.2495 - val_loss: 80.8071 - val_keras_r2: 0.0329\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.3221 - keras_r2: 0.0209 - val_loss: 77.4160 - val_keras_r2: 0.0683\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 76.7509 - keras_r2: 0.0641 - val_loss: 74.0403 - val_keras_r2: 0.1192\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6409 - keras_r2: 0.0713 - val_loss: 75.8048 - val_keras_r2: 0.1002\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.0743 - keras_r2: -0.0449 - val_loss: 74.5905 - val_keras_r2: 0.1133\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 74.5152 - keras_r2: 0.0542 - val_loss: 76.3862 - val_keras_r2: 0.0910\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 75.1710 - keras_r2: 0.0193 - val_loss: 78.9954 - val_keras_r2: 0.0509\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.3647 - keras_r2: 0.0980 - val_loss: 76.4992 - val_keras_r2: 0.0915\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.8449 - keras_r2: -0.0496 - val_loss: 75.8352 - val_keras_r2: 0.1010\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.9052 - keras_r2: 0.1186 - val_loss: 74.4971 - val_keras_r2: 0.1121\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.2883 - keras_r2: 0.1174 - val_loss: 76.2222 - val_keras_r2: 0.0897\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.7727 - keras_r2: 0.0997 - val_loss: 74.8990 - val_keras_r2: 0.1082\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 71.2306 - keras_r2: 0.1074 - val_loss: 76.2199 - val_keras_r2: 0.0911\n",
            "Epoch 21: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=75; total time=  11.2s\n",
            "Epoch 1/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 231.3494 - keras_r2: -2.0197 - val_loss: 100.0392 - val_keras_r2: -0.2940\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 90.5141 - keras_r2: -0.1246 - val_loss: 75.0834 - val_keras_r2: 0.0455\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 86.4447 - keras_r2: -0.0932 - val_loss: 78.9433 - val_keras_r2: -0.0069\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 84.6689 - keras_r2: -0.0511 - val_loss: 73.8085 - val_keras_r2: 0.0572\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.8950 - keras_r2: -0.0216 - val_loss: 71.3183 - val_keras_r2: 0.0944\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 81.0608 - keras_r2: -0.0086 - val_loss: 73.2765 - val_keras_r2: 0.0738\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.1163 - keras_r2: -0.0033 - val_loss: 77.3601 - val_keras_r2: 0.0232\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.2746 - keras_r2: -0.0277 - val_loss: 76.3050 - val_keras_r2: 0.0438\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 79.1217 - keras_r2: 0.0021 - val_loss: 79.2639 - val_keras_r2: -0.0115\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 77.6170 - keras_r2: 0.0293 - val_loss: 73.2011 - val_keras_r2: 0.0726\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.1791 - keras_r2: 0.0736 - val_loss: 69.1074 - val_keras_r2: 0.1278\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 75.5236 - keras_r2: -0.0571 - val_loss: 74.0342 - val_keras_r2: 0.0662\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 74.6745 - keras_r2: 0.0535 - val_loss: 75.3579 - val_keras_r2: 0.0597\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 73.0572 - keras_r2: 0.0923 - val_loss: 71.0326 - val_keras_r2: 0.0992\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.7810 - keras_r2: 0.0982 - val_loss: 70.8958 - val_keras_r2: 0.1100\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 72.8636 - keras_r2: 0.0974 - val_loss: 68.5203 - val_keras_r2: 0.1386\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.6907 - keras_r2: 0.1083 - val_loss: 67.9792 - val_keras_r2: 0.1422\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 71.3122 - keras_r2: 0.1134 - val_loss: 66.4454 - val_keras_r2: 0.1663\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 70.2774 - keras_r2: 0.1191 - val_loss: 67.3269 - val_keras_r2: 0.1565\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.9778 - keras_r2: 0.1378 - val_loss: 71.5156 - val_keras_r2: 0.0927\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 69.6744 - keras_r2: 0.1479 - val_loss: 67.6264 - val_keras_r2: 0.1519\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.0051 - keras_r2: 0.1462 - val_loss: 69.9528 - val_keras_r2: 0.1144\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 69.2414 - keras_r2: 0.1330 - val_loss: 71.7379 - val_keras_r2: 0.0927\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 68.9356 - keras_r2: 0.1223 - val_loss: 66.5606 - val_keras_r2: 0.1686\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 1s 3ms/step - loss: 68.6677 - keras_r2: 0.1581 - val_loss: 67.7633 - val_keras_r2: 0.1525\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.5867 - keras_r2: 0.1651 - val_loss: 66.8774 - val_keras_r2: 0.1622\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.4377 - keras_r2: 0.1627 - val_loss: 68.3665 - val_keras_r2: 0.1473\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 0s 3ms/step - loss: 67.3738 - keras_r2: 0.1603 - val_loss: 68.2307 - val_keras_r2: 0.1429\n",
            "Epoch 28: early stopping\n",
            "[CV] END activation=tanh, batch_normalization=False, dropout=0.3, n_hidden=1, n_neurons=75; total time=  14.6s\n",
            "Epoch 1/100\n",
            "219/219 [==============================] - 2s 4ms/step - loss: 225.0540 - keras_r2: -1.9216 - val_loss: 85.1813 - val_keras_r2: -0.0592\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 117.3417 - keras_r2: -0.4836 - val_loss: 71.9542 - val_keras_r2: 0.1378\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 107.3401 - keras_r2: -0.3367 - val_loss: 74.7000 - val_keras_r2: 0.0907\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 104.8154 - keras_r2: -0.3240 - val_loss: 81.1734 - val_keras_r2: -0.0045\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 101.8637 - keras_r2: -0.2861 - val_loss: 71.3649 - val_keras_r2: 0.1405\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 98.3490 - keras_r2: -0.2208 - val_loss: 74.6075 - val_keras_r2: 0.0935\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 96.2937 - keras_r2: -0.1934 - val_loss: 71.0920 - val_keras_r2: 0.1460\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 94.8655 - keras_r2: -0.1853 - val_loss: 72.3080 - val_keras_r2: 0.1287\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 93.9526 - keras_r2: -0.1791 - val_loss: 73.2871 - val_keras_r2: 0.1114\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 90.5268 - keras_r2: -0.1409 - val_loss: 71.6772 - val_keras_r2: 0.1357\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 89.8183 - keras_r2: -0.1407 - val_loss: 74.1674 - val_keras_r2: 0.0973\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 86.8248 - keras_r2: -0.0760 - val_loss: 71.5542 - val_keras_r2: 0.1371\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 87.4147 - keras_r2: -0.0874 - val_loss: 73.0069 - val_keras_r2: 0.1170\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 84.6511 - keras_r2: -0.0487 - val_loss: 72.2331 - val_keras_r2: 0.1267\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 84.6393 - keras_r2: -0.0480 - val_loss: 71.5114 - val_keras_r2: 0.1376\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 82.5871 - keras_r2: -0.0255 - val_loss: 70.8602 - val_keras_r2: 0.1478\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 82.4077 - keras_r2: -0.0239 - val_loss: 71.3403 - val_keras_r2: 0.1410\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 79.4625 - keras_r2: 0.0066 - val_loss: 70.5837 - val_keras_r2: 0.1532\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 79.1760 - keras_r2: 0.0258 - val_loss: 71.4434 - val_keras_r2: 0.1381\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 78.2934 - keras_r2: 0.0286 - val_loss: 72.7568 - val_keras_r2: 0.1188\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 78.6412 - keras_r2: 0.0349 - val_loss: 70.4434 - val_keras_r2: 0.1581\n",
            "Epoch 22/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 77.5416 - keras_r2: 0.0400 - val_loss: 71.0379 - val_keras_r2: 0.1461\n",
            "Epoch 23/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 76.9436 - keras_r2: 0.0506 - val_loss: 72.7737 - val_keras_r2: 0.1197\n",
            "Epoch 24/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 75.6426 - keras_r2: 0.0661 - val_loss: 70.5823 - val_keras_r2: 0.1526\n",
            "Epoch 25/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 75.0797 - keras_r2: 0.0702 - val_loss: 72.1014 - val_keras_r2: 0.1282\n",
            "Epoch 26/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 74.8752 - keras_r2: 0.0861 - val_loss: 72.6286 - val_keras_r2: 0.1204\n",
            "Epoch 27/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 73.2860 - keras_r2: 0.1002 - val_loss: 71.5389 - val_keras_r2: 0.1365\n",
            "Epoch 28/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 72.4303 - keras_r2: 0.1110 - val_loss: 71.2190 - val_keras_r2: 0.1408\n",
            "Epoch 29/100\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 72.7704 - keras_r2: 0.1096 - val_loss: 71.0480 - val_keras_r2: 0.1467\n",
            "Epoch 30/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 72.8848 - keras_r2: 0.1139 - val_loss: 70.3120 - val_keras_r2: 0.1555\n",
            "Epoch 31/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 70.9309 - keras_r2: 0.1362 - val_loss: 70.7572 - val_keras_r2: 0.1504\n",
            "Epoch 32/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 70.6452 - keras_r2: 0.1403 - val_loss: 73.2104 - val_keras_r2: 0.1112\n",
            "Epoch 33/100\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 71.5909 - keras_r2: 0.1259 - val_loss: 70.1754 - val_keras_r2: 0.1579\n",
            "Epoch 34/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 70.7707 - keras_r2: 0.1413 - val_loss: 70.1575 - val_keras_r2: 0.1603\n",
            "Epoch 35/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 69.7822 - keras_r2: 0.1489 - val_loss: 70.4423 - val_keras_r2: 0.1522\n",
            "Epoch 36/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 69.6393 - keras_r2: 0.1450 - val_loss: 71.0750 - val_keras_r2: 0.1440\n",
            "Epoch 37/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 69.9760 - keras_r2: 0.1523 - val_loss: 70.0586 - val_keras_r2: 0.1599\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 69.7590 - keras_r2: 0.1481 - val_loss: 70.7236 - val_keras_r2: 0.1492\n",
            "Epoch 39/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 68.9396 - keras_r2: 0.1570 - val_loss: 70.7309 - val_keras_r2: 0.1469\n",
            "Epoch 40/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 68.9398 - keras_r2: 0.1630 - val_loss: 71.1656 - val_keras_r2: 0.1407\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 68.7387 - keras_r2: 0.1625 - val_loss: 70.1014 - val_keras_r2: 0.1586\n",
            "Epoch 42/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 68.9104 - keras_r2: 0.1524 - val_loss: 70.3657 - val_keras_r2: 0.1541\n",
            "Epoch 43/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 67.8018 - keras_r2: 0.1798 - val_loss: 70.3379 - val_keras_r2: 0.1553\n",
            "Epoch 44/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 67.3664 - keras_r2: 0.1724 - val_loss: 70.4877 - val_keras_r2: 0.1510\n",
            "Epoch 45/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 68.0699 - keras_r2: 0.1702 - val_loss: 70.0711 - val_keras_r2: 0.1600\n",
            "Epoch 46/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 67.9329 - keras_r2: 0.1723 - val_loss: 70.4095 - val_keras_r2: 0.1530\n",
            "Epoch 47/100\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 67.6688 - keras_r2: 0.1685 - val_loss: 70.8877 - val_keras_r2: 0.1462\n",
            "Epoch 47: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'activation': 'elu',\n",
              " 'batch_normalization': True,\n",
              " 'dropout': 0.2,\n",
              " 'n_hidden': 2,\n",
              " 'n_neurons': 9}"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_distribs_3 = {\n",
        "    \"n_hidden\": [1, 2, 3, 4, 5],\n",
        "    \"n_neurons\": np.arange(1, 100),\n",
        "    \"activation\": [\"relu\", \"elu\", \"sigmoid\", \"tanh\"],\n",
        "    \"dropout\": [0.1, 0.2, 0.3],\n",
        "    \"batch_normalization\": [True, False],\n",
        "}\n",
        "\n",
        "rnd_search_cv_3 = RandomizedSearchCV(keras_class, param_distribs_3, n_iter=10, cv=kFold, verbose=2, scoring=\"r2\")\n",
        "rnd_search_cv_3.fit(X_train_keras, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping_grid_search])\n",
        "rnd_search_cv_3.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7hGjOUqpm6H",
        "outputId": "1f7d84c1-46b8-4d70-a8de-ae109abbec03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 9)                 594       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 9)                36        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 9)                 0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 9)                 81        \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 9)                36        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 9)                 0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 757\n",
            "Trainable params: 721\n",
            "Non-trainable params: 36\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "history_3 = History()\n",
        "\n",
        "model_3 = Sequential()\n",
        "model_3.add(keras.layers.InputLayer(input_shape=X_train_keras.shape[1],))\n",
        "model_3.add(Dense(9, use_bias=False))\n",
        "model_3.add(BatchNormalization())\n",
        "model_3.add(Activation(\"elu\"))\n",
        "model_3.add(Dropout(0.2))\n",
        "model_3.add(Dense(9, use_bias=False))\n",
        "model_3.add(BatchNormalization())\n",
        "model_3.add(Activation(\"elu\"))\n",
        "model_3.add(Dropout(0.2))\n",
        "model_3.add(Dense(1,activation=\"relu\"))\n",
        "model_3.summary()\n",
        "\n",
        "model_3.compile(loss=\"mean_squared_error\",optimizer=\"sgd\", metrics=[keras_r2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhf78XEwqDkn",
        "outputId": "273fbb3a-d3ba-4250-9593-2801038343f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 3.7505 - keras_r2: -3.7145 - val_loss: 0.8118 - val_keras_r2: -0.0299\n",
            "Epoch 2/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.3798 - keras_r2: -0.7553 - val_loss: 0.7498 - val_keras_r2: 0.0612\n",
            "Epoch 3/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.1060 - keras_r2: -0.3776 - val_loss: 0.7223 - val_keras_r2: 0.1040\n",
            "Epoch 4/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9884 - keras_r2: -0.2214 - val_loss: 0.7375 - val_keras_r2: 0.0714\n",
            "Epoch 5/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.9135 - keras_r2: -0.1128 - val_loss: 0.7071 - val_keras_r2: 0.1278\n",
            "Epoch 6/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.8562 - keras_r2: -0.0402 - val_loss: 0.7001 - val_keras_r2: 0.1360\n",
            "Epoch 7/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.8217 - keras_r2: -0.0027 - val_loss: 0.7031 - val_keras_r2: 0.1274\n",
            "Epoch 8/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7987 - keras_r2: 0.0328 - val_loss: 0.6979 - val_keras_r2: 0.1333\n",
            "Epoch 9/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7834 - keras_r2: 0.0560 - val_loss: 0.6927 - val_keras_r2: 0.1429\n",
            "Epoch 10/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7745 - keras_r2: 0.0631 - val_loss: 0.6955 - val_keras_r2: 0.1353\n",
            "Epoch 11/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7531 - keras_r2: 0.0888 - val_loss: 0.6851 - val_keras_r2: 0.1577\n",
            "Epoch 12/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7468 - keras_r2: 0.0991 - val_loss: 0.6808 - val_keras_r2: 0.1590\n",
            "Epoch 13/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7431 - keras_r2: 0.1077 - val_loss: 0.6827 - val_keras_r2: 0.1561\n",
            "Epoch 14/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7407 - keras_r2: 0.1051 - val_loss: 0.6762 - val_keras_r2: 0.1665\n",
            "Epoch 15/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7266 - keras_r2: 0.1267 - val_loss: 0.6727 - val_keras_r2: 0.1708\n",
            "Epoch 16/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7409 - keras_r2: 0.1104 - val_loss: 0.6850 - val_keras_r2: 0.1484\n",
            "Epoch 17/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7254 - keras_r2: 0.1263 - val_loss: 0.6712 - val_keras_r2: 0.1752\n",
            "Epoch 18/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7200 - keras_r2: 0.1337 - val_loss: 0.6697 - val_keras_r2: 0.1761\n",
            "Epoch 19/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7232 - keras_r2: 0.1332 - val_loss: 0.6658 - val_keras_r2: 0.1802\n",
            "Epoch 20/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7200 - keras_r2: 0.1351 - val_loss: 0.6666 - val_keras_r2: 0.1776\n",
            "Epoch 21/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7167 - keras_r2: 0.1330 - val_loss: 0.6735 - val_keras_r2: 0.1671\n",
            "Epoch 22/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7165 - keras_r2: 0.1357 - val_loss: 0.6648 - val_keras_r2: 0.1821\n",
            "Epoch 23/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7197 - keras_r2: 0.1407 - val_loss: 0.6631 - val_keras_r2: 0.1837\n",
            "Epoch 24/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7115 - keras_r2: 0.1457 - val_loss: 0.6651 - val_keras_r2: 0.1809\n",
            "Epoch 25/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7142 - keras_r2: 0.1433 - val_loss: 0.6619 - val_keras_r2: 0.1860\n",
            "Epoch 26/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7164 - keras_r2: 0.1373 - val_loss: 0.6661 - val_keras_r2: 0.1807\n",
            "Epoch 27/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7140 - keras_r2: 0.1455 - val_loss: 0.6602 - val_keras_r2: 0.1877\n",
            "Epoch 28/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7117 - keras_r2: 0.1449 - val_loss: 0.6599 - val_keras_r2: 0.1877\n",
            "Epoch 29/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7152 - keras_r2: 0.1389 - val_loss: 0.6633 - val_keras_r2: 0.1853\n",
            "Epoch 30/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7120 - keras_r2: 0.1468 - val_loss: 0.6677 - val_keras_r2: 0.1746\n",
            "Epoch 31/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7117 - keras_r2: 0.1437 - val_loss: 0.6605 - val_keras_r2: 0.1875\n",
            "Epoch 32/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7128 - keras_r2: 0.1485 - val_loss: 0.6618 - val_keras_r2: 0.1836\n",
            "Epoch 33/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7097 - keras_r2: 0.1461 - val_loss: 0.6605 - val_keras_r2: 0.1888\n",
            "Epoch 34/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7160 - keras_r2: 0.1375 - val_loss: 0.6569 - val_keras_r2: 0.1914\n",
            "Epoch 35/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7104 - keras_r2: 0.1434 - val_loss: 0.6632 - val_keras_r2: 0.1832\n",
            "Epoch 36/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7118 - keras_r2: 0.1414 - val_loss: 0.6672 - val_keras_r2: 0.1794\n",
            "Epoch 37/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7119 - keras_r2: 0.1452 - val_loss: 0.6587 - val_keras_r2: 0.1873\n",
            "Epoch 38/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7061 - keras_r2: 0.1509 - val_loss: 0.6594 - val_keras_r2: 0.1888\n",
            "Epoch 39/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7041 - keras_r2: 0.1617 - val_loss: 0.6586 - val_keras_r2: 0.1906\n",
            "Epoch 40/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7094 - keras_r2: 0.1432 - val_loss: 0.6572 - val_keras_r2: 0.1921\n",
            "Epoch 41/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7131 - keras_r2: 0.1439 - val_loss: 0.6582 - val_keras_r2: 0.1904\n",
            "Epoch 42/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7099 - keras_r2: 0.1463 - val_loss: 0.6591 - val_keras_r2: 0.1892\n",
            "Epoch 43/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7086 - keras_r2: 0.1514 - val_loss: 0.6671 - val_keras_r2: 0.1765\n",
            "Epoch 44/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7080 - keras_r2: 0.1496 - val_loss: 0.6619 - val_keras_r2: 0.1844\n",
            "Epoch 45/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7034 - keras_r2: 0.1630 - val_loss: 0.6609 - val_keras_r2: 0.1863\n",
            "Epoch 46/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7050 - keras_r2: 0.1483 - val_loss: 0.6542 - val_keras_r2: 0.1938\n",
            "Epoch 47/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7061 - keras_r2: 0.1544 - val_loss: 0.6571 - val_keras_r2: 0.1892\n",
            "Epoch 48/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7055 - keras_r2: 0.1523 - val_loss: 0.6583 - val_keras_r2: 0.1879\n",
            "Epoch 49/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7054 - keras_r2: 0.1490 - val_loss: 0.6579 - val_keras_r2: 0.1874\n",
            "Epoch 50/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7061 - keras_r2: 0.1547 - val_loss: 0.6572 - val_keras_r2: 0.1915\n",
            "Epoch 51/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7089 - keras_r2: 0.1499 - val_loss: 0.6591 - val_keras_r2: 0.1898\n",
            "Epoch 52/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7094 - keras_r2: 0.1463 - val_loss: 0.6577 - val_keras_r2: 0.1906\n",
            "Epoch 53/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7026 - keras_r2: 0.1601 - val_loss: 0.6543 - val_keras_r2: 0.1946\n",
            "Epoch 54/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7037 - keras_r2: 0.1659 - val_loss: 0.6581 - val_keras_r2: 0.1906\n",
            "Epoch 55/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7029 - keras_r2: 0.1590 - val_loss: 0.6553 - val_keras_r2: 0.1928\n",
            "Epoch 56/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7030 - keras_r2: 0.1495 - val_loss: 0.6579 - val_keras_r2: 0.1920\n",
            "Epoch 57/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7051 - keras_r2: 0.1538 - val_loss: 0.6587 - val_keras_r2: 0.1895\n",
            "Epoch 58/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6998 - keras_r2: 0.1637 - val_loss: 0.6550 - val_keras_r2: 0.1939\n",
            "Epoch 59/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6974 - keras_r2: 0.1664 - val_loss: 0.6545 - val_keras_r2: 0.1941\n",
            "Epoch 60/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7065 - keras_r2: 0.1499 - val_loss: 0.6545 - val_keras_r2: 0.1937\n",
            "Epoch 61/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7050 - keras_r2: 0.1429 - val_loss: 0.6533 - val_keras_r2: 0.1954\n",
            "Epoch 62/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7042 - keras_r2: 0.1534 - val_loss: 0.6543 - val_keras_r2: 0.1949\n",
            "Epoch 63/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7031 - keras_r2: 0.1596 - val_loss: 0.6543 - val_keras_r2: 0.1948\n",
            "Epoch 64/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6991 - keras_r2: 0.1584 - val_loss: 0.6532 - val_keras_r2: 0.1960\n",
            "Epoch 65/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7069 - keras_r2: 0.1473 - val_loss: 0.6568 - val_keras_r2: 0.1915\n",
            "Epoch 66/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7021 - keras_r2: 0.1558 - val_loss: 0.6546 - val_keras_r2: 0.1946\n",
            "Epoch 67/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7010 - keras_r2: 0.1483 - val_loss: 0.6539 - val_keras_r2: 0.1949\n",
            "Epoch 68/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7018 - keras_r2: 0.1583 - val_loss: 0.6559 - val_keras_r2: 0.1903\n",
            "Epoch 69/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7032 - keras_r2: 0.1583 - val_loss: 0.6544 - val_keras_r2: 0.1951\n",
            "Epoch 70/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7042 - keras_r2: 0.1524 - val_loss: 0.6506 - val_keras_r2: 0.1979\n",
            "Epoch 71/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6971 - keras_r2: 0.1655 - val_loss: 0.6532 - val_keras_r2: 0.1960\n",
            "Epoch 72/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6980 - keras_r2: 0.1672 - val_loss: 0.6508 - val_keras_r2: 0.1976\n",
            "Epoch 73/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7011 - keras_r2: 0.1661 - val_loss: 0.6516 - val_keras_r2: 0.1979\n",
            "Epoch 74/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7022 - keras_r2: 0.1668 - val_loss: 0.6523 - val_keras_r2: 0.1963\n",
            "Epoch 75/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6996 - keras_r2: 0.1579 - val_loss: 0.6515 - val_keras_r2: 0.1953\n",
            "Epoch 76/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7010 - keras_r2: 0.1610 - val_loss: 0.6553 - val_keras_r2: 0.1928\n",
            "Epoch 77/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6978 - keras_r2: 0.1662 - val_loss: 0.6538 - val_keras_r2: 0.1954\n",
            "Epoch 78/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6982 - keras_r2: 0.1595 - val_loss: 0.6516 - val_keras_r2: 0.1973\n",
            "Epoch 79/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7026 - keras_r2: 0.1521 - val_loss: 0.6514 - val_keras_r2: 0.1980\n",
            "Epoch 80/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6923 - keras_r2: 0.1786 - val_loss: 0.6563 - val_keras_r2: 0.1889\n",
            "Epoch 81/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6990 - keras_r2: 0.1613 - val_loss: 0.6488 - val_keras_r2: 0.2000\n",
            "Epoch 82/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7002 - keras_r2: 0.1613 - val_loss: 0.6518 - val_keras_r2: 0.1968\n",
            "Epoch 83/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6939 - keras_r2: 0.1673 - val_loss: 0.6542 - val_keras_r2: 0.1936\n",
            "Epoch 84/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6918 - keras_r2: 0.1665 - val_loss: 0.6523 - val_keras_r2: 0.1977\n",
            "Epoch 85/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7027 - keras_r2: 0.1507 - val_loss: 0.6522 - val_keras_r2: 0.1969\n",
            "Epoch 86/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7006 - keras_r2: 0.1568 - val_loss: 0.6493 - val_keras_r2: 0.1995\n",
            "Epoch 87/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7024 - keras_r2: 0.1580 - val_loss: 0.6525 - val_keras_r2: 0.1975\n",
            "Epoch 88/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6940 - keras_r2: 0.1666 - val_loss: 0.6480 - val_keras_r2: 0.2009\n",
            "Epoch 89/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6956 - keras_r2: 0.1652 - val_loss: 0.6480 - val_keras_r2: 0.2012\n",
            "Epoch 90/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7011 - keras_r2: 0.1547 - val_loss: 0.6487 - val_keras_r2: 0.2010\n",
            "Epoch 91/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6987 - keras_r2: 0.1621 - val_loss: 0.6511 - val_keras_r2: 0.1991\n",
            "Epoch 92/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6950 - keras_r2: 0.1694 - val_loss: 0.6492 - val_keras_r2: 0.2010\n",
            "Epoch 93/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6974 - keras_r2: 0.1613 - val_loss: 0.6470 - val_keras_r2: 0.2027\n",
            "Epoch 94/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7009 - keras_r2: 0.1515 - val_loss: 0.6508 - val_keras_r2: 0.1969\n",
            "Epoch 95/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6920 - keras_r2: 0.1630 - val_loss: 0.6491 - val_keras_r2: 0.2010\n",
            "Epoch 96/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6967 - keras_r2: 0.1657 - val_loss: 0.6481 - val_keras_r2: 0.2024\n",
            "Epoch 97/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6922 - keras_r2: 0.1712 - val_loss: 0.6496 - val_keras_r2: 0.1998\n",
            "Epoch 98/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7000 - keras_r2: 0.1553 - val_loss: 0.6481 - val_keras_r2: 0.2021\n",
            "Epoch 99/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7000 - keras_r2: 0.1587 - val_loss: 0.6496 - val_keras_r2: 0.2006\n",
            "Epoch 100/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6967 - keras_r2: 0.1636 - val_loss: 0.6519 - val_keras_r2: 0.1968\n",
            "Epoch 101/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6998 - keras_r2: 0.1579 - val_loss: 0.6498 - val_keras_r2: 0.2005\n",
            "Epoch 102/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6951 - keras_r2: 0.1682 - val_loss: 0.6490 - val_keras_r2: 0.2021\n",
            "Epoch 103/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6908 - keras_r2: 0.1667 - val_loss: 0.6501 - val_keras_r2: 0.1993\n",
            "Epoch 104/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7010 - keras_r2: 0.1521 - val_loss: 0.6500 - val_keras_r2: 0.1987\n",
            "Epoch 105/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6943 - keras_r2: 0.1670 - val_loss: 0.6576 - val_keras_r2: 0.1903\n",
            "Epoch 106/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6993 - keras_r2: 0.1610 - val_loss: 0.6445 - val_keras_r2: 0.2046\n",
            "Epoch 107/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6971 - keras_r2: 0.1639 - val_loss: 0.6475 - val_keras_r2: 0.2018\n",
            "Epoch 108/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6912 - keras_r2: 0.1747 - val_loss: 0.6510 - val_keras_r2: 0.1992\n",
            "Epoch 109/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6925 - keras_r2: 0.1702 - val_loss: 0.6457 - val_keras_r2: 0.2044\n",
            "Epoch 110/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6937 - keras_r2: 0.1652 - val_loss: 0.6486 - val_keras_r2: 0.2005\n",
            "Epoch 111/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6927 - keras_r2: 0.1715 - val_loss: 0.6490 - val_keras_r2: 0.2004\n",
            "Epoch 112/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6957 - keras_r2: 0.1604 - val_loss: 0.6503 - val_keras_r2: 0.1950\n",
            "Epoch 113/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6988 - keras_r2: 0.1567 - val_loss: 0.6454 - val_keras_r2: 0.2041\n",
            "Epoch 114/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6950 - keras_r2: 0.1612 - val_loss: 0.6507 - val_keras_r2: 0.1970\n",
            "Epoch 115/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6911 - keras_r2: 0.1736 - val_loss: 0.6529 - val_keras_r2: 0.1952\n",
            "Epoch 116/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6896 - keras_r2: 0.1749 - val_loss: 0.6460 - val_keras_r2: 0.2043\n",
            "Epoch 117/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6987 - keras_r2: 0.1598 - val_loss: 0.6451 - val_keras_r2: 0.2048\n",
            "Epoch 118/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6939 - keras_r2: 0.1620 - val_loss: 0.6468 - val_keras_r2: 0.2044\n",
            "Epoch 119/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6966 - keras_r2: 0.1599 - val_loss: 0.6447 - val_keras_r2: 0.2049\n",
            "Epoch 120/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6938 - keras_r2: 0.1714 - val_loss: 0.6437 - val_keras_r2: 0.2058\n",
            "Epoch 121/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6887 - keras_r2: 0.1737 - val_loss: 0.6436 - val_keras_r2: 0.2076\n",
            "Epoch 122/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6928 - keras_r2: 0.1660 - val_loss: 0.6459 - val_keras_r2: 0.2044\n",
            "Epoch 123/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6899 - keras_r2: 0.1664 - val_loss: 0.6489 - val_keras_r2: 0.2000\n",
            "Epoch 124/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6905 - keras_r2: 0.1721 - val_loss: 0.6427 - val_keras_r2: 0.2072\n",
            "Epoch 125/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6904 - keras_r2: 0.1698 - val_loss: 0.6421 - val_keras_r2: 0.2080\n",
            "Epoch 126/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6934 - keras_r2: 0.1673 - val_loss: 0.6455 - val_keras_r2: 0.2057\n",
            "Epoch 127/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6956 - keras_r2: 0.1650 - val_loss: 0.6414 - val_keras_r2: 0.2082\n",
            "Epoch 128/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6915 - keras_r2: 0.1727 - val_loss: 0.6436 - val_keras_r2: 0.2062\n",
            "Epoch 129/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6903 - keras_r2: 0.1709 - val_loss: 0.6428 - val_keras_r2: 0.2070\n",
            "Epoch 130/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6970 - keras_r2: 0.1625 - val_loss: 0.6454 - val_keras_r2: 0.2038\n",
            "Epoch 131/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6920 - keras_r2: 0.1723 - val_loss: 0.6448 - val_keras_r2: 0.2058\n",
            "Epoch 132/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6967 - keras_r2: 0.1604 - val_loss: 0.6632 - val_keras_r2: 0.1812\n",
            "Epoch 133/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6885 - keras_r2: 0.1736 - val_loss: 0.6454 - val_keras_r2: 0.2048\n",
            "Epoch 134/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6927 - keras_r2: 0.1701 - val_loss: 0.6449 - val_keras_r2: 0.2053\n",
            "Epoch 135/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6939 - keras_r2: 0.1733 - val_loss: 0.6403 - val_keras_r2: 0.2085\n",
            "Epoch 136/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6934 - keras_r2: 0.1645 - val_loss: 0.6450 - val_keras_r2: 0.2039\n",
            "Epoch 137/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6915 - keras_r2: 0.1727 - val_loss: 0.6407 - val_keras_r2: 0.2095\n",
            "Epoch 138/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6922 - keras_r2: 0.1631 - val_loss: 0.6474 - val_keras_r2: 0.2007\n",
            "Epoch 139/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6905 - keras_r2: 0.1650 - val_loss: 0.6461 - val_keras_r2: 0.2036\n",
            "Epoch 140/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6918 - keras_r2: 0.1713 - val_loss: 0.6420 - val_keras_r2: 0.2078\n",
            "Epoch 141/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6937 - keras_r2: 0.1645 - val_loss: 0.6447 - val_keras_r2: 0.2057\n",
            "Epoch 142/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6954 - keras_r2: 0.1585 - val_loss: 0.6442 - val_keras_r2: 0.2058\n",
            "Epoch 143/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6909 - keras_r2: 0.1653 - val_loss: 0.6417 - val_keras_r2: 0.2083\n",
            "Epoch 144/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6898 - keras_r2: 0.1777 - val_loss: 0.6380 - val_keras_r2: 0.2117\n",
            "Epoch 145/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6877 - keras_r2: 0.1757 - val_loss: 0.6484 - val_keras_r2: 0.2004\n",
            "Epoch 146/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6943 - keras_r2: 0.1624 - val_loss: 0.6410 - val_keras_r2: 0.2099\n",
            "Epoch 147/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6871 - keras_r2: 0.1738 - val_loss: 0.6426 - val_keras_r2: 0.2075\n",
            "Epoch 148/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6908 - keras_r2: 0.1717 - val_loss: 0.6392 - val_keras_r2: 0.2107\n",
            "Epoch 149/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6951 - keras_r2: 0.1647 - val_loss: 0.6462 - val_keras_r2: 0.2024\n",
            "Epoch 150/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6854 - keras_r2: 0.1733 - val_loss: 0.6395 - val_keras_r2: 0.2114\n",
            "Epoch 151/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6845 - keras_r2: 0.1795 - val_loss: 0.6450 - val_keras_r2: 0.2054\n",
            "Epoch 152/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6912 - keras_r2: 0.1663 - val_loss: 0.6423 - val_keras_r2: 0.2064\n",
            "Epoch 153/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6945 - keras_r2: 0.1698 - val_loss: 0.6382 - val_keras_r2: 0.2134\n",
            "Epoch 154/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6936 - keras_r2: 0.1664 - val_loss: 0.6426 - val_keras_r2: 0.2090\n",
            "Epoch 155/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6901 - keras_r2: 0.1722 - val_loss: 0.6386 - val_keras_r2: 0.2124\n",
            "Epoch 156/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6903 - keras_r2: 0.1769 - val_loss: 0.6392 - val_keras_r2: 0.2119\n",
            "Epoch 157/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6929 - keras_r2: 0.1687 - val_loss: 0.6414 - val_keras_r2: 0.2104\n",
            "Epoch 158/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6891 - keras_r2: 0.1705 - val_loss: 0.6482 - val_keras_r2: 0.2011\n",
            "Epoch 159/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6915 - keras_r2: 0.1656 - val_loss: 0.6413 - val_keras_r2: 0.2075\n",
            "Epoch 160/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6861 - keras_r2: 0.1736 - val_loss: 0.6389 - val_keras_r2: 0.2105\n",
            "Epoch 161/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6929 - keras_r2: 0.1655 - val_loss: 0.6405 - val_keras_r2: 0.2104\n",
            "Epoch 162/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6871 - keras_r2: 0.1744 - val_loss: 0.6429 - val_keras_r2: 0.2079\n",
            "Epoch 163/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6863 - keras_r2: 0.1827 - val_loss: 0.6400 - val_keras_r2: 0.2112\n",
            "Epoch 164/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6853 - keras_r2: 0.1765 - val_loss: 0.6390 - val_keras_r2: 0.2121\n",
            "Epoch 165/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6893 - keras_r2: 0.1646 - val_loss: 0.6407 - val_keras_r2: 0.2109\n",
            "Epoch 166/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6884 - keras_r2: 0.1752 - val_loss: 0.6377 - val_keras_r2: 0.2123\n",
            "Epoch 167/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6926 - keras_r2: 0.1708 - val_loss: 0.6405 - val_keras_r2: 0.2092\n",
            "Epoch 168/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6888 - keras_r2: 0.1793 - val_loss: 0.6352 - val_keras_r2: 0.2150\n",
            "Epoch 169/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6904 - keras_r2: 0.1714 - val_loss: 0.6365 - val_keras_r2: 0.2143\n",
            "Epoch 170/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6909 - keras_r2: 0.1678 - val_loss: 0.6409 - val_keras_r2: 0.2110\n",
            "Epoch 171/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6839 - keras_r2: 0.1805 - val_loss: 0.6338 - val_keras_r2: 0.2174\n",
            "Epoch 172/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6856 - keras_r2: 0.1768 - val_loss: 0.6380 - val_keras_r2: 0.2134\n",
            "Epoch 173/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6866 - keras_r2: 0.1727 - val_loss: 0.6344 - val_keras_r2: 0.2156\n",
            "Epoch 174/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6837 - keras_r2: 0.1837 - val_loss: 0.6339 - val_keras_r2: 0.2166\n",
            "Epoch 175/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6907 - keras_r2: 0.1620 - val_loss: 0.6398 - val_keras_r2: 0.2122\n",
            "Epoch 176/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6860 - keras_r2: 0.1720 - val_loss: 0.6369 - val_keras_r2: 0.2126\n",
            "Epoch 177/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6881 - keras_r2: 0.1711 - val_loss: 0.6395 - val_keras_r2: 0.2129\n",
            "Epoch 178/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6890 - keras_r2: 0.1716 - val_loss: 0.6361 - val_keras_r2: 0.2153\n",
            "Epoch 179/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6895 - keras_r2: 0.1751 - val_loss: 0.6348 - val_keras_r2: 0.2163\n",
            "Epoch 180/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6895 - keras_r2: 0.1724 - val_loss: 0.6363 - val_keras_r2: 0.2139\n",
            "Epoch 181/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6831 - keras_r2: 0.1807 - val_loss: 0.6391 - val_keras_r2: 0.2117\n",
            "Epoch 182/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6910 - keras_r2: 0.1667 - val_loss: 0.6353 - val_keras_r2: 0.2155\n",
            "Epoch 183/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6825 - keras_r2: 0.1794 - val_loss: 0.6349 - val_keras_r2: 0.2158\n",
            "Epoch 184/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6927 - keras_r2: 0.1631 - val_loss: 0.6331 - val_keras_r2: 0.2175\n",
            "Epoch 185/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6826 - keras_r2: 0.1841 - val_loss: 0.6398 - val_keras_r2: 0.2129\n",
            "Epoch 186/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6809 - keras_r2: 0.1822 - val_loss: 0.6330 - val_keras_r2: 0.2165\n",
            "Epoch 187/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6903 - keras_r2: 0.1690 - val_loss: 0.6327 - val_keras_r2: 0.2179\n",
            "Epoch 188/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6872 - keras_r2: 0.1768 - val_loss: 0.6348 - val_keras_r2: 0.2158\n",
            "Epoch 189/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6870 - keras_r2: 0.1743 - val_loss: 0.6383 - val_keras_r2: 0.2117\n",
            "Epoch 190/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6864 - keras_r2: 0.1781 - val_loss: 0.6401 - val_keras_r2: 0.2106\n",
            "Epoch 191/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6848 - keras_r2: 0.1735 - val_loss: 0.6359 - val_keras_r2: 0.2150\n",
            "Epoch 192/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6849 - keras_r2: 0.1776 - val_loss: 0.6411 - val_keras_r2: 0.2094\n",
            "Epoch 193/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6837 - keras_r2: 0.1775 - val_loss: 0.6351 - val_keras_r2: 0.2159\n",
            "Epoch 194/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6866 - keras_r2: 0.1830 - val_loss: 0.6387 - val_keras_r2: 0.2119\n",
            "Epoch 195/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6860 - keras_r2: 0.1715 - val_loss: 0.6382 - val_keras_r2: 0.2127\n",
            "Epoch 196/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6835 - keras_r2: 0.1814 - val_loss: 0.6320 - val_keras_r2: 0.2178\n",
            "Epoch 197/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6827 - keras_r2: 0.1833 - val_loss: 0.6383 - val_keras_r2: 0.2108\n",
            "Epoch 198/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6887 - keras_r2: 0.1650 - val_loss: 0.6366 - val_keras_r2: 0.2141\n",
            "Epoch 199/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6873 - keras_r2: 0.1768 - val_loss: 0.6352 - val_keras_r2: 0.2151\n",
            "Epoch 200/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6850 - keras_r2: 0.1712 - val_loss: 0.6412 - val_keras_r2: 0.2100\n",
            "Epoch 201/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6807 - keras_r2: 0.1827 - val_loss: 0.6337 - val_keras_r2: 0.2172\n",
            "Epoch 202/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6837 - keras_r2: 0.1799 - val_loss: 0.6396 - val_keras_r2: 0.2112\n",
            "Epoch 203/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6852 - keras_r2: 0.1787 - val_loss: 0.6380 - val_keras_r2: 0.2129\n",
            "Epoch 204/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6854 - keras_r2: 0.1810 - val_loss: 0.6337 - val_keras_r2: 0.2184\n",
            "Epoch 205/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6819 - keras_r2: 0.1805 - val_loss: 0.6329 - val_keras_r2: 0.2185\n",
            "Epoch 206/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6870 - keras_r2: 0.1781 - val_loss: 0.6324 - val_keras_r2: 0.2181\n",
            "Epoch 207/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6802 - keras_r2: 0.1832 - val_loss: 0.6342 - val_keras_r2: 0.2160\n",
            "Epoch 208/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6838 - keras_r2: 0.1720 - val_loss: 0.6343 - val_keras_r2: 0.2156\n",
            "Epoch 209/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6823 - keras_r2: 0.1803 - val_loss: 0.6316 - val_keras_r2: 0.2190\n",
            "Epoch 210/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6884 - keras_r2: 0.1732 - val_loss: 0.6348 - val_keras_r2: 0.2165\n",
            "Epoch 211/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6810 - keras_r2: 0.1854 - val_loss: 0.6313 - val_keras_r2: 0.2198\n",
            "Epoch 212/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6844 - keras_r2: 0.1664 - val_loss: 0.6329 - val_keras_r2: 0.2170\n",
            "Epoch 213/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6876 - keras_r2: 0.1703 - val_loss: 0.6383 - val_keras_r2: 0.2121\n",
            "Epoch 214/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6825 - keras_r2: 0.1874 - val_loss: 0.6352 - val_keras_r2: 0.2154\n",
            "Epoch 215/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6850 - keras_r2: 0.1788 - val_loss: 0.6337 - val_keras_r2: 0.2186\n",
            "Epoch 216/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6827 - keras_r2: 0.1756 - val_loss: 0.6311 - val_keras_r2: 0.2208\n",
            "Epoch 217/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6863 - keras_r2: 0.1729 - val_loss: 0.6286 - val_keras_r2: 0.2226\n",
            "Epoch 218/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6870 - keras_r2: 0.1804 - val_loss: 0.6345 - val_keras_r2: 0.2178\n",
            "Epoch 219/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6847 - keras_r2: 0.1825 - val_loss: 0.6355 - val_keras_r2: 0.2160\n",
            "Epoch 220/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6825 - keras_r2: 0.1763 - val_loss: 0.6299 - val_keras_r2: 0.2207\n",
            "Epoch 221/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6762 - keras_r2: 0.1857 - val_loss: 0.6296 - val_keras_r2: 0.2221\n",
            "Epoch 222/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6815 - keras_r2: 0.1783 - val_loss: 0.6286 - val_keras_r2: 0.2229\n",
            "Epoch 223/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6839 - keras_r2: 0.1792 - val_loss: 0.6329 - val_keras_r2: 0.2186\n",
            "Epoch 224/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6830 - keras_r2: 0.1803 - val_loss: 0.6282 - val_keras_r2: 0.2241\n",
            "Epoch 225/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6849 - keras_r2: 0.1731 - val_loss: 0.6347 - val_keras_r2: 0.2183\n",
            "Epoch 226/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6846 - keras_r2: 0.1781 - val_loss: 0.6284 - val_keras_r2: 0.2227\n",
            "Epoch 227/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6807 - keras_r2: 0.1831 - val_loss: 0.6280 - val_keras_r2: 0.2238\n",
            "Epoch 228/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6848 - keras_r2: 0.1743 - val_loss: 0.6305 - val_keras_r2: 0.2224\n",
            "Epoch 229/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6835 - keras_r2: 0.1798 - val_loss: 0.6293 - val_keras_r2: 0.2233\n",
            "Epoch 230/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6775 - keras_r2: 0.1901 - val_loss: 0.6355 - val_keras_r2: 0.2159\n",
            "Epoch 231/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6766 - keras_r2: 0.1902 - val_loss: 0.6293 - val_keras_r2: 0.2193\n",
            "Epoch 232/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6845 - keras_r2: 0.1823 - val_loss: 0.6322 - val_keras_r2: 0.2196\n",
            "Epoch 233/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6803 - keras_r2: 0.1860 - val_loss: 0.6308 - val_keras_r2: 0.2211\n",
            "Epoch 234/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6902 - keras_r2: 0.1639 - val_loss: 0.6326 - val_keras_r2: 0.2195\n",
            "Epoch 235/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6848 - keras_r2: 0.1767 - val_loss: 0.6285 - val_keras_r2: 0.2226\n",
            "Epoch 236/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6786 - keras_r2: 0.1819 - val_loss: 0.6354 - val_keras_r2: 0.2149\n",
            "Epoch 237/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6837 - keras_r2: 0.1799 - val_loss: 0.6350 - val_keras_r2: 0.2166\n",
            "Epoch 238/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6798 - keras_r2: 0.1933 - val_loss: 0.6344 - val_keras_r2: 0.2176\n",
            "Epoch 239/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6823 - keras_r2: 0.1842 - val_loss: 0.6317 - val_keras_r2: 0.2192\n",
            "Epoch 240/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6853 - keras_r2: 0.1729 - val_loss: 0.6410 - val_keras_r2: 0.2084\n",
            "Epoch 241/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6814 - keras_r2: 0.1806 - val_loss: 0.6397 - val_keras_r2: 0.2104\n",
            "Epoch 242/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6826 - keras_r2: 0.1825 - val_loss: 0.6322 - val_keras_r2: 0.2201\n",
            "Epoch 243/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6790 - keras_r2: 0.1812 - val_loss: 0.6299 - val_keras_r2: 0.2207\n",
            "Epoch 244/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6783 - keras_r2: 0.1843 - val_loss: 0.6268 - val_keras_r2: 0.2245\n",
            "Epoch 245/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6817 - keras_r2: 0.1814 - val_loss: 0.6280 - val_keras_r2: 0.2229\n",
            "Epoch 246/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6802 - keras_r2: 0.1804 - val_loss: 0.6262 - val_keras_r2: 0.2240\n",
            "Epoch 247/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6844 - keras_r2: 0.1799 - val_loss: 0.6305 - val_keras_r2: 0.2204\n",
            "Epoch 248/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6776 - keras_r2: 0.1885 - val_loss: 0.6283 - val_keras_r2: 0.2239\n",
            "Epoch 249/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6802 - keras_r2: 0.1818 - val_loss: 0.6284 - val_keras_r2: 0.2233\n",
            "Epoch 250/1000\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 0.6789 - keras_r2: 0.1860 - val_loss: 0.6325 - val_keras_r2: 0.2206\n",
            "Epoch 251/1000\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.6811 - keras_r2: 0.1920 - val_loss: 0.6281 - val_keras_r2: 0.2235\n",
            "Epoch 252/1000\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.6786 - keras_r2: 0.1815 - val_loss: 0.6261 - val_keras_r2: 0.2230\n",
            "Epoch 253/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6835 - keras_r2: 0.1778 - val_loss: 0.6286 - val_keras_r2: 0.2236\n",
            "Epoch 254/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6805 - keras_r2: 0.1858 - val_loss: 0.6265 - val_keras_r2: 0.2257\n",
            "Epoch 255/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6744 - keras_r2: 0.1931 - val_loss: 0.6285 - val_keras_r2: 0.2231\n",
            "Epoch 256/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6787 - keras_r2: 0.1970 - val_loss: 0.6299 - val_keras_r2: 0.2215\n",
            "Epoch 257/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6766 - keras_r2: 0.1926 - val_loss: 0.6287 - val_keras_r2: 0.2227\n",
            "Epoch 258/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6782 - keras_r2: 0.1865 - val_loss: 0.6273 - val_keras_r2: 0.2248\n",
            "Epoch 259/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6821 - keras_r2: 0.1809 - val_loss: 0.6348 - val_keras_r2: 0.2170\n",
            "Epoch 260/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6798 - keras_r2: 0.1900 - val_loss: 0.6280 - val_keras_r2: 0.2230\n",
            "Epoch 261/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6762 - keras_r2: 0.1858 - val_loss: 0.6287 - val_keras_r2: 0.2237\n",
            "Epoch 262/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6797 - keras_r2: 0.1870 - val_loss: 0.6234 - val_keras_r2: 0.2280\n",
            "Epoch 263/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6762 - keras_r2: 0.1837 - val_loss: 0.6244 - val_keras_r2: 0.2267\n",
            "Epoch 264/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6824 - keras_r2: 0.1737 - val_loss: 0.6288 - val_keras_r2: 0.2233\n",
            "Epoch 265/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6807 - keras_r2: 0.1857 - val_loss: 0.6274 - val_keras_r2: 0.2243\n",
            "Epoch 266/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6825 - keras_r2: 0.1821 - val_loss: 0.6247 - val_keras_r2: 0.2265\n",
            "Epoch 267/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6812 - keras_r2: 0.1792 - val_loss: 0.6261 - val_keras_r2: 0.2258\n",
            "Epoch 268/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6843 - keras_r2: 0.1808 - val_loss: 0.6258 - val_keras_r2: 0.2254\n",
            "Epoch 269/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6783 - keras_r2: 0.1892 - val_loss: 0.6255 - val_keras_r2: 0.2259\n",
            "Epoch 270/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6779 - keras_r2: 0.1802 - val_loss: 0.6302 - val_keras_r2: 0.2211\n",
            "Epoch 271/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6790 - keras_r2: 0.1846 - val_loss: 0.6300 - val_keras_r2: 0.2225\n",
            "Epoch 272/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6826 - keras_r2: 0.1884 - val_loss: 0.6291 - val_keras_r2: 0.2226\n",
            "Epoch 273/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6783 - keras_r2: 0.1857 - val_loss: 0.6255 - val_keras_r2: 0.2262\n",
            "Epoch 274/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6779 - keras_r2: 0.1851 - val_loss: 0.6287 - val_keras_r2: 0.2236\n",
            "Epoch 275/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6795 - keras_r2: 0.1802 - val_loss: 0.6298 - val_keras_r2: 0.2227\n",
            "Epoch 276/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1872 - val_loss: 0.6257 - val_keras_r2: 0.2251\n",
            "Epoch 277/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6789 - keras_r2: 0.1841 - val_loss: 0.6248 - val_keras_r2: 0.2254\n",
            "Epoch 278/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6765 - keras_r2: 0.1907 - val_loss: 0.6252 - val_keras_r2: 0.2263\n",
            "Epoch 279/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6757 - keras_r2: 0.1898 - val_loss: 0.6258 - val_keras_r2: 0.2262\n",
            "Epoch 280/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6800 - keras_r2: 0.1842 - val_loss: 0.6305 - val_keras_r2: 0.2219\n",
            "Epoch 281/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6791 - keras_r2: 0.1828 - val_loss: 0.6276 - val_keras_r2: 0.2247\n",
            "Epoch 282/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6786 - keras_r2: 0.1880 - val_loss: 0.6252 - val_keras_r2: 0.2258\n",
            "Epoch 283/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6733 - keras_r2: 0.1920 - val_loss: 0.6275 - val_keras_r2: 0.2248\n",
            "Epoch 284/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6739 - keras_r2: 0.1894 - val_loss: 0.6250 - val_keras_r2: 0.2278\n",
            "Epoch 285/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6777 - keras_r2: 0.1861 - val_loss: 0.6244 - val_keras_r2: 0.2263\n",
            "Epoch 286/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1876 - val_loss: 0.6297 - val_keras_r2: 0.2218\n",
            "Epoch 287/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6788 - keras_r2: 0.1833 - val_loss: 0.6237 - val_keras_r2: 0.2286\n",
            "Epoch 288/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6813 - keras_r2: 0.1815 - val_loss: 0.6293 - val_keras_r2: 0.2238\n",
            "Epoch 289/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6777 - keras_r2: 0.1869 - val_loss: 0.6240 - val_keras_r2: 0.2283\n",
            "Epoch 290/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6702 - keras_r2: 0.2003 - val_loss: 0.6257 - val_keras_r2: 0.2253\n",
            "Epoch 291/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6773 - keras_r2: 0.1879 - val_loss: 0.6300 - val_keras_r2: 0.2221\n",
            "Epoch 292/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6785 - keras_r2: 0.1863 - val_loss: 0.6243 - val_keras_r2: 0.2266\n",
            "Epoch 293/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6752 - keras_r2: 0.1921 - val_loss: 0.6235 - val_keras_r2: 0.2280\n",
            "Epoch 294/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6746 - keras_r2: 0.1948 - val_loss: 0.6282 - val_keras_r2: 0.2243\n",
            "Epoch 295/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6793 - keras_r2: 0.1863 - val_loss: 0.6286 - val_keras_r2: 0.2235\n",
            "Epoch 296/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6734 - keras_r2: 0.1939 - val_loss: 0.6285 - val_keras_r2: 0.2246\n",
            "Epoch 297/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6769 - keras_r2: 0.1848 - val_loss: 0.6314 - val_keras_r2: 0.2208\n",
            "Epoch 298/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6798 - keras_r2: 0.1800 - val_loss: 0.6280 - val_keras_r2: 0.2243\n",
            "Epoch 299/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6760 - keras_r2: 0.1844 - val_loss: 0.6263 - val_keras_r2: 0.2265\n",
            "Epoch 300/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6773 - keras_r2: 0.1882 - val_loss: 0.6265 - val_keras_r2: 0.2255\n",
            "Epoch 301/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6771 - keras_r2: 0.1876 - val_loss: 0.6235 - val_keras_r2: 0.2286\n",
            "Epoch 302/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6760 - keras_r2: 0.1889 - val_loss: 0.6238 - val_keras_r2: 0.2278\n",
            "Epoch 303/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6788 - keras_r2: 0.1864 - val_loss: 0.6276 - val_keras_r2: 0.2250\n",
            "Epoch 304/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6832 - keras_r2: 0.1802 - val_loss: 0.6263 - val_keras_r2: 0.2259\n",
            "Epoch 305/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6761 - keras_r2: 0.1882 - val_loss: 0.6296 - val_keras_r2: 0.2210\n",
            "Epoch 306/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6784 - keras_r2: 0.1810 - val_loss: 0.6295 - val_keras_r2: 0.2228\n",
            "Epoch 307/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6709 - keras_r2: 0.1909 - val_loss: 0.6236 - val_keras_r2: 0.2270\n",
            "Epoch 308/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6761 - keras_r2: 0.1884 - val_loss: 0.6278 - val_keras_r2: 0.2249\n",
            "Epoch 309/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6747 - keras_r2: 0.1885 - val_loss: 0.6251 - val_keras_r2: 0.2271\n",
            "Epoch 310/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6745 - keras_r2: 0.1876 - val_loss: 0.6235 - val_keras_r2: 0.2273\n",
            "Epoch 311/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6723 - keras_r2: 0.1835 - val_loss: 0.6290 - val_keras_r2: 0.2230\n",
            "Epoch 312/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6799 - keras_r2: 0.1773 - val_loss: 0.6260 - val_keras_r2: 0.2261\n",
            "Epoch 313/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6758 - keras_r2: 0.1941 - val_loss: 0.6256 - val_keras_r2: 0.2262\n",
            "Epoch 314/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6824 - keras_r2: 0.1848 - val_loss: 0.6294 - val_keras_r2: 0.2230\n",
            "Epoch 315/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6727 - keras_r2: 0.1858 - val_loss: 0.6245 - val_keras_r2: 0.2273\n",
            "Epoch 316/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6772 - keras_r2: 0.1854 - val_loss: 0.6256 - val_keras_r2: 0.2244\n",
            "Epoch 317/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6818 - keras_r2: 0.1763 - val_loss: 0.6280 - val_keras_r2: 0.2248\n",
            "Epoch 318/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6777 - keras_r2: 0.1826 - val_loss: 0.6249 - val_keras_r2: 0.2276\n",
            "Epoch 319/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6780 - keras_r2: 0.1876 - val_loss: 0.6247 - val_keras_r2: 0.2271\n",
            "Epoch 320/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6768 - keras_r2: 0.1814 - val_loss: 0.6271 - val_keras_r2: 0.2247\n",
            "Epoch 321/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6780 - keras_r2: 0.1828 - val_loss: 0.6247 - val_keras_r2: 0.2264\n",
            "Epoch 322/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6789 - keras_r2: 0.1857 - val_loss: 0.6265 - val_keras_r2: 0.2249\n",
            "Epoch 323/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6781 - keras_r2: 0.1876 - val_loss: 0.6244 - val_keras_r2: 0.2281\n",
            "Epoch 324/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6688 - keras_r2: 0.2009 - val_loss: 0.6251 - val_keras_r2: 0.2254\n",
            "Epoch 325/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6720 - keras_r2: 0.1974 - val_loss: 0.6218 - val_keras_r2: 0.2288\n",
            "Epoch 326/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6783 - keras_r2: 0.1840 - val_loss: 0.6261 - val_keras_r2: 0.2266\n",
            "Epoch 327/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6775 - keras_r2: 0.1887 - val_loss: 0.6219 - val_keras_r2: 0.2287\n",
            "Epoch 328/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6771 - keras_r2: 0.1871 - val_loss: 0.6203 - val_keras_r2: 0.2306\n",
            "Epoch 329/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6788 - keras_r2: 0.1808 - val_loss: 0.6231 - val_keras_r2: 0.2290\n",
            "Epoch 330/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6697 - keras_r2: 0.2004 - val_loss: 0.6226 - val_keras_r2: 0.2299\n",
            "Epoch 331/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6752 - keras_r2: 0.1900 - val_loss: 0.6181 - val_keras_r2: 0.2335\n",
            "Epoch 332/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6801 - keras_r2: 0.1786 - val_loss: 0.6249 - val_keras_r2: 0.2271\n",
            "Epoch 333/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6742 - keras_r2: 0.1995 - val_loss: 0.6195 - val_keras_r2: 0.2333\n",
            "Epoch 334/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6760 - keras_r2: 0.1905 - val_loss: 0.6240 - val_keras_r2: 0.2286\n",
            "Epoch 335/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1853 - val_loss: 0.6212 - val_keras_r2: 0.2308\n",
            "Epoch 336/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6712 - keras_r2: 0.1890 - val_loss: 0.6211 - val_keras_r2: 0.2311\n",
            "Epoch 337/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6729 - keras_r2: 0.1917 - val_loss: 0.6240 - val_keras_r2: 0.2287\n",
            "Epoch 338/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6739 - keras_r2: 0.1910 - val_loss: 0.6207 - val_keras_r2: 0.2307\n",
            "Epoch 339/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6784 - keras_r2: 0.1886 - val_loss: 0.6218 - val_keras_r2: 0.2297\n",
            "Epoch 340/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6795 - keras_r2: 0.1885 - val_loss: 0.6269 - val_keras_r2: 0.2258\n",
            "Epoch 341/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6730 - keras_r2: 0.1954 - val_loss: 0.6198 - val_keras_r2: 0.2322\n",
            "Epoch 342/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6766 - keras_r2: 0.1885 - val_loss: 0.6227 - val_keras_r2: 0.2292\n",
            "Epoch 343/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6827 - keras_r2: 0.1853 - val_loss: 0.6267 - val_keras_r2: 0.2259\n",
            "Epoch 344/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6770 - keras_r2: 0.1907 - val_loss: 0.6246 - val_keras_r2: 0.2282\n",
            "Epoch 345/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6774 - keras_r2: 0.1872 - val_loss: 0.6247 - val_keras_r2: 0.2273\n",
            "Epoch 346/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6766 - keras_r2: 0.1870 - val_loss: 0.6250 - val_keras_r2: 0.2263\n",
            "Epoch 347/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6727 - keras_r2: 0.1920 - val_loss: 0.6231 - val_keras_r2: 0.2283\n",
            "Epoch 348/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6727 - keras_r2: 0.1901 - val_loss: 0.6243 - val_keras_r2: 0.2271\n",
            "Epoch 349/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6713 - keras_r2: 0.1959 - val_loss: 0.6304 - val_keras_r2: 0.2208\n",
            "Epoch 350/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6756 - keras_r2: 0.1933 - val_loss: 0.6224 - val_keras_r2: 0.2289\n",
            "Epoch 351/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6682 - keras_r2: 0.1976 - val_loss: 0.6254 - val_keras_r2: 0.2261\n",
            "Epoch 352/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6817 - keras_r2: 0.1903 - val_loss: 0.6211 - val_keras_r2: 0.2305\n",
            "Epoch 353/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6748 - keras_r2: 0.1864 - val_loss: 0.6240 - val_keras_r2: 0.2285\n",
            "Epoch 354/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6769 - keras_r2: 0.1894 - val_loss: 0.6227 - val_keras_r2: 0.2298\n",
            "Epoch 355/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6733 - keras_r2: 0.1926 - val_loss: 0.6269 - val_keras_r2: 0.2262\n",
            "Epoch 356/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6741 - keras_r2: 0.1869 - val_loss: 0.6214 - val_keras_r2: 0.2295\n",
            "Epoch 357/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6801 - keras_r2: 0.1838 - val_loss: 0.6225 - val_keras_r2: 0.2300\n",
            "Epoch 358/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6757 - keras_r2: 0.1864 - val_loss: 0.6196 - val_keras_r2: 0.2328\n",
            "Epoch 359/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6786 - keras_r2: 0.1781 - val_loss: 0.6221 - val_keras_r2: 0.2295\n",
            "Epoch 360/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6711 - keras_r2: 0.1926 - val_loss: 0.6214 - val_keras_r2: 0.2298\n",
            "Epoch 361/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6774 - keras_r2: 0.1862 - val_loss: 0.6233 - val_keras_r2: 0.2287\n",
            "Epoch 362/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1905 - val_loss: 0.6229 - val_keras_r2: 0.2299\n",
            "Epoch 363/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6812 - keras_r2: 0.1777 - val_loss: 0.6268 - val_keras_r2: 0.2262\n",
            "Epoch 364/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6796 - keras_r2: 0.1870 - val_loss: 0.6232 - val_keras_r2: 0.2287\n",
            "Epoch 365/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6749 - keras_r2: 0.1867 - val_loss: 0.6208 - val_keras_r2: 0.2324\n",
            "Epoch 366/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.1968 - val_loss: 0.6190 - val_keras_r2: 0.2340\n",
            "Epoch 367/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6780 - keras_r2: 0.1762 - val_loss: 0.6216 - val_keras_r2: 0.2314\n",
            "Epoch 368/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6769 - keras_r2: 0.1903 - val_loss: 0.6212 - val_keras_r2: 0.2314\n",
            "Epoch 369/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6784 - keras_r2: 0.1817 - val_loss: 0.6223 - val_keras_r2: 0.2292\n",
            "Epoch 370/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6704 - keras_r2: 0.2007 - val_loss: 0.6202 - val_keras_r2: 0.2315\n",
            "Epoch 371/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6738 - keras_r2: 0.1867 - val_loss: 0.6189 - val_keras_r2: 0.2327\n",
            "Epoch 372/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6724 - keras_r2: 0.1955 - val_loss: 0.6196 - val_keras_r2: 0.2324\n",
            "Epoch 373/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6756 - keras_r2: 0.1938 - val_loss: 0.6198 - val_keras_r2: 0.2321\n",
            "Epoch 374/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6727 - keras_r2: 0.2046 - val_loss: 0.6185 - val_keras_r2: 0.2319\n",
            "Epoch 375/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6725 - keras_r2: 0.1973 - val_loss: 0.6221 - val_keras_r2: 0.2283\n",
            "Epoch 376/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6771 - keras_r2: 0.1834 - val_loss: 0.6246 - val_keras_r2: 0.2275\n",
            "Epoch 377/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6741 - keras_r2: 0.1899 - val_loss: 0.6217 - val_keras_r2: 0.2302\n",
            "Epoch 378/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6752 - keras_r2: 0.1944 - val_loss: 0.6191 - val_keras_r2: 0.2324\n",
            "Epoch 379/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6731 - keras_r2: 0.1958 - val_loss: 0.6196 - val_keras_r2: 0.2315\n",
            "Epoch 380/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6757 - keras_r2: 0.1877 - val_loss: 0.6209 - val_keras_r2: 0.2316\n",
            "Epoch 381/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6784 - keras_r2: 0.1900 - val_loss: 0.6203 - val_keras_r2: 0.2324\n",
            "Epoch 382/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6784 - keras_r2: 0.1845 - val_loss: 0.6214 - val_keras_r2: 0.2321\n",
            "Epoch 383/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6754 - keras_r2: 0.1863 - val_loss: 0.6246 - val_keras_r2: 0.2276\n",
            "Epoch 384/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.2053 - val_loss: 0.6180 - val_keras_r2: 0.2333\n",
            "Epoch 385/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6759 - keras_r2: 0.1864 - val_loss: 0.6183 - val_keras_r2: 0.2331\n",
            "Epoch 386/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6743 - keras_r2: 0.1878 - val_loss: 0.6211 - val_keras_r2: 0.2306\n",
            "Epoch 387/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6766 - keras_r2: 0.1895 - val_loss: 0.6185 - val_keras_r2: 0.2335\n",
            "Epoch 388/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6795 - keras_r2: 0.1854 - val_loss: 0.6207 - val_keras_r2: 0.2316\n",
            "Epoch 389/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6723 - keras_r2: 0.1954 - val_loss: 0.6201 - val_keras_r2: 0.2319\n",
            "Epoch 390/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6785 - keras_r2: 0.1867 - val_loss: 0.6212 - val_keras_r2: 0.2321\n",
            "Epoch 391/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6720 - keras_r2: 0.1917 - val_loss: 0.6181 - val_keras_r2: 0.2342\n",
            "Epoch 392/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6780 - keras_r2: 0.1816 - val_loss: 0.6232 - val_keras_r2: 0.2282\n",
            "Epoch 393/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1889 - val_loss: 0.6225 - val_keras_r2: 0.2304\n",
            "Epoch 394/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6724 - keras_r2: 0.1955 - val_loss: 0.6198 - val_keras_r2: 0.2333\n",
            "Epoch 395/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6679 - keras_r2: 0.2027 - val_loss: 0.6209 - val_keras_r2: 0.2322\n",
            "Epoch 396/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1966 - val_loss: 0.6234 - val_keras_r2: 0.2297\n",
            "Epoch 397/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6750 - keras_r2: 0.1850 - val_loss: 0.6209 - val_keras_r2: 0.2313\n",
            "Epoch 398/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1871 - val_loss: 0.6229 - val_keras_r2: 0.2298\n",
            "Epoch 399/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6743 - keras_r2: 0.1855 - val_loss: 0.6210 - val_keras_r2: 0.2315\n",
            "Epoch 400/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1998 - val_loss: 0.6180 - val_keras_r2: 0.2332\n",
            "Epoch 401/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6799 - keras_r2: 0.1764 - val_loss: 0.6238 - val_keras_r2: 0.2290\n",
            "Epoch 402/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6731 - keras_r2: 0.1921 - val_loss: 0.6189 - val_keras_r2: 0.2342\n",
            "Epoch 403/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6726 - keras_r2: 0.1870 - val_loss: 0.6212 - val_keras_r2: 0.2301\n",
            "Epoch 404/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6753 - keras_r2: 0.1926 - val_loss: 0.6215 - val_keras_r2: 0.2303\n",
            "Epoch 405/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6720 - keras_r2: 0.1909 - val_loss: 0.6202 - val_keras_r2: 0.2325\n",
            "Epoch 406/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6711 - keras_r2: 0.1875 - val_loss: 0.6171 - val_keras_r2: 0.2343\n",
            "Epoch 407/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6712 - keras_r2: 0.1994 - val_loss: 0.6215 - val_keras_r2: 0.2308\n",
            "Epoch 408/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6777 - keras_r2: 0.1872 - val_loss: 0.6205 - val_keras_r2: 0.2315\n",
            "Epoch 409/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6756 - keras_r2: 0.1925 - val_loss: 0.6207 - val_keras_r2: 0.2315\n",
            "Epoch 410/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6757 - keras_r2: 0.1907 - val_loss: 0.6202 - val_keras_r2: 0.2321\n",
            "Epoch 411/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6765 - keras_r2: 0.1914 - val_loss: 0.6240 - val_keras_r2: 0.2288\n",
            "Epoch 412/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6710 - keras_r2: 0.1956 - val_loss: 0.6239 - val_keras_r2: 0.2294\n",
            "Epoch 413/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6758 - keras_r2: 0.1836 - val_loss: 0.6186 - val_keras_r2: 0.2332\n",
            "Epoch 414/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6731 - keras_r2: 0.1925 - val_loss: 0.6182 - val_keras_r2: 0.2327\n",
            "Epoch 415/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6710 - keras_r2: 0.1932 - val_loss: 0.6239 - val_keras_r2: 0.2293\n",
            "Epoch 416/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.2037 - val_loss: 0.6255 - val_keras_r2: 0.2276\n",
            "Epoch 417/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6674 - keras_r2: 0.2024 - val_loss: 0.6207 - val_keras_r2: 0.2307\n",
            "Epoch 418/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6722 - keras_r2: 0.1932 - val_loss: 0.6170 - val_keras_r2: 0.2342\n",
            "Epoch 419/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6712 - keras_r2: 0.2017 - val_loss: 0.6170 - val_keras_r2: 0.2336\n",
            "Epoch 420/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6748 - keras_r2: 0.1862 - val_loss: 0.6177 - val_keras_r2: 0.2345\n",
            "Epoch 421/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6721 - keras_r2: 0.1893 - val_loss: 0.6230 - val_keras_r2: 0.2297\n",
            "Epoch 422/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6740 - keras_r2: 0.1969 - val_loss: 0.6199 - val_keras_r2: 0.2329\n",
            "Epoch 423/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6705 - keras_r2: 0.1941 - val_loss: 0.6195 - val_keras_r2: 0.2338\n",
            "Epoch 424/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6718 - keras_r2: 0.1906 - val_loss: 0.6188 - val_keras_r2: 0.2326\n",
            "Epoch 425/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6722 - keras_r2: 0.1914 - val_loss: 0.6262 - val_keras_r2: 0.2255\n",
            "Epoch 426/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.2053 - val_loss: 0.6224 - val_keras_r2: 0.2303\n",
            "Epoch 427/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6774 - keras_r2: 0.1787 - val_loss: 0.6211 - val_keras_r2: 0.2306\n",
            "Epoch 428/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6735 - keras_r2: 0.1919 - val_loss: 0.6238 - val_keras_r2: 0.2288\n",
            "Epoch 429/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6750 - keras_r2: 0.1858 - val_loss: 0.6214 - val_keras_r2: 0.2314\n",
            "Epoch 430/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6755 - keras_r2: 0.1889 - val_loss: 0.6207 - val_keras_r2: 0.2317\n",
            "Epoch 431/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6735 - keras_r2: 0.1967 - val_loss: 0.6185 - val_keras_r2: 0.2317\n",
            "Epoch 432/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6708 - keras_r2: 0.1966 - val_loss: 0.6279 - val_keras_r2: 0.2229\n",
            "Epoch 433/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6752 - keras_r2: 0.1836 - val_loss: 0.6173 - val_keras_r2: 0.2345\n",
            "Epoch 434/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6721 - keras_r2: 0.1987 - val_loss: 0.6177 - val_keras_r2: 0.2333\n",
            "Epoch 435/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6755 - keras_r2: 0.1861 - val_loss: 0.6217 - val_keras_r2: 0.2309\n",
            "Epoch 436/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6715 - keras_r2: 0.1981 - val_loss: 0.6203 - val_keras_r2: 0.2314\n",
            "Epoch 437/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6732 - keras_r2: 0.1964 - val_loss: 0.6206 - val_keras_r2: 0.2301\n",
            "Epoch 438/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6699 - keras_r2: 0.1912 - val_loss: 0.6211 - val_keras_r2: 0.2317\n",
            "Epoch 439/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6723 - keras_r2: 0.1968 - val_loss: 0.6190 - val_keras_r2: 0.2327\n",
            "Epoch 440/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6716 - keras_r2: 0.1898 - val_loss: 0.6183 - val_keras_r2: 0.2349\n",
            "Epoch 441/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6751 - keras_r2: 0.1870 - val_loss: 0.6171 - val_keras_r2: 0.2350\n",
            "Epoch 442/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6744 - keras_r2: 0.1924 - val_loss: 0.6171 - val_keras_r2: 0.2340\n",
            "Epoch 443/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6741 - keras_r2: 0.1867 - val_loss: 0.6209 - val_keras_r2: 0.2307\n",
            "Epoch 444/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6743 - keras_r2: 0.1913 - val_loss: 0.6223 - val_keras_r2: 0.2294\n",
            "Epoch 445/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6666 - keras_r2: 0.2011 - val_loss: 0.6180 - val_keras_r2: 0.2322\n",
            "Epoch 446/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6748 - keras_r2: 0.1880 - val_loss: 0.6218 - val_keras_r2: 0.2298\n",
            "Epoch 447/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6734 - keras_r2: 0.1936 - val_loss: 0.6169 - val_keras_r2: 0.2354\n",
            "Epoch 448/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1915 - val_loss: 0.6187 - val_keras_r2: 0.2339\n",
            "Epoch 449/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6682 - keras_r2: 0.2010 - val_loss: 0.6194 - val_keras_r2: 0.2340\n",
            "Epoch 450/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6701 - keras_r2: 0.1933 - val_loss: 0.6177 - val_keras_r2: 0.2350\n",
            "Epoch 451/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1945 - val_loss: 0.6174 - val_keras_r2: 0.2355\n",
            "Epoch 452/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1986 - val_loss: 0.6146 - val_keras_r2: 0.2374\n",
            "Epoch 453/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6793 - keras_r2: 0.1789 - val_loss: 0.6228 - val_keras_r2: 0.2292\n",
            "Epoch 454/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6776 - keras_r2: 0.1853 - val_loss: 0.6224 - val_keras_r2: 0.2302\n",
            "Epoch 455/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1976 - val_loss: 0.6191 - val_keras_r2: 0.2338\n",
            "Epoch 456/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6768 - keras_r2: 0.1832 - val_loss: 0.6220 - val_keras_r2: 0.2315\n",
            "Epoch 457/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6719 - keras_r2: 0.1961 - val_loss: 0.6155 - val_keras_r2: 0.2358\n",
            "Epoch 458/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6700 - keras_r2: 0.2008 - val_loss: 0.6178 - val_keras_r2: 0.2345\n",
            "Epoch 459/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6741 - keras_r2: 0.1871 - val_loss: 0.6194 - val_keras_r2: 0.2338\n",
            "Epoch 460/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.1966 - val_loss: 0.6179 - val_keras_r2: 0.2341\n",
            "Epoch 461/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6727 - keras_r2: 0.1879 - val_loss: 0.6178 - val_keras_r2: 0.2342\n",
            "Epoch 462/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6729 - keras_r2: 0.2008 - val_loss: 0.6184 - val_keras_r2: 0.2347\n",
            "Epoch 463/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6710 - keras_r2: 0.1956 - val_loss: 0.6186 - val_keras_r2: 0.2343\n",
            "Epoch 464/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6776 - keras_r2: 0.1765 - val_loss: 0.6202 - val_keras_r2: 0.2327\n",
            "Epoch 465/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6713 - keras_r2: 0.2034 - val_loss: 0.6205 - val_keras_r2: 0.2325\n",
            "Epoch 466/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6719 - keras_r2: 0.1942 - val_loss: 0.6189 - val_keras_r2: 0.2335\n",
            "Epoch 467/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6698 - keras_r2: 0.1966 - val_loss: 0.6172 - val_keras_r2: 0.2349\n",
            "Epoch 468/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6752 - keras_r2: 0.1919 - val_loss: 0.6169 - val_keras_r2: 0.2342\n",
            "Epoch 469/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.2022 - val_loss: 0.6177 - val_keras_r2: 0.2340\n",
            "Epoch 470/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.2024 - val_loss: 0.6240 - val_keras_r2: 0.2290\n",
            "Epoch 471/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6692 - keras_r2: 0.1958 - val_loss: 0.6177 - val_keras_r2: 0.2327\n",
            "Epoch 472/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6726 - keras_r2: 0.1923 - val_loss: 0.6191 - val_keras_r2: 0.2337\n",
            "Epoch 473/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6793 - keras_r2: 0.1787 - val_loss: 0.6180 - val_keras_r2: 0.2350\n",
            "Epoch 474/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6699 - keras_r2: 0.1903 - val_loss: 0.6153 - val_keras_r2: 0.2361\n",
            "Epoch 475/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1992 - val_loss: 0.6192 - val_keras_r2: 0.2331\n",
            "Epoch 476/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.2051 - val_loss: 0.6202 - val_keras_r2: 0.2314\n",
            "Epoch 477/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6710 - keras_r2: 0.1884 - val_loss: 0.6166 - val_keras_r2: 0.2362\n",
            "Epoch 478/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.1911 - val_loss: 0.6160 - val_keras_r2: 0.2363\n",
            "Epoch 479/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1970 - val_loss: 0.6159 - val_keras_r2: 0.2357\n",
            "Epoch 480/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6728 - keras_r2: 0.1936 - val_loss: 0.6163 - val_keras_r2: 0.2338\n",
            "Epoch 481/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6699 - keras_r2: 0.1955 - val_loss: 0.6164 - val_keras_r2: 0.2350\n",
            "Epoch 482/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6696 - keras_r2: 0.1888 - val_loss: 0.6151 - val_keras_r2: 0.2373\n",
            "Epoch 483/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1995 - val_loss: 0.6149 - val_keras_r2: 0.2371\n",
            "Epoch 484/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1924 - val_loss: 0.6196 - val_keras_r2: 0.2335\n",
            "Epoch 485/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.1961 - val_loss: 0.6174 - val_keras_r2: 0.2359\n",
            "Epoch 486/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6712 - keras_r2: 0.1936 - val_loss: 0.6168 - val_keras_r2: 0.2359\n",
            "Epoch 487/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6706 - keras_r2: 0.1928 - val_loss: 0.6165 - val_keras_r2: 0.2364\n",
            "Epoch 488/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6731 - keras_r2: 0.1860 - val_loss: 0.6175 - val_keras_r2: 0.2349\n",
            "Epoch 489/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.1957 - val_loss: 0.6193 - val_keras_r2: 0.2330\n",
            "Epoch 490/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6716 - keras_r2: 0.1889 - val_loss: 0.6155 - val_keras_r2: 0.2360\n",
            "Epoch 491/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6711 - keras_r2: 0.1939 - val_loss: 0.6141 - val_keras_r2: 0.2378\n",
            "Epoch 492/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6713 - keras_r2: 0.1985 - val_loss: 0.6172 - val_keras_r2: 0.2345\n",
            "Epoch 493/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6710 - keras_r2: 0.1930 - val_loss: 0.6144 - val_keras_r2: 0.2371\n",
            "Epoch 494/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6740 - keras_r2: 0.1914 - val_loss: 0.6162 - val_keras_r2: 0.2350\n",
            "Epoch 495/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6684 - keras_r2: 0.1932 - val_loss: 0.6183 - val_keras_r2: 0.2332\n",
            "Epoch 496/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6738 - keras_r2: 0.1861 - val_loss: 0.6134 - val_keras_r2: 0.2374\n",
            "Epoch 497/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6652 - keras_r2: 0.2033 - val_loss: 0.6161 - val_keras_r2: 0.2343\n",
            "Epoch 498/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.2019 - val_loss: 0.6137 - val_keras_r2: 0.2364\n",
            "Epoch 499/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6689 - keras_r2: 0.1893 - val_loss: 0.6177 - val_keras_r2: 0.2336\n",
            "Epoch 500/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6685 - keras_r2: 0.1983 - val_loss: 0.6178 - val_keras_r2: 0.2338\n",
            "Epoch 501/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6706 - keras_r2: 0.1971 - val_loss: 0.6154 - val_keras_r2: 0.2360\n",
            "Epoch 502/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6699 - keras_r2: 0.1986 - val_loss: 0.6184 - val_keras_r2: 0.2333\n",
            "Epoch 503/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6670 - keras_r2: 0.2032 - val_loss: 0.6164 - val_keras_r2: 0.2338\n",
            "Epoch 504/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6645 - keras_r2: 0.2018 - val_loss: 0.6187 - val_keras_r2: 0.2320\n",
            "Epoch 505/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6689 - keras_r2: 0.1910 - val_loss: 0.6209 - val_keras_r2: 0.2306\n",
            "Epoch 506/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.1918 - val_loss: 0.6167 - val_keras_r2: 0.2343\n",
            "Epoch 507/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6723 - keras_r2: 0.1943 - val_loss: 0.6207 - val_keras_r2: 0.2310\n",
            "Epoch 508/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6670 - keras_r2: 0.1990 - val_loss: 0.6183 - val_keras_r2: 0.2328\n",
            "Epoch 509/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6697 - keras_r2: 0.2021 - val_loss: 0.6148 - val_keras_r2: 0.2357\n",
            "Epoch 510/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6781 - keras_r2: 0.1828 - val_loss: 0.6178 - val_keras_r2: 0.2347\n",
            "Epoch 511/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6668 - keras_r2: 0.1989 - val_loss: 0.6152 - val_keras_r2: 0.2363\n",
            "Epoch 512/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6722 - keras_r2: 0.1948 - val_loss: 0.6185 - val_keras_r2: 0.2320\n",
            "Epoch 513/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6688 - keras_r2: 0.1916 - val_loss: 0.6149 - val_keras_r2: 0.2361\n",
            "Epoch 514/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6701 - keras_r2: 0.1895 - val_loss: 0.6159 - val_keras_r2: 0.2362\n",
            "Epoch 515/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.2025 - val_loss: 0.6167 - val_keras_r2: 0.2352\n",
            "Epoch 516/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.2010 - val_loss: 0.6163 - val_keras_r2: 0.2355\n",
            "Epoch 517/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6713 - keras_r2: 0.1882 - val_loss: 0.6155 - val_keras_r2: 0.2361\n",
            "Epoch 518/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6701 - keras_r2: 0.1918 - val_loss: 0.6151 - val_keras_r2: 0.2362\n",
            "Epoch 519/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6699 - keras_r2: 0.1992 - val_loss: 0.6150 - val_keras_r2: 0.2369\n",
            "Epoch 520/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.1992 - val_loss: 0.6170 - val_keras_r2: 0.2337\n",
            "Epoch 521/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6708 - keras_r2: 0.1984 - val_loss: 0.6166 - val_keras_r2: 0.2345\n",
            "Epoch 522/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.2027 - val_loss: 0.6142 - val_keras_r2: 0.2358\n",
            "Epoch 523/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2138 - val_loss: 0.6166 - val_keras_r2: 0.2356\n",
            "Epoch 524/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6713 - keras_r2: 0.1903 - val_loss: 0.6148 - val_keras_r2: 0.2371\n",
            "Epoch 525/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6725 - keras_r2: 0.1910 - val_loss: 0.6159 - val_keras_r2: 0.2360\n",
            "Epoch 526/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.1963 - val_loss: 0.6225 - val_keras_r2: 0.2301\n",
            "Epoch 527/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.2030 - val_loss: 0.6158 - val_keras_r2: 0.2368\n",
            "Epoch 528/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6676 - keras_r2: 0.2012 - val_loss: 0.6175 - val_keras_r2: 0.2348\n",
            "Epoch 529/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6684 - keras_r2: 0.1921 - val_loss: 0.6125 - val_keras_r2: 0.2388\n",
            "Epoch 530/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6722 - keras_r2: 0.1966 - val_loss: 0.6162 - val_keras_r2: 0.2357\n",
            "Epoch 531/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1862 - val_loss: 0.6138 - val_keras_r2: 0.2369\n",
            "Epoch 532/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6698 - keras_r2: 0.1925 - val_loss: 0.6169 - val_keras_r2: 0.2353\n",
            "Epoch 533/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2075 - val_loss: 0.6167 - val_keras_r2: 0.2362\n",
            "Epoch 534/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6682 - keras_r2: 0.2013 - val_loss: 0.6128 - val_keras_r2: 0.2389\n",
            "Epoch 535/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6728 - keras_r2: 0.1936 - val_loss: 0.6175 - val_keras_r2: 0.2354\n",
            "Epoch 536/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6713 - keras_r2: 0.1872 - val_loss: 0.6192 - val_keras_r2: 0.2341\n",
            "Epoch 537/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6720 - keras_r2: 0.1944 - val_loss: 0.6156 - val_keras_r2: 0.2367\n",
            "Epoch 538/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6723 - keras_r2: 0.1847 - val_loss: 0.6164 - val_keras_r2: 0.2361\n",
            "Epoch 539/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6736 - keras_r2: 0.1917 - val_loss: 0.6151 - val_keras_r2: 0.2372\n",
            "Epoch 540/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6701 - keras_r2: 0.2005 - val_loss: 0.6147 - val_keras_r2: 0.2380\n",
            "Epoch 541/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6684 - keras_r2: 0.2023 - val_loss: 0.6146 - val_keras_r2: 0.2369\n",
            "Epoch 542/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6652 - keras_r2: 0.2061 - val_loss: 0.6118 - val_keras_r2: 0.2394\n",
            "Epoch 543/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2060 - val_loss: 0.6118 - val_keras_r2: 0.2392\n",
            "Epoch 544/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.1994 - val_loss: 0.6169 - val_keras_r2: 0.2359\n",
            "Epoch 545/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.2030 - val_loss: 0.6123 - val_keras_r2: 0.2384\n",
            "Epoch 546/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6721 - keras_r2: 0.1930 - val_loss: 0.6170 - val_keras_r2: 0.2357\n",
            "Epoch 547/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.1961 - val_loss: 0.6155 - val_keras_r2: 0.2371\n",
            "Epoch 548/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6675 - keras_r2: 0.2010 - val_loss: 0.6184 - val_keras_r2: 0.2331\n",
            "Epoch 549/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.2049 - val_loss: 0.6163 - val_keras_r2: 0.2362\n",
            "Epoch 550/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6636 - keras_r2: 0.1980 - val_loss: 0.6136 - val_keras_r2: 0.2369\n",
            "Epoch 551/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.1945 - val_loss: 0.6105 - val_keras_r2: 0.2391\n",
            "Epoch 552/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6698 - keras_r2: 0.1949 - val_loss: 0.6152 - val_keras_r2: 0.2372\n",
            "Epoch 553/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.2043 - val_loss: 0.6132 - val_keras_r2: 0.2390\n",
            "Epoch 554/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6716 - keras_r2: 0.1889 - val_loss: 0.6136 - val_keras_r2: 0.2389\n",
            "Epoch 555/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6653 - keras_r2: 0.1986 - val_loss: 0.6136 - val_keras_r2: 0.2385\n",
            "Epoch 556/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6722 - keras_r2: 0.1978 - val_loss: 0.6159 - val_keras_r2: 0.2362\n",
            "Epoch 557/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6591 - keras_r2: 0.2075 - val_loss: 0.6112 - val_keras_r2: 0.2395\n",
            "Epoch 558/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6662 - keras_r2: 0.2030 - val_loss: 0.6180 - val_keras_r2: 0.2339\n",
            "Epoch 559/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6700 - keras_r2: 0.1995 - val_loss: 0.6127 - val_keras_r2: 0.2387\n",
            "Epoch 560/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6686 - keras_r2: 0.1971 - val_loss: 0.6115 - val_keras_r2: 0.2402\n",
            "Epoch 561/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6704 - keras_r2: 0.1987 - val_loss: 0.6147 - val_keras_r2: 0.2378\n",
            "Epoch 562/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6650 - keras_r2: 0.1921 - val_loss: 0.6136 - val_keras_r2: 0.2383\n",
            "Epoch 563/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6652 - keras_r2: 0.2073 - val_loss: 0.6153 - val_keras_r2: 0.2370\n",
            "Epoch 564/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6685 - keras_r2: 0.1946 - val_loss: 0.6184 - val_keras_r2: 0.2353\n",
            "Epoch 565/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.2002 - val_loss: 0.6113 - val_keras_r2: 0.2405\n",
            "Epoch 566/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.2057 - val_loss: 0.6117 - val_keras_r2: 0.2410\n",
            "Epoch 567/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6691 - keras_r2: 0.1926 - val_loss: 0.6091 - val_keras_r2: 0.2429\n",
            "Epoch 568/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.2049 - val_loss: 0.6094 - val_keras_r2: 0.2417\n",
            "Epoch 569/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6650 - keras_r2: 0.1976 - val_loss: 0.6129 - val_keras_r2: 0.2395\n",
            "Epoch 570/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6631 - keras_r2: 0.2091 - val_loss: 0.6141 - val_keras_r2: 0.2395\n",
            "Epoch 571/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6640 - keras_r2: 0.2084 - val_loss: 0.6133 - val_keras_r2: 0.2402\n",
            "Epoch 572/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6718 - keras_r2: 0.1959 - val_loss: 0.6117 - val_keras_r2: 0.2416\n",
            "Epoch 573/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6702 - keras_r2: 0.1956 - val_loss: 0.6117 - val_keras_r2: 0.2408\n",
            "Epoch 574/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.2027 - val_loss: 0.6091 - val_keras_r2: 0.2431\n",
            "Epoch 575/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6674 - keras_r2: 0.2067 - val_loss: 0.6143 - val_keras_r2: 0.2389\n",
            "Epoch 576/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6657 - keras_r2: 0.2066 - val_loss: 0.6096 - val_keras_r2: 0.2414\n",
            "Epoch 577/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6642 - keras_r2: 0.2047 - val_loss: 0.6111 - val_keras_r2: 0.2411\n",
            "Epoch 578/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6714 - keras_r2: 0.1846 - val_loss: 0.6145 - val_keras_r2: 0.2385\n",
            "Epoch 579/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6657 - keras_r2: 0.1971 - val_loss: 0.6122 - val_keras_r2: 0.2394\n",
            "Epoch 580/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.1965 - val_loss: 0.6129 - val_keras_r2: 0.2397\n",
            "Epoch 581/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6709 - keras_r2: 0.1898 - val_loss: 0.6137 - val_keras_r2: 0.2395\n",
            "Epoch 582/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6716 - keras_r2: 0.1909 - val_loss: 0.6174 - val_keras_r2: 0.2338\n",
            "Epoch 583/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.2007 - val_loss: 0.6149 - val_keras_r2: 0.2382\n",
            "Epoch 584/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6734 - keras_r2: 0.1902 - val_loss: 0.6119 - val_keras_r2: 0.2395\n",
            "Epoch 585/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6740 - keras_r2: 0.1856 - val_loss: 0.6181 - val_keras_r2: 0.2340\n",
            "Epoch 586/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6697 - keras_r2: 0.1948 - val_loss: 0.6173 - val_keras_r2: 0.2352\n",
            "Epoch 587/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6698 - keras_r2: 0.1976 - val_loss: 0.6121 - val_keras_r2: 0.2390\n",
            "Epoch 588/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1972 - val_loss: 0.6179 - val_keras_r2: 0.2347\n",
            "Epoch 589/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1938 - val_loss: 0.6151 - val_keras_r2: 0.2367\n",
            "Epoch 590/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6702 - keras_r2: 0.1990 - val_loss: 0.6143 - val_keras_r2: 0.2378\n",
            "Epoch 591/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6636 - keras_r2: 0.2051 - val_loss: 0.6114 - val_keras_r2: 0.2406\n",
            "Epoch 592/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6637 - keras_r2: 0.2010 - val_loss: 0.6121 - val_keras_r2: 0.2406\n",
            "Epoch 593/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6675 - keras_r2: 0.2010 - val_loss: 0.6128 - val_keras_r2: 0.2390\n",
            "Epoch 594/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6651 - keras_r2: 0.2029 - val_loss: 0.6122 - val_keras_r2: 0.2404\n",
            "Epoch 595/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.2004 - val_loss: 0.6109 - val_keras_r2: 0.2412\n",
            "Epoch 596/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6707 - keras_r2: 0.1974 - val_loss: 0.6141 - val_keras_r2: 0.2375\n",
            "Epoch 597/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6695 - keras_r2: 0.1968 - val_loss: 0.6156 - val_keras_r2: 0.2371\n",
            "Epoch 598/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6732 - keras_r2: 0.1913 - val_loss: 0.6114 - val_keras_r2: 0.2401\n",
            "Epoch 599/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.1992 - val_loss: 0.6178 - val_keras_r2: 0.2347\n",
            "Epoch 600/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.2087 - val_loss: 0.6118 - val_keras_r2: 0.2398\n",
            "Epoch 601/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.2020 - val_loss: 0.6116 - val_keras_r2: 0.2412\n",
            "Epoch 602/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6672 - keras_r2: 0.2102 - val_loss: 0.6101 - val_keras_r2: 0.2420\n",
            "Epoch 603/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6710 - keras_r2: 0.1895 - val_loss: 0.6126 - val_keras_r2: 0.2394\n",
            "Epoch 604/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6685 - keras_r2: 0.1921 - val_loss: 0.6102 - val_keras_r2: 0.2412\n",
            "Epoch 605/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2058 - val_loss: 0.6115 - val_keras_r2: 0.2407\n",
            "Epoch 606/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6762 - keras_r2: 0.1871 - val_loss: 0.6170 - val_keras_r2: 0.2367\n",
            "Epoch 607/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.2058 - val_loss: 0.6146 - val_keras_r2: 0.2384\n",
            "Epoch 608/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6614 - keras_r2: 0.2032 - val_loss: 0.6115 - val_keras_r2: 0.2410\n",
            "Epoch 609/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6642 - keras_r2: 0.2091 - val_loss: 0.6116 - val_keras_r2: 0.2406\n",
            "Epoch 610/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.2001 - val_loss: 0.6136 - val_keras_r2: 0.2387\n",
            "Epoch 611/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6707 - keras_r2: 0.1926 - val_loss: 0.6138 - val_keras_r2: 0.2384\n",
            "Epoch 612/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.1988 - val_loss: 0.6132 - val_keras_r2: 0.2392\n",
            "Epoch 613/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6677 - keras_r2: 0.1946 - val_loss: 0.6127 - val_keras_r2: 0.2380\n",
            "Epoch 614/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1984 - val_loss: 0.6144 - val_keras_r2: 0.2369\n",
            "Epoch 615/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.2022 - val_loss: 0.6122 - val_keras_r2: 0.2387\n",
            "Epoch 616/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6747 - keras_r2: 0.1847 - val_loss: 0.6127 - val_keras_r2: 0.2392\n",
            "Epoch 617/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6665 - keras_r2: 0.1999 - val_loss: 0.6134 - val_keras_r2: 0.2382\n",
            "Epoch 618/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1951 - val_loss: 0.6161 - val_keras_r2: 0.2364\n",
            "Epoch 619/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6709 - keras_r2: 0.1933 - val_loss: 0.6183 - val_keras_r2: 0.2343\n",
            "Epoch 620/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6652 - keras_r2: 0.1959 - val_loss: 0.6133 - val_keras_r2: 0.2374\n",
            "Epoch 621/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6675 - keras_r2: 0.2009 - val_loss: 0.6146 - val_keras_r2: 0.2377\n",
            "Epoch 622/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2044 - val_loss: 0.6161 - val_keras_r2: 0.2363\n",
            "Epoch 623/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6602 - keras_r2: 0.2082 - val_loss: 0.6134 - val_keras_r2: 0.2389\n",
            "Epoch 624/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6668 - keras_r2: 0.1992 - val_loss: 0.6118 - val_keras_r2: 0.2399\n",
            "Epoch 625/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6682 - keras_r2: 0.2000 - val_loss: 0.6097 - val_keras_r2: 0.2413\n",
            "Epoch 626/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6670 - keras_r2: 0.1954 - val_loss: 0.6136 - val_keras_r2: 0.2366\n",
            "Epoch 627/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6643 - keras_r2: 0.2018 - val_loss: 0.6166 - val_keras_r2: 0.2364\n",
            "Epoch 628/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1969 - val_loss: 0.6132 - val_keras_r2: 0.2392\n",
            "Epoch 629/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.2096 - val_loss: 0.6151 - val_keras_r2: 0.2383\n",
            "Epoch 630/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.2078 - val_loss: 0.6122 - val_keras_r2: 0.2400\n",
            "Epoch 631/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6666 - keras_r2: 0.1932 - val_loss: 0.6118 - val_keras_r2: 0.2390\n",
            "Epoch 632/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.1914 - val_loss: 0.6147 - val_keras_r2: 0.2363\n",
            "Epoch 633/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6657 - keras_r2: 0.2023 - val_loss: 0.6137 - val_keras_r2: 0.2382\n",
            "Epoch 634/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6627 - keras_r2: 0.2071 - val_loss: 0.6103 - val_keras_r2: 0.2404\n",
            "Epoch 635/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6595 - keras_r2: 0.2080 - val_loss: 0.6130 - val_keras_r2: 0.2396\n",
            "Epoch 636/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6672 - keras_r2: 0.2030 - val_loss: 0.6140 - val_keras_r2: 0.2372\n",
            "Epoch 637/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6734 - keras_r2: 0.1937 - val_loss: 0.6160 - val_keras_r2: 0.2348\n",
            "Epoch 638/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6657 - keras_r2: 0.2047 - val_loss: 0.6115 - val_keras_r2: 0.2415\n",
            "Epoch 639/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6754 - keras_r2: 0.1830 - val_loss: 0.6156 - val_keras_r2: 0.2368\n",
            "Epoch 640/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6666 - keras_r2: 0.1967 - val_loss: 0.6117 - val_keras_r2: 0.2405\n",
            "Epoch 641/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6646 - keras_r2: 0.2075 - val_loss: 0.6120 - val_keras_r2: 0.2403\n",
            "Epoch 642/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6723 - keras_r2: 0.1929 - val_loss: 0.6156 - val_keras_r2: 0.2379\n",
            "Epoch 643/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6668 - keras_r2: 0.1996 - val_loss: 0.6098 - val_keras_r2: 0.2417\n",
            "Epoch 644/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6653 - keras_r2: 0.1991 - val_loss: 0.6140 - val_keras_r2: 0.2399\n",
            "Epoch 645/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6644 - keras_r2: 0.2027 - val_loss: 0.6142 - val_keras_r2: 0.2384\n",
            "Epoch 646/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.1889 - val_loss: 0.6112 - val_keras_r2: 0.2408\n",
            "Epoch 647/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6672 - keras_r2: 0.2038 - val_loss: 0.6104 - val_keras_r2: 0.2420\n",
            "Epoch 648/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.2050 - val_loss: 0.6094 - val_keras_r2: 0.2422\n",
            "Epoch 649/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6653 - keras_r2: 0.2019 - val_loss: 0.6111 - val_keras_r2: 0.2410\n",
            "Epoch 650/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6702 - keras_r2: 0.1934 - val_loss: 0.6149 - val_keras_r2: 0.2368\n",
            "Epoch 651/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.2016 - val_loss: 0.6133 - val_keras_r2: 0.2389\n",
            "Epoch 652/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6773 - keras_r2: 0.1829 - val_loss: 0.6179 - val_keras_r2: 0.2333\n",
            "Epoch 653/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.1965 - val_loss: 0.6118 - val_keras_r2: 0.2397\n",
            "Epoch 654/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.2022 - val_loss: 0.6100 - val_keras_r2: 0.2411\n",
            "Epoch 655/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6638 - keras_r2: 0.2035 - val_loss: 0.6161 - val_keras_r2: 0.2363\n",
            "Epoch 656/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6592 - keras_r2: 0.2035 - val_loss: 0.6105 - val_keras_r2: 0.2402\n",
            "Epoch 657/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6704 - keras_r2: 0.1920 - val_loss: 0.6129 - val_keras_r2: 0.2406\n",
            "Epoch 658/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6676 - keras_r2: 0.1980 - val_loss: 0.6106 - val_keras_r2: 0.2418\n",
            "Epoch 659/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.1961 - val_loss: 0.6094 - val_keras_r2: 0.2421\n",
            "Epoch 660/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.1988 - val_loss: 0.6113 - val_keras_r2: 0.2417\n",
            "Epoch 661/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6610 - keras_r2: 0.2083 - val_loss: 0.6117 - val_keras_r2: 0.2412\n",
            "Epoch 662/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6675 - keras_r2: 0.1986 - val_loss: 0.6096 - val_keras_r2: 0.2421\n",
            "Epoch 663/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6651 - keras_r2: 0.2090 - val_loss: 0.6114 - val_keras_r2: 0.2397\n",
            "Epoch 664/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6638 - keras_r2: 0.2008 - val_loss: 0.6136 - val_keras_r2: 0.2392\n",
            "Epoch 665/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.2017 - val_loss: 0.6116 - val_keras_r2: 0.2405\n",
            "Epoch 666/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6629 - keras_r2: 0.1989 - val_loss: 0.6091 - val_keras_r2: 0.2403\n",
            "Epoch 667/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6602 - keras_r2: 0.2094 - val_loss: 0.6105 - val_keras_r2: 0.2416\n",
            "Epoch 668/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.1957 - val_loss: 0.6124 - val_keras_r2: 0.2394\n",
            "Epoch 669/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6730 - keras_r2: 0.1789 - val_loss: 0.6086 - val_keras_r2: 0.2421\n",
            "Epoch 670/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6697 - keras_r2: 0.1846 - val_loss: 0.6150 - val_keras_r2: 0.2360\n",
            "Epoch 671/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6666 - keras_r2: 0.2002 - val_loss: 0.6119 - val_keras_r2: 0.2409\n",
            "Epoch 672/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6659 - keras_r2: 0.2006 - val_loss: 0.6118 - val_keras_r2: 0.2403\n",
            "Epoch 673/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6749 - keras_r2: 0.1938 - val_loss: 0.6126 - val_keras_r2: 0.2403\n",
            "Epoch 674/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6650 - keras_r2: 0.1999 - val_loss: 0.6077 - val_keras_r2: 0.2445\n",
            "Epoch 675/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6718 - keras_r2: 0.1932 - val_loss: 0.6114 - val_keras_r2: 0.2413\n",
            "Epoch 676/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6698 - keras_r2: 0.2010 - val_loss: 0.6148 - val_keras_r2: 0.2387\n",
            "Epoch 677/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6682 - keras_r2: 0.1957 - val_loss: 0.6130 - val_keras_r2: 0.2407\n",
            "Epoch 678/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6702 - keras_r2: 0.1944 - val_loss: 0.6131 - val_keras_r2: 0.2393\n",
            "Epoch 679/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6695 - keras_r2: 0.1954 - val_loss: 0.6092 - val_keras_r2: 0.2424\n",
            "Epoch 680/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1891 - val_loss: 0.6130 - val_keras_r2: 0.2382\n",
            "Epoch 681/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6662 - keras_r2: 0.1935 - val_loss: 0.6110 - val_keras_r2: 0.2424\n",
            "Epoch 682/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1962 - val_loss: 0.6094 - val_keras_r2: 0.2431\n",
            "Epoch 683/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.1997 - val_loss: 0.6116 - val_keras_r2: 0.2419\n",
            "Epoch 684/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.2005 - val_loss: 0.6157 - val_keras_r2: 0.2368\n",
            "Epoch 685/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6580 - keras_r2: 0.2086 - val_loss: 0.6122 - val_keras_r2: 0.2409\n",
            "Epoch 686/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.2023 - val_loss: 0.6168 - val_keras_r2: 0.2369\n",
            "Epoch 687/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6604 - keras_r2: 0.2061 - val_loss: 0.6121 - val_keras_r2: 0.2413\n",
            "Epoch 688/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.2015 - val_loss: 0.6114 - val_keras_r2: 0.2411\n",
            "Epoch 689/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.2066 - val_loss: 0.6120 - val_keras_r2: 0.2409\n",
            "Epoch 690/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.1934 - val_loss: 0.6094 - val_keras_r2: 0.2422\n",
            "Epoch 691/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6698 - keras_r2: 0.1971 - val_loss: 0.6202 - val_keras_r2: 0.2338\n",
            "Epoch 692/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.1996 - val_loss: 0.6099 - val_keras_r2: 0.2428\n",
            "Epoch 693/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6712 - keras_r2: 0.1882 - val_loss: 0.6097 - val_keras_r2: 0.2425\n",
            "Epoch 694/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.1990 - val_loss: 0.6109 - val_keras_r2: 0.2421\n",
            "Epoch 695/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6720 - keras_r2: 0.1950 - val_loss: 0.6145 - val_keras_r2: 0.2392\n",
            "Epoch 696/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6615 - keras_r2: 0.2105 - val_loss: 0.6110 - val_keras_r2: 0.2406\n",
            "Epoch 697/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.1955 - val_loss: 0.6125 - val_keras_r2: 0.2382\n",
            "Epoch 698/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6679 - keras_r2: 0.1967 - val_loss: 0.6152 - val_keras_r2: 0.2352\n",
            "Epoch 699/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.2027 - val_loss: 0.6125 - val_keras_r2: 0.2409\n",
            "Epoch 700/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6635 - keras_r2: 0.2097 - val_loss: 0.6109 - val_keras_r2: 0.2414\n",
            "Epoch 701/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.2033 - val_loss: 0.6110 - val_keras_r2: 0.2426\n",
            "Epoch 702/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6597 - keras_r2: 0.2066 - val_loss: 0.6123 - val_keras_r2: 0.2408\n",
            "Epoch 703/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6717 - keras_r2: 0.1909 - val_loss: 0.6153 - val_keras_r2: 0.2377\n",
            "Epoch 704/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6700 - keras_r2: 0.1860 - val_loss: 0.6103 - val_keras_r2: 0.2417\n",
            "Epoch 705/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6685 - keras_r2: 0.1936 - val_loss: 0.6116 - val_keras_r2: 0.2410\n",
            "Epoch 706/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6652 - keras_r2: 0.1948 - val_loss: 0.6099 - val_keras_r2: 0.2415\n",
            "Epoch 707/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.2015 - val_loss: 0.6141 - val_keras_r2: 0.2390\n",
            "Epoch 708/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6704 - keras_r2: 0.1963 - val_loss: 0.6126 - val_keras_r2: 0.2403\n",
            "Epoch 709/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6666 - keras_r2: 0.1967 - val_loss: 0.6089 - val_keras_r2: 0.2413\n",
            "Epoch 710/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6672 - keras_r2: 0.2032 - val_loss: 0.6118 - val_keras_r2: 0.2400\n",
            "Epoch 711/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6670 - keras_r2: 0.1981 - val_loss: 0.6144 - val_keras_r2: 0.2367\n",
            "Epoch 712/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.1979 - val_loss: 0.6097 - val_keras_r2: 0.2417\n",
            "Epoch 713/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6646 - keras_r2: 0.2021 - val_loss: 0.6114 - val_keras_r2: 0.2392\n",
            "Epoch 714/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6692 - keras_r2: 0.1977 - val_loss: 0.6148 - val_keras_r2: 0.2383\n",
            "Epoch 715/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6651 - keras_r2: 0.1967 - val_loss: 0.6125 - val_keras_r2: 0.2404\n",
            "Epoch 716/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6665 - keras_r2: 0.1957 - val_loss: 0.6087 - val_keras_r2: 0.2444\n",
            "Epoch 717/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1932 - val_loss: 0.6118 - val_keras_r2: 0.2417\n",
            "Epoch 718/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6607 - keras_r2: 0.2018 - val_loss: 0.6113 - val_keras_r2: 0.2424\n",
            "Epoch 719/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6632 - keras_r2: 0.2054 - val_loss: 0.6086 - val_keras_r2: 0.2436\n",
            "Epoch 720/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6643 - keras_r2: 0.2022 - val_loss: 0.6102 - val_keras_r2: 0.2425\n",
            "Epoch 721/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6629 - keras_r2: 0.2024 - val_loss: 0.6096 - val_keras_r2: 0.2433\n",
            "Epoch 722/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6585 - keras_r2: 0.2098 - val_loss: 0.6086 - val_keras_r2: 0.2439\n",
            "Epoch 723/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.2088 - val_loss: 0.6088 - val_keras_r2: 0.2431\n",
            "Epoch 724/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6694 - keras_r2: 0.1909 - val_loss: 0.6113 - val_keras_r2: 0.2403\n",
            "Epoch 725/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6737 - keras_r2: 0.1870 - val_loss: 0.6094 - val_keras_r2: 0.2430\n",
            "Epoch 726/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6632 - keras_r2: 0.2047 - val_loss: 0.6071 - val_keras_r2: 0.2426\n",
            "Epoch 727/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.2027 - val_loss: 0.6106 - val_keras_r2: 0.2420\n",
            "Epoch 728/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6626 - keras_r2: 0.2109 - val_loss: 0.6095 - val_keras_r2: 0.2421\n",
            "Epoch 729/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6669 - keras_r2: 0.1966 - val_loss: 0.6107 - val_keras_r2: 0.2425\n",
            "Epoch 730/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6653 - keras_r2: 0.1976 - val_loss: 0.6095 - val_keras_r2: 0.2430\n",
            "Epoch 731/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.2001 - val_loss: 0.6116 - val_keras_r2: 0.2398\n",
            "Epoch 732/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1957 - val_loss: 0.6119 - val_keras_r2: 0.2412\n",
            "Epoch 733/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6611 - keras_r2: 0.2035 - val_loss: 0.6071 - val_keras_r2: 0.2419\n",
            "Epoch 734/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.1990 - val_loss: 0.6129 - val_keras_r2: 0.2392\n",
            "Epoch 735/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6688 - keras_r2: 0.1981 - val_loss: 0.6091 - val_keras_r2: 0.2428\n",
            "Epoch 736/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6651 - keras_r2: 0.1992 - val_loss: 0.6102 - val_keras_r2: 0.2414\n",
            "Epoch 737/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1923 - val_loss: 0.6127 - val_keras_r2: 0.2408\n",
            "Epoch 738/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.2011 - val_loss: 0.6086 - val_keras_r2: 0.2423\n",
            "Epoch 739/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6638 - keras_r2: 0.1979 - val_loss: 0.6120 - val_keras_r2: 0.2415\n",
            "Epoch 740/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6638 - keras_r2: 0.2031 - val_loss: 0.6121 - val_keras_r2: 0.2409\n",
            "Epoch 741/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2029 - val_loss: 0.6118 - val_keras_r2: 0.2413\n",
            "Epoch 742/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2071 - val_loss: 0.6109 - val_keras_r2: 0.2426\n",
            "Epoch 743/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.2075 - val_loss: 0.6076 - val_keras_r2: 0.2446\n",
            "Epoch 744/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2039 - val_loss: 0.6127 - val_keras_r2: 0.2405\n",
            "Epoch 745/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.2000 - val_loss: 0.6137 - val_keras_r2: 0.2394\n",
            "Epoch 746/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6667 - keras_r2: 0.1948 - val_loss: 0.6091 - val_keras_r2: 0.2425\n",
            "Epoch 747/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6672 - keras_r2: 0.2044 - val_loss: 0.6126 - val_keras_r2: 0.2397\n",
            "Epoch 748/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6631 - keras_r2: 0.2034 - val_loss: 0.6140 - val_keras_r2: 0.2389\n",
            "Epoch 749/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6624 - keras_r2: 0.1986 - val_loss: 0.6099 - val_keras_r2: 0.2424\n",
            "Epoch 750/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2035 - val_loss: 0.6104 - val_keras_r2: 0.2399\n",
            "Epoch 751/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.1960 - val_loss: 0.6107 - val_keras_r2: 0.2419\n",
            "Epoch 752/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6613 - keras_r2: 0.2040 - val_loss: 0.6088 - val_keras_r2: 0.2416\n",
            "Epoch 753/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6612 - keras_r2: 0.2039 - val_loss: 0.6076 - val_keras_r2: 0.2442\n",
            "Epoch 754/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.2028 - val_loss: 0.6184 - val_keras_r2: 0.2354\n",
            "Epoch 755/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2105 - val_loss: 0.6088 - val_keras_r2: 0.2424\n",
            "Epoch 756/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6680 - keras_r2: 0.1970 - val_loss: 0.6087 - val_keras_r2: 0.2438\n",
            "Epoch 757/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6632 - keras_r2: 0.2031 - val_loss: 0.6105 - val_keras_r2: 0.2424\n",
            "Epoch 758/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.2067 - val_loss: 0.6086 - val_keras_r2: 0.2426\n",
            "Epoch 759/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6625 - keras_r2: 0.2012 - val_loss: 0.6105 - val_keras_r2: 0.2421\n",
            "Epoch 760/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6601 - keras_r2: 0.2087 - val_loss: 0.6108 - val_keras_r2: 0.2413\n",
            "Epoch 761/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6704 - keras_r2: 0.1917 - val_loss: 0.6123 - val_keras_r2: 0.2388\n",
            "Epoch 762/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6643 - keras_r2: 0.2018 - val_loss: 0.6081 - val_keras_r2: 0.2435\n",
            "Epoch 763/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6635 - keras_r2: 0.2035 - val_loss: 0.6119 - val_keras_r2: 0.2406\n",
            "Epoch 764/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6677 - keras_r2: 0.1924 - val_loss: 0.6090 - val_keras_r2: 0.2432\n",
            "Epoch 765/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2001 - val_loss: 0.6091 - val_keras_r2: 0.2423\n",
            "Epoch 766/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6659 - keras_r2: 0.2064 - val_loss: 0.6105 - val_keras_r2: 0.2422\n",
            "Epoch 767/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6701 - keras_r2: 0.1786 - val_loss: 0.6113 - val_keras_r2: 0.2415\n",
            "Epoch 768/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.1999 - val_loss: 0.6129 - val_keras_r2: 0.2395\n",
            "Epoch 769/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.2030 - val_loss: 0.6101 - val_keras_r2: 0.2420\n",
            "Epoch 770/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6635 - keras_r2: 0.2016 - val_loss: 0.6096 - val_keras_r2: 0.2432\n",
            "Epoch 771/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6705 - keras_r2: 0.1922 - val_loss: 0.6109 - val_keras_r2: 0.2416\n",
            "Epoch 772/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.1945 - val_loss: 0.6091 - val_keras_r2: 0.2428\n",
            "Epoch 773/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6704 - keras_r2: 0.1927 - val_loss: 0.6123 - val_keras_r2: 0.2409\n",
            "Epoch 774/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.1975 - val_loss: 0.6108 - val_keras_r2: 0.2415\n",
            "Epoch 775/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6680 - keras_r2: 0.2018 - val_loss: 0.6129 - val_keras_r2: 0.2397\n",
            "Epoch 776/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6691 - keras_r2: 0.1975 - val_loss: 0.6138 - val_keras_r2: 0.2389\n",
            "Epoch 777/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.2047 - val_loss: 0.6093 - val_keras_r2: 0.2422\n",
            "Epoch 778/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.2010 - val_loss: 0.6105 - val_keras_r2: 0.2410\n",
            "Epoch 779/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6646 - keras_r2: 0.2013 - val_loss: 0.6126 - val_keras_r2: 0.2403\n",
            "Epoch 780/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.2015 - val_loss: 0.6117 - val_keras_r2: 0.2416\n",
            "Epoch 781/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6597 - keras_r2: 0.2085 - val_loss: 0.6083 - val_keras_r2: 0.2422\n",
            "Epoch 782/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.1976 - val_loss: 0.6101 - val_keras_r2: 0.2418\n",
            "Epoch 783/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6653 - keras_r2: 0.2045 - val_loss: 0.6105 - val_keras_r2: 0.2416\n",
            "Epoch 784/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6548 - keras_r2: 0.2135 - val_loss: 0.6105 - val_keras_r2: 0.2425\n",
            "Epoch 785/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6679 - keras_r2: 0.1906 - val_loss: 0.6114 - val_keras_r2: 0.2416\n",
            "Epoch 786/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6626 - keras_r2: 0.2026 - val_loss: 0.6123 - val_keras_r2: 0.2415\n",
            "Epoch 787/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6684 - keras_r2: 0.1911 - val_loss: 0.6137 - val_keras_r2: 0.2395\n",
            "Epoch 788/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6615 - keras_r2: 0.2063 - val_loss: 0.6079 - val_keras_r2: 0.2442\n",
            "Epoch 789/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6659 - keras_r2: 0.1986 - val_loss: 0.6077 - val_keras_r2: 0.2446\n",
            "Epoch 790/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6643 - keras_r2: 0.1992 - val_loss: 0.6100 - val_keras_r2: 0.2425\n",
            "Epoch 791/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6685 - keras_r2: 0.1963 - val_loss: 0.6108 - val_keras_r2: 0.2422\n",
            "Epoch 792/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6650 - keras_r2: 0.2018 - val_loss: 0.6079 - val_keras_r2: 0.2445\n",
            "Epoch 793/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.1988 - val_loss: 0.6073 - val_keras_r2: 0.2447\n",
            "Epoch 794/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6688 - keras_r2: 0.1893 - val_loss: 0.6071 - val_keras_r2: 0.2425\n",
            "Epoch 795/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6636 - keras_r2: 0.1983 - val_loss: 0.6072 - val_keras_r2: 0.2451\n",
            "Epoch 796/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6631 - keras_r2: 0.2007 - val_loss: 0.6072 - val_keras_r2: 0.2442\n",
            "Epoch 797/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6630 - keras_r2: 0.2046 - val_loss: 0.6131 - val_keras_r2: 0.2401\n",
            "Epoch 798/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6624 - keras_r2: 0.2124 - val_loss: 0.6100 - val_keras_r2: 0.2430\n",
            "Epoch 799/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6651 - keras_r2: 0.2095 - val_loss: 0.6073 - val_keras_r2: 0.2446\n",
            "Epoch 800/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6682 - keras_r2: 0.1972 - val_loss: 0.6123 - val_keras_r2: 0.2409\n",
            "Epoch 801/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2010 - val_loss: 0.6160 - val_keras_r2: 0.2369\n",
            "Epoch 802/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6645 - keras_r2: 0.1969 - val_loss: 0.6111 - val_keras_r2: 0.2413\n",
            "Epoch 803/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.1903 - val_loss: 0.6145 - val_keras_r2: 0.2390\n",
            "Epoch 804/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6598 - keras_r2: 0.2094 - val_loss: 0.6104 - val_keras_r2: 0.2422\n",
            "Epoch 805/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6662 - keras_r2: 0.1953 - val_loss: 0.6130 - val_keras_r2: 0.2409\n",
            "Epoch 806/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2021 - val_loss: 0.6068 - val_keras_r2: 0.2448\n",
            "Epoch 807/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2059 - val_loss: 0.6092 - val_keras_r2: 0.2436\n",
            "Epoch 808/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.2006 - val_loss: 0.6130 - val_keras_r2: 0.2403\n",
            "Epoch 809/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6615 - keras_r2: 0.2100 - val_loss: 0.6103 - val_keras_r2: 0.2428\n",
            "Epoch 810/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6675 - keras_r2: 0.1977 - val_loss: 0.6098 - val_keras_r2: 0.2434\n",
            "Epoch 811/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.1957 - val_loss: 0.6134 - val_keras_r2: 0.2398\n",
            "Epoch 812/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6669 - keras_r2: 0.1974 - val_loss: 0.6118 - val_keras_r2: 0.2409\n",
            "Epoch 813/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6638 - keras_r2: 0.1975 - val_loss: 0.6136 - val_keras_r2: 0.2393\n",
            "Epoch 814/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6665 - keras_r2: 0.1985 - val_loss: 0.6104 - val_keras_r2: 0.2411\n",
            "Epoch 815/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6624 - keras_r2: 0.2099 - val_loss: 0.6051 - val_keras_r2: 0.2463\n",
            "Epoch 816/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6617 - keras_r2: 0.2040 - val_loss: 0.6119 - val_keras_r2: 0.2415\n",
            "Epoch 817/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6573 - keras_r2: 0.2124 - val_loss: 0.6078 - val_keras_r2: 0.2447\n",
            "Epoch 818/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6655 - keras_r2: 0.2001 - val_loss: 0.6065 - val_keras_r2: 0.2462\n",
            "Epoch 819/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6610 - keras_r2: 0.2041 - val_loss: 0.6055 - val_keras_r2: 0.2468\n",
            "Epoch 820/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6668 - keras_r2: 0.1995 - val_loss: 0.6126 - val_keras_r2: 0.2400\n",
            "Epoch 821/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6626 - keras_r2: 0.2052 - val_loss: 0.6092 - val_keras_r2: 0.2441\n",
            "Epoch 822/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2002 - val_loss: 0.6063 - val_keras_r2: 0.2454\n",
            "Epoch 823/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6680 - keras_r2: 0.1956 - val_loss: 0.6081 - val_keras_r2: 0.2442\n",
            "Epoch 824/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6700 - keras_r2: 0.1876 - val_loss: 0.6105 - val_keras_r2: 0.2413\n",
            "Epoch 825/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6619 - keras_r2: 0.2045 - val_loss: 0.6093 - val_keras_r2: 0.2430\n",
            "Epoch 826/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6592 - keras_r2: 0.2107 - val_loss: 0.6079 - val_keras_r2: 0.2453\n",
            "Epoch 827/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.1989 - val_loss: 0.6069 - val_keras_r2: 0.2449\n",
            "Epoch 828/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.1927 - val_loss: 0.6075 - val_keras_r2: 0.2449\n",
            "Epoch 829/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6632 - keras_r2: 0.1985 - val_loss: 0.6074 - val_keras_r2: 0.2445\n",
            "Epoch 830/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.2036 - val_loss: 0.6107 - val_keras_r2: 0.2430\n",
            "Epoch 831/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6649 - keras_r2: 0.2024 - val_loss: 0.6122 - val_keras_r2: 0.2420\n",
            "Epoch 832/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6702 - keras_r2: 0.1908 - val_loss: 0.6058 - val_keras_r2: 0.2450\n",
            "Epoch 833/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2055 - val_loss: 0.6095 - val_keras_r2: 0.2439\n",
            "Epoch 834/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2060 - val_loss: 0.6074 - val_keras_r2: 0.2450\n",
            "Epoch 835/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6678 - keras_r2: 0.1998 - val_loss: 0.6157 - val_keras_r2: 0.2380\n",
            "Epoch 836/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6591 - keras_r2: 0.2060 - val_loss: 0.6084 - val_keras_r2: 0.2439\n",
            "Epoch 837/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2075 - val_loss: 0.6094 - val_keras_r2: 0.2428\n",
            "Epoch 838/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6637 - keras_r2: 0.2010 - val_loss: 0.6084 - val_keras_r2: 0.2440\n",
            "Epoch 839/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6663 - keras_r2: 0.1986 - val_loss: 0.6097 - val_keras_r2: 0.2428\n",
            "Epoch 840/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6610 - keras_r2: 0.2107 - val_loss: 0.6072 - val_keras_r2: 0.2446\n",
            "Epoch 841/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6605 - keras_r2: 0.2076 - val_loss: 0.6078 - val_keras_r2: 0.2448\n",
            "Epoch 842/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.1938 - val_loss: 0.6123 - val_keras_r2: 0.2413\n",
            "Epoch 843/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6622 - keras_r2: 0.2033 - val_loss: 0.6093 - val_keras_r2: 0.2421\n",
            "Epoch 844/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6692 - keras_r2: 0.1961 - val_loss: 0.6081 - val_keras_r2: 0.2443\n",
            "Epoch 845/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6558 - keras_r2: 0.2206 - val_loss: 0.6046 - val_keras_r2: 0.2449\n",
            "Epoch 846/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6568 - keras_r2: 0.2130 - val_loss: 0.6062 - val_keras_r2: 0.2454\n",
            "Epoch 847/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6668 - keras_r2: 0.1986 - val_loss: 0.6124 - val_keras_r2: 0.2404\n",
            "Epoch 848/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6622 - keras_r2: 0.2057 - val_loss: 0.6081 - val_keras_r2: 0.2444\n",
            "Epoch 849/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6652 - keras_r2: 0.1950 - val_loss: 0.6076 - val_keras_r2: 0.2449\n",
            "Epoch 850/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.2064 - val_loss: 0.6096 - val_keras_r2: 0.2428\n",
            "Epoch 851/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6627 - keras_r2: 0.2055 - val_loss: 0.6080 - val_keras_r2: 0.2450\n",
            "Epoch 852/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.2021 - val_loss: 0.6085 - val_keras_r2: 0.2447\n",
            "Epoch 853/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6655 - keras_r2: 0.2066 - val_loss: 0.6082 - val_keras_r2: 0.2436\n",
            "Epoch 854/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6553 - keras_r2: 0.2155 - val_loss: 0.6058 - val_keras_r2: 0.2473\n",
            "Epoch 855/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6618 - keras_r2: 0.2048 - val_loss: 0.6068 - val_keras_r2: 0.2458\n",
            "Epoch 856/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2018 - val_loss: 0.6071 - val_keras_r2: 0.2460\n",
            "Epoch 857/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1951 - val_loss: 0.6058 - val_keras_r2: 0.2468\n",
            "Epoch 858/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6675 - keras_r2: 0.1945 - val_loss: 0.6090 - val_keras_r2: 0.2442\n",
            "Epoch 859/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6640 - keras_r2: 0.2052 - val_loss: 0.6108 - val_keras_r2: 0.2416\n",
            "Epoch 860/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6610 - keras_r2: 0.2026 - val_loss: 0.6072 - val_keras_r2: 0.2448\n",
            "Epoch 861/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.1993 - val_loss: 0.6082 - val_keras_r2: 0.2440\n",
            "Epoch 862/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.2082 - val_loss: 0.6108 - val_keras_r2: 0.2423\n",
            "Epoch 863/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6685 - keras_r2: 0.1924 - val_loss: 0.6119 - val_keras_r2: 0.2402\n",
            "Epoch 864/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6637 - keras_r2: 0.2038 - val_loss: 0.6075 - val_keras_r2: 0.2443\n",
            "Epoch 865/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6616 - keras_r2: 0.2097 - val_loss: 0.6098 - val_keras_r2: 0.2436\n",
            "Epoch 866/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6597 - keras_r2: 0.2049 - val_loss: 0.6071 - val_keras_r2: 0.2456\n",
            "Epoch 867/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6592 - keras_r2: 0.2140 - val_loss: 0.6072 - val_keras_r2: 0.2457\n",
            "Epoch 868/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6632 - keras_r2: 0.2016 - val_loss: 0.6078 - val_keras_r2: 0.2460\n",
            "Epoch 869/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6613 - keras_r2: 0.2028 - val_loss: 0.6066 - val_keras_r2: 0.2460\n",
            "Epoch 870/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.2044 - val_loss: 0.6109 - val_keras_r2: 0.2414\n",
            "Epoch 871/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6576 - keras_r2: 0.2057 - val_loss: 0.6056 - val_keras_r2: 0.2451\n",
            "Epoch 872/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6659 - keras_r2: 0.1951 - val_loss: 0.6125 - val_keras_r2: 0.2408\n",
            "Epoch 873/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6624 - keras_r2: 0.2046 - val_loss: 0.6086 - val_keras_r2: 0.2440\n",
            "Epoch 874/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6622 - keras_r2: 0.2037 - val_loss: 0.6097 - val_keras_r2: 0.2429\n",
            "Epoch 875/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6582 - keras_r2: 0.2165 - val_loss: 0.6070 - val_keras_r2: 0.2458\n",
            "Epoch 876/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6593 - keras_r2: 0.2015 - val_loss: 0.6062 - val_keras_r2: 0.2446\n",
            "Epoch 877/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.1998 - val_loss: 0.6125 - val_keras_r2: 0.2402\n",
            "Epoch 878/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6572 - keras_r2: 0.2156 - val_loss: 0.6040 - val_keras_r2: 0.2471\n",
            "Epoch 879/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6623 - keras_r2: 0.2003 - val_loss: 0.6088 - val_keras_r2: 0.2447\n",
            "Epoch 880/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.2059 - val_loss: 0.6065 - val_keras_r2: 0.2458\n",
            "Epoch 881/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.1978 - val_loss: 0.6119 - val_keras_r2: 0.2418\n",
            "Epoch 882/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2007 - val_loss: 0.6062 - val_keras_r2: 0.2467\n",
            "Epoch 883/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6624 - keras_r2: 0.2052 - val_loss: 0.6077 - val_keras_r2: 0.2454\n",
            "Epoch 884/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6676 - keras_r2: 0.1955 - val_loss: 0.6071 - val_keras_r2: 0.2457\n",
            "Epoch 885/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6650 - keras_r2: 0.1986 - val_loss: 0.6088 - val_keras_r2: 0.2446\n",
            "Epoch 886/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6624 - keras_r2: 0.2039 - val_loss: 0.6079 - val_keras_r2: 0.2449\n",
            "Epoch 887/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6630 - keras_r2: 0.2011 - val_loss: 0.6058 - val_keras_r2: 0.2468\n",
            "Epoch 888/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6637 - keras_r2: 0.2081 - val_loss: 0.6059 - val_keras_r2: 0.2464\n",
            "Epoch 889/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.1988 - val_loss: 0.6056 - val_keras_r2: 0.2462\n",
            "Epoch 890/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.1979 - val_loss: 0.6077 - val_keras_r2: 0.2455\n",
            "Epoch 891/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6709 - keras_r2: 0.1981 - val_loss: 0.6069 - val_keras_r2: 0.2457\n",
            "Epoch 892/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6598 - keras_r2: 0.2012 - val_loss: 0.6112 - val_keras_r2: 0.2413\n",
            "Epoch 893/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6645 - keras_r2: 0.1992 - val_loss: 0.6072 - val_keras_r2: 0.2448\n",
            "Epoch 894/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6622 - keras_r2: 0.2055 - val_loss: 0.6117 - val_keras_r2: 0.2424\n",
            "Epoch 895/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6708 - keras_r2: 0.1936 - val_loss: 0.6087 - val_keras_r2: 0.2452\n",
            "Epoch 896/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.1992 - val_loss: 0.6114 - val_keras_r2: 0.2430\n",
            "Epoch 897/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.2133 - val_loss: 0.6088 - val_keras_r2: 0.2453\n",
            "Epoch 898/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6636 - keras_r2: 0.1946 - val_loss: 0.6081 - val_keras_r2: 0.2451\n",
            "Epoch 899/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6690 - keras_r2: 0.1863 - val_loss: 0.6079 - val_keras_r2: 0.2459\n",
            "Epoch 900/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6619 - keras_r2: 0.2065 - val_loss: 0.6079 - val_keras_r2: 0.2456\n",
            "Epoch 901/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6681 - keras_r2: 0.1991 - val_loss: 0.6043 - val_keras_r2: 0.2481\n",
            "Epoch 902/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6653 - keras_r2: 0.1990 - val_loss: 0.6073 - val_keras_r2: 0.2465\n",
            "Epoch 903/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6599 - keras_r2: 0.2106 - val_loss: 0.6073 - val_keras_r2: 0.2469\n",
            "Epoch 904/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6618 - keras_r2: 0.2049 - val_loss: 0.6086 - val_keras_r2: 0.2448\n",
            "Epoch 905/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2046 - val_loss: 0.6053 - val_keras_r2: 0.2455\n",
            "Epoch 906/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6694 - keras_r2: 0.1953 - val_loss: 0.6091 - val_keras_r2: 0.2448\n",
            "Epoch 907/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6665 - keras_r2: 0.1998 - val_loss: 0.6120 - val_keras_r2: 0.2412\n",
            "Epoch 908/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.1980 - val_loss: 0.6064 - val_keras_r2: 0.2459\n",
            "Epoch 909/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6614 - keras_r2: 0.2026 - val_loss: 0.6067 - val_keras_r2: 0.2449\n",
            "Epoch 910/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6636 - keras_r2: 0.2046 - val_loss: 0.6098 - val_keras_r2: 0.2431\n",
            "Epoch 911/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6556 - keras_r2: 0.2196 - val_loss: 0.6098 - val_keras_r2: 0.2435\n",
            "Epoch 912/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2030 - val_loss: 0.6119 - val_keras_r2: 0.2424\n",
            "Epoch 913/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6659 - keras_r2: 0.2031 - val_loss: 0.6082 - val_keras_r2: 0.2448\n",
            "Epoch 914/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6672 - keras_r2: 0.2017 - val_loss: 0.6069 - val_keras_r2: 0.2466\n",
            "Epoch 915/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6626 - keras_r2: 0.2039 - val_loss: 0.6068 - val_keras_r2: 0.2461\n",
            "Epoch 916/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6642 - keras_r2: 0.1991 - val_loss: 0.6064 - val_keras_r2: 0.2457\n",
            "Epoch 917/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6656 - keras_r2: 0.1981 - val_loss: 0.6074 - val_keras_r2: 0.2457\n",
            "Epoch 918/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6642 - keras_r2: 0.2009 - val_loss: 0.6110 - val_keras_r2: 0.2431\n",
            "Epoch 919/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6625 - keras_r2: 0.2076 - val_loss: 0.6068 - val_keras_r2: 0.2464\n",
            "Epoch 920/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.1977 - val_loss: 0.6081 - val_keras_r2: 0.2458\n",
            "Epoch 921/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.1986 - val_loss: 0.6088 - val_keras_r2: 0.2449\n",
            "Epoch 922/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6666 - keras_r2: 0.2011 - val_loss: 0.6051 - val_keras_r2: 0.2476\n",
            "Epoch 923/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6625 - keras_r2: 0.2028 - val_loss: 0.6077 - val_keras_r2: 0.2463\n",
            "Epoch 924/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.2047 - val_loss: 0.6080 - val_keras_r2: 0.2467\n",
            "Epoch 925/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6699 - keras_r2: 0.1916 - val_loss: 0.6057 - val_keras_r2: 0.2477\n",
            "Epoch 926/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6627 - keras_r2: 0.2084 - val_loss: 0.6101 - val_keras_r2: 0.2447\n",
            "Epoch 927/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6606 - keras_r2: 0.2058 - val_loss: 0.6086 - val_keras_r2: 0.2445\n",
            "Epoch 928/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6593 - keras_r2: 0.2072 - val_loss: 0.6091 - val_keras_r2: 0.2440\n",
            "Epoch 929/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6567 - keras_r2: 0.2095 - val_loss: 0.6095 - val_keras_r2: 0.2432\n",
            "Epoch 930/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6589 - keras_r2: 0.2098 - val_loss: 0.6054 - val_keras_r2: 0.2473\n",
            "Epoch 931/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6621 - keras_r2: 0.2068 - val_loss: 0.6046 - val_keras_r2: 0.2479\n",
            "Epoch 932/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6630 - keras_r2: 0.2128 - val_loss: 0.6133 - val_keras_r2: 0.2405\n",
            "Epoch 933/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6614 - keras_r2: 0.2122 - val_loss: 0.6082 - val_keras_r2: 0.2450\n",
            "Epoch 934/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6646 - keras_r2: 0.2037 - val_loss: 0.6054 - val_keras_r2: 0.2479\n",
            "Epoch 935/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6609 - keras_r2: 0.2020 - val_loss: 0.6075 - val_keras_r2: 0.2462\n",
            "Epoch 936/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.2023 - val_loss: 0.6089 - val_keras_r2: 0.2453\n",
            "Epoch 937/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6650 - keras_r2: 0.1948 - val_loss: 0.6073 - val_keras_r2: 0.2459\n",
            "Epoch 938/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6546 - keras_r2: 0.2166 - val_loss: 0.6044 - val_keras_r2: 0.2454\n",
            "Epoch 939/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6579 - keras_r2: 0.1949 - val_loss: 0.6084 - val_keras_r2: 0.2453\n",
            "Epoch 940/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6665 - keras_r2: 0.2040 - val_loss: 0.6064 - val_keras_r2: 0.2470\n",
            "Epoch 941/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6582 - keras_r2: 0.2078 - val_loss: 0.6089 - val_keras_r2: 0.2442\n",
            "Epoch 942/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6626 - keras_r2: 0.2053 - val_loss: 0.6089 - val_keras_r2: 0.2444\n",
            "Epoch 943/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6660 - keras_r2: 0.1973 - val_loss: 0.6103 - val_keras_r2: 0.2434\n",
            "Epoch 944/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2035 - val_loss: 0.6059 - val_keras_r2: 0.2469\n",
            "Epoch 945/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6628 - keras_r2: 0.2028 - val_loss: 0.6105 - val_keras_r2: 0.2435\n",
            "Epoch 946/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6683 - keras_r2: 0.1927 - val_loss: 0.6106 - val_keras_r2: 0.2438\n",
            "Epoch 947/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6590 - keras_r2: 0.2125 - val_loss: 0.6082 - val_keras_r2: 0.2443\n",
            "Epoch 948/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6566 - keras_r2: 0.2099 - val_loss: 0.6085 - val_keras_r2: 0.2444\n",
            "Epoch 949/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6648 - keras_r2: 0.2046 - val_loss: 0.6060 - val_keras_r2: 0.2461\n",
            "Epoch 950/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6603 - keras_r2: 0.2073 - val_loss: 0.6106 - val_keras_r2: 0.2406\n",
            "Epoch 951/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.1982 - val_loss: 0.6070 - val_keras_r2: 0.2453\n",
            "Epoch 952/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6664 - keras_r2: 0.1969 - val_loss: 0.6082 - val_keras_r2: 0.2428\n",
            "Epoch 953/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6605 - keras_r2: 0.1970 - val_loss: 0.6094 - val_keras_r2: 0.2438\n",
            "Epoch 954/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2049 - val_loss: 0.6068 - val_keras_r2: 0.2458\n",
            "Epoch 955/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6620 - keras_r2: 0.2110 - val_loss: 0.6075 - val_keras_r2: 0.2453\n",
            "Epoch 956/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2022 - val_loss: 0.6060 - val_keras_r2: 0.2466\n",
            "Epoch 957/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.2050 - val_loss: 0.6111 - val_keras_r2: 0.2411\n",
            "Epoch 958/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6598 - keras_r2: 0.2079 - val_loss: 0.6051 - val_keras_r2: 0.2469\n",
            "Epoch 959/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6642 - keras_r2: 0.1986 - val_loss: 0.6078 - val_keras_r2: 0.2452\n",
            "Epoch 960/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6596 - keras_r2: 0.2099 - val_loss: 0.6064 - val_keras_r2: 0.2460\n",
            "Epoch 961/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6626 - keras_r2: 0.2031 - val_loss: 0.6049 - val_keras_r2: 0.2474\n",
            "Epoch 962/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6679 - keras_r2: 0.1985 - val_loss: 0.6061 - val_keras_r2: 0.2463\n",
            "Epoch 963/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6671 - keras_r2: 0.1937 - val_loss: 0.6063 - val_keras_r2: 0.2464\n",
            "Epoch 964/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6601 - keras_r2: 0.2049 - val_loss: 0.6077 - val_keras_r2: 0.2454\n",
            "Epoch 965/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6603 - keras_r2: 0.2103 - val_loss: 0.6078 - val_keras_r2: 0.2453\n",
            "Epoch 966/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6573 - keras_r2: 0.2098 - val_loss: 0.6086 - val_keras_r2: 0.2438\n",
            "Epoch 967/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2041 - val_loss: 0.6117 - val_keras_r2: 0.2418\n",
            "Epoch 968/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6590 - keras_r2: 0.2112 - val_loss: 0.6066 - val_keras_r2: 0.2465\n",
            "Epoch 969/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.2042 - val_loss: 0.6097 - val_keras_r2: 0.2432\n",
            "Epoch 970/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6647 - keras_r2: 0.2074 - val_loss: 0.6071 - val_keras_r2: 0.2448\n",
            "Epoch 971/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6631 - keras_r2: 0.2044 - val_loss: 0.6073 - val_keras_r2: 0.2462\n",
            "Epoch 972/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6635 - keras_r2: 0.2110 - val_loss: 0.6066 - val_keras_r2: 0.2473\n",
            "Epoch 973/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6639 - keras_r2: 0.2047 - val_loss: 0.6092 - val_keras_r2: 0.2438\n",
            "Epoch 974/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6569 - keras_r2: 0.2134 - val_loss: 0.6061 - val_keras_r2: 0.2472\n",
            "Epoch 975/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6557 - keras_r2: 0.2147 - val_loss: 0.6083 - val_keras_r2: 0.2451\n",
            "Epoch 976/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6641 - keras_r2: 0.2040 - val_loss: 0.6094 - val_keras_r2: 0.2448\n",
            "Epoch 977/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6603 - keras_r2: 0.2075 - val_loss: 0.6054 - val_keras_r2: 0.2466\n",
            "Epoch 978/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6604 - keras_r2: 0.2011 - val_loss: 0.6063 - val_keras_r2: 0.2458\n",
            "Epoch 979/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6599 - keras_r2: 0.2125 - val_loss: 0.6127 - val_keras_r2: 0.2413\n",
            "Epoch 980/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6564 - keras_r2: 0.2144 - val_loss: 0.6099 - val_keras_r2: 0.2431\n",
            "Epoch 981/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6631 - keras_r2: 0.2007 - val_loss: 0.6065 - val_keras_r2: 0.2462\n",
            "Epoch 982/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6665 - keras_r2: 0.2065 - val_loss: 0.6077 - val_keras_r2: 0.2454\n",
            "Epoch 983/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6679 - keras_r2: 0.1985 - val_loss: 0.6084 - val_keras_r2: 0.2451\n",
            "Epoch 984/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6615 - keras_r2: 0.2099 - val_loss: 0.6078 - val_keras_r2: 0.2439\n",
            "Epoch 985/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6624 - keras_r2: 0.2081 - val_loss: 0.6071 - val_keras_r2: 0.2451\n",
            "Epoch 986/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6580 - keras_r2: 0.2096 - val_loss: 0.6099 - val_keras_r2: 0.2440\n",
            "Epoch 987/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6615 - keras_r2: 0.2064 - val_loss: 0.6105 - val_keras_r2: 0.2430\n",
            "Epoch 988/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6654 - keras_r2: 0.2010 - val_loss: 0.6124 - val_keras_r2: 0.2413\n",
            "Epoch 989/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6634 - keras_r2: 0.2017 - val_loss: 0.6115 - val_keras_r2: 0.2421\n",
            "Epoch 990/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6633 - keras_r2: 0.2072 - val_loss: 0.6081 - val_keras_r2: 0.2451\n",
            "Epoch 991/1000\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6653 - keras_r2: 0.2025 - val_loss: 0.6086 - val_keras_r2: 0.2443\n",
            "Epoch 992/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6609 - keras_r2: 0.2059 - val_loss: 0.6107 - val_keras_r2: 0.2416\n",
            "Epoch 993/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6627 - keras_r2: 0.2076 - val_loss: 0.6095 - val_keras_r2: 0.2439\n",
            "Epoch 994/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6658 - keras_r2: 0.1981 - val_loss: 0.6089 - val_keras_r2: 0.2444\n",
            "Epoch 995/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6615 - keras_r2: 0.2092 - val_loss: 0.6120 - val_keras_r2: 0.2422\n",
            "Epoch 996/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6569 - keras_r2: 0.2178 - val_loss: 0.6044 - val_keras_r2: 0.2461\n",
            "Epoch 997/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6638 - keras_r2: 0.2018 - val_loss: 0.6086 - val_keras_r2: 0.2437\n",
            "Epoch 998/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6575 - keras_r2: 0.2114 - val_loss: 0.6103 - val_keras_r2: 0.2422\n",
            "Epoch 999/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6592 - keras_r2: 0.2068 - val_loss: 0.6107 - val_keras_r2: 0.2414\n",
            "Epoch 1000/1000\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6598 - keras_r2: 0.2099 - val_loss: 0.6090 - val_keras_r2: 0.2447\n"
          ]
        }
      ],
      "source": [
        "# history_3 = model_3.fit(X_train_keras, y_train, validation_data=(\n",
        "#     X_test_keras, y_test), batch_size=32, epochs=100, callbacks=[EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)])\n",
        "history_3 = model_3.fit(X_train_keras, y_train, validation_data=(\n",
        "    X_test_keras, y_test), batch_size=32, epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ClimPK2qNHn",
        "outputId": "83df81f0-5da3-4146-a398-20d02d1d390b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6090 - keras_r2: 0.2447\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6090407967567444, 0.2447379231452942]"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3.evaluate(X_test_keras, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Px4IIxqFqRv4",
        "outputId": "f65d3410-8108-4d60-dd00-550e34d7f4bc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.ylim(ymin=0, ymax=1)\n",
        "\n",
        "plt.plot(history_3.history['loss'], label=\"loss\")\n",
        "plt.plot(history_3.history['val_loss'], label=\"val_loss \")\n",
        "\n",
        "plt.plot(history_3.history['keras_r2'], label=\"r2\")\n",
        "plt.plot(history_3.history['val_keras_r2'], label=\"val_r2\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podobnie jak w przypadku 2 poprzednich modeli, hiperparametry tutaj wyznaczone zostały w sposób losowy, jednak tym razem brana pod uwagę była ewentualna normalizacja batchy oraz dropout.\n",
        "\n",
        "Efekt tego jest zauważalny, gdyż o ile poprzednie modele głębokie musiały mieć dodany `early stopping`, ponieważ ostatecznie traciły dokładność, tutaj jest to nie wymagane. Jak widać na wykresie histori, zarówno dla treningu i walidacji `r^2` rosło, matomiast `loss` malało. Dla walidacji, krzywe te dosyć mocno oscylują, natomiast widać ogólny trend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Parametry dobrane ręcznie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 100)               6600      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 50)                5000      \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 50)               200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 50)                0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 10)                500       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 10)               40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,751\n",
            "Trainable params: 12,431\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "history_4 = History()\n",
        "\n",
        "model_4 = Sequential()\n",
        "model_4.add(keras.layers.InputLayer(input_shape=X_train_keras.shape[1],))\n",
        "model_4.add(Dense(100, use_bias=False))\n",
        "model_4.add(BatchNormalization())\n",
        "model_4.add(Activation(\"elu\"))\n",
        "model_4.add(Dropout(0.15))\n",
        "model_4.add(Dense(50, use_bias=False))\n",
        "model_4.add(BatchNormalization())\n",
        "model_4.add(Activation(\"elu\"))\n",
        "model_4.add(Dropout(0.15))\n",
        "model_4.add(Dense(10, use_bias=False))\n",
        "model_4.add(BatchNormalization())\n",
        "model_4.add(Activation(\"elu\"))\n",
        "model_4.add(Dropout(0.15))\n",
        "model_4.add(Dense(1,activation=\"relu\"))\n",
        "model_4.summary()\n",
        "\n",
        "model_4.compile(loss=\"mean_squared_error\",optimizer=\"Adam\", metrics=[keras_r2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "274/274 [==============================] - 3s 5ms/step - loss: 23.6071 - keras_r2: -29.7619 - val_loss: 13.8857 - val_keras_r2: -19.0824\n",
            "Epoch 2/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 13.0018 - keras_r2: -15.9998 - val_loss: 8.9519 - val_keras_r2: -11.8363\n",
            "Epoch 3/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 10.7720 - keras_r2: -13.1529 - val_loss: 8.0984 - val_keras_r2: -10.4803\n",
            "Epoch 4/300\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9.6061 - keras_r2: -11.6920 - val_loss: 4.8462 - val_keras_r2: -5.6993\n",
            "Epoch 5/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5.9800 - keras_r2: -6.8274 - val_loss: 3.9574 - val_keras_r2: -4.2544\n",
            "Epoch 6/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5.4821 - keras_r2: -6.2498 - val_loss: 3.8588 - val_keras_r2: -4.1214\n",
            "Epoch 7/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5.1273 - keras_r2: -5.7711 - val_loss: 3.8401 - val_keras_r2: -4.1193\n",
            "Epoch 8/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5.0686 - keras_r2: -5.6360 - val_loss: 3.8013 - val_keras_r2: -4.0813\n",
            "Epoch 9/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4.4414 - keras_r2: -4.7951 - val_loss: 1.3411 - val_keras_r2: -0.8022\n",
            "Epoch 10/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.5944 - keras_r2: -1.0127 - val_loss: 0.7270 - val_keras_r2: 0.0950\n",
            "Epoch 11/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.5159 - keras_r2: -0.9207 - val_loss: 0.6894 - val_keras_r2: 0.1535\n",
            "Epoch 12/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.4166 - keras_r2: -0.7786 - val_loss: 0.6898 - val_keras_r2: 0.1471\n",
            "Epoch 13/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.3808 - keras_r2: -0.7602 - val_loss: 0.6754 - val_keras_r2: 0.1703\n",
            "Epoch 14/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.3615 - keras_r2: -0.7259 - val_loss: 0.6842 - val_keras_r2: 0.1546\n",
            "Epoch 15/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.3292 - keras_r2: -0.6770 - val_loss: 0.6796 - val_keras_r2: 0.1598\n",
            "Epoch 16/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.2644 - keras_r2: -0.5842 - val_loss: 0.6751 - val_keras_r2: 0.1644\n",
            "Epoch 17/300\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.2504 - keras_r2: -0.5733 - val_loss: 0.6808 - val_keras_r2: 0.1564\n",
            "Epoch 18/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.2201 - keras_r2: -0.5435 - val_loss: 0.6647 - val_keras_r2: 0.1791\n",
            "Epoch 19/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.2017 - keras_r2: -0.5148 - val_loss: 0.6678 - val_keras_r2: 0.1742\n",
            "Epoch 20/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.1833 - keras_r2: -0.4828 - val_loss: 0.6797 - val_keras_r2: 0.1543\n",
            "Epoch 21/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.1699 - keras_r2: -0.4536 - val_loss: 0.6661 - val_keras_r2: 0.1769\n",
            "Epoch 22/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.1331 - keras_r2: -0.4226 - val_loss: 0.6651 - val_keras_r2: 0.1751\n",
            "Epoch 23/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1.1239 - keras_r2: -0.4109 - val_loss: 0.6660 - val_keras_r2: 0.1737\n",
            "Epoch 24/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.0884 - keras_r2: -0.3612 - val_loss: 0.6711 - val_keras_r2: 0.1684\n",
            "Epoch 25/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1.0781 - keras_r2: -0.3473 - val_loss: 0.6589 - val_keras_r2: 0.1830\n",
            "Epoch 26/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.0316 - keras_r2: -0.2973 - val_loss: 0.6506 - val_keras_r2: 0.1949\n",
            "Epoch 27/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.0054 - keras_r2: -0.2515 - val_loss: 0.6440 - val_keras_r2: 0.2027\n",
            "Epoch 28/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1.0238 - keras_r2: -0.2685 - val_loss: 0.6394 - val_keras_r2: 0.2067\n",
            "Epoch 29/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9879 - keras_r2: -0.2366 - val_loss: 0.6576 - val_keras_r2: 0.1799\n",
            "Epoch 30/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.9848 - keras_r2: -0.2318 - val_loss: 0.6407 - val_keras_r2: 0.2057\n",
            "Epoch 31/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9526 - keras_r2: -0.1843 - val_loss: 0.6293 - val_keras_r2: 0.2176\n",
            "Epoch 32/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9487 - keras_r2: -0.1680 - val_loss: 0.6342 - val_keras_r2: 0.2135\n",
            "Epoch 33/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9260 - keras_r2: -0.1344 - val_loss: 0.6378 - val_keras_r2: 0.2109\n",
            "Epoch 34/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9063 - keras_r2: -0.1117 - val_loss: 0.6365 - val_keras_r2: 0.2150\n",
            "Epoch 35/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.9152 - keras_r2: -0.1340 - val_loss: 0.6341 - val_keras_r2: 0.2160\n",
            "Epoch 36/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8918 - keras_r2: -0.1052 - val_loss: 0.6364 - val_keras_r2: 0.2095\n",
            "Epoch 37/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8550 - keras_r2: -0.0501 - val_loss: 0.6298 - val_keras_r2: 0.2156\n",
            "Epoch 38/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.8640 - keras_r2: -0.0698 - val_loss: 0.6276 - val_keras_r2: 0.2233\n",
            "Epoch 39/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8524 - keras_r2: -0.0513 - val_loss: 0.6275 - val_keras_r2: 0.2181\n",
            "Epoch 40/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8456 - keras_r2: -0.0452 - val_loss: 0.6155 - val_keras_r2: 0.2354\n",
            "Epoch 41/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.8261 - keras_r2: -0.0069 - val_loss: 0.6242 - val_keras_r2: 0.2216\n",
            "Epoch 42/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.8045 - keras_r2: 0.0117 - val_loss: 0.6138 - val_keras_r2: 0.2351\n",
            "Epoch 43/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.8262 - keras_r2: -0.0125 - val_loss: 0.6164 - val_keras_r2: 0.2322\n",
            "Epoch 44/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8211 - keras_r2: 0.0056 - val_loss: 0.6196 - val_keras_r2: 0.2274\n",
            "Epoch 45/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8087 - keras_r2: 0.0080 - val_loss: 0.6093 - val_keras_r2: 0.2401\n",
            "Epoch 46/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.8015 - keras_r2: 0.0281 - val_loss: 0.6144 - val_keras_r2: 0.2336\n",
            "Epoch 47/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7998 - keras_r2: 0.0236 - val_loss: 0.6142 - val_keras_r2: 0.2339\n",
            "Epoch 48/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7803 - keras_r2: 0.0476 - val_loss: 0.6170 - val_keras_r2: 0.2324\n",
            "Epoch 49/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7811 - keras_r2: 0.0451 - val_loss: 0.6129 - val_keras_r2: 0.2336\n",
            "Epoch 50/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7749 - keras_r2: 0.0635 - val_loss: 0.6112 - val_keras_r2: 0.2367\n",
            "Epoch 51/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7601 - keras_r2: 0.0710 - val_loss: 0.6206 - val_keras_r2: 0.2243\n",
            "Epoch 52/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7546 - keras_r2: 0.0844 - val_loss: 0.6147 - val_keras_r2: 0.2289\n",
            "Epoch 53/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7429 - keras_r2: 0.0902 - val_loss: 0.6152 - val_keras_r2: 0.2256\n",
            "Epoch 54/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7374 - keras_r2: 0.1024 - val_loss: 0.6141 - val_keras_r2: 0.2327\n",
            "Epoch 55/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7475 - keras_r2: 0.0841 - val_loss: 0.6098 - val_keras_r2: 0.2421\n",
            "Epoch 56/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7365 - keras_r2: 0.1044 - val_loss: 0.6094 - val_keras_r2: 0.2404\n",
            "Epoch 57/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7320 - keras_r2: 0.1059 - val_loss: 0.6031 - val_keras_r2: 0.2494\n",
            "Epoch 58/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7259 - keras_r2: 0.1183 - val_loss: 0.6018 - val_keras_r2: 0.2512\n",
            "Epoch 59/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7187 - keras_r2: 0.1284 - val_loss: 0.6067 - val_keras_r2: 0.2456\n",
            "Epoch 60/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7143 - keras_r2: 0.1270 - val_loss: 0.6055 - val_keras_r2: 0.2445\n",
            "Epoch 61/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.7164 - keras_r2: 0.1322 - val_loss: 0.6081 - val_keras_r2: 0.2373\n",
            "Epoch 62/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7145 - keras_r2: 0.1304 - val_loss: 0.6058 - val_keras_r2: 0.2434\n",
            "Epoch 63/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7027 - keras_r2: 0.1495 - val_loss: 0.6054 - val_keras_r2: 0.2423\n",
            "Epoch 64/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.7112 - keras_r2: 0.1410 - val_loss: 0.5970 - val_keras_r2: 0.2525\n",
            "Epoch 65/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6922 - keras_r2: 0.1590 - val_loss: 0.5984 - val_keras_r2: 0.2510\n",
            "Epoch 66/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6928 - keras_r2: 0.1567 - val_loss: 0.5997 - val_keras_r2: 0.2504\n",
            "Epoch 67/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6978 - keras_r2: 0.1522 - val_loss: 0.6044 - val_keras_r2: 0.2433\n",
            "Epoch 68/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6844 - keras_r2: 0.1663 - val_loss: 0.6062 - val_keras_r2: 0.2429\n",
            "Epoch 69/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6897 - keras_r2: 0.1579 - val_loss: 0.6006 - val_keras_r2: 0.2494\n",
            "Epoch 70/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6792 - keras_r2: 0.1697 - val_loss: 0.5996 - val_keras_r2: 0.2459\n",
            "Epoch 71/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6753 - keras_r2: 0.1863 - val_loss: 0.6066 - val_keras_r2: 0.2403\n",
            "Epoch 72/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6727 - keras_r2: 0.1916 - val_loss: 0.5996 - val_keras_r2: 0.2482\n",
            "Epoch 73/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6742 - keras_r2: 0.1858 - val_loss: 0.5990 - val_keras_r2: 0.2465\n",
            "Epoch 74/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6673 - keras_r2: 0.1850 - val_loss: 0.6020 - val_keras_r2: 0.2464\n",
            "Epoch 75/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6752 - keras_r2: 0.1871 - val_loss: 0.6019 - val_keras_r2: 0.2486\n",
            "Epoch 76/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6770 - keras_r2: 0.1751 - val_loss: 0.6022 - val_keras_r2: 0.2455\n",
            "Epoch 77/300\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 0.6610 - keras_r2: 0.2003 - val_loss: 0.5957 - val_keras_r2: 0.2575\n",
            "Epoch 78/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6648 - keras_r2: 0.2005 - val_loss: 0.5938 - val_keras_r2: 0.2547\n",
            "Epoch 79/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6609 - keras_r2: 0.2019 - val_loss: 0.6011 - val_keras_r2: 0.2487\n",
            "Epoch 80/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6660 - keras_r2: 0.1922 - val_loss: 0.5983 - val_keras_r2: 0.2530\n",
            "Epoch 81/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6604 - keras_r2: 0.2026 - val_loss: 0.5980 - val_keras_r2: 0.2532\n",
            "Epoch 82/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6520 - keras_r2: 0.2059 - val_loss: 0.6017 - val_keras_r2: 0.2460\n",
            "Epoch 83/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6498 - keras_r2: 0.2169 - val_loss: 0.5943 - val_keras_r2: 0.2557\n",
            "Epoch 84/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6518 - keras_r2: 0.2095 - val_loss: 0.5973 - val_keras_r2: 0.2514\n",
            "Epoch 85/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6534 - keras_r2: 0.2079 - val_loss: 0.5985 - val_keras_r2: 0.2495\n",
            "Epoch 86/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6497 - keras_r2: 0.2154 - val_loss: 0.5990 - val_keras_r2: 0.2491\n",
            "Epoch 87/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6449 - keras_r2: 0.2181 - val_loss: 0.5962 - val_keras_r2: 0.2533\n",
            "Epoch 88/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6416 - keras_r2: 0.2236 - val_loss: 0.5962 - val_keras_r2: 0.2529\n",
            "Epoch 89/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6382 - keras_r2: 0.2334 - val_loss: 0.5968 - val_keras_r2: 0.2500\n",
            "Epoch 90/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6300 - keras_r2: 0.2388 - val_loss: 0.5909 - val_keras_r2: 0.2587\n",
            "Epoch 91/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6409 - keras_r2: 0.2234 - val_loss: 0.5953 - val_keras_r2: 0.2503\n",
            "Epoch 92/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6344 - keras_r2: 0.2299 - val_loss: 0.5906 - val_keras_r2: 0.2598\n",
            "Epoch 93/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6409 - keras_r2: 0.2244 - val_loss: 0.5938 - val_keras_r2: 0.2520\n",
            "Epoch 94/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6361 - keras_r2: 0.2308 - val_loss: 0.5964 - val_keras_r2: 0.2520\n",
            "Epoch 95/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6367 - keras_r2: 0.2367 - val_loss: 0.5997 - val_keras_r2: 0.2478\n",
            "Epoch 96/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6416 - keras_r2: 0.2229 - val_loss: 0.5967 - val_keras_r2: 0.2544\n",
            "Epoch 97/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6363 - keras_r2: 0.2302 - val_loss: 0.5941 - val_keras_r2: 0.2527\n",
            "Epoch 98/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6307 - keras_r2: 0.2259 - val_loss: 0.5915 - val_keras_r2: 0.2570\n",
            "Epoch 99/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6347 - keras_r2: 0.2330 - val_loss: 0.5980 - val_keras_r2: 0.2525\n",
            "Epoch 100/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6289 - keras_r2: 0.2423 - val_loss: 0.5952 - val_keras_r2: 0.2521\n",
            "Epoch 101/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6236 - keras_r2: 0.2447 - val_loss: 0.5954 - val_keras_r2: 0.2542\n",
            "Epoch 102/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6298 - keras_r2: 0.2435 - val_loss: 0.5885 - val_keras_r2: 0.2581\n",
            "Epoch 103/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6248 - keras_r2: 0.2446 - val_loss: 0.5915 - val_keras_r2: 0.2562\n",
            "Epoch 104/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6295 - keras_r2: 0.2322 - val_loss: 0.5902 - val_keras_r2: 0.2586\n",
            "Epoch 105/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6215 - keras_r2: 0.2552 - val_loss: 0.5906 - val_keras_r2: 0.2609\n",
            "Epoch 106/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6291 - keras_r2: 0.2387 - val_loss: 0.5943 - val_keras_r2: 0.2516\n",
            "Epoch 107/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6183 - keras_r2: 0.2547 - val_loss: 0.5891 - val_keras_r2: 0.2576\n",
            "Epoch 108/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6230 - keras_r2: 0.2489 - val_loss: 0.5916 - val_keras_r2: 0.2568\n",
            "Epoch 109/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6213 - keras_r2: 0.2476 - val_loss: 0.5914 - val_keras_r2: 0.2589\n",
            "Epoch 110/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6207 - keras_r2: 0.2588 - val_loss: 0.5872 - val_keras_r2: 0.2614\n",
            "Epoch 111/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6219 - keras_r2: 0.2507 - val_loss: 0.5893 - val_keras_r2: 0.2600\n",
            "Epoch 112/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6170 - keras_r2: 0.2627 - val_loss: 0.5969 - val_keras_r2: 0.2471\n",
            "Epoch 113/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6207 - keras_r2: 0.2454 - val_loss: 0.5906 - val_keras_r2: 0.2566\n",
            "Epoch 114/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6149 - keras_r2: 0.2544 - val_loss: 0.5911 - val_keras_r2: 0.2549\n",
            "Epoch 115/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6115 - keras_r2: 0.2650 - val_loss: 0.5948 - val_keras_r2: 0.2541\n",
            "Epoch 116/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6223 - keras_r2: 0.2501 - val_loss: 0.5886 - val_keras_r2: 0.2571\n",
            "Epoch 117/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6191 - keras_r2: 0.2476 - val_loss: 0.5874 - val_keras_r2: 0.2618\n",
            "Epoch 118/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6185 - keras_r2: 0.2495 - val_loss: 0.5918 - val_keras_r2: 0.2555\n",
            "Epoch 119/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6120 - keras_r2: 0.2595 - val_loss: 0.5884 - val_keras_r2: 0.2617\n",
            "Epoch 120/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6117 - keras_r2: 0.2566 - val_loss: 0.5934 - val_keras_r2: 0.2539\n",
            "Epoch 121/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6159 - keras_r2: 0.2581 - val_loss: 0.5879 - val_keras_r2: 0.2589\n",
            "Epoch 122/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6124 - keras_r2: 0.2581 - val_loss: 0.5890 - val_keras_r2: 0.2594\n",
            "Epoch 123/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6154 - keras_r2: 0.2564 - val_loss: 0.5918 - val_keras_r2: 0.2574\n",
            "Epoch 124/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6171 - keras_r2: 0.2580 - val_loss: 0.5884 - val_keras_r2: 0.2601\n",
            "Epoch 125/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6099 - keras_r2: 0.2678 - val_loss: 0.5909 - val_keras_r2: 0.2532\n",
            "Epoch 126/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6101 - keras_r2: 0.2610 - val_loss: 0.5898 - val_keras_r2: 0.2577\n",
            "Epoch 127/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6111 - keras_r2: 0.2651 - val_loss: 0.5882 - val_keras_r2: 0.2631\n",
            "Epoch 128/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6079 - keras_r2: 0.2664 - val_loss: 0.5874 - val_keras_r2: 0.2587\n",
            "Epoch 129/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6043 - keras_r2: 0.2718 - val_loss: 0.5875 - val_keras_r2: 0.2614\n",
            "Epoch 130/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6147 - keras_r2: 0.2538 - val_loss: 0.5906 - val_keras_r2: 0.2581\n",
            "Epoch 131/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6050 - keras_r2: 0.2620 - val_loss: 0.5875 - val_keras_r2: 0.2606\n",
            "Epoch 132/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6043 - keras_r2: 0.2672 - val_loss: 0.5941 - val_keras_r2: 0.2519\n",
            "Epoch 133/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5979 - keras_r2: 0.2793 - val_loss: 0.5867 - val_keras_r2: 0.2609\n",
            "Epoch 134/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6024 - keras_r2: 0.2687 - val_loss: 0.5925 - val_keras_r2: 0.2480\n",
            "Epoch 135/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6037 - keras_r2: 0.2772 - val_loss: 0.5857 - val_keras_r2: 0.2606\n",
            "Epoch 136/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5965 - keras_r2: 0.2769 - val_loss: 0.5926 - val_keras_r2: 0.2547\n",
            "Epoch 137/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6038 - keras_r2: 0.2648 - val_loss: 0.5855 - val_keras_r2: 0.2619\n",
            "Epoch 138/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6061 - keras_r2: 0.2615 - val_loss: 0.5901 - val_keras_r2: 0.2546\n",
            "Epoch 139/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6013 - keras_r2: 0.2727 - val_loss: 0.5864 - val_keras_r2: 0.2600\n",
            "Epoch 140/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6008 - keras_r2: 0.2709 - val_loss: 0.5898 - val_keras_r2: 0.2542\n",
            "Epoch 141/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6082 - keras_r2: 0.2612 - val_loss: 0.5869 - val_keras_r2: 0.2625\n",
            "Epoch 142/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6034 - keras_r2: 0.2765 - val_loss: 0.5949 - val_keras_r2: 0.2456\n",
            "Epoch 143/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6004 - keras_r2: 0.2722 - val_loss: 0.5861 - val_keras_r2: 0.2639\n",
            "Epoch 144/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5964 - keras_r2: 0.2834 - val_loss: 0.5868 - val_keras_r2: 0.2608\n",
            "Epoch 145/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5964 - keras_r2: 0.2764 - val_loss: 0.5871 - val_keras_r2: 0.2586\n",
            "Epoch 146/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5942 - keras_r2: 0.2815 - val_loss: 0.5850 - val_keras_r2: 0.2612\n",
            "Epoch 147/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6026 - keras_r2: 0.2719 - val_loss: 0.5864 - val_keras_r2: 0.2615\n",
            "Epoch 148/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6061 - keras_r2: 0.2618 - val_loss: 0.5928 - val_keras_r2: 0.2550\n",
            "Epoch 149/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.6031 - keras_r2: 0.2745 - val_loss: 0.5874 - val_keras_r2: 0.2605\n",
            "Epoch 150/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6053 - keras_r2: 0.2694 - val_loss: 0.5821 - val_keras_r2: 0.2624\n",
            "Epoch 151/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5916 - keras_r2: 0.2882 - val_loss: 0.5821 - val_keras_r2: 0.2659\n",
            "Epoch 152/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.6013 - keras_r2: 0.2707 - val_loss: 0.5915 - val_keras_r2: 0.2529\n",
            "Epoch 153/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5914 - keras_r2: 0.2905 - val_loss: 0.5883 - val_keras_r2: 0.2607\n",
            "Epoch 154/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5968 - keras_r2: 0.2750 - val_loss: 0.5901 - val_keras_r2: 0.2530\n",
            "Epoch 155/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5939 - keras_r2: 0.2818 - val_loss: 0.5857 - val_keras_r2: 0.2634\n",
            "Epoch 156/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5911 - keras_r2: 0.2876 - val_loss: 0.5843 - val_keras_r2: 0.2639\n",
            "Epoch 157/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5912 - keras_r2: 0.2883 - val_loss: 0.5842 - val_keras_r2: 0.2651\n",
            "Epoch 158/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5966 - keras_r2: 0.2783 - val_loss: 0.5862 - val_keras_r2: 0.2629\n",
            "Epoch 159/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.5945 - keras_r2: 0.2795 - val_loss: 0.5918 - val_keras_r2: 0.2521\n",
            "Epoch 160/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5899 - keras_r2: 0.2789 - val_loss: 0.5872 - val_keras_r2: 0.2592\n",
            "Epoch 161/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5988 - keras_r2: 0.2792 - val_loss: 0.5925 - val_keras_r2: 0.2519\n",
            "Epoch 162/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5937 - keras_r2: 0.2798 - val_loss: 0.5880 - val_keras_r2: 0.2580\n",
            "Epoch 163/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5914 - keras_r2: 0.2821 - val_loss: 0.5913 - val_keras_r2: 0.2534\n",
            "Epoch 164/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5878 - keras_r2: 0.2893 - val_loss: 0.5840 - val_keras_r2: 0.2629\n",
            "Epoch 165/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.5932 - keras_r2: 0.2820 - val_loss: 0.5900 - val_keras_r2: 0.2536\n",
            "Epoch 166/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5928 - keras_r2: 0.2821 - val_loss: 0.5854 - val_keras_r2: 0.2613\n",
            "Epoch 167/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5922 - keras_r2: 0.2873 - val_loss: 0.5854 - val_keras_r2: 0.2609\n",
            "Epoch 168/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5945 - keras_r2: 0.2814 - val_loss: 0.5856 - val_keras_r2: 0.2591\n",
            "Epoch 169/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5798 - keras_r2: 0.2938 - val_loss: 0.5816 - val_keras_r2: 0.2669\n",
            "Epoch 170/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5846 - keras_r2: 0.2867 - val_loss: 0.5914 - val_keras_r2: 0.2490\n",
            "Epoch 171/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5848 - keras_r2: 0.2954 - val_loss: 0.5887 - val_keras_r2: 0.2549\n",
            "Epoch 172/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5919 - keras_r2: 0.2882 - val_loss: 0.5834 - val_keras_r2: 0.2648\n",
            "Epoch 173/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5857 - keras_r2: 0.2940 - val_loss: 0.5895 - val_keras_r2: 0.2559\n",
            "Epoch 174/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5893 - keras_r2: 0.2821 - val_loss: 0.5900 - val_keras_r2: 0.2591\n",
            "Epoch 175/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5869 - keras_r2: 0.2909 - val_loss: 0.5837 - val_keras_r2: 0.2614\n",
            "Epoch 176/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5896 - keras_r2: 0.2822 - val_loss: 0.5936 - val_keras_r2: 0.2489\n",
            "Epoch 177/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5819 - keras_r2: 0.2958 - val_loss: 0.5909 - val_keras_r2: 0.2556\n",
            "Epoch 178/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5843 - keras_r2: 0.2983 - val_loss: 0.5941 - val_keras_r2: 0.2510\n",
            "Epoch 179/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5848 - keras_r2: 0.2918 - val_loss: 0.5894 - val_keras_r2: 0.2585\n",
            "Epoch 180/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.5911 - keras_r2: 0.2847 - val_loss: 0.5871 - val_keras_r2: 0.2600\n",
            "Epoch 181/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5763 - keras_r2: 0.3089 - val_loss: 0.5814 - val_keras_r2: 0.2651\n",
            "Epoch 182/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5814 - keras_r2: 0.2987 - val_loss: 0.5914 - val_keras_r2: 0.2510\n",
            "Epoch 183/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5838 - keras_r2: 0.2903 - val_loss: 0.5896 - val_keras_r2: 0.2557\n",
            "Epoch 184/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5781 - keras_r2: 0.3041 - val_loss: 0.5913 - val_keras_r2: 0.2544\n",
            "Epoch 185/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5808 - keras_r2: 0.2952 - val_loss: 0.5861 - val_keras_r2: 0.2588\n",
            "Epoch 186/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5915 - keras_r2: 0.2816 - val_loss: 0.5933 - val_keras_r2: 0.2466\n",
            "Epoch 187/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5836 - keras_r2: 0.2891 - val_loss: 0.5912 - val_keras_r2: 0.2487\n",
            "Epoch 188/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5847 - keras_r2: 0.2901 - val_loss: 0.5925 - val_keras_r2: 0.2468\n",
            "Epoch 189/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5833 - keras_r2: 0.2925 - val_loss: 0.5906 - val_keras_r2: 0.2545\n",
            "Epoch 190/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5790 - keras_r2: 0.2969 - val_loss: 0.5807 - val_keras_r2: 0.2661\n",
            "Epoch 191/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5767 - keras_r2: 0.3002 - val_loss: 0.5897 - val_keras_r2: 0.2509\n",
            "Epoch 192/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5793 - keras_r2: 0.2960 - val_loss: 0.5855 - val_keras_r2: 0.2538\n",
            "Epoch 193/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5803 - keras_r2: 0.2897 - val_loss: 0.5884 - val_keras_r2: 0.2528\n",
            "Epoch 194/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5774 - keras_r2: 0.2989 - val_loss: 0.5926 - val_keras_r2: 0.2531\n",
            "Epoch 195/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5814 - keras_r2: 0.2946 - val_loss: 0.5891 - val_keras_r2: 0.2549\n",
            "Epoch 196/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5805 - keras_r2: 0.2915 - val_loss: 0.5854 - val_keras_r2: 0.2571\n",
            "Epoch 197/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5804 - keras_r2: 0.3001 - val_loss: 0.5850 - val_keras_r2: 0.2591\n",
            "Epoch 198/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5830 - keras_r2: 0.2947 - val_loss: 0.5953 - val_keras_r2: 0.2485\n",
            "Epoch 199/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5768 - keras_r2: 0.2982 - val_loss: 0.5830 - val_keras_r2: 0.2615\n",
            "Epoch 200/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5762 - keras_r2: 0.3104 - val_loss: 0.5860 - val_keras_r2: 0.2562\n",
            "Epoch 201/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5754 - keras_r2: 0.3015 - val_loss: 0.5778 - val_keras_r2: 0.2698\n",
            "Epoch 202/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5840 - keras_r2: 0.2967 - val_loss: 0.5878 - val_keras_r2: 0.2552\n",
            "Epoch 203/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5758 - keras_r2: 0.3035 - val_loss: 0.5816 - val_keras_r2: 0.2623\n",
            "Epoch 204/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5745 - keras_r2: 0.3070 - val_loss: 0.5904 - val_keras_r2: 0.2505\n",
            "Epoch 205/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5795 - keras_r2: 0.2848 - val_loss: 0.5855 - val_keras_r2: 0.2615\n",
            "Epoch 206/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5731 - keras_r2: 0.3039 - val_loss: 0.5834 - val_keras_r2: 0.2595\n",
            "Epoch 207/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5756 - keras_r2: 0.3066 - val_loss: 0.5828 - val_keras_r2: 0.2599\n",
            "Epoch 208/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5775 - keras_r2: 0.2947 - val_loss: 0.5907 - val_keras_r2: 0.2518\n",
            "Epoch 209/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5793 - keras_r2: 0.2986 - val_loss: 0.5883 - val_keras_r2: 0.2549\n",
            "Epoch 210/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5747 - keras_r2: 0.3040 - val_loss: 0.5895 - val_keras_r2: 0.2550\n",
            "Epoch 211/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5747 - keras_r2: 0.3042 - val_loss: 0.5828 - val_keras_r2: 0.2607\n",
            "Epoch 212/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5697 - keras_r2: 0.3104 - val_loss: 0.5894 - val_keras_r2: 0.2526\n",
            "Epoch 213/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5759 - keras_r2: 0.2998 - val_loss: 0.5816 - val_keras_r2: 0.2633\n",
            "Epoch 214/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5784 - keras_r2: 0.2993 - val_loss: 0.5828 - val_keras_r2: 0.2632\n",
            "Epoch 215/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5730 - keras_r2: 0.3022 - val_loss: 0.5862 - val_keras_r2: 0.2579\n",
            "Epoch 216/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5703 - keras_r2: 0.3043 - val_loss: 0.5815 - val_keras_r2: 0.2576\n",
            "Epoch 217/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5736 - keras_r2: 0.3012 - val_loss: 0.5862 - val_keras_r2: 0.2547\n",
            "Epoch 218/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5724 - keras_r2: 0.3058 - val_loss: 0.5839 - val_keras_r2: 0.2601\n",
            "Epoch 219/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5747 - keras_r2: 0.2998 - val_loss: 0.5831 - val_keras_r2: 0.2666\n",
            "Epoch 220/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5741 - keras_r2: 0.3035 - val_loss: 0.5830 - val_keras_r2: 0.2591\n",
            "Epoch 221/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5662 - keras_r2: 0.3162 - val_loss: 0.5847 - val_keras_r2: 0.2569\n",
            "Epoch 222/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5755 - keras_r2: 0.3036 - val_loss: 0.5839 - val_keras_r2: 0.2631\n",
            "Epoch 223/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5713 - keras_r2: 0.3100 - val_loss: 0.5893 - val_keras_r2: 0.2526\n",
            "Epoch 224/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5710 - keras_r2: 0.3024 - val_loss: 0.5874 - val_keras_r2: 0.2545\n",
            "Epoch 225/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5695 - keras_r2: 0.3137 - val_loss: 0.5948 - val_keras_r2: 0.2422\n",
            "Epoch 226/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5625 - keras_r2: 0.3203 - val_loss: 0.5846 - val_keras_r2: 0.2608\n",
            "Epoch 227/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5714 - keras_r2: 0.3102 - val_loss: 0.5877 - val_keras_r2: 0.2494\n",
            "Epoch 228/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5657 - keras_r2: 0.3158 - val_loss: 0.5867 - val_keras_r2: 0.2521\n",
            "Epoch 229/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5635 - keras_r2: 0.3180 - val_loss: 0.5835 - val_keras_r2: 0.2558\n",
            "Epoch 230/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5680 - keras_r2: 0.3108 - val_loss: 0.5801 - val_keras_r2: 0.2673\n",
            "Epoch 231/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5664 - keras_r2: 0.3150 - val_loss: 0.5922 - val_keras_r2: 0.2429\n",
            "Epoch 232/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.5638 - keras_r2: 0.3150 - val_loss: 0.5839 - val_keras_r2: 0.2576\n",
            "Epoch 233/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5662 - keras_r2: 0.3127 - val_loss: 0.5864 - val_keras_r2: 0.2534\n",
            "Epoch 234/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5627 - keras_r2: 0.3081 - val_loss: 0.5869 - val_keras_r2: 0.2465\n",
            "Epoch 235/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5739 - keras_r2: 0.2996 - val_loss: 0.5847 - val_keras_r2: 0.2577\n",
            "Epoch 236/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5642 - keras_r2: 0.3153 - val_loss: 0.5868 - val_keras_r2: 0.2519\n",
            "Epoch 237/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5665 - keras_r2: 0.3032 - val_loss: 0.5842 - val_keras_r2: 0.2584\n",
            "Epoch 238/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5632 - keras_r2: 0.3199 - val_loss: 0.5916 - val_keras_r2: 0.2435\n",
            "Epoch 239/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5712 - keras_r2: 0.3044 - val_loss: 0.5894 - val_keras_r2: 0.2430\n",
            "Epoch 240/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5623 - keras_r2: 0.3119 - val_loss: 0.5809 - val_keras_r2: 0.2602\n",
            "Epoch 241/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5726 - keras_r2: 0.2966 - val_loss: 0.5838 - val_keras_r2: 0.2611\n",
            "Epoch 242/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5676 - keras_r2: 0.3127 - val_loss: 0.5827 - val_keras_r2: 0.2606\n",
            "Epoch 243/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5657 - keras_r2: 0.3133 - val_loss: 0.5834 - val_keras_r2: 0.2558\n",
            "Epoch 244/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5640 - keras_r2: 0.3195 - val_loss: 0.5861 - val_keras_r2: 0.2535\n",
            "Epoch 245/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5683 - keras_r2: 0.3105 - val_loss: 0.5906 - val_keras_r2: 0.2489\n",
            "Epoch 246/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5641 - keras_r2: 0.3224 - val_loss: 0.5924 - val_keras_r2: 0.2447\n",
            "Epoch 247/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5612 - keras_r2: 0.3104 - val_loss: 0.5887 - val_keras_r2: 0.2516\n",
            "Epoch 248/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5660 - keras_r2: 0.3160 - val_loss: 0.5825 - val_keras_r2: 0.2592\n",
            "Epoch 249/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5642 - keras_r2: 0.3071 - val_loss: 0.5919 - val_keras_r2: 0.2432\n",
            "Epoch 250/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5612 - keras_r2: 0.3192 - val_loss: 0.5902 - val_keras_r2: 0.2484\n",
            "Epoch 251/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.5661 - keras_r2: 0.3099 - val_loss: 0.5897 - val_keras_r2: 0.2485\n",
            "Epoch 252/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5687 - keras_r2: 0.3046 - val_loss: 0.5924 - val_keras_r2: 0.2446\n",
            "Epoch 253/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5576 - keras_r2: 0.3233 - val_loss: 0.5901 - val_keras_r2: 0.2537\n",
            "Epoch 254/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5577 - keras_r2: 0.3220 - val_loss: 0.5852 - val_keras_r2: 0.2570\n",
            "Epoch 255/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5584 - keras_r2: 0.3220 - val_loss: 0.5867 - val_keras_r2: 0.2541\n",
            "Epoch 256/300\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 0.5623 - keras_r2: 0.3142 - val_loss: 0.5816 - val_keras_r2: 0.2634\n",
            "Epoch 257/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5606 - keras_r2: 0.3238 - val_loss: 0.5871 - val_keras_r2: 0.2524\n",
            "Epoch 258/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5636 - keras_r2: 0.3120 - val_loss: 0.5853 - val_keras_r2: 0.2585\n",
            "Epoch 259/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5586 - keras_r2: 0.3227 - val_loss: 0.5812 - val_keras_r2: 0.2635\n",
            "Epoch 260/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5619 - keras_r2: 0.3211 - val_loss: 0.5851 - val_keras_r2: 0.2554\n",
            "Epoch 261/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5657 - keras_r2: 0.3130 - val_loss: 0.5887 - val_keras_r2: 0.2507\n",
            "Epoch 262/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5658 - keras_r2: 0.3157 - val_loss: 0.5829 - val_keras_r2: 0.2645\n",
            "Epoch 263/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5663 - keras_r2: 0.3108 - val_loss: 0.5865 - val_keras_r2: 0.2537\n",
            "Epoch 264/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5534 - keras_r2: 0.3272 - val_loss: 0.5862 - val_keras_r2: 0.2508\n",
            "Epoch 265/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5627 - keras_r2: 0.3171 - val_loss: 0.5880 - val_keras_r2: 0.2565\n",
            "Epoch 266/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5536 - keras_r2: 0.3289 - val_loss: 0.5954 - val_keras_r2: 0.2412\n",
            "Epoch 267/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5596 - keras_r2: 0.3231 - val_loss: 0.5874 - val_keras_r2: 0.2544\n",
            "Epoch 268/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5579 - keras_r2: 0.3257 - val_loss: 0.5874 - val_keras_r2: 0.2539\n",
            "Epoch 269/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5550 - keras_r2: 0.3229 - val_loss: 0.5885 - val_keras_r2: 0.2516\n",
            "Epoch 270/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5600 - keras_r2: 0.3125 - val_loss: 0.5845 - val_keras_r2: 0.2613\n",
            "Epoch 271/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5516 - keras_r2: 0.3305 - val_loss: 0.5955 - val_keras_r2: 0.2479\n",
            "Epoch 272/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5558 - keras_r2: 0.3235 - val_loss: 0.5964 - val_keras_r2: 0.2461\n",
            "Epoch 273/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5550 - keras_r2: 0.3234 - val_loss: 0.5885 - val_keras_r2: 0.2538\n",
            "Epoch 274/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5575 - keras_r2: 0.3234 - val_loss: 0.5864 - val_keras_r2: 0.2598\n",
            "Epoch 275/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5585 - keras_r2: 0.3162 - val_loss: 0.5924 - val_keras_r2: 0.2511\n",
            "Epoch 276/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5493 - keras_r2: 0.3345 - val_loss: 0.5935 - val_keras_r2: 0.2483\n",
            "Epoch 277/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5584 - keras_r2: 0.3246 - val_loss: 0.5825 - val_keras_r2: 0.2602\n",
            "Epoch 278/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5543 - keras_r2: 0.3204 - val_loss: 0.5920 - val_keras_r2: 0.2416\n",
            "Epoch 279/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5510 - keras_r2: 0.3345 - val_loss: 0.5939 - val_keras_r2: 0.2471\n",
            "Epoch 280/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5470 - keras_r2: 0.3335 - val_loss: 0.5905 - val_keras_r2: 0.2494\n",
            "Epoch 281/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5467 - keras_r2: 0.3338 - val_loss: 0.5888 - val_keras_r2: 0.2532\n",
            "Epoch 282/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5578 - keras_r2: 0.3262 - val_loss: 0.6004 - val_keras_r2: 0.2327\n",
            "Epoch 283/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5545 - keras_r2: 0.3228 - val_loss: 0.5922 - val_keras_r2: 0.2504\n",
            "Epoch 284/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5506 - keras_r2: 0.3252 - val_loss: 0.5917 - val_keras_r2: 0.2471\n",
            "Epoch 285/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5587 - keras_r2: 0.3155 - val_loss: 0.5953 - val_keras_r2: 0.2379\n",
            "Epoch 286/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5628 - keras_r2: 0.3104 - val_loss: 0.5871 - val_keras_r2: 0.2507\n",
            "Epoch 287/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5546 - keras_r2: 0.3271 - val_loss: 0.5838 - val_keras_r2: 0.2559\n",
            "Epoch 288/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5549 - keras_r2: 0.3217 - val_loss: 0.5844 - val_keras_r2: 0.2574\n",
            "Epoch 289/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5565 - keras_r2: 0.3206 - val_loss: 0.5889 - val_keras_r2: 0.2529\n",
            "Epoch 290/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5534 - keras_r2: 0.3244 - val_loss: 0.5882 - val_keras_r2: 0.2522\n",
            "Epoch 291/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5507 - keras_r2: 0.3225 - val_loss: 0.5844 - val_keras_r2: 0.2581\n",
            "Epoch 292/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5505 - keras_r2: 0.3347 - val_loss: 0.5888 - val_keras_r2: 0.2471\n",
            "Epoch 293/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5586 - keras_r2: 0.3211 - val_loss: 0.5881 - val_keras_r2: 0.2491\n",
            "Epoch 294/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5491 - keras_r2: 0.3390 - val_loss: 0.5877 - val_keras_r2: 0.2527\n",
            "Epoch 295/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5608 - keras_r2: 0.3211 - val_loss: 0.5882 - val_keras_r2: 0.2533\n",
            "Epoch 296/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5405 - keras_r2: 0.3480 - val_loss: 0.5931 - val_keras_r2: 0.2461\n",
            "Epoch 297/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5464 - keras_r2: 0.3392 - val_loss: 0.5889 - val_keras_r2: 0.2481\n",
            "Epoch 298/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5539 - keras_r2: 0.3251 - val_loss: 0.5812 - val_keras_r2: 0.2627\n",
            "Epoch 299/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5517 - keras_r2: 0.3319 - val_loss: 0.5871 - val_keras_r2: 0.2527\n",
            "Epoch 300/300\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 0.5477 - keras_r2: 0.3303 - val_loss: 0.5869 - val_keras_r2: 0.2543\n"
          ]
        }
      ],
      "source": [
        "# history_4 = model_4.fit(X_train_keras, y_train, validation_data=(\n",
        "#     X_test_keras, y_test), batch_size=32, epochs=100, callbacks=[EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)])\n",
        "history_4 = model_4.fit(X_train_keras, y_train, validation_data=(\n",
        "    X_test_keras, y_test), batch_size=32, epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5869 - keras_r2: 0.2543\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5868998765945435, 0.25427451729774475]"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_4.evaluate(X_test_keras, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.ylim(ymin=0, ymax=1)\n",
        "\n",
        "plt.plot(history_4.history['loss'], label=\"loss\")\n",
        "plt.plot(history_4.history['val_loss'], label=\"val_loss \")\n",
        "\n",
        "plt.plot(history_4.history['keras_r2'], label=\"r2\")\n",
        "plt.plot(history_4.history['val_keras_r2'], label=\"val_r2\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "W odróżnieniu od pozostałych modeli głębokich, dane tutaj zostały dobrane ręcznie. Oznacza to, że nie było ograniczenia co do tego, że w każdej warstwie ukrytej musi być tyle samo neuronów.\n",
        "\n",
        "Podobnie jak w przypadku poprzedniego modelu krzywe oscylują (jest to bardziej wyraźne, ze względu na mniejszą ilość epok), ale dalej da się zauważyć trend (przedewszystkim przy treningu, ale również przy walidacji) gdzie `r^2` rośnie, podczas gdy `loss` maleje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYjFAVQ3y5uN"
      },
      "source": [
        "**Porównanie modeli głębokich**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "KaKMJK1Ty_s9",
        "outputId": "800c49ca-f8f7-43ff-b342-7d08459fbc67"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model name</th>\n",
              "      <th>test score (r2)</th>\n",
              "      <th>test score (mean squared error)</th>\n",
              "      <th>test score (max error)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Podstawowa (wczesne zatrzymanie)</td>\n",
              "      <td>0.245594</td>\n",
              "      <td>0.626892</td>\n",
              "      <td>4.577204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Podstawowa z dobraną funkcją aktywacji (wczesn...</td>\n",
              "      <td>0.263892</td>\n",
              "      <td>0.611687</td>\n",
              "      <td>4.182799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Z Batch Normalization i Dropout (1000 epok)</td>\n",
              "      <td>0.267076</td>\n",
              "      <td>0.609041</td>\n",
              "      <td>4.237071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dobrane ręcznie parametry (300 epok)</td>\n",
              "      <td>0.293721</td>\n",
              "      <td>0.586900</td>\n",
              "      <td>3.259960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          model name  test score (r2)  \\\n",
              "0                   Podstawowa (wczesne zatrzymanie)         0.245594   \n",
              "1  Podstawowa z dobraną funkcją aktywacji (wczesn...         0.263892   \n",
              "2        Z Batch Normalization i Dropout (1000 epok)         0.267076   \n",
              "3               Dobrane ręcznie parametry (300 epok)         0.293721   \n",
              "\n",
              "   test score (mean squared error)  test score (max error)  \n",
              "0                         0.626892                4.577204  \n",
              "1                         0.611687                4.182799  \n",
              "2                         0.609041                4.237071  \n",
              "3                         0.586900                3.259960  "
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, max_error\n",
        "\n",
        "models = []\n",
        "\n",
        "models.append((\"Podstawowa (wczesne zatrzymanie)\", model_1))\n",
        "models.append((\"Podstawowa z dobraną funkcją aktywacji (wczesne zatrzymanie)\", model_2))\n",
        "models.append((\"Z Batch Normalization i Dropout (1000 epok)\", model_3))\n",
        "models.append((\"Dobrane ręcznie parametry (300 epok)\", model_4))\n",
        "\n",
        "names = []\n",
        "scores_test_r2 = []\n",
        "scores_test_mse = []\n",
        "scores_test_me = []\n",
        "\n",
        "for name, estimator in models:\n",
        "    names.append(name)\n",
        "\n",
        "    r2_test_score = r2_score(y_test, estimator.predict(X_test_keras))\n",
        "    scores_test_r2.append(r2_test_score)\n",
        "\n",
        "    mse_test_score = mean_squared_error(y_test, estimator.predict(X_test_keras))\n",
        "    scores_test_mse.append(mse_test_score)\n",
        "\n",
        "    me_test_score = max_error(y_test, estimator.predict(X_test_keras))\n",
        "    scores_test_me.append(me_test_score)\n",
        "\n",
        "\n",
        "model_data = {\n",
        "    \"model name\": names,\n",
        "    \"test score (r2)\": scores_test_r2,\n",
        "    \"test score (mean squared error)\": scores_test_mse,\n",
        "    \"test score (max error)\": scores_test_me\n",
        "}\n",
        "table = pd.DataFrame(model_data)\n",
        "table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prawdziwy rozkład\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Podstawowa (wczesne zatrzymanie)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFlCAYAAADlICPeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAARt0lEQVR4nO3df6ydB13H8feHzqogQXRXxLajjamSBqbD60RJlMAwXWZaDIpdggGjNkaqE4jaqZlm/jPRIPzRGJoxJQqUOYlepToNaIhGlt7JArZz0NRJbwV3+W00MApf/7hn9nC57T333nPvuf3e9ytpdp7nPOecb062954+5zzPSVUhSerrSZMeQJK0vgy9JDVn6CWpOUMvSc0ZeklqztBLUnPXTOqFr7322tq9e/ekXl6SrkoPPvjgJ6pqaiWPmVjod+/ezezs7KReXpKuSkn+Y6WP8dCNJDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtScxO7eqWkzWP30Xd/1bpH77plApNoPbhHL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnMjhT7J/iSPJDmb5OgS9/9+kocGfz6c5DNjn1SStCrLXtQsyTbgGPASYA44lWSmqs48sU1VvWZo+18AbliHWSWtwmovWLb4cV7k7Oo1yh79jcDZqjpXVY8DJ4CDV9j+VuAd4xhOkrR2o4R+B3B+aHlusO6rJHkWsAd479pHkySNw7g/jD0E3FdVX1rqziSHk8wmmZ2fnx/zS0uSljJK6C8Au4aWdw7WLeUQVzhsU1XHq2q6qqanpqZGn1KStGqjhP4UsDfJniTbWYj5zOKNkjwbeDrwz+MdUZK0FsuGvqouAkeA+4GHgXur6nSSO5McGNr0EHCiqmp9RpUkrcZIvxlbVSeBk4vW3bFo+bfGN5YkaVw8M1aSmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaG+nMWElXj6V+aERbm3v0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKa84QpaQvypKqtxT16SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpuZFCn2R/kkeSnE1y9DLbvDzJmSSnk7x9vGNKklZr2R8eSbINOAa8BJgDTiWZqaozQ9vsBW4HXlBVn07yLes1sLSVLfWDIY/edcsEJtHVZJQ9+huBs1V1rqoeB04ABxdt87PAsar6NEBVPTbeMSVJqzVK6HcA54eW5wbrhn0H8B1J/inJ+5PsX+qJkhxOMptkdn5+fnUTS5JWZFy/GXsNsBd4IbATeF+S51bVZ4Y3qqrjwHGA6enpGtNrS1uav/+q5YyyR38B2DW0vHOwbtgcMFNVX6yqfwc+zEL4JUkTNkroTwF7k+xJsh04BMws2ubPWdibJ8m1LBzKOTe+MSVJq7XsoZuqupjkCHA/sA24p6pOJ7kTmK2qmcF9P5zkDPAl4Jer6pPrObi0FXhYRuMw0jH6qjoJnFy07o6h2wW8dvBHkrSJeGasJDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNTdS6JPsT/JIkrNJji5x/6uSzCd5aPDnZ8Y/qiRpNa5ZboMk24BjwEuAOeBUkpmqOrNo03dW1ZF1mFGStAaj7NHfCJytqnNV9ThwAji4vmNJksZllNDvAM4PLc8N1i32siQfTHJfkl1LPVGSw0lmk8zOz8+vYlxJ0kqN68PYvwR2V9X1wN8Bb11qo6o6XlXTVTU9NTU1ppeWJF3JKKG/AAzvoe8crPt/VfXJqvrCYPFu4HvGM54kaa1GCf0pYG+SPUm2A4eAmeENkjxzaPEA8PD4RpQkrcWy37qpqotJjgD3A9uAe6rqdJI7gdmqmgF+MckB4CLwKeBV6zizJGkFlg09QFWdBE4uWnfH0O3bgdvHO5okaRw8M1aSmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaGyn0SfYneSTJ2SRHr7Ddy5JUkunxjShJWotlQ59kG3AMuBnYB9yaZN8S2z0VuA14YNxDSpJWb5Q9+huBs1V1rqoeB04AB5fY7reB3wE+P8b5JElrNErodwDnh5bnBuv+X5LnAbuq6t1XeqIkh5PMJpmdn59f8bCSpJVb84exSZ4EvAF43XLbVtXxqpququmpqam1vrQkaQTXjLDNBWDX0PLOwbonPBV4DvAPSQC+FZhJcqCqZsc1qNTN7qNf+RfgR++6ZUKTqLtR9uhPAXuT7EmyHTgEzDxxZ1V9tqqurardVbUbeD9g5CVpk1g29FV1ETgC3A88DNxbVaeT3JnkwHoPKElam1EO3VBVJ4GTi9bdcZltX7j2sSRJ4+KZsZLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktTcSGfGSlp/iy9yJo2Le/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnGfGShrJUmfuPnrXLROYRCvlHr0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1JzI4U+yf4kjyQ5m+ToEvf/XJIPJXkoyT8m2Tf+USVJq7Fs6JNsA44BNwP7gFuXCPnbq+q5VfXdwOuBN4x7UEnS6oyyR38jcLaqzlXV48AJ4ODwBlX1uaHFpwA1vhElSWsxyg+P7ADODy3PAd+3eKMkrwZeC2wHXrTUEyU5DBwGuO6661Y6qyRpFcb2YWxVHauqbwd+FfiNy2xzvKqmq2p6ampqXC8tSbqCUUJ/Adg1tLxzsO5yTgAvXcNMkqQxGiX0p4C9SfYk2Q4cAmaGN0iyd2jxFuAj4xtRkrQWyx6jr6qLSY4A9wPbgHuq6nSSO4HZqpoBjiS5Cfgi8Gngles5tCRpdKN8GEtVnQROLlp3x9Dt28Y8lyRpTDwzVpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Nw1kx5A0tVr99F3f8Xyo3fdMqFJdCXu0UtSc4Zekprz0I20ARYf4pA2knv0ktScoZek5gy9JDU3UuiT7E/ySJKzSY4ucf9rk5xJ8sEk70nyrPGPKklajWVDn2QbcAy4GdgH3Jpk36LNPgBMV9X1wH3A68c9qCRpdUbZo78ROFtV56rqceAEcHB4g6r6+6r638Hi+4Gd4x1TkrRao4R+B3B+aHlusO5yfhr467UMJUkan7F+jz7JK4Bp4Icuc/9h4DDAddddN86XliRdxih79BeAXUPLOwfrvkKSm4BfBw5U1ReWeqKqOl5V01U1PTU1tZp5JUkrNEroTwF7k+xJsh04BMwMb5DkBuDNLET+sfGPKUlarWVDX1UXgSPA/cDDwL1VdTrJnUkODDb7XeAbgD9N8lCSmcs8nSRpg410jL6qTgInF627Y+j2TWOeS5I0Jp4ZK0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDXnb8ZKGpvFv4376F23TGgSDXOPXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScPyUoad0s/mlB8OcFJ8E9eklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNTfS1yuT7AfeBGwD7q6quxbd/4PAG4HrgUNVdd+Y55SuKkt9rVCalGX36JNsA44BNwP7gFuT7Fu02UeBVwFvH/eAkqS1GWWP/kbgbFWdA0hyAjgInHlig6p6dHDfl9dhRknSGoxyjH4HcH5oeW6wTpJ0FdjQD2OTHE4ym2R2fn5+I19akrasUUJ/Adg1tLxzsG7Fqup4VU1X1fTU1NRqnkKStEKjhP4UsDfJniTbgUPAzPqOJUkal2VDX1UXgSPA/cDDwL1VdTrJnUkOACT53iRzwI8Db05yej2HliSNbqTv0VfVSeDkonV3DN0+xcIhHUnSJuOZsZLUnD88ImnTWXxmsT9Wsjbu0UtSc4Zekpoz9JLUnKGXpOYMvSQ157duJG0ov1Gz8dyjl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNeVEzaRlehGt9LX5/NX7u0UtSc4Zekpoz9JLUnMfopRXymLKuNu7RS1Jzhl6SmjP0ktScoZek5gy9JDXnt260ZSz1bRnPctVW4B69JDVn6CWpuZFCn2R/kkeSnE1ydIn7vzbJOwf3P5Bk99gnlSStSqrqyhsk24APAy8B5oBTwK1VdWZom58Hrq+qn0tyCPjRqvqJKz3v9PR0zc7OrnV+6bI8g7W35T5f6fqZTJIHq2p6JY8ZZY/+RuBsVZ2rqseBE8DBRdscBN46uH0f8OIkWckgkqT1MUrodwDnh5bnBuuW3KaqLgKfBb55HANKktZmQ79emeQwcHiw+IUk/7qRr7+JXQt8YtJDbBK+F5f4XlzyVe9FfmflT7Kax2xC37nSB4wS+gvArqHlnYN1S20zl+Qa4GnAJxc/UVUdB44DJJld6XGmrnwvLvG9uMT34hLfi0uSrPjDzVEO3ZwC9ibZk2Q7cAiYWbTNDPDKwe0fA95by33KK0naEMvu0VfVxSRHgPuBbcA9VXU6yZ3AbFXNAG8B/jjJWeBTLPzPQJK0CYx0jL6qTgInF627Y+j254EfX+FrH1/h9p35Xlzie3GJ78UlvheXrPi9WPZ79JKkq5uXQJCk5iYS+uUuqbBVJNmV5O+TnElyOsltk55pkpJsS/KBJH816VkmLck3Jrkvyb8leTjJ9096pklI8prBfxv/muQdSb5u0jNtpCT3JHls+KvoSb4pyd8l+cjgn09f7nk2PPSDSyocA24G9gG3Jtm30XNsEheB11XVPuD5wKu38HsBcBvw8KSH2CTeBPxNVT0b+C624PuSZAfwi8B0VT2HhS+DbLUvevwRsH/RuqPAe6pqL/CewfIVTWKPfpRLKmwJVfWxqvqXwe3/ZuE/5sVnHW8JSXYCtwB3T3qWSUvyNOAHWfg2G1X1eFV9ZqJDTc41wNcPzs95MvCfE55nQ1XV+1j4JuOw4UvOvBV46XLPM4nQj3JJhS1ncMXPG4AHJjzKpLwR+BXgyxOeYzPYA8wDfzg4lHV3kqdMeqiNVlUXgN8DPgp8DPhsVf3tZKfaFJ5RVR8b3P448IzlHuCHsZtAkm8A/gz4par63KTn2WhJfgR4rKoenPQsm8Q1wPOAP6iqG4D/YYS/nnczOPZ8kIX/8X0b8JQkr5jsVJvL4MTUZb86OYnQj3JJhS0jydewEPm3VdW7Jj3PhLwAOJDkURYO5b0oyZ9MdqSJmgPmquqJv93dx0L4t5qbgH+vqvmq+iLwLuAHJjzTZvBfSZ4JMPjnY8s9YBKhH+WSClvC4FLObwEerqo3THqeSamq26tqZ1XtZuHfh/dW1Zbdc6uqjwPnkzxx8aoXA2eu8JCuPgo8P8mTB/+tvJgt+KH0EoYvOfNK4C+We8CG/zj45S6psNFzbBIvAH4S+FCShwbrfm1wJrK2tl8A3jbYGToH/NSE59lwVfVAkvuAf2HhG2ofYIudIZvkHcALgWuTzAG/CdwF3Jvkp4H/AF6+7PN4Zqwk9eaHsZLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6Smvs/qOsd6eeW1rIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Podstawowa z dobraną funkcją aktywacji (wczesne zatrzymanie)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Z Batch Normalization i Dropout (1000 epok)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFlCAYAAADlICPeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP2klEQVR4nO3df6zdd13H8eeLlon8ENReCbadd4lFbYhmeDOnS3RxmHTUrCYqrgZFstB/GKIgpqgZZv5T1KCYTLTC+CVumZNoY6vTwAiJEbI7pkg7p00p6y3DFcRpJDAa3/5xz9bDpd099/b0fu/e9/lIlp3zPd97zjsn67Offc/3fG+qCklSX88YegBJ0qVl6CWpOUMvSc0ZeklqztBLUnOGXpKa2zzUC2/ZsqVmZ2eHenlJelq6//77P19VMyv5mcFCPzs7y/z8/FAvL0lPS0k+s9Kf8dCNJDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzS0b+iS3J3k0yacu8HiS/EGS40k+meSl0x9TkrRak6zo3wPseorHrwd2jP7ZB7zj4seSJE3LslevrKqPJpl9il32AO+rqgI+luQFSV5UVY9Ma0hJ0zW7//CTt08e2D3gJFoL0zhGvxU4NXZ/YbTt6yTZl2Q+yfyZM2em8NKSpOWs6YexVXWwquaqam5mZkXXzZckrdI0Qn8a2D52f9tomyRpHZhG6A8BPz86++Zq4DGPz0vS+rHsh7FJ7gCuBbYkWQDeAjwToKr+CDgCvBw4DnwJePWlGlaStHKTnHWzd5nHC3jt1CaSJE2V34yVpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1t3noASSt3uz+w0/ePnlg94CTaD1zRS9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc35G6akp5nx3yolTcIVvSQ1Z+glqTlDL0nNeYxe2uDGj/mfPLB7wEl0qbiil6TmDL0kNWfoJak5j9FLDXncXeMmWtEn2ZXkoSTHk+w/z+OXJ7k3yQNJPpnk5dMfVZK0GsuGPskm4DbgemAnsDfJziW7/QZwV1VdCdwI/OG0B5Ukrc4kK/qrgONVdaKqHgfuBPYs2aeAbxrdfj7w2emNKEm6GJOEfitwauz+wmjbuN8EXplkATgCvO58T5RkX5L5JPNnzpxZxbiSpJWa1lk3e4H3VNU24OXA+5N83XNX1cGqmququZmZmSm9tCTpqUwS+tPA9rH720bbxt0E3AVQVf8IPAvYMo0BJUkXZ5LQ3wfsSHJFkstY/LD10JJ9HgauA0jyPSyG3mMzkrQOLBv6qjoL3AzcAzzI4tk1R5PcmuSG0W5vBF6T5J+BO4BfqKq6VENLkiY30RemquoIix+yjm+7Zez2MeCa6Y4mSZoGL4EgSc15CQSpOS+HIFf0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmvASCpCd5uYSeXNFLUnOGXpKa89CNtIGMH5rRxuGKXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmvM3TElN+NujdCGu6CWpOUMvSc0ZeklqzmP00jo1fsz95IHdA06ipztX9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5rwEgvQ04CWIdTFc0UtSc4Zekpoz9JLUnKGXpOYmCn2SXUkeSnI8yf4L7POKJMeSHE3yZ9MdU5K0WsuedZNkE3Ab8GPAAnBfkkNVdWxsnx3Am4FrquqLSb7tUg0sSVqZSVb0VwHHq+pEVT0O3AnsWbLPa4DbquqLAFX16HTHlCSt1iSh3wqcGru/MNo27sXAi5P8Q5KPJdl1vidKsi/JfJL5M2fOrG5iSdKKTOvD2M3ADuBaYC/wJ0lesHSnqjpYVXNVNTczMzOll5YkPZVJQn8a2D52f9to27gF4FBVfbWqPg38G4vhlyQNbJLQ3wfsSHJFksuAG4FDS/b5SxZX8yTZwuKhnBPTG1OStFrLhr6qzgI3A/cADwJ3VdXRJLcmuWG02z3AF5IcA+4F3lRVX7hUQ0uSJjfRRc2q6ghwZMm2W8ZuF/CG0T+SpHXEb8ZKUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNTXQ9eklrY3b/4aFHUEOu6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4ZekpqbKPRJdiV5KMnxJPufYr+fTFJJ5qY3oiTpYiwb+iSbgNuA64GdwN4kO8+z3/OA1wMfn/aQkqTVm2RFfxVwvKpOVNXjwJ3AnvPs91vAW4EvT3E+SdJF2jzBPluBU2P3F4AfGN8hyUuB7VV1OMmbLvRESfYB+wAuv/zylU8rNTS7//DQI6i5i/4wNskzgLcBb1xu36o6WFVzVTU3MzNzsS8tSZrAJKE/DWwfu79ttO0JzwNeAnwkyUngauCQH8hK0vowyaGb+4AdSa5gMfA3Aj/7xINV9Riw5Yn7ST4C/EpVzU93VElrafyQ0skDuwecRBdr2RV9VZ0FbgbuAR4E7qqqo0luTXLDpR5QknRxJlnRU1VHgCNLtt1ygX2vvfixJEnT4jdjJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1N9EXpiRtbF4O4enNFb0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWpu89ADSBvR7P7DQ4+gDcQVvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKamyj0SXYleSjJ8ST7z/P4G5IcS/LJJB9K8h3TH1WStBrLhj7JJuA24HpgJ7A3yc4luz0AzFXV9wJ3A7897UElSaszyYr+KuB4VZ2oqseBO4E94ztU1b1V9aXR3Y8B26Y7piRptSYJ/Vbg1Nj9hdG2C7kJ+JuLGUqSND1T/VWCSV4JzAE/coHH9wH7AC6//PJpvrSkNTL+axBPHtg94CSa1CQr+tPA9rH720bbvkaSlwG/DtxQVV853xNV1cGqmququZmZmdXMK0laoUlCfx+wI8kVSS4DbgQOje+Q5Ergj1mM/KPTH1OStFrLHrqpqrNJbgbuATYBt1fV0SS3AvNVdQj4HeC5wJ8nAXi4qm64hHNLWmc8pLN+TXSMvqqOAEeWbLtl7PbLpjyXJGlK/GasJDVn6CWpuameXilpYxk/Lq/1yxW9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5L4Egaeq8ZPH64opekpoz9JLUnKGXpOY8Ri+tES/pq6G4opek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc1tHnoASb3N7j/85O2TB3ZfcJsuHVf0ktScoZek5jx0I11i44cppCG4opek5gy9JDVn6CWpuYmO0SfZBbwd2AS8s6oOLHn8G4D3Ad8PfAH4mao6Od1RpeF4OuB0+HnFMJZd0SfZBNwGXA/sBPYm2blkt5uAL1bVdwK/B7x12oNKklZnkkM3VwHHq+pEVT0O3AnsWbLPHuC9o9t3A9clyfTGlCSt1iSh3wqcGru/MNp23n2q6izwGPCt0xhQknRx1vQ8+iT7gH2ju19J8qm1fP11bAvw+aGHWCfW/XuRtTswue7fi2mY8P3cEO/FhL5rpT8wSehPA9vH7m8bbTvfPgtJNgPPZ/FD2a9RVQeBgwBJ5qtqbqUDd+R7cY7vxTm+F+f4XpyTZH6lPzPJoZv7gB1JrkhyGXAjcGjJPoeAV41u/xTw4aqqlQ4jSZq+ZVf0VXU2yc3APSyeXnl7VR1NciswX1WHgHcB709yHPhPFv8ykCStAxMdo6+qI8CRJdtuGbv9ZeCnV/jaB1e4f2e+F+f4Xpzje3GO78U5K34v4hEWSerNSyBIUnODhD7JriQPJTmeZP8QM6wHSbYnuTfJsSRHk7x+6JmGlGRTkgeS/PXQswwtyQuS3J3kX5M8mOQHh55pCEl+efRn41NJ7kjyrKFnWktJbk/y6Pip6Em+JcnfJ/n30b+/ebnnWfPQT3hJhY3iLPDGqtoJXA28dgO/FwCvBx4ceoh14u3A31bVdwPfxwZ8X5JsBX4RmKuql7B4MshGO9HjPcCuJdv2Ax+qqh3Ah0b3n9IQK/pJLqmwIVTVI1X1idHt/2HxD/PSbx1vCEm2AbuBdw49y9CSPB/4YRbPZqOqHq+q/xp0qOFsBr5x9P2cZwOfHXieNVVVH2XxTMZx45eceS/wE8s9zxChn+SSChtOklngSuDjA48ylN8HfhX4v4HnWA+uAM4A7x4dynpnkucMPdRaq6rTwO8CDwOPAI9V1d8NO9W68MKqemR0+3PAC5f7AT+MXQeSPBf4C+CXquq/h55nrSX5ceDRqrp/6FnWic3AS4F3VNWVwP8ywf+edzM69ryHxb/4vh14TpJXDjvV+jL6Yuqyp04OEfpJLqmwYSR5JouR/0BVfXDoeQZyDXBDkpMsHsr70SR/OuxIg1oAFqrqif+7u5vF8G80LwM+XVVnquqrwAeBHxp4pvXgP5K8CGD070eX+4EhQj/JJRU2hNGlnN8FPFhVbxt6nqFU1ZuraltVzbL438OHq2rDrtyq6nPAqSRPXLzqOuDYgCMN5WHg6iTPHv1ZuY4N+KH0eYxfcuZVwF8t9wNrevVKuPAlFdZ6jnXiGuDngH9J8k+jbb82+iayNrbXAR8YLYZOAK8eeJ41V1UfT3I38AkWz1B7gA32DdkkdwDXAluSLABvAQ4AdyW5CfgM8Ipln8dvxkpSb34YK0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpuf8H+0dOB97LRT4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model: Dobrane ręcznie parametry (300 epok)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,6))\n",
        "print(f\"Prawdziwy rozkład\")\n",
        "plt.hist(y_test, bins=30, density=True)\n",
        "plt.show()\n",
        "\n",
        "for name, estimator in models:\n",
        "    print(f\"model: {name}\")\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.xlim((0,10))\n",
        "    plt.hist(estimator.predict(X_test_keras), bins=30, density=True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podobnie jak w przypadku modeli płytkich, modele głębokie przewidują rozkład normalny ocen, natomiast jest on bardziej zbliżony do rozkładu prawdziwego. W szczególności w modelu, z dobranymi ręcznie parametrami można zauważyć wyraźnie więcej punktów o wartości 6 i 7, co pokrywa się z rozkładem prawdziwych wyników i wynika z losowego podziału na zbiór treningowy i testowy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Podsumowanie"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "projetk.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
